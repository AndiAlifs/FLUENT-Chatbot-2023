{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Dec 13 10:44:40 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.141.03   Driver Version: 470.141.03   CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM...  On   | 00000000:47:00.0 Off |                    0 |\n",
      "| N/A   33C    P0    72W / 400W |  38474MiB / 81251MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, GPT2LMHeadModel, GPT2Tokenizer\n",
    "from sklearn.decomposition import PCA\n",
    "from torch import nn\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pertanyaan</th>\n",
       "      <th>Jawaban</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>visi filkom</td>\n",
       "      <td>menjadi fakultas yang berdaya saing internasio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>misi filkom</td>\n",
       "      <td>menyelenggarakan pendidikan di bidang teknolog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>apa tujuan filkom?</td>\n",
       "      <td>menghasilkan lulusan yang kompeten , profesion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sasaran pendidikan filkom</td>\n",
       "      <td>meningkatkan kompetensi dan kualifikasi pendid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>email fitra a. bachtiar</td>\n",
       "      <td>fitra.bachtiar[at]ub.ac.id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bidang penelitian fitra a. bachtiar</td>\n",
       "      <td>affective computing, affective engineering, in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tanggal dibentuk ptiik</td>\n",
       "      <td>27 oktober 2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sasaran pengabdian filkom</td>\n",
       "      <td>1. meningkatkan kualitas dan kuantitas pengabd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sasaran kerjasama filkom</td>\n",
       "      <td>1. mengadakan kerjasama pendidikan, penlitian ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dekan fakultas ilmu komputer filkom</td>\n",
       "      <td>prof. ir. wayan firdaus mahmudy, s.si., mt., p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>wakil dekan bidang akademik / wakil dekan 1</td>\n",
       "      <td>dr. eng. ir. herman tolle, st., mt.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>wakil dekan bidang umum, keuangan, dan sumber ...</td>\n",
       "      <td>agus wahyu widodo, st., m.cs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>wakil dekan bidang kemahasiswaan, alumni, dan ...</td>\n",
       "      <td>drs. muh. arif rahman, m.kom.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ketua departemen teknik informatika</td>\n",
       "      <td>achmad basuki, s.t., m.mg., ph.d.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sekretaris departemen teknik informatika</td>\n",
       "      <td>ir. primantara hari trisnawan, m.sc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ketua program studi magister ilmu komputer</td>\n",
       "      <td>sabriansyah rizqika akbar, s.t., m.eng., ph.d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ketua program studi sarjana teknik informatika</td>\n",
       "      <td>adhitya bhawiyuga, s.kom., m.sc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ketua program studi sarjana teknik komputer</td>\n",
       "      <td>barlian henryranu prasetio, s.t., m.t., ph.d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ketua departemen sistem informasi</td>\n",
       "      <td>issa arwani, s.kom., m.sc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>seketaris departemen sistem informasi</td>\n",
       "      <td>satrio agung wicaksono, s.kom., m.kom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ketua program studi sarjana sistem informasi</td>\n",
       "      <td>yusi tyroni mursityo, s.kom., m.s.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ketua program studi sarjana pendidikan teknolo...</td>\n",
       "      <td>ir. admaja dwi herlambang, s.pd., m.pd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ketua program studi sarjana teknologi informasi</td>\n",
       "      <td>ir. widhy hayuhardhika nugraha putra, s.kom., ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>berikan saya informasi alumni</td>\n",
       "      <td>informasi alumni dapat diakses pada link berik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>apa saja layanan kemahasiswaan filkom ub ?</td>\n",
       "      <td>1. pengajuan proposal dan lpj kegiatan kemahas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>bagaimana pengajuan proposal dan lpj kegiatan ...</td>\n",
       "      <td>pengajuan proposal kegiatan kemahasiswaan\\npen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>berikan informasi dokumen kemahasiswaan ?</td>\n",
       "      <td>informasi dokumen kemahasiswaan dapat dilihat ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>bagaimana pengajuan surat tugas dosen pembimbi...</td>\n",
       "      <td>informasi pengajuan surat tugas dosen pembimbi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>bagaimana permohonan validasi data skm ?</td>\n",
       "      <td>permohonan validasi data skm dapat dilihat pad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>berikan informasi mengenai validasi syarat wisuda</td>\n",
       "      <td>1. unggah dokumen di siam\\n2. mengisi gform pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>bagaimana mengakses tracer study fakultas ?</td>\n",
       "      <td>tracer study fakultas dapat diakses pada tauta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>bagaimana cara pendaftaran wisuda ulang ?</td>\n",
       "      <td>pendaftaran wisuda ulang dapat diakses pada ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>berikan informasi mengenai layanan bimbingan d...</td>\n",
       "      <td>layanan bimbingan dan konseling dapat diaksesp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>berikan informasi mengenai layanan ultksp (uni...</td>\n",
       "      <td>layanan ultksp dapat diaksespada tautan beriku...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>berikan informasi mengenai tracking layanan ke...</td>\n",
       "      <td>tracking layanan kemahasiswaan dapat diaksespa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>berikan informasi mengenai bimbingan dan konse...</td>\n",
       "      <td>dalam perjalanannya menuntut ilmu, mahasiswa t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>apa tujuan unit konseling ?</td>\n",
       "      <td>1. mewujudkan potensi dirinya secara optimal, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>apa fungsi bimbingan dan konseling serta penas...</td>\n",
       "      <td>1. penyaluran: bimbingan berfungsi dalam memba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>apa saja program layanan unit konseling ?</td>\n",
       "      <td>1. pelayanan bantuan pemecahan masalah, baik y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>apa manfaat konseling filkom ?</td>\n",
       "      <td>1. masalah ditangani oleh ahli yang kompeten d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>berikan informasi mengenai layanan konseling</td>\n",
       "      <td>informasi mengenai layanan konseling dapat dia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>siapa konselor bimbingan dan konseling di filk...</td>\n",
       "      <td>ada 2 konselor bimbingan dan konseling di filk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>siapa koordinator konselor sebaya ?</td>\n",
       "      <td>koordinator konselor sebaya adalah muhammad da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>berikan rincian layanan ultksp</td>\n",
       "      <td>rincian layanan ultksp dapat diakses pada taut...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Pertanyaan  \\\n",
       "0                                         visi filkom   \n",
       "1                                         misi filkom   \n",
       "2                                  apa tujuan filkom?   \n",
       "3                           sasaran pendidikan filkom   \n",
       "4                             email fitra a. bachtiar   \n",
       "5                 bidang penelitian fitra a. bachtiar   \n",
       "6                              tanggal dibentuk ptiik   \n",
       "7                           sasaran pengabdian filkom   \n",
       "8                            sasaran kerjasama filkom   \n",
       "9                 dekan fakultas ilmu komputer filkom   \n",
       "10        wakil dekan bidang akademik / wakil dekan 1   \n",
       "11  wakil dekan bidang umum, keuangan, dan sumber ...   \n",
       "12  wakil dekan bidang kemahasiswaan, alumni, dan ...   \n",
       "13                ketua departemen teknik informatika   \n",
       "14           sekretaris departemen teknik informatika   \n",
       "15         ketua program studi magister ilmu komputer   \n",
       "16     ketua program studi sarjana teknik informatika   \n",
       "17        ketua program studi sarjana teknik komputer   \n",
       "18                  ketua departemen sistem informasi   \n",
       "19              seketaris departemen sistem informasi   \n",
       "20       ketua program studi sarjana sistem informasi   \n",
       "21  ketua program studi sarjana pendidikan teknolo...   \n",
       "22    ketua program studi sarjana teknologi informasi   \n",
       "23                      berikan saya informasi alumni   \n",
       "24         apa saja layanan kemahasiswaan filkom ub ?   \n",
       "25  bagaimana pengajuan proposal dan lpj kegiatan ...   \n",
       "26          berikan informasi dokumen kemahasiswaan ?   \n",
       "27  bagaimana pengajuan surat tugas dosen pembimbi...   \n",
       "28           bagaimana permohonan validasi data skm ?   \n",
       "29  berikan informasi mengenai validasi syarat wisuda   \n",
       "30        bagaimana mengakses tracer study fakultas ?   \n",
       "31          bagaimana cara pendaftaran wisuda ulang ?   \n",
       "32  berikan informasi mengenai layanan bimbingan d...   \n",
       "33  berikan informasi mengenai layanan ultksp (uni...   \n",
       "34  berikan informasi mengenai tracking layanan ke...   \n",
       "35  berikan informasi mengenai bimbingan dan konse...   \n",
       "36                        apa tujuan unit konseling ?   \n",
       "37  apa fungsi bimbingan dan konseling serta penas...   \n",
       "38          apa saja program layanan unit konseling ?   \n",
       "39                     apa manfaat konseling filkom ?   \n",
       "40       berikan informasi mengenai layanan konseling   \n",
       "41  siapa konselor bimbingan dan konseling di filk...   \n",
       "42                siapa koordinator konselor sebaya ?   \n",
       "43                     berikan rincian layanan ultksp   \n",
       "\n",
       "                                              Jawaban  \n",
       "0   menjadi fakultas yang berdaya saing internasio...  \n",
       "1   menyelenggarakan pendidikan di bidang teknolog...  \n",
       "2   menghasilkan lulusan yang kompeten , profesion...  \n",
       "3   meningkatkan kompetensi dan kualifikasi pendid...  \n",
       "4                          fitra.bachtiar[at]ub.ac.id  \n",
       "5   affective computing, affective engineering, in...  \n",
       "6                                     27 oktober 2011  \n",
       "7   1. meningkatkan kualitas dan kuantitas pengabd...  \n",
       "8   1. mengadakan kerjasama pendidikan, penlitian ...  \n",
       "9   prof. ir. wayan firdaus mahmudy, s.si., mt., p...  \n",
       "10                dr. eng. ir. herman tolle, st., mt.  \n",
       "11                      agus wahyu widodo, st., m.cs.  \n",
       "12                      drs. muh. arif rahman, m.kom.  \n",
       "13                  achmad basuki, s.t., m.mg., ph.d.  \n",
       "14               ir. primantara hari trisnawan, m.sc.  \n",
       "15      sabriansyah rizqika akbar, s.t., m.eng., ph.d  \n",
       "16                   adhitya bhawiyuga, s.kom., m.sc.  \n",
       "17       barlian henryranu prasetio, s.t., m.t., ph.d  \n",
       "18                         issa arwani, s.kom., m.sc.  \n",
       "19              satrio agung wicaksono, s.kom., m.kom  \n",
       "20                 yusi tyroni mursityo, s.kom., m.s.  \n",
       "21            ir. admaja dwi herlambang, s.pd., m.pd.  \n",
       "22  ir. widhy hayuhardhika nugraha putra, s.kom., ...  \n",
       "23  informasi alumni dapat diakses pada link berik...  \n",
       "24  1. pengajuan proposal dan lpj kegiatan kemahas...  \n",
       "25  pengajuan proposal kegiatan kemahasiswaan\\npen...  \n",
       "26  informasi dokumen kemahasiswaan dapat dilihat ...  \n",
       "27  informasi pengajuan surat tugas dosen pembimbi...  \n",
       "28  permohonan validasi data skm dapat dilihat pad...  \n",
       "29  1. unggah dokumen di siam\\n2. mengisi gform pe...  \n",
       "30  tracer study fakultas dapat diakses pada tauta...  \n",
       "31  pendaftaran wisuda ulang dapat diakses pada ta...  \n",
       "32  layanan bimbingan dan konseling dapat diaksesp...  \n",
       "33  layanan ultksp dapat diaksespada tautan beriku...  \n",
       "34  tracking layanan kemahasiswaan dapat diaksespa...  \n",
       "35  dalam perjalanannya menuntut ilmu, mahasiswa t...  \n",
       "36  1. mewujudkan potensi dirinya secara optimal, ...  \n",
       "37  1. penyaluran: bimbingan berfungsi dalam memba...  \n",
       "38  1. pelayanan bantuan pemecahan masalah, baik y...  \n",
       "39  1. masalah ditangani oleh ahli yang kompeten d...  \n",
       "40  informasi mengenai layanan konseling dapat dia...  \n",
       "41  ada 2 konselor bimbingan dan konseling di filk...  \n",
       "42  koordinator konselor sebaya adalah muhammad da...  \n",
       "43  rincian layanan ultksp dapat diakses pada taut...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# knowledgebase_url = 'https://github.com/AndiAlifs/FLUENT-Chatbot-2023/raw/main/KnowledgeBaseFilkom.xlsx'\n",
    "knowledgebase_url = 'https://github.com/AndiAlifs/FLUENT-Chatbot-2023/raw/main/KnowledgeBaseFilkom_simple.xlsx'\n",
    "knowledgebase = pd.read_excel(knowledgebase_url)\n",
    "\n",
    "qa_paired = knowledgebase.drop(columns=knowledgebase.columns.drop(['Pertanyaan', 'Jawaban']))\n",
    "qa_paired.dropna(inplace=True)\n",
    "qa_paired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pertanyaan</th>\n",
       "      <th>Jawaban</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apa visi fakultas</td>\n",
       "      <td>menjadi fakultas yang berdaya saing internasio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>visi dari filkom</td>\n",
       "      <td>menjadi fakultas yang berdaya saing internasio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>apa saja visi filkom</td>\n",
       "      <td>menjadi fakultas yang berdaya saing internasio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>apa misi fakultas</td>\n",
       "      <td>menyelenggarakan pendidikan di bidang teknolog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>apa saja misi flkom</td>\n",
       "      <td>menyelenggarakan pendidikan di bidang teknolog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>dapatkah anda memberi tahu siapa konselor bimb...</td>\n",
       "      <td>ada 2 konselor bimbingan dan konseling di filk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>siapa yang menjadi koordinator konselor sebaya?</td>\n",
       "      <td>koordinator konselor sebaya adalah muhammad da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>siapa koordinator untuk konselor sebaya?</td>\n",
       "      <td>koordinator konselor sebaya adalah muhammad da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>mohon rincian mengenai layanan ultksp.</td>\n",
       "      <td>rincian layanan ultksp dapat diakses pada taut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>berikan rincian layanan ultksp</td>\n",
       "      <td>rincian layanan ultksp dapat diakses pada taut...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Pertanyaan  \\\n",
       "0                                   apa visi fakultas   \n",
       "1                                    visi dari filkom   \n",
       "2                                apa saja visi filkom   \n",
       "3                                   apa misi fakultas   \n",
       "4                                 apa saja misi flkom   \n",
       "..                                                ...   \n",
       "86  dapatkah anda memberi tahu siapa konselor bimb...   \n",
       "87    siapa yang menjadi koordinator konselor sebaya?   \n",
       "88           siapa koordinator untuk konselor sebaya?   \n",
       "89             mohon rincian mengenai layanan ultksp.   \n",
       "90                     berikan rincian layanan ultksp   \n",
       "\n",
       "                                              Jawaban  \n",
       "0   menjadi fakultas yang berdaya saing internasio...  \n",
       "1   menjadi fakultas yang berdaya saing internasio...  \n",
       "2   menjadi fakultas yang berdaya saing internasio...  \n",
       "3   menyelenggarakan pendidikan di bidang teknolog...  \n",
       "4   menyelenggarakan pendidikan di bidang teknolog...  \n",
       "..                                                ...  \n",
       "86  ada 2 konselor bimbingan dan konseling di filk...  \n",
       "87  koordinator konselor sebaya adalah muhammad da...  \n",
       "88  koordinator konselor sebaya adalah muhammad da...  \n",
       "89  rincian layanan ultksp dapat diakses pada taut...  \n",
       "90  rincian layanan ultksp dapat diakses pada taut...  \n",
       "\n",
       "[91 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knowledgebase_eval_url = 'https://github.com/AndiAlifs/FLUENT-Chatbot-2023/raw/main/KnowledgeBaseFilkom_eval.xlsx'\n",
    "knowledgebase_eval = pd.read_excel(knowledgebase_eval_url)\n",
    "\n",
    "qa_paired_eval = knowledgebase_eval.drop(columns=knowledgebase_eval.columns.drop(['Pertanyaan', 'Jawaban']))\n",
    "qa_paired_eval.dropna(inplace=True)\n",
    "qa_paired_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.014760971069335938,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "tokenizer_config.json",
       "rate": null,
       "total": 2,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4d556e25973494fbc48ca586a0f9748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.015265703201293945,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "config.json",
       "rate": null,
       "total": 1534,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d110ab92c33a4ddab9d7d7998a5f3240",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.016209125518798828,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "vocab.txt",
       "rate": null,
       "total": 229167,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c3c644d02da440f834e358e1c4b92c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/229k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.014745473861694336,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "special_tokens_map.json",
       "rate": null,
       "total": 112,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe5f9c9bf3d745bb838f34321d00903e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.014751672744750977,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "pytorch_model.bin",
       "rate": null,
       "total": 497810400,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b6901c84a234099bb0197ad91f54ace",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/498M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "enc_tokenizer = AutoTokenizer.from_pretrained('indobenchmark/indobert-base-p1')\n",
    "enc_model = AutoModel.from_pretrained('indobenchmark/indobert-base-p1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 = [CLS]\n",
      "387 = apa\n",
      "377 = saja\n",
      "5186 = visi\n",
      "4510 = misi\n",
      "769 = fil\n",
      "3498 = ##kom\n",
      "3 = [SEP]\n"
     ]
    }
   ],
   "source": [
    "tes_kalimat = \"apa saja visi misi filkom\"\n",
    "enc_input = enc_tokenizer(tes_kalimat, return_tensors='pt', padding=True, truncation=True)\n",
    "for id in enc_input.input_ids[0]:\n",
    "    print(f'{id} = {enc_tokenizer.decode(id)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50266, 1024)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_name_dec = 'flax-community/gpt2-medium-indonesian'\n",
    "model_name_dec = 'indonesian-nlp/gpt2-medium-indonesian'\n",
    "\n",
    "dec_model = GPT2LMHeadModel.from_pretrained(model_name_dec)\n",
    "dec_tokenizer = GPT2Tokenizer.from_pretrained(model_name_dec)\n",
    "\n",
    "dec_tokenizer.add_tokens(['[PRE1]'])\n",
    "dec_tokenizer.add_tokens(['[PRE2]'])\n",
    "dec_tokenizer.add_tokens(['[PRE3]'])\n",
    "dec_tokenizer.add_tokens(['[PRE4]'])\n",
    "dec_tokenizer.add_tokens(['[PRE5]'])\n",
    "\n",
    "dec_tokenizer.add_special_tokens({'pad_token': '[PAD]',\n",
    "                                    'bos_token': '[BOS]',\n",
    "                                    'eos_token': '[EOS]',\n",
    "                                    'sep_token': '[SEP]',})\n",
    "\n",
    "# Add a new token to the tokenizer\n",
    "dec_model.config.pad_token_id = dec_tokenizer.pad_token_id\n",
    "dec_model.config.bos_token_id = dec_tokenizer.bos_token_id\n",
    "dec_model.config.eos_token_id = dec_tokenizer.eos_token_id\n",
    "dec_model.config.sep_token_id = dec_tokenizer.sep_token_id\n",
    "\n",
    "dec_model.resize_token_embeddings(len(dec_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "enc_model = enc_model.to(device)\n",
    "dec_model = dec_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pertanyaan</th>\n",
       "      <th>Jawaban</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>visi filkom</td>\n",
       "      <td>[BOS]menjadi fakultas yang berdaya saing inter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>misi filkom</td>\n",
       "      <td>[BOS]menyelenggarakan pendidikan di bidang tek...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>apa tujuan filkom?</td>\n",
       "      <td>[BOS]menghasilkan lulusan yang kompeten , prof...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sasaran pendidikan filkom</td>\n",
       "      <td>[BOS]meningkatkan kompetensi dan kualifikasi p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>email fitra a. bachtiar</td>\n",
       "      <td>[BOS] fitra.bachtiar[at]ub.ac.id[EOS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bidang penelitian fitra a. bachtiar</td>\n",
       "      <td>[BOS]affective computing, affective engineerin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tanggal dibentuk ptiik</td>\n",
       "      <td>[BOS]27 oktober 2011[EOS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sasaran pengabdian filkom</td>\n",
       "      <td>[BOS]1. meningkatkan kualitas dan kuantitas pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sasaran kerjasama filkom</td>\n",
       "      <td>[BOS]1. mengadakan kerjasama pendidikan, penli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dekan fakultas ilmu komputer filkom</td>\n",
       "      <td>[BOS]prof. ir. wayan firdaus mahmudy, s.si., m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>wakil dekan bidang akademik / wakil dekan 1</td>\n",
       "      <td>[BOS]dr. eng. ir. herman tolle, st., mt.[EOS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>wakil dekan bidang umum, keuangan, dan sumber ...</td>\n",
       "      <td>[BOS]agus wahyu widodo, st., m.cs.[EOS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>wakil dekan bidang kemahasiswaan, alumni, dan ...</td>\n",
       "      <td>[BOS]drs. muh. arif rahman, m.kom.[EOS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ketua departemen teknik informatika</td>\n",
       "      <td>[BOS]achmad basuki, s.t., m.mg., ph.d.[EOS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sekretaris departemen teknik informatika</td>\n",
       "      <td>[BOS]ir. primantara hari trisnawan, m.sc.[EOS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ketua program studi magister ilmu komputer</td>\n",
       "      <td>[BOS]sabriansyah rizqika akbar, s.t., m.eng., ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ketua program studi sarjana teknik informatika</td>\n",
       "      <td>[BOS]adhitya bhawiyuga, s.kom., m.sc.[EOS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ketua program studi sarjana teknik komputer</td>\n",
       "      <td>[BOS]barlian henryranu prasetio, s.t., m.t., p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ketua departemen sistem informasi</td>\n",
       "      <td>[BOS]issa arwani, s.kom., m.sc.[EOS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>seketaris departemen sistem informasi</td>\n",
       "      <td>[BOS]satrio agung wicaksono, s.kom., m.kom[EOS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ketua program studi sarjana sistem informasi</td>\n",
       "      <td>[BOS]yusi tyroni mursityo, s.kom., m.s.[EOS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ketua program studi sarjana pendidikan teknolo...</td>\n",
       "      <td>[BOS]ir. admaja dwi herlambang, s.pd., m.pd.[EOS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ketua program studi sarjana teknologi informasi</td>\n",
       "      <td>[BOS]ir. widhy hayuhardhika nugraha putra, s.k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>berikan saya informasi alumni</td>\n",
       "      <td>[BOS]informasi alumni dapat diakses pada link ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>apa saja layanan kemahasiswaan filkom ub ?</td>\n",
       "      <td>[BOS]1. pengajuan proposal dan lpj kegiatan ke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>bagaimana pengajuan proposal dan lpj kegiatan ...</td>\n",
       "      <td>[BOS]pengajuan proposal kegiatan kemahasiswaan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>berikan informasi dokumen kemahasiswaan ?</td>\n",
       "      <td>[BOS]informasi dokumen kemahasiswaan dapat dil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>bagaimana pengajuan surat tugas dosen pembimbi...</td>\n",
       "      <td>[BOS]informasi pengajuan surat tugas dosen pem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>bagaimana permohonan validasi data skm ?</td>\n",
       "      <td>[BOS]permohonan validasi data skm dapat diliha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>berikan informasi mengenai validasi syarat wisuda</td>\n",
       "      <td>[BOS]1. unggah dokumen di siam\\n2. mengisi gfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>bagaimana mengakses tracer study fakultas ?</td>\n",
       "      <td>[BOS]tracer study fakultas dapat diakses pada ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>bagaimana cara pendaftaran wisuda ulang ?</td>\n",
       "      <td>[BOS]pendaftaran wisuda ulang dapat diakses pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>berikan informasi mengenai layanan bimbingan d...</td>\n",
       "      <td>[BOS]layanan bimbingan dan konseling dapat dia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>berikan informasi mengenai layanan ultksp (uni...</td>\n",
       "      <td>[BOS]layanan ultksp dapat diaksespada tautan b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>berikan informasi mengenai tracking layanan ke...</td>\n",
       "      <td>[BOS]tracking layanan kemahasiswaan dapat diak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>berikan informasi mengenai bimbingan dan konse...</td>\n",
       "      <td>[BOS]dalam perjalanannya menuntut ilmu, mahasi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>apa tujuan unit konseling ?</td>\n",
       "      <td>[BOS]1. mewujudkan potensi dirinya secara opti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>apa fungsi bimbingan dan konseling serta penas...</td>\n",
       "      <td>[BOS]1. penyaluran: bimbingan berfungsi dalam ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>apa saja program layanan unit konseling ?</td>\n",
       "      <td>[BOS]1. pelayanan bantuan pemecahan masalah, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>apa manfaat konseling filkom ?</td>\n",
       "      <td>[BOS]1. masalah ditangani oleh ahli yang kompe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>berikan informasi mengenai layanan konseling</td>\n",
       "      <td>[BOS]informasi mengenai layanan konseling dapa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>siapa konselor bimbingan dan konseling di filk...</td>\n",
       "      <td>[BOS]ada 2 konselor bimbingan dan konseling di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>siapa koordinator konselor sebaya ?</td>\n",
       "      <td>[BOS]koordinator konselor sebaya adalah muhamm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>berikan rincian layanan ultksp</td>\n",
       "      <td>[BOS]rincian layanan ultksp dapat diakses pada...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Pertanyaan  \\\n",
       "0                                         visi filkom   \n",
       "1                                         misi filkom   \n",
       "2                                  apa tujuan filkom?   \n",
       "3                           sasaran pendidikan filkom   \n",
       "4                             email fitra a. bachtiar   \n",
       "5                 bidang penelitian fitra a. bachtiar   \n",
       "6                              tanggal dibentuk ptiik   \n",
       "7                           sasaran pengabdian filkom   \n",
       "8                            sasaran kerjasama filkom   \n",
       "9                 dekan fakultas ilmu komputer filkom   \n",
       "10        wakil dekan bidang akademik / wakil dekan 1   \n",
       "11  wakil dekan bidang umum, keuangan, dan sumber ...   \n",
       "12  wakil dekan bidang kemahasiswaan, alumni, dan ...   \n",
       "13                ketua departemen teknik informatika   \n",
       "14           sekretaris departemen teknik informatika   \n",
       "15         ketua program studi magister ilmu komputer   \n",
       "16     ketua program studi sarjana teknik informatika   \n",
       "17        ketua program studi sarjana teknik komputer   \n",
       "18                  ketua departemen sistem informasi   \n",
       "19              seketaris departemen sistem informasi   \n",
       "20       ketua program studi sarjana sistem informasi   \n",
       "21  ketua program studi sarjana pendidikan teknolo...   \n",
       "22    ketua program studi sarjana teknologi informasi   \n",
       "23                      berikan saya informasi alumni   \n",
       "24         apa saja layanan kemahasiswaan filkom ub ?   \n",
       "25  bagaimana pengajuan proposal dan lpj kegiatan ...   \n",
       "26          berikan informasi dokumen kemahasiswaan ?   \n",
       "27  bagaimana pengajuan surat tugas dosen pembimbi...   \n",
       "28           bagaimana permohonan validasi data skm ?   \n",
       "29  berikan informasi mengenai validasi syarat wisuda   \n",
       "30        bagaimana mengakses tracer study fakultas ?   \n",
       "31          bagaimana cara pendaftaran wisuda ulang ?   \n",
       "32  berikan informasi mengenai layanan bimbingan d...   \n",
       "33  berikan informasi mengenai layanan ultksp (uni...   \n",
       "34  berikan informasi mengenai tracking layanan ke...   \n",
       "35  berikan informasi mengenai bimbingan dan konse...   \n",
       "36                        apa tujuan unit konseling ?   \n",
       "37  apa fungsi bimbingan dan konseling serta penas...   \n",
       "38          apa saja program layanan unit konseling ?   \n",
       "39                     apa manfaat konseling filkom ?   \n",
       "40       berikan informasi mengenai layanan konseling   \n",
       "41  siapa konselor bimbingan dan konseling di filk...   \n",
       "42                siapa koordinator konselor sebaya ?   \n",
       "43                     berikan rincian layanan ultksp   \n",
       "\n",
       "                                              Jawaban  \n",
       "0   [BOS]menjadi fakultas yang berdaya saing inter...  \n",
       "1   [BOS]menyelenggarakan pendidikan di bidang tek...  \n",
       "2   [BOS]menghasilkan lulusan yang kompeten , prof...  \n",
       "3   [BOS]meningkatkan kompetensi dan kualifikasi p...  \n",
       "4               [BOS] fitra.bachtiar[at]ub.ac.id[EOS]  \n",
       "5   [BOS]affective computing, affective engineerin...  \n",
       "6                           [BOS]27 oktober 2011[EOS]  \n",
       "7   [BOS]1. meningkatkan kualitas dan kuantitas pe...  \n",
       "8   [BOS]1. mengadakan kerjasama pendidikan, penli...  \n",
       "9   [BOS]prof. ir. wayan firdaus mahmudy, s.si., m...  \n",
       "10      [BOS]dr. eng. ir. herman tolle, st., mt.[EOS]  \n",
       "11            [BOS]agus wahyu widodo, st., m.cs.[EOS]  \n",
       "12            [BOS]drs. muh. arif rahman, m.kom.[EOS]  \n",
       "13        [BOS]achmad basuki, s.t., m.mg., ph.d.[EOS]  \n",
       "14     [BOS]ir. primantara hari trisnawan, m.sc.[EOS]  \n",
       "15  [BOS]sabriansyah rizqika akbar, s.t., m.eng., ...  \n",
       "16         [BOS]adhitya bhawiyuga, s.kom., m.sc.[EOS]  \n",
       "17  [BOS]barlian henryranu prasetio, s.t., m.t., p...  \n",
       "18               [BOS]issa arwani, s.kom., m.sc.[EOS]  \n",
       "19    [BOS]satrio agung wicaksono, s.kom., m.kom[EOS]  \n",
       "20       [BOS]yusi tyroni mursityo, s.kom., m.s.[EOS]  \n",
       "21  [BOS]ir. admaja dwi herlambang, s.pd., m.pd.[EOS]  \n",
       "22  [BOS]ir. widhy hayuhardhika nugraha putra, s.k...  \n",
       "23  [BOS]informasi alumni dapat diakses pada link ...  \n",
       "24  [BOS]1. pengajuan proposal dan lpj kegiatan ke...  \n",
       "25  [BOS]pengajuan proposal kegiatan kemahasiswaan...  \n",
       "26  [BOS]informasi dokumen kemahasiswaan dapat dil...  \n",
       "27  [BOS]informasi pengajuan surat tugas dosen pem...  \n",
       "28  [BOS]permohonan validasi data skm dapat diliha...  \n",
       "29  [BOS]1. unggah dokumen di siam\\n2. mengisi gfo...  \n",
       "30  [BOS]tracer study fakultas dapat diakses pada ...  \n",
       "31  [BOS]pendaftaran wisuda ulang dapat diakses pa...  \n",
       "32  [BOS]layanan bimbingan dan konseling dapat dia...  \n",
       "33  [BOS]layanan ultksp dapat diaksespada tautan b...  \n",
       "34  [BOS]tracking layanan kemahasiswaan dapat diak...  \n",
       "35  [BOS]dalam perjalanannya menuntut ilmu, mahasi...  \n",
       "36  [BOS]1. mewujudkan potensi dirinya secara opti...  \n",
       "37  [BOS]1. penyaluran: bimbingan berfungsi dalam ...  \n",
       "38  [BOS]1. pelayanan bantuan pemecahan masalah, b...  \n",
       "39  [BOS]1. masalah ditangani oleh ahli yang kompe...  \n",
       "40  [BOS]informasi mengenai layanan konseling dapa...  \n",
       "41  [BOS]ada 2 konselor bimbingan dan konseling di...  \n",
       "42  [BOS]koordinator konselor sebaya adalah muhamm...  \n",
       "43  [BOS]rincian layanan ultksp dapat diakses pada...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_paired_test = qa_paired\n",
    "qa_paired_test = qa_paired_test.applymap(lambda x: x.lower() if isinstance(x, str) else x)\n",
    "qa_paired_test['Jawaban'] = qa_paired_test['Jawaban'].apply(lambda x: '[BOS]' + x + '[EOS]')\n",
    "qa_paired_test = qa_paired_test.reset_index(drop=True)\n",
    "qa_paired_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FLUENTSOTA(nn.Module):\n",
    "    def __init__(self, enc_model, dec_model, enc_tokenizer, dec_tokenizer, max_length=200):\n",
    "        super(FLUENTSOTA, self).__init__()\n",
    "        self.enc_model = enc_model\n",
    "        self.dec_model = dec_model\n",
    "        self.enc_tokenizer = enc_tokenizer\n",
    "        self.dec_tokenizer = dec_tokenizer\n",
    "        self.enc_mapper = nn.Linear(768, 1024)\n",
    "        self.enc_mapper2 = nn.Linear(1024, 1024)\n",
    "        self.prefix_nn = nn.Linear(1024, 1024)\n",
    "        self.prefix_nn2 = nn.Linear(1024, 1024)\n",
    "        self.prefix_nn3 = nn.Linear(1024, 1024)\n",
    "        self.prefix_nn4 = nn.Linear(1024, 1024)\n",
    "        self.prefix_nn5 = nn.Linear(1024, 1024)\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def encoding(self, sentence):\n",
    "        tokens = self.enc_tokenizer(sentence, return_tensors='pt', padding=True, truncation=True, max_length=self.max_length)\n",
    "        tokens = tokens.to(device)\n",
    "        with torch.no_grad():\n",
    "            output = self.enc_model(**tokens)\n",
    "        enc_logits = output.last_hidden_state.mean(dim=1)\n",
    "        enc_logits = self.enc_mapper(enc_logits).to(device)\n",
    "        enc_logits = self.enc_mapper2(enc_logits).to(device)\n",
    "        return enc_logits\n",
    "\n",
    "    def get_embedding(self, sentence):\n",
    "        tokens = self.dec_tokenizer(sentence, return_tensors='pt', padding=True, truncation=True, max_length=self.max_length)\n",
    "        tokens = tokens.to(device)\n",
    "        wte = self.dec_model.get_input_embeddings()\n",
    "        return wte(tokens['input_ids'])\n",
    "\n",
    "    def dec_tokenizer(self, sentence):\n",
    "        tokens = self.dec_tokenizer(sentence, return_tensors='pt', padding=True, truncation=True, max_length=self.max_length)\n",
    "        return tokens\n",
    "\n",
    "    def add_prefix(self, enc_logits):\n",
    "        prefix_1 = self.prefix_nn(enc_logits)\n",
    "        prefix_2 = self.prefix_nn2(enc_logits)\n",
    "        prefix_3 = self.prefix_nn3(enc_logits)\n",
    "        prefix_4 = self.prefix_nn4(enc_logits)\n",
    "        prefix_5 = self.prefix_nn5(enc_logits)\n",
    "\n",
    "        prefixs = torch.stack((prefix_1, prefix_2, prefix_3, prefix_4, prefix_5), dim=1)\n",
    "        return prefixs\n",
    "\n",
    "    def decoding_train(self, enc_logits, target, target_with_pre):\n",
    "        prefixs = self.add_prefix(enc_logits)\n",
    "        embed = self.get_embedding(target)\n",
    "        pref_with_embed = torch.cat((prefixs, embed), dim=1)\n",
    "        output = self.dec_model(inputs_embeds=pref_with_embed, labels=target_with_pre)\n",
    "        return output\n",
    "\n",
    "    def generate(self, quest):\n",
    "        enc_logits = self.encoding(quest)\n",
    "        prefix_se = '[BOS]'\n",
    "        prefix_dec_embed = self.get_embedding(prefix_se)\n",
    "        prefixs = self.add_prefix(enc_logits)\n",
    "        \n",
    "        pref_with_embed = torch.cat((prefixs, prefix_dec_embed), dim=1)\n",
    "\n",
    "        output = self.dec_model.generate(   inputs_embeds=pref_with_embed, \n",
    "                                            max_length=self.max_length, \n",
    "                                            pad_token_id=self.dec_model.config.eos_token_id)\n",
    "        returned_output = []\n",
    "        for i in range(len(output[0])):\n",
    "            if output[0][i] != self.dec_model.config.eos_token_id:\n",
    "                returned_output.append(output[0][i])\n",
    "            else:\n",
    "                break\n",
    "        return torch.tensor(returned_output).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in enc_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in dec_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in dec_model.transformer.h[:-15].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in enc_model.encoder.layer[:-15].parameters():\n",
    "    param.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FLUENTSOTA(\n",
       "  (enc_model): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(50000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dec_model): GPT2LMHeadModel(\n",
       "    (transformer): GPT2Model(\n",
       "      (wte): Embedding(50266, 1024)\n",
       "      (wpe): Embedding(1024, 1024)\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "      (h): ModuleList(\n",
       "        (0): GPT2Block(\n",
       "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): GPT2Attention(\n",
       "            (c_attn): Conv1D(nf=3072, nx=1024)\n",
       "            (c_proj): Conv1D(nf=1024, nx=1024)\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): GPT2MLP(\n",
       "            (c_fc): Conv1D(nf=4096, nx=1024)\n",
       "            (c_proj): Conv1D(nf=1024, nx=4096)\n",
       "            (act): NewGELUActivation()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): GPT2Block(\n",
       "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): GPT2Attention(\n",
       "            (c_attn): Conv1D(nf=3072, nx=1024)\n",
       "            (c_proj): Conv1D(nf=1024, nx=1024)\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): GPT2MLP(\n",
       "            (c_fc): Conv1D(nf=4096, nx=1024)\n",
       "            (c_proj): Conv1D(nf=1024, nx=4096)\n",
       "            (act): NewGELUActivation()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): GPT2Block(\n",
       "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): GPT2Attention(\n",
       "            (c_attn): Conv1D(nf=3072, nx=1024)\n",
       "            (c_proj): Conv1D(nf=1024, nx=1024)\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): GPT2MLP(\n",
       "            (c_fc): Conv1D(nf=4096, nx=1024)\n",
       "            (c_proj): Conv1D(nf=1024, nx=4096)\n",
       "            (act): NewGELUActivation()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): GPT2Block(\n",
       "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): GPT2Attention(\n",
       "            (c_attn): Conv1D(nf=3072, nx=1024)\n",
       "            (c_proj): Conv1D(nf=1024, nx=1024)\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): GPT2MLP(\n",
       "            (c_fc): Conv1D(nf=4096, nx=1024)\n",
       "            (c_proj): Conv1D(nf=1024, nx=4096)\n",
       "            (act): NewGELUActivation()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): GPT2Block(\n",
       "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): GPT2Attention(\n",
       "            (c_attn): Conv1D(nf=3072, nx=1024)\n",
       "            (c_proj): Conv1D(nf=1024, nx=1024)\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): GPT2MLP(\n",
       "            (c_fc): Conv1D(nf=4096, nx=1024)\n",
       "            (c_proj): Conv1D(nf=1024, nx=4096)\n",
       "            (act): NewGELUActivation()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): GPT2Block(\n",
       "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): GPT2Attention(\n",
       "            (c_attn): Conv1D(nf=3072, nx=1024)\n",
       "            (c_proj): Conv1D(nf=1024, nx=1024)\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): GPT2MLP(\n",
       "            (c_fc): Conv1D(nf=4096, nx=1024)\n",
       "            (c_proj): Conv1D(nf=1024, nx=4096)\n",
       "            (act): NewGELUActivation()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): GPT2Block(\n",
       "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): GPT2Attention(\n",
       "            (c_attn): Conv1D(nf=3072, nx=1024)\n",
       "            (c_proj): Conv1D(nf=1024, nx=1024)\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): GPT2MLP(\n",
       "            (c_fc): Conv1D(nf=4096, nx=1024)\n",
       "            (c_proj): Conv1D(nf=1024, nx=4096)\n",
       "            (act): NewGELUActivation()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): GPT2Block(\n",
       "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): GPT2Attention(\n",
       "            (c_attn): Conv1D(nf=3072, nx=1024)\n",
       "            (c_proj): Conv1D(nf=1024, nx=1024)\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): GPT2MLP(\n",
       "            (c_fc): Conv1D(nf=4096, nx=1024)\n",
       "            (c_proj): Conv1D(nf=1024, nx=4096)\n",
       "            (act): NewGELUActivation()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): GPT2Block(\n",
       "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): GPT2Attention(\n",
       "            (c_attn): Conv1D(nf=3072, nx=1024)\n",
       "            (c_proj): Conv1D(nf=1024, nx=1024)\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): GPT2MLP(\n",
       "            (c_fc): Conv1D(nf=4096, nx=1024)\n",
       "            (c_proj): Conv1D(nf=1024, nx=4096)\n",
       "            (act): NewGELUActivation()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): GPT2Block(\n",
       "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): GPT2Attention(\n",
       "            (c_attn): Conv1D(nf=3072, nx=1024)\n",
       "            (c_proj): Conv1D(nf=1024, nx=1024)\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): GPT2MLP(\n",
       "            (c_fc): Conv1D(nf=4096, nx=1024)\n",
       "            (c_proj): Conv1D(nf=1024, nx=4096)\n",
       "            (act): NewGELUActivation()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): GPT2Block(\n",
       "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): GPT2Attention(\n",
       "            (c_attn): Conv1D(nf=3072, nx=1024)\n",
       "            (c_proj): Conv1D(nf=1024, nx=1024)\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): GPT2MLP(\n",
       "            (c_fc): Conv1D(nf=4096, nx=1024)\n",
       "            (c_proj): Conv1D(nf=1024, nx=4096)\n",
       "            (act): NewGELUActivation()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): GPT2Block(\n",
       "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): GPT2Attention(\n",
       "            (c_attn): Conv1D(nf=3072, nx=1024)\n",
       "            (c_proj): Conv1D(nf=1024, nx=1024)\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): GPT2MLP(\n",
       "            (c_fc): Conv1D(nf=4096, nx=1024)\n",
       "            (c_proj): Conv1D(nf=1024, nx=4096)\n",
       "            (act): NewGELUActivation()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (12): GPT2Block(\n",
       "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): GPT2Attention(\n",
       "            (c_attn): Conv1D(nf=3072, nx=1024)\n",
       "            (c_proj): Conv1D(nf=1024, nx=1024)\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): GPT2MLP(\n",
       "            (c_fc): Conv1D(nf=4096, nx=1024)\n",
       "            (c_proj): Conv1D(nf=1024, nx=4096)\n",
       "            (act): NewGELUActivation()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (13): GPT2Block(\n",
       "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): GPT2Attention(\n",
       "            (c_attn): Conv1D(nf=3072, nx=1024)\n",
       "            (c_proj): Conv1D(nf=1024, nx=1024)\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): GPT2MLP(\n",
       "            (c_fc): Conv1D(nf=4096, nx=1024)\n",
       "            (c_proj): Conv1D(nf=1024, nx=4096)\n",
       "            (act): NewGELUActivation()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (14): GPT2Block(\n",
       "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): GPT2Attention(\n",
       "            (c_attn): Conv1D(nf=3072, nx=1024)\n",
       "            (c_proj): Conv1D(nf=1024, nx=1024)\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): GPT2MLP(\n",
       "            (c_fc): Conv1D(nf=4096, nx=1024)\n",
       "            (c_proj): Conv1D(nf=1024, nx=4096)\n",
       "            (act): NewGELUActivation()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (15): GPT2Block(\n",
       "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): GPT2Attention(\n",
       "            (c_attn): Conv1D(nf=3072, nx=1024)\n",
       "            (c_proj): Conv1D(nf=1024, nx=1024)\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): GPT2MLP(\n",
       "            (c_fc): Conv1D(nf=4096, nx=1024)\n",
       "            (c_proj): Conv1D(nf=1024, nx=4096)\n",
       "            (act): NewGELUActivation()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (16): GPT2Block(\n",
       "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): GPT2Attention(\n",
       "            (c_attn): Conv1D(nf=3072, nx=1024)\n",
       "            (c_proj): Conv1D(nf=1024, nx=1024)\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): GPT2MLP(\n",
       "            (c_fc): Conv1D(nf=4096, nx=1024)\n",
       "            (c_proj): Conv1D(nf=1024, nx=4096)\n",
       "            (act): NewGELUActivation()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (17): GPT2Block(\n",
       "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): GPT2Attention(\n",
       "            (c_attn): Conv1D(nf=3072, nx=1024)\n",
       "            (c_proj): Conv1D(nf=1024, nx=1024)\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): GPT2MLP(\n",
       "            (c_fc): Conv1D(nf=4096, nx=1024)\n",
       "            (c_proj): Conv1D(nf=1024, nx=4096)\n",
       "            (act): NewGELUActivation()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (18): GPT2Block(\n",
       "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): GPT2Attention(\n",
       "            (c_attn): Conv1D(nf=3072, nx=1024)\n",
       "            (c_proj): Conv1D(nf=1024, nx=1024)\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): GPT2MLP(\n",
       "            (c_fc): Conv1D(nf=4096, nx=1024)\n",
       "            (c_proj): Conv1D(nf=1024, nx=4096)\n",
       "            (act): NewGELUActivation()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (19): GPT2Block(\n",
       "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): GPT2Attention(\n",
       "            (c_attn): Conv1D(nf=3072, nx=1024)\n",
       "            (c_proj): Conv1D(nf=1024, nx=1024)\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): GPT2MLP(\n",
       "            (c_fc): Conv1D(nf=4096, nx=1024)\n",
       "            (c_proj): Conv1D(nf=1024, nx=4096)\n",
       "            (act): NewGELUActivation()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (20): GPT2Block(\n",
       "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): GPT2Attention(\n",
       "            (c_attn): Conv1D(nf=3072, nx=1024)\n",
       "            (c_proj): Conv1D(nf=1024, nx=1024)\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): GPT2MLP(\n",
       "            (c_fc): Conv1D(nf=4096, nx=1024)\n",
       "            (c_proj): Conv1D(nf=1024, nx=4096)\n",
       "            (act): NewGELUActivation()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (21): GPT2Block(\n",
       "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): GPT2Attention(\n",
       "            (c_attn): Conv1D(nf=3072, nx=1024)\n",
       "            (c_proj): Conv1D(nf=1024, nx=1024)\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): GPT2MLP(\n",
       "            (c_fc): Conv1D(nf=4096, nx=1024)\n",
       "            (c_proj): Conv1D(nf=1024, nx=4096)\n",
       "            (act): NewGELUActivation()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (22): GPT2Block(\n",
       "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): GPT2Attention(\n",
       "            (c_attn): Conv1D(nf=3072, nx=1024)\n",
       "            (c_proj): Conv1D(nf=1024, nx=1024)\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): GPT2MLP(\n",
       "            (c_fc): Conv1D(nf=4096, nx=1024)\n",
       "            (c_proj): Conv1D(nf=1024, nx=4096)\n",
       "            (act): NewGELUActivation()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (23): GPT2Block(\n",
       "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): GPT2Attention(\n",
       "            (c_attn): Conv1D(nf=3072, nx=1024)\n",
       "            (c_proj): Conv1D(nf=1024, nx=1024)\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): GPT2MLP(\n",
       "            (c_fc): Conv1D(nf=4096, nx=1024)\n",
       "            (c_proj): Conv1D(nf=1024, nx=4096)\n",
       "            (act): NewGELUActivation()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (lm_head): Linear(in_features=1024, out_features=50266, bias=False)\n",
       "  )\n",
       "  (enc_mapper): Linear(in_features=768, out_features=1024, bias=True)\n",
       "  (enc_mapper2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (prefix_nn): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (prefix_nn2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (prefix_nn3): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (prefix_nn4): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (prefix_nn5): Linear(in_features=1024, out_features=1024, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = FLUENTSOTA(enc_model, dec_model, enc_tokenizer, dec_tokenizer)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All parameters: 486,358,784\n",
      "Trainable parameters: 120,451,072 (24.77%)\n",
      "Untrainable parameters: 365,907,712 (75.23%)\n"
     ]
    }
   ],
   "source": [
    "all_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "untrainable_params = all_params - trainable_params\n",
    "\n",
    "print(f'All parameters: {all_params:,}')\n",
    "print(f'Trainable parameters: {trainable_params:,} ({trainable_params/all_params*100:.2f}%)')\n",
    "print(f'Untrainable parameters: {untrainable_params:,} ({untrainable_params/all_params*100:.2f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bleu(preds, questions, answers):\n",
    "    bleu_score_1 = 0\n",
    "    bleu_score_2 = 0\n",
    "    bleu_score_3 = 0\n",
    "    bleu_score_4 = 0\n",
    "    cum_bleu_score_1 = 0\n",
    "    cum_bleu_score_2 = 0\n",
    "    cum_bleu_score_3 = 0\n",
    "    cum_bleu_score_4 = 0\n",
    "\n",
    "    num_of_rows_calculated = 0\n",
    "    smoothing_function = SmoothingFunction().method1\n",
    "\n",
    "    for i, (question, real_answer) in enumerate(zip(questions, answers)):\n",
    "        # print(f\"Question: {question}\")\n",
    "        # print(f\"Real Answer: {real_answer}\")\n",
    "        # print(f\"Predicted Answer: {preds[i]}\")\n",
    "        refs = [real_answer.split(' ')]\n",
    "        hyp = preds[i].split(' ')\n",
    "\n",
    "        bleu_score_1 += sentence_bleu(refs, hyp, weights=(1,0,0,0), smoothing_function=smoothing_function)\n",
    "        bleu_score_2 += sentence_bleu(refs, hyp, weights=(0,1,0,0), smoothing_function=smoothing_function)\n",
    "        bleu_score_3 += sentence_bleu(refs, hyp, weights=(0,0,1,0), smoothing_function=smoothing_function)\n",
    "        bleu_score_4 += sentence_bleu(refs, hyp, weights=(0,0,0,1), smoothing_function=smoothing_function)\n",
    "        cum_bleu_score_1 += sentence_bleu(refs, hyp, weights=(1,0,0,0), smoothing_function=smoothing_function)\n",
    "        cum_bleu_score_2 += sentence_bleu(refs, hyp, weights=(0.5,0.5,0,0), smoothing_function=smoothing_function)\n",
    "        cum_bleu_score_3 += sentence_bleu(refs, hyp, weights=(0.33,0.33,0.33,0), smoothing_function=smoothing_function)\n",
    "        cum_bleu_score_4 += sentence_bleu(refs, hyp, weights=(0.25,0.25,0.25,0.25), smoothing_function=smoothing_function)\n",
    "\n",
    "        num_of_rows_calculated+=1\n",
    "\n",
    "    results = {\"1-gram\": (bleu_score_1/num_of_rows_calculated),\n",
    "                \"2-gram\": (bleu_score_2/num_of_rows_calculated),\n",
    "                \"3-gram\": (bleu_score_3/num_of_rows_calculated),\n",
    "                \"4-gram\": (bleu_score_4/num_of_rows_calculated),\n",
    "                \"cumulative-1-gram\": (cum_bleu_score_1/num_of_rows_calculated),\n",
    "                \"cumulative-2-gram\": (cum_bleu_score_2/num_of_rows_calculated),\n",
    "                \"cumulative-3-gram\": (cum_bleu_score_3/num_of_rows_calculated),\n",
    "                \"cumulative-4-gram\": (cum_bleu_score_4/num_of_rows_calculated)}\n",
    "\n",
    "    return results\n",
    "\n",
    "def count_bleu_score(model_count, real_answers, questions):\n",
    "    preds = []\n",
    "    for question in questions:\n",
    "        outputs = model_count.generate(question)\n",
    "        decoded_output = model_count.dec_tokenizer.decode(outputs[0])\n",
    "        preds.append(decoded_output)\n",
    "    return calculate_bleu(preds, questions, real_answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500 - Loss: 179.6923\n",
      "Epoch 2/500 - Loss: 159.2909\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m tokenized_jawaban_withpre \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mdec_tokenizer(jawaban_withpre)\n\u001b[1;32m     26\u001b[0m tokenized_jawaban_withpre \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(tokenized_jawaban_withpre[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 28\u001b[0m enc_logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpertanyaan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m output \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mdecoding_train(enc_logits, target\u001b[38;5;241m=\u001b[39mjawaban, target_with_pre\u001b[38;5;241m=\u001b[39mtokenized_jawaban_withpre)\n\u001b[1;32m     31\u001b[0m loss \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mloss\n",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36mFLUENTSOTA.encoding\u001b[0;34m(self, sentence)\u001b[0m\n\u001b[1;32m     19\u001b[0m tokens \u001b[38;5;241m=\u001b[39m tokens\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 21\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menc_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m enc_logits \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mlast_hidden_state\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     23\u001b[0m enc_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menc_mapper(enc_logits)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:1142\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m   1140\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m-> 1142\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1153\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1154\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1155\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:695\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    684\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    685\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    686\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    692\u001b[0m         output_attentions,\n\u001b[1;32m    693\u001b[0m     )\n\u001b[1;32m    694\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 695\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:585\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    574\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    575\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    582\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    584\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 585\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    592\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    594\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:515\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    507\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    513\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    514\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m--> 515\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    524\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[1;32m    525\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:334\u001b[0m, in \u001b[0;36mBertSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    331\u001b[0m     attention_scores \u001b[38;5;241m=\u001b[39m attention_scores \u001b[38;5;241m+\u001b[39m attention_mask\n\u001b[1;32m    333\u001b[0m \u001b[38;5;66;03m# Normalize the attention scores to probabilities.\u001b[39;00m\n\u001b[0;32m--> 334\u001b[0m attention_probs \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_scores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;66;03m# This is actually dropping out entire tokens to attend to, which might\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;66;03m# seem a bit unusual, but is taken from the original Transformer paper.\u001b[39;00m\n\u001b[1;32m    338\u001b[0m attention_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(attention_probs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:1811\u001b[0m, in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1807\u001b[0m         ret \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m-\u001b[39m\u001b[38;5;28minput\u001b[39m)\u001b[38;5;241m.\u001b[39msoftmax(dim, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\n\u001b[0;32m-> 1811\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msoftmax\u001b[39m(\u001b[38;5;28minput\u001b[39m: Tensor, dim: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, _stacklevel: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m, dtype: Optional[DType] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m   1812\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Applies a softmax function.\u001b[39;00m\n\u001b[1;32m   1813\u001b[0m \n\u001b[1;32m   1814\u001b[0m \u001b[38;5;124;03m    Softmax is defined as:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1834\u001b[0m \n\u001b[1;32m   1835\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1836\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28minput\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bleu_score_eval = pd.DataFrame(columns=['Epoch', '1-gram', '2-gram', '3-gram', '4-gram', 'cumulative-1-gram', 'cumulative-2-gram', 'cumulative-3-gram', 'cumulative-4-gram'])\n",
    "bleu_score_train = pd.DataFrame(columns=['Epoch', '1-gram', '2-gram', '3-gram', '4-gram', 'cumulative-1-gram', 'cumulative-2-gram', 'cumulative-3-gram', 'cumulative-4-gram'])\n",
    "\n",
    "questions = qa_paired_test['Pertanyaan'].apply(lambda x: x.lower().replace('[BOS]', '').replace('[EOS]', '')).to_list()\n",
    "answers = qa_paired_test['Jawaban'].apply(lambda x: x.replace('[BOS]', '').replace('[EOS]', '').lower().strip()).to_list()\n",
    "questions_eval = qa_paired_eval['Pertanyaan'].apply(lambda x: x.lower().replace('[BOS]', '').replace('[EOS]', '')).to_list()\n",
    "answers_eval = qa_paired_eval['Jawaban'].apply(lambda x: x.replace('[BOS]', '').replace('[EOS]', '').lower().strip()).to_list()\n",
    "\n",
    "epochs = 500\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for ep in range(epochs):\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    total_loss = 0\n",
    "    for instance in qa_paired_test.iterrows():\n",
    "        # print(\"---------------\")\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        pertanyaan = instance[1]['Pertanyaan']\n",
    "        jawaban = instance[1]['Jawaban']\n",
    "        jawaban_withpre = '[PRE1][PRE2][PRE3][PRE4][PRE5]' + jawaban\n",
    "\n",
    "        tokenized_jawaban_withpre = model.dec_tokenizer(jawaban_withpre)\n",
    "        tokenized_jawaban_withpre = torch.tensor(tokenized_jawaban_withpre['input_ids']).unsqueeze(0)\n",
    "\n",
    "        enc_logits = model.encoding(pertanyaan)\n",
    "        output = model.decoding_train(enc_logits, target=jawaban, target_with_pre=tokenized_jawaban_withpre)\n",
    "\n",
    "        loss = output.loss\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch {ep+1}/{epochs} - Loss: {total_loss:.4f}')\n",
    "    if (ep+1) % 10 == 0:\n",
    "        print(f'\\n-----------------------------------------')\n",
    "        test_question = qa_paired_test['Pertanyaan'].iloc[0]\n",
    "        outputs = model.generate(test_question)\n",
    "        decoded_output = model.dec_tokenizer.decode(outputs[0])\n",
    "        print(f'Q >>> {test_question}')\n",
    "        print(f'A <<< {decoded_output}')\n",
    "        test_question = qa_paired_test['Pertanyaan'].iloc[1]\n",
    "        outputs = model.generate(test_question)\n",
    "        decoded_output = model.dec_tokenizer.decode(outputs[0])\n",
    "        print(f'Q >>> {test_question}')\n",
    "        print(f'A <<< {decoded_output}')\n",
    "        test_question = qa_paired_test['Pertanyaan'].iloc[4]\n",
    "        outputs = model.generate(test_question)\n",
    "        decoded_output = model.dec_tokenizer.decode(outputs[0])\n",
    "        print(f'Q >>> {test_question}')\n",
    "        print(f'A <<< {decoded_output}')\n",
    "        print(f'-----------------------------------------\\n')\n",
    "\n",
    "    if (ep+1) % 10 == 0:\n",
    "        bleu_result = count_bleu_score(model, answers_eval, questions_eval)\n",
    "        bleu_score_eval = pd.concat([bleu_score_eval, pd.DataFrame({'Epoch': ep+1, **bleu_result}, index=[len(bleu_score_eval)])], ignore_index=True)\n",
    "        print(f'BLEU Score Eval: {bleu_result[\"cumulative-4-gram\"]:.4f}\\n')\n",
    "\n",
    "        bleu_result = count_bleu_score(model, answers, questions)\n",
    "        bleu_score_train = pd.concat([bleu_score_train, pd.DataFrame({'Epoch': ep+1, **bleu_result}, index=[len(bleu_score_train)])], ignore_index=True)\n",
    "        print(f'BLEU Score Train: {bleu_result[\"cumulative-4-gram\"]:.4f}\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu_score_eval.to_excel('bleu_score_eval_101024.xlsx', index=False)\n",
    "bleu_score_train.to_excel('bleu_score_train_101024.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>1-gram</th>\n",
       "      <th>2-gram</th>\n",
       "      <th>3-gram</th>\n",
       "      <th>4-gram</th>\n",
       "      <th>cumulative-1-gram</th>\n",
       "      <th>cumulative-2-gram</th>\n",
       "      <th>cumulative-3-gram</th>\n",
       "      <th>cumulative-4-gram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0.006132</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.006132</td>\n",
       "      <td>0.001077</td>\n",
       "      <td>0.000656</td>\n",
       "      <td>0.000472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>0.017492</td>\n",
       "      <td>0.001470</td>\n",
       "      <td>0.001758</td>\n",
       "      <td>0.002248</td>\n",
       "      <td>0.017492</td>\n",
       "      <td>0.004905</td>\n",
       "      <td>0.003576</td>\n",
       "      <td>0.003073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>0.049587</td>\n",
       "      <td>0.014581</td>\n",
       "      <td>0.007514</td>\n",
       "      <td>0.007975</td>\n",
       "      <td>0.049587</td>\n",
       "      <td>0.024409</td>\n",
       "      <td>0.015926</td>\n",
       "      <td>0.012289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>0.219343</td>\n",
       "      <td>0.167178</td>\n",
       "      <td>0.149043</td>\n",
       "      <td>0.134266</td>\n",
       "      <td>0.219343</td>\n",
       "      <td>0.183226</td>\n",
       "      <td>0.167228</td>\n",
       "      <td>0.154149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>0.316215</td>\n",
       "      <td>0.285167</td>\n",
       "      <td>0.268384</td>\n",
       "      <td>0.233905</td>\n",
       "      <td>0.316215</td>\n",
       "      <td>0.294964</td>\n",
       "      <td>0.283547</td>\n",
       "      <td>0.260478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>0.486234</td>\n",
       "      <td>0.468212</td>\n",
       "      <td>0.461691</td>\n",
       "      <td>0.455646</td>\n",
       "      <td>0.486234</td>\n",
       "      <td>0.473718</td>\n",
       "      <td>0.469041</td>\n",
       "      <td>0.464014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>70</td>\n",
       "      <td>0.605207</td>\n",
       "      <td>0.582459</td>\n",
       "      <td>0.576759</td>\n",
       "      <td>0.549651</td>\n",
       "      <td>0.605207</td>\n",
       "      <td>0.589060</td>\n",
       "      <td>0.584718</td>\n",
       "      <td>0.569969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>80</td>\n",
       "      <td>0.458456</td>\n",
       "      <td>0.442561</td>\n",
       "      <td>0.435074</td>\n",
       "      <td>0.407156</td>\n",
       "      <td>0.458456</td>\n",
       "      <td>0.448189</td>\n",
       "      <td>0.443232</td>\n",
       "      <td>0.427878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>90</td>\n",
       "      <td>0.763833</td>\n",
       "      <td>0.730404</td>\n",
       "      <td>0.723839</td>\n",
       "      <td>0.699205</td>\n",
       "      <td>0.763833</td>\n",
       "      <td>0.742151</td>\n",
       "      <td>0.734749</td>\n",
       "      <td>0.719159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100</td>\n",
       "      <td>0.821018</td>\n",
       "      <td>0.793999</td>\n",
       "      <td>0.789716</td>\n",
       "      <td>0.766655</td>\n",
       "      <td>0.821018</td>\n",
       "      <td>0.803726</td>\n",
       "      <td>0.798373</td>\n",
       "      <td>0.784373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>110</td>\n",
       "      <td>0.820731</td>\n",
       "      <td>0.808242</td>\n",
       "      <td>0.804006</td>\n",
       "      <td>0.780971</td>\n",
       "      <td>0.820731</td>\n",
       "      <td>0.813510</td>\n",
       "      <td>0.810093</td>\n",
       "      <td>0.796950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>120</td>\n",
       "      <td>0.804928</td>\n",
       "      <td>0.786187</td>\n",
       "      <td>0.779892</td>\n",
       "      <td>0.752283</td>\n",
       "      <td>0.804928</td>\n",
       "      <td>0.793675</td>\n",
       "      <td>0.788843</td>\n",
       "      <td>0.773334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>130</td>\n",
       "      <td>0.887026</td>\n",
       "      <td>0.868484</td>\n",
       "      <td>0.865385</td>\n",
       "      <td>0.842464</td>\n",
       "      <td>0.887026</td>\n",
       "      <td>0.875587</td>\n",
       "      <td>0.872126</td>\n",
       "      <td>0.859219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>140</td>\n",
       "      <td>0.901046</td>\n",
       "      <td>0.884730</td>\n",
       "      <td>0.882048</td>\n",
       "      <td>0.859206</td>\n",
       "      <td>0.901046</td>\n",
       "      <td>0.890962</td>\n",
       "      <td>0.888135</td>\n",
       "      <td>0.875455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>150</td>\n",
       "      <td>0.924941</td>\n",
       "      <td>0.906546</td>\n",
       "      <td>0.904251</td>\n",
       "      <td>0.882117</td>\n",
       "      <td>0.924941</td>\n",
       "      <td>0.913637</td>\n",
       "      <td>0.910562</td>\n",
       "      <td>0.898079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>160</td>\n",
       "      <td>0.934775</td>\n",
       "      <td>0.919970</td>\n",
       "      <td>0.917587</td>\n",
       "      <td>0.895443</td>\n",
       "      <td>0.934775</td>\n",
       "      <td>0.925546</td>\n",
       "      <td>0.923016</td>\n",
       "      <td>0.910826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>170</td>\n",
       "      <td>0.973666</td>\n",
       "      <td>0.961736</td>\n",
       "      <td>0.960404</td>\n",
       "      <td>0.938759</td>\n",
       "      <td>0.973666</td>\n",
       "      <td>0.965939</td>\n",
       "      <td>0.964030</td>\n",
       "      <td>0.952616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>180</td>\n",
       "      <td>0.983736</td>\n",
       "      <td>0.974280</td>\n",
       "      <td>0.973904</td>\n",
       "      <td>0.953063</td>\n",
       "      <td>0.983736</td>\n",
       "      <td>0.977271</td>\n",
       "      <td>0.976006</td>\n",
       "      <td>0.965263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>190</td>\n",
       "      <td>0.975676</td>\n",
       "      <td>0.966126</td>\n",
       "      <td>0.965655</td>\n",
       "      <td>0.944717</td>\n",
       "      <td>0.975676</td>\n",
       "      <td>0.969164</td>\n",
       "      <td>0.967894</td>\n",
       "      <td>0.957059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>200</td>\n",
       "      <td>0.986457</td>\n",
       "      <td>0.977031</td>\n",
       "      <td>0.976687</td>\n",
       "      <td>0.955878</td>\n",
       "      <td>0.986457</td>\n",
       "      <td>0.980007</td>\n",
       "      <td>0.978731</td>\n",
       "      <td>0.968031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>210</td>\n",
       "      <td>0.986457</td>\n",
       "      <td>0.977031</td>\n",
       "      <td>0.976687</td>\n",
       "      <td>0.955878</td>\n",
       "      <td>0.986457</td>\n",
       "      <td>0.980007</td>\n",
       "      <td>0.978731</td>\n",
       "      <td>0.968031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>220</td>\n",
       "      <td>0.986457</td>\n",
       "      <td>0.977031</td>\n",
       "      <td>0.976687</td>\n",
       "      <td>0.955878</td>\n",
       "      <td>0.986457</td>\n",
       "      <td>0.980007</td>\n",
       "      <td>0.978731</td>\n",
       "      <td>0.968031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>230</td>\n",
       "      <td>0.986457</td>\n",
       "      <td>0.977031</td>\n",
       "      <td>0.976687</td>\n",
       "      <td>0.955878</td>\n",
       "      <td>0.986457</td>\n",
       "      <td>0.980007</td>\n",
       "      <td>0.978731</td>\n",
       "      <td>0.968031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>240</td>\n",
       "      <td>0.721554</td>\n",
       "      <td>0.701194</td>\n",
       "      <td>0.700559</td>\n",
       "      <td>0.679778</td>\n",
       "      <td>0.721554</td>\n",
       "      <td>0.706891</td>\n",
       "      <td>0.704543</td>\n",
       "      <td>0.693104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>250</td>\n",
       "      <td>0.946529</td>\n",
       "      <td>0.932504</td>\n",
       "      <td>0.931192</td>\n",
       "      <td>0.909729</td>\n",
       "      <td>0.946529</td>\n",
       "      <td>0.937649</td>\n",
       "      <td>0.935441</td>\n",
       "      <td>0.923821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>260</td>\n",
       "      <td>0.986457</td>\n",
       "      <td>0.977031</td>\n",
       "      <td>0.976687</td>\n",
       "      <td>0.955878</td>\n",
       "      <td>0.986457</td>\n",
       "      <td>0.980007</td>\n",
       "      <td>0.978731</td>\n",
       "      <td>0.968031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>270</td>\n",
       "      <td>0.986457</td>\n",
       "      <td>0.977031</td>\n",
       "      <td>0.976687</td>\n",
       "      <td>0.955878</td>\n",
       "      <td>0.986457</td>\n",
       "      <td>0.980007</td>\n",
       "      <td>0.978731</td>\n",
       "      <td>0.968031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>280</td>\n",
       "      <td>0.986457</td>\n",
       "      <td>0.977031</td>\n",
       "      <td>0.976687</td>\n",
       "      <td>0.955878</td>\n",
       "      <td>0.986457</td>\n",
       "      <td>0.980007</td>\n",
       "      <td>0.978731</td>\n",
       "      <td>0.968031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>290</td>\n",
       "      <td>0.986457</td>\n",
       "      <td>0.977031</td>\n",
       "      <td>0.976687</td>\n",
       "      <td>0.955878</td>\n",
       "      <td>0.986457</td>\n",
       "      <td>0.980007</td>\n",
       "      <td>0.978731</td>\n",
       "      <td>0.968031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>300</td>\n",
       "      <td>0.986457</td>\n",
       "      <td>0.977031</td>\n",
       "      <td>0.976687</td>\n",
       "      <td>0.955878</td>\n",
       "      <td>0.986457</td>\n",
       "      <td>0.980007</td>\n",
       "      <td>0.978731</td>\n",
       "      <td>0.968031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>310</td>\n",
       "      <td>0.986457</td>\n",
       "      <td>0.977031</td>\n",
       "      <td>0.976687</td>\n",
       "      <td>0.955878</td>\n",
       "      <td>0.986457</td>\n",
       "      <td>0.980007</td>\n",
       "      <td>0.978731</td>\n",
       "      <td>0.968031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>320</td>\n",
       "      <td>0.986457</td>\n",
       "      <td>0.977031</td>\n",
       "      <td>0.976687</td>\n",
       "      <td>0.955878</td>\n",
       "      <td>0.986457</td>\n",
       "      <td>0.980007</td>\n",
       "      <td>0.978731</td>\n",
       "      <td>0.968031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>330</td>\n",
       "      <td>0.986457</td>\n",
       "      <td>0.977031</td>\n",
       "      <td>0.976687</td>\n",
       "      <td>0.955878</td>\n",
       "      <td>0.986457</td>\n",
       "      <td>0.980007</td>\n",
       "      <td>0.978731</td>\n",
       "      <td>0.968031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>340</td>\n",
       "      <td>0.986457</td>\n",
       "      <td>0.977031</td>\n",
       "      <td>0.976687</td>\n",
       "      <td>0.955878</td>\n",
       "      <td>0.986457</td>\n",
       "      <td>0.980007</td>\n",
       "      <td>0.978731</td>\n",
       "      <td>0.968031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>350</td>\n",
       "      <td>0.857388</td>\n",
       "      <td>0.838464</td>\n",
       "      <td>0.838322</td>\n",
       "      <td>0.817944</td>\n",
       "      <td>0.857388</td>\n",
       "      <td>0.843268</td>\n",
       "      <td>0.841087</td>\n",
       "      <td>0.830159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>360</td>\n",
       "      <td>0.966936</td>\n",
       "      <td>0.954689</td>\n",
       "      <td>0.954441</td>\n",
       "      <td>0.933792</td>\n",
       "      <td>0.966936</td>\n",
       "      <td>0.958391</td>\n",
       "      <td>0.956871</td>\n",
       "      <td>0.946089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>370</td>\n",
       "      <td>0.966936</td>\n",
       "      <td>0.954689</td>\n",
       "      <td>0.954441</td>\n",
       "      <td>0.933792</td>\n",
       "      <td>0.966936</td>\n",
       "      <td>0.958391</td>\n",
       "      <td>0.956871</td>\n",
       "      <td>0.946089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>380</td>\n",
       "      <td>0.986457</td>\n",
       "      <td>0.977031</td>\n",
       "      <td>0.976687</td>\n",
       "      <td>0.955878</td>\n",
       "      <td>0.986457</td>\n",
       "      <td>0.980007</td>\n",
       "      <td>0.978731</td>\n",
       "      <td>0.968031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>390</td>\n",
       "      <td>0.986457</td>\n",
       "      <td>0.977031</td>\n",
       "      <td>0.976687</td>\n",
       "      <td>0.955878</td>\n",
       "      <td>0.986457</td>\n",
       "      <td>0.980007</td>\n",
       "      <td>0.978731</td>\n",
       "      <td>0.968031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>400</td>\n",
       "      <td>0.986457</td>\n",
       "      <td>0.977031</td>\n",
       "      <td>0.976687</td>\n",
       "      <td>0.955878</td>\n",
       "      <td>0.986457</td>\n",
       "      <td>0.980007</td>\n",
       "      <td>0.978731</td>\n",
       "      <td>0.968031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>410</td>\n",
       "      <td>0.986457</td>\n",
       "      <td>0.977031</td>\n",
       "      <td>0.976687</td>\n",
       "      <td>0.955878</td>\n",
       "      <td>0.986457</td>\n",
       "      <td>0.980007</td>\n",
       "      <td>0.978731</td>\n",
       "      <td>0.968031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>420</td>\n",
       "      <td>0.986457</td>\n",
       "      <td>0.977031</td>\n",
       "      <td>0.976687</td>\n",
       "      <td>0.955878</td>\n",
       "      <td>0.986457</td>\n",
       "      <td>0.980007</td>\n",
       "      <td>0.978731</td>\n",
       "      <td>0.968031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>430</td>\n",
       "      <td>0.986457</td>\n",
       "      <td>0.977031</td>\n",
       "      <td>0.976687</td>\n",
       "      <td>0.955878</td>\n",
       "      <td>0.986457</td>\n",
       "      <td>0.980007</td>\n",
       "      <td>0.978731</td>\n",
       "      <td>0.968031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>440</td>\n",
       "      <td>0.986457</td>\n",
       "      <td>0.977031</td>\n",
       "      <td>0.976687</td>\n",
       "      <td>0.955878</td>\n",
       "      <td>0.986457</td>\n",
       "      <td>0.980007</td>\n",
       "      <td>0.978731</td>\n",
       "      <td>0.968031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>450</td>\n",
       "      <td>0.986457</td>\n",
       "      <td>0.977031</td>\n",
       "      <td>0.976687</td>\n",
       "      <td>0.955878</td>\n",
       "      <td>0.986457</td>\n",
       "      <td>0.980007</td>\n",
       "      <td>0.978731</td>\n",
       "      <td>0.968031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>460</td>\n",
       "      <td>0.986457</td>\n",
       "      <td>0.977031</td>\n",
       "      <td>0.976687</td>\n",
       "      <td>0.955878</td>\n",
       "      <td>0.986457</td>\n",
       "      <td>0.980007</td>\n",
       "      <td>0.978731</td>\n",
       "      <td>0.968031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>470</td>\n",
       "      <td>0.986457</td>\n",
       "      <td>0.977031</td>\n",
       "      <td>0.976687</td>\n",
       "      <td>0.955878</td>\n",
       "      <td>0.986457</td>\n",
       "      <td>0.980007</td>\n",
       "      <td>0.978731</td>\n",
       "      <td>0.968031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>480</td>\n",
       "      <td>0.983175</td>\n",
       "      <td>0.973682</td>\n",
       "      <td>0.973267</td>\n",
       "      <td>0.952384</td>\n",
       "      <td>0.983175</td>\n",
       "      <td>0.976692</td>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.964644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>490</td>\n",
       "      <td>0.930263</td>\n",
       "      <td>0.917862</td>\n",
       "      <td>0.917486</td>\n",
       "      <td>0.896682</td>\n",
       "      <td>0.930263</td>\n",
       "      <td>0.921622</td>\n",
       "      <td>0.920106</td>\n",
       "      <td>0.909178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>500</td>\n",
       "      <td>0.986457</td>\n",
       "      <td>0.977031</td>\n",
       "      <td>0.976687</td>\n",
       "      <td>0.955878</td>\n",
       "      <td>0.986457</td>\n",
       "      <td>0.980007</td>\n",
       "      <td>0.978731</td>\n",
       "      <td>0.968031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Epoch    1-gram    2-gram    3-gram    4-gram  cumulative-1-gram  \\\n",
       "0     10  0.006132  0.000210  0.000212  0.000214           0.006132   \n",
       "1     20  0.017492  0.001470  0.001758  0.002248           0.017492   \n",
       "2     30  0.049587  0.014581  0.007514  0.007975           0.049587   \n",
       "3     40  0.219343  0.167178  0.149043  0.134266           0.219343   \n",
       "4     50  0.316215  0.285167  0.268384  0.233905           0.316215   \n",
       "5     60  0.486234  0.468212  0.461691  0.455646           0.486234   \n",
       "6     70  0.605207  0.582459  0.576759  0.549651           0.605207   \n",
       "7     80  0.458456  0.442561  0.435074  0.407156           0.458456   \n",
       "8     90  0.763833  0.730404  0.723839  0.699205           0.763833   \n",
       "9    100  0.821018  0.793999  0.789716  0.766655           0.821018   \n",
       "10   110  0.820731  0.808242  0.804006  0.780971           0.820731   \n",
       "11   120  0.804928  0.786187  0.779892  0.752283           0.804928   \n",
       "12   130  0.887026  0.868484  0.865385  0.842464           0.887026   \n",
       "13   140  0.901046  0.884730  0.882048  0.859206           0.901046   \n",
       "14   150  0.924941  0.906546  0.904251  0.882117           0.924941   \n",
       "15   160  0.934775  0.919970  0.917587  0.895443           0.934775   \n",
       "16   170  0.973666  0.961736  0.960404  0.938759           0.973666   \n",
       "17   180  0.983736  0.974280  0.973904  0.953063           0.983736   \n",
       "18   190  0.975676  0.966126  0.965655  0.944717           0.975676   \n",
       "19   200  0.986457  0.977031  0.976687  0.955878           0.986457   \n",
       "20   210  0.986457  0.977031  0.976687  0.955878           0.986457   \n",
       "21   220  0.986457  0.977031  0.976687  0.955878           0.986457   \n",
       "22   230  0.986457  0.977031  0.976687  0.955878           0.986457   \n",
       "23   240  0.721554  0.701194  0.700559  0.679778           0.721554   \n",
       "24   250  0.946529  0.932504  0.931192  0.909729           0.946529   \n",
       "25   260  0.986457  0.977031  0.976687  0.955878           0.986457   \n",
       "26   270  0.986457  0.977031  0.976687  0.955878           0.986457   \n",
       "27   280  0.986457  0.977031  0.976687  0.955878           0.986457   \n",
       "28   290  0.986457  0.977031  0.976687  0.955878           0.986457   \n",
       "29   300  0.986457  0.977031  0.976687  0.955878           0.986457   \n",
       "30   310  0.986457  0.977031  0.976687  0.955878           0.986457   \n",
       "31   320  0.986457  0.977031  0.976687  0.955878           0.986457   \n",
       "32   330  0.986457  0.977031  0.976687  0.955878           0.986457   \n",
       "33   340  0.986457  0.977031  0.976687  0.955878           0.986457   \n",
       "34   350  0.857388  0.838464  0.838322  0.817944           0.857388   \n",
       "35   360  0.966936  0.954689  0.954441  0.933792           0.966936   \n",
       "36   370  0.966936  0.954689  0.954441  0.933792           0.966936   \n",
       "37   380  0.986457  0.977031  0.976687  0.955878           0.986457   \n",
       "38   390  0.986457  0.977031  0.976687  0.955878           0.986457   \n",
       "39   400  0.986457  0.977031  0.976687  0.955878           0.986457   \n",
       "40   410  0.986457  0.977031  0.976687  0.955878           0.986457   \n",
       "41   420  0.986457  0.977031  0.976687  0.955878           0.986457   \n",
       "42   430  0.986457  0.977031  0.976687  0.955878           0.986457   \n",
       "43   440  0.986457  0.977031  0.976687  0.955878           0.986457   \n",
       "44   450  0.986457  0.977031  0.976687  0.955878           0.986457   \n",
       "45   460  0.986457  0.977031  0.976687  0.955878           0.986457   \n",
       "46   470  0.986457  0.977031  0.976687  0.955878           0.986457   \n",
       "47   480  0.983175  0.973682  0.973267  0.952384           0.983175   \n",
       "48   490  0.930263  0.917862  0.917486  0.896682           0.930263   \n",
       "49   500  0.986457  0.977031  0.976687  0.955878           0.986457   \n",
       "\n",
       "    cumulative-2-gram  cumulative-3-gram  cumulative-4-gram  \n",
       "0            0.001077           0.000656           0.000472  \n",
       "1            0.004905           0.003576           0.003073  \n",
       "2            0.024409           0.015926           0.012289  \n",
       "3            0.183226           0.167228           0.154149  \n",
       "4            0.294964           0.283547           0.260478  \n",
       "5            0.473718           0.469041           0.464014  \n",
       "6            0.589060           0.584718           0.569969  \n",
       "7            0.448189           0.443232           0.427878  \n",
       "8            0.742151           0.734749           0.719159  \n",
       "9            0.803726           0.798373           0.784373  \n",
       "10           0.813510           0.810093           0.796950  \n",
       "11           0.793675           0.788843           0.773334  \n",
       "12           0.875587           0.872126           0.859219  \n",
       "13           0.890962           0.888135           0.875455  \n",
       "14           0.913637           0.910562           0.898079  \n",
       "15           0.925546           0.923016           0.910826  \n",
       "16           0.965939           0.964030           0.952616  \n",
       "17           0.977271           0.976006           0.965263  \n",
       "18           0.969164           0.967894           0.957059  \n",
       "19           0.980007           0.978731           0.968031  \n",
       "20           0.980007           0.978731           0.968031  \n",
       "21           0.980007           0.978731           0.968031  \n",
       "22           0.980007           0.978731           0.968031  \n",
       "23           0.706891           0.704543           0.693104  \n",
       "24           0.937649           0.935441           0.923821  \n",
       "25           0.980007           0.978731           0.968031  \n",
       "26           0.980007           0.978731           0.968031  \n",
       "27           0.980007           0.978731           0.968031  \n",
       "28           0.980007           0.978731           0.968031  \n",
       "29           0.980007           0.978731           0.968031  \n",
       "30           0.980007           0.978731           0.968031  \n",
       "31           0.980007           0.978731           0.968031  \n",
       "32           0.980007           0.978731           0.968031  \n",
       "33           0.980007           0.978731           0.968031  \n",
       "34           0.843268           0.841087           0.830159  \n",
       "35           0.958391           0.956871           0.946089  \n",
       "36           0.958391           0.956871           0.946089  \n",
       "37           0.980007           0.978731           0.968031  \n",
       "38           0.980007           0.978731           0.968031  \n",
       "39           0.980007           0.978731           0.968031  \n",
       "40           0.980007           0.978731           0.968031  \n",
       "41           0.980007           0.978731           0.968031  \n",
       "42           0.980007           0.978731           0.968031  \n",
       "43           0.980007           0.978731           0.968031  \n",
       "44           0.980007           0.978731           0.968031  \n",
       "45           0.980007           0.978731           0.968031  \n",
       "46           0.980007           0.978731           0.968031  \n",
       "47           0.976692           0.975410           0.964644  \n",
       "48           0.921622           0.920106           0.909178  \n",
       "49           0.980007           0.978731           0.968031  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_score_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>1-gram</th>\n",
       "      <th>2-gram</th>\n",
       "      <th>3-gram</th>\n",
       "      <th>4-gram</th>\n",
       "      <th>cumulative-1-gram</th>\n",
       "      <th>cumulative-2-gram</th>\n",
       "      <th>cumulative-3-gram</th>\n",
       "      <th>cumulative-4-gram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0.004903</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.004903</td>\n",
       "      <td>0.001112</td>\n",
       "      <td>0.000644</td>\n",
       "      <td>0.000460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>0.009442</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>0.000966</td>\n",
       "      <td>0.001229</td>\n",
       "      <td>0.009442</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>0.001934</td>\n",
       "      <td>0.001660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>0.026292</td>\n",
       "      <td>0.007027</td>\n",
       "      <td>0.003490</td>\n",
       "      <td>0.004435</td>\n",
       "      <td>0.026292</td>\n",
       "      <td>0.012309</td>\n",
       "      <td>0.007752</td>\n",
       "      <td>0.006308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>0.108800</td>\n",
       "      <td>0.079267</td>\n",
       "      <td>0.068468</td>\n",
       "      <td>0.061633</td>\n",
       "      <td>0.108800</td>\n",
       "      <td>0.088711</td>\n",
       "      <td>0.078672</td>\n",
       "      <td>0.071751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>0.185021</td>\n",
       "      <td>0.159121</td>\n",
       "      <td>0.150455</td>\n",
       "      <td>0.121467</td>\n",
       "      <td>0.185021</td>\n",
       "      <td>0.166140</td>\n",
       "      <td>0.158620</td>\n",
       "      <td>0.140903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>0.263746</td>\n",
       "      <td>0.246038</td>\n",
       "      <td>0.242323</td>\n",
       "      <td>0.239587</td>\n",
       "      <td>0.263746</td>\n",
       "      <td>0.250493</td>\n",
       "      <td>0.247097</td>\n",
       "      <td>0.244367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>70</td>\n",
       "      <td>0.320986</td>\n",
       "      <td>0.293362</td>\n",
       "      <td>0.285651</td>\n",
       "      <td>0.257836</td>\n",
       "      <td>0.320986</td>\n",
       "      <td>0.300694</td>\n",
       "      <td>0.293869</td>\n",
       "      <td>0.277458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>80</td>\n",
       "      <td>0.242649</td>\n",
       "      <td>0.227480</td>\n",
       "      <td>0.222661</td>\n",
       "      <td>0.193203</td>\n",
       "      <td>0.242649</td>\n",
       "      <td>0.232031</td>\n",
       "      <td>0.228439</td>\n",
       "      <td>0.212286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>90</td>\n",
       "      <td>0.432147</td>\n",
       "      <td>0.404531</td>\n",
       "      <td>0.392861</td>\n",
       "      <td>0.364574</td>\n",
       "      <td>0.432147</td>\n",
       "      <td>0.413350</td>\n",
       "      <td>0.403624</td>\n",
       "      <td>0.386366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100</td>\n",
       "      <td>0.507660</td>\n",
       "      <td>0.483261</td>\n",
       "      <td>0.478088</td>\n",
       "      <td>0.453176</td>\n",
       "      <td>0.507660</td>\n",
       "      <td>0.490509</td>\n",
       "      <td>0.484345</td>\n",
       "      <td>0.469929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>110</td>\n",
       "      <td>0.483896</td>\n",
       "      <td>0.456369</td>\n",
       "      <td>0.444460</td>\n",
       "      <td>0.415887</td>\n",
       "      <td>0.483896</td>\n",
       "      <td>0.465294</td>\n",
       "      <td>0.455557</td>\n",
       "      <td>0.438302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>120</td>\n",
       "      <td>0.437754</td>\n",
       "      <td>0.421454</td>\n",
       "      <td>0.415984</td>\n",
       "      <td>0.388430</td>\n",
       "      <td>0.437754</td>\n",
       "      <td>0.426591</td>\n",
       "      <td>0.422013</td>\n",
       "      <td>0.406961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>130</td>\n",
       "      <td>0.510480</td>\n",
       "      <td>0.488751</td>\n",
       "      <td>0.482970</td>\n",
       "      <td>0.457609</td>\n",
       "      <td>0.510480</td>\n",
       "      <td>0.495681</td>\n",
       "      <td>0.489819</td>\n",
       "      <td>0.475120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>140</td>\n",
       "      <td>0.524839</td>\n",
       "      <td>0.501995</td>\n",
       "      <td>0.495619</td>\n",
       "      <td>0.469555</td>\n",
       "      <td>0.524839</td>\n",
       "      <td>0.509432</td>\n",
       "      <td>0.503532</td>\n",
       "      <td>0.488123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>150</td>\n",
       "      <td>0.505490</td>\n",
       "      <td>0.483564</td>\n",
       "      <td>0.477963</td>\n",
       "      <td>0.452653</td>\n",
       "      <td>0.505490</td>\n",
       "      <td>0.490765</td>\n",
       "      <td>0.485465</td>\n",
       "      <td>0.470692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>160</td>\n",
       "      <td>0.531013</td>\n",
       "      <td>0.507112</td>\n",
       "      <td>0.505563</td>\n",
       "      <td>0.480497</td>\n",
       "      <td>0.531013</td>\n",
       "      <td>0.513766</td>\n",
       "      <td>0.510584</td>\n",
       "      <td>0.496304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>170</td>\n",
       "      <td>0.532765</td>\n",
       "      <td>0.507767</td>\n",
       "      <td>0.499139</td>\n",
       "      <td>0.474170</td>\n",
       "      <td>0.532765</td>\n",
       "      <td>0.514459</td>\n",
       "      <td>0.507068</td>\n",
       "      <td>0.492016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>180</td>\n",
       "      <td>0.530244</td>\n",
       "      <td>0.509802</td>\n",
       "      <td>0.501318</td>\n",
       "      <td>0.476794</td>\n",
       "      <td>0.530244</td>\n",
       "      <td>0.515295</td>\n",
       "      <td>0.507952</td>\n",
       "      <td>0.493441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>190</td>\n",
       "      <td>0.510641</td>\n",
       "      <td>0.492023</td>\n",
       "      <td>0.483380</td>\n",
       "      <td>0.458685</td>\n",
       "      <td>0.510641</td>\n",
       "      <td>0.497345</td>\n",
       "      <td>0.490229</td>\n",
       "      <td>0.475495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>200</td>\n",
       "      <td>0.528273</td>\n",
       "      <td>0.511924</td>\n",
       "      <td>0.503234</td>\n",
       "      <td>0.478446</td>\n",
       "      <td>0.528273</td>\n",
       "      <td>0.516939</td>\n",
       "      <td>0.510023</td>\n",
       "      <td>0.495268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>210</td>\n",
       "      <td>0.526692</td>\n",
       "      <td>0.511599</td>\n",
       "      <td>0.503287</td>\n",
       "      <td>0.478808</td>\n",
       "      <td>0.526692</td>\n",
       "      <td>0.516268</td>\n",
       "      <td>0.509753</td>\n",
       "      <td>0.495430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>220</td>\n",
       "      <td>0.526331</td>\n",
       "      <td>0.511732</td>\n",
       "      <td>0.503165</td>\n",
       "      <td>0.478522</td>\n",
       "      <td>0.526331</td>\n",
       "      <td>0.516438</td>\n",
       "      <td>0.509727</td>\n",
       "      <td>0.495250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>230</td>\n",
       "      <td>0.515802</td>\n",
       "      <td>0.498687</td>\n",
       "      <td>0.489896</td>\n",
       "      <td>0.465270</td>\n",
       "      <td>0.515802</td>\n",
       "      <td>0.503945</td>\n",
       "      <td>0.496699</td>\n",
       "      <td>0.482093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>240</td>\n",
       "      <td>0.437668</td>\n",
       "      <td>0.413855</td>\n",
       "      <td>0.411185</td>\n",
       "      <td>0.384442</td>\n",
       "      <td>0.437668</td>\n",
       "      <td>0.420017</td>\n",
       "      <td>0.416094</td>\n",
       "      <td>0.400905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>250</td>\n",
       "      <td>0.565869</td>\n",
       "      <td>0.540792</td>\n",
       "      <td>0.536132</td>\n",
       "      <td>0.510552</td>\n",
       "      <td>0.565869</td>\n",
       "      <td>0.547519</td>\n",
       "      <td>0.542213</td>\n",
       "      <td>0.527931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>260</td>\n",
       "      <td>0.570275</td>\n",
       "      <td>0.551283</td>\n",
       "      <td>0.545903</td>\n",
       "      <td>0.517965</td>\n",
       "      <td>0.570275</td>\n",
       "      <td>0.556275</td>\n",
       "      <td>0.551232</td>\n",
       "      <td>0.536419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>270</td>\n",
       "      <td>0.580203</td>\n",
       "      <td>0.553247</td>\n",
       "      <td>0.547492</td>\n",
       "      <td>0.519630</td>\n",
       "      <td>0.580203</td>\n",
       "      <td>0.560526</td>\n",
       "      <td>0.554077</td>\n",
       "      <td>0.538916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>280</td>\n",
       "      <td>0.585840</td>\n",
       "      <td>0.558688</td>\n",
       "      <td>0.552584</td>\n",
       "      <td>0.526105</td>\n",
       "      <td>0.585840</td>\n",
       "      <td>0.566391</td>\n",
       "      <td>0.559318</td>\n",
       "      <td>0.544219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>290</td>\n",
       "      <td>0.590943</td>\n",
       "      <td>0.565112</td>\n",
       "      <td>0.560541</td>\n",
       "      <td>0.534635</td>\n",
       "      <td>0.590943</td>\n",
       "      <td>0.572210</td>\n",
       "      <td>0.566590</td>\n",
       "      <td>0.551721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>300</td>\n",
       "      <td>0.586728</td>\n",
       "      <td>0.562156</td>\n",
       "      <td>0.558152</td>\n",
       "      <td>0.533111</td>\n",
       "      <td>0.586728</td>\n",
       "      <td>0.568991</td>\n",
       "      <td>0.563601</td>\n",
       "      <td>0.549201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>310</td>\n",
       "      <td>0.605030</td>\n",
       "      <td>0.578561</td>\n",
       "      <td>0.574032</td>\n",
       "      <td>0.548140</td>\n",
       "      <td>0.605030</td>\n",
       "      <td>0.585704</td>\n",
       "      <td>0.579942</td>\n",
       "      <td>0.565205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>320</td>\n",
       "      <td>0.604942</td>\n",
       "      <td>0.578201</td>\n",
       "      <td>0.571685</td>\n",
       "      <td>0.546543</td>\n",
       "      <td>0.604942</td>\n",
       "      <td>0.585952</td>\n",
       "      <td>0.578574</td>\n",
       "      <td>0.563273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>330</td>\n",
       "      <td>0.612332</td>\n",
       "      <td>0.582051</td>\n",
       "      <td>0.572398</td>\n",
       "      <td>0.547266</td>\n",
       "      <td>0.612332</td>\n",
       "      <td>0.591055</td>\n",
       "      <td>0.581185</td>\n",
       "      <td>0.565065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>340</td>\n",
       "      <td>0.643911</td>\n",
       "      <td>0.616702</td>\n",
       "      <td>0.611064</td>\n",
       "      <td>0.586926</td>\n",
       "      <td>0.643911</td>\n",
       "      <td>0.624414</td>\n",
       "      <td>0.617322</td>\n",
       "      <td>0.602943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>350</td>\n",
       "      <td>0.634088</td>\n",
       "      <td>0.599502</td>\n",
       "      <td>0.596244</td>\n",
       "      <td>0.572653</td>\n",
       "      <td>0.634088</td>\n",
       "      <td>0.608144</td>\n",
       "      <td>0.602307</td>\n",
       "      <td>0.588498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>360</td>\n",
       "      <td>0.691606</td>\n",
       "      <td>0.668368</td>\n",
       "      <td>0.667492</td>\n",
       "      <td>0.643015</td>\n",
       "      <td>0.691606</td>\n",
       "      <td>0.674329</td>\n",
       "      <td>0.671228</td>\n",
       "      <td>0.657971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>370</td>\n",
       "      <td>0.732011</td>\n",
       "      <td>0.709005</td>\n",
       "      <td>0.707906</td>\n",
       "      <td>0.682889</td>\n",
       "      <td>0.732011</td>\n",
       "      <td>0.714860</td>\n",
       "      <td>0.712049</td>\n",
       "      <td>0.698498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>380</td>\n",
       "      <td>0.745481</td>\n",
       "      <td>0.724424</td>\n",
       "      <td>0.721279</td>\n",
       "      <td>0.696187</td>\n",
       "      <td>0.745481</td>\n",
       "      <td>0.730305</td>\n",
       "      <td>0.726161</td>\n",
       "      <td>0.712275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>390</td>\n",
       "      <td>0.741307</td>\n",
       "      <td>0.723355</td>\n",
       "      <td>0.720457</td>\n",
       "      <td>0.695692</td>\n",
       "      <td>0.741307</td>\n",
       "      <td>0.728428</td>\n",
       "      <td>0.724682</td>\n",
       "      <td>0.711176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>400</td>\n",
       "      <td>0.730380</td>\n",
       "      <td>0.710933</td>\n",
       "      <td>0.709888</td>\n",
       "      <td>0.684796</td>\n",
       "      <td>0.730380</td>\n",
       "      <td>0.716008</td>\n",
       "      <td>0.713679</td>\n",
       "      <td>0.700172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>410</td>\n",
       "      <td>0.750583</td>\n",
       "      <td>0.725901</td>\n",
       "      <td>0.724665</td>\n",
       "      <td>0.699379</td>\n",
       "      <td>0.750583</td>\n",
       "      <td>0.732778</td>\n",
       "      <td>0.729678</td>\n",
       "      <td>0.715729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>420</td>\n",
       "      <td>0.762480</td>\n",
       "      <td>0.738921</td>\n",
       "      <td>0.737922</td>\n",
       "      <td>0.712855</td>\n",
       "      <td>0.762480</td>\n",
       "      <td>0.745483</td>\n",
       "      <td>0.742623</td>\n",
       "      <td>0.728975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>430</td>\n",
       "      <td>0.763633</td>\n",
       "      <td>0.738941</td>\n",
       "      <td>0.737943</td>\n",
       "      <td>0.712876</td>\n",
       "      <td>0.763633</td>\n",
       "      <td>0.745619</td>\n",
       "      <td>0.742698</td>\n",
       "      <td>0.729027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>440</td>\n",
       "      <td>0.764867</td>\n",
       "      <td>0.739030</td>\n",
       "      <td>0.738034</td>\n",
       "      <td>0.712970</td>\n",
       "      <td>0.764867</td>\n",
       "      <td>0.745922</td>\n",
       "      <td>0.742899</td>\n",
       "      <td>0.729188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>450</td>\n",
       "      <td>0.760585</td>\n",
       "      <td>0.735565</td>\n",
       "      <td>0.734686</td>\n",
       "      <td>0.709743</td>\n",
       "      <td>0.760585</td>\n",
       "      <td>0.742176</td>\n",
       "      <td>0.739255</td>\n",
       "      <td>0.725691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>460</td>\n",
       "      <td>0.760172</td>\n",
       "      <td>0.735632</td>\n",
       "      <td>0.734679</td>\n",
       "      <td>0.709736</td>\n",
       "      <td>0.760172</td>\n",
       "      <td>0.742302</td>\n",
       "      <td>0.739283</td>\n",
       "      <td>0.725700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>470</td>\n",
       "      <td>0.762448</td>\n",
       "      <td>0.735836</td>\n",
       "      <td>0.734717</td>\n",
       "      <td>0.709774</td>\n",
       "      <td>0.762448</td>\n",
       "      <td>0.742869</td>\n",
       "      <td>0.739517</td>\n",
       "      <td>0.725842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>480</td>\n",
       "      <td>0.759519</td>\n",
       "      <td>0.733779</td>\n",
       "      <td>0.732674</td>\n",
       "      <td>0.707688</td>\n",
       "      <td>0.759519</td>\n",
       "      <td>0.740661</td>\n",
       "      <td>0.737451</td>\n",
       "      <td>0.723778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>490</td>\n",
       "      <td>0.718795</td>\n",
       "      <td>0.691334</td>\n",
       "      <td>0.689329</td>\n",
       "      <td>0.664039</td>\n",
       "      <td>0.718795</td>\n",
       "      <td>0.698739</td>\n",
       "      <td>0.695012</td>\n",
       "      <td>0.680954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>500</td>\n",
       "      <td>0.818541</td>\n",
       "      <td>0.795101</td>\n",
       "      <td>0.792783</td>\n",
       "      <td>0.767156</td>\n",
       "      <td>0.818541</td>\n",
       "      <td>0.801820</td>\n",
       "      <td>0.798406</td>\n",
       "      <td>0.784266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Epoch    1-gram    2-gram    3-gram    4-gram  cumulative-1-gram  \\\n",
       "0     10  0.004903  0.000341  0.000206  0.000209           0.004903   \n",
       "1     20  0.009442  0.000815  0.000966  0.001229           0.009442   \n",
       "2     30  0.026292  0.007027  0.003490  0.004435           0.026292   \n",
       "3     40  0.108800  0.079267  0.068468  0.061633           0.108800   \n",
       "4     50  0.185021  0.159121  0.150455  0.121467           0.185021   \n",
       "5     60  0.263746  0.246038  0.242323  0.239587           0.263746   \n",
       "6     70  0.320986  0.293362  0.285651  0.257836           0.320986   \n",
       "7     80  0.242649  0.227480  0.222661  0.193203           0.242649   \n",
       "8     90  0.432147  0.404531  0.392861  0.364574           0.432147   \n",
       "9    100  0.507660  0.483261  0.478088  0.453176           0.507660   \n",
       "10   110  0.483896  0.456369  0.444460  0.415887           0.483896   \n",
       "11   120  0.437754  0.421454  0.415984  0.388430           0.437754   \n",
       "12   130  0.510480  0.488751  0.482970  0.457609           0.510480   \n",
       "13   140  0.524839  0.501995  0.495619  0.469555           0.524839   \n",
       "14   150  0.505490  0.483564  0.477963  0.452653           0.505490   \n",
       "15   160  0.531013  0.507112  0.505563  0.480497           0.531013   \n",
       "16   170  0.532765  0.507767  0.499139  0.474170           0.532765   \n",
       "17   180  0.530244  0.509802  0.501318  0.476794           0.530244   \n",
       "18   190  0.510641  0.492023  0.483380  0.458685           0.510641   \n",
       "19   200  0.528273  0.511924  0.503234  0.478446           0.528273   \n",
       "20   210  0.526692  0.511599  0.503287  0.478808           0.526692   \n",
       "21   220  0.526331  0.511732  0.503165  0.478522           0.526331   \n",
       "22   230  0.515802  0.498687  0.489896  0.465270           0.515802   \n",
       "23   240  0.437668  0.413855  0.411185  0.384442           0.437668   \n",
       "24   250  0.565869  0.540792  0.536132  0.510552           0.565869   \n",
       "25   260  0.570275  0.551283  0.545903  0.517965           0.570275   \n",
       "26   270  0.580203  0.553247  0.547492  0.519630           0.580203   \n",
       "27   280  0.585840  0.558688  0.552584  0.526105           0.585840   \n",
       "28   290  0.590943  0.565112  0.560541  0.534635           0.590943   \n",
       "29   300  0.586728  0.562156  0.558152  0.533111           0.586728   \n",
       "30   310  0.605030  0.578561  0.574032  0.548140           0.605030   \n",
       "31   320  0.604942  0.578201  0.571685  0.546543           0.604942   \n",
       "32   330  0.612332  0.582051  0.572398  0.547266           0.612332   \n",
       "33   340  0.643911  0.616702  0.611064  0.586926           0.643911   \n",
       "34   350  0.634088  0.599502  0.596244  0.572653           0.634088   \n",
       "35   360  0.691606  0.668368  0.667492  0.643015           0.691606   \n",
       "36   370  0.732011  0.709005  0.707906  0.682889           0.732011   \n",
       "37   380  0.745481  0.724424  0.721279  0.696187           0.745481   \n",
       "38   390  0.741307  0.723355  0.720457  0.695692           0.741307   \n",
       "39   400  0.730380  0.710933  0.709888  0.684796           0.730380   \n",
       "40   410  0.750583  0.725901  0.724665  0.699379           0.750583   \n",
       "41   420  0.762480  0.738921  0.737922  0.712855           0.762480   \n",
       "42   430  0.763633  0.738941  0.737943  0.712876           0.763633   \n",
       "43   440  0.764867  0.739030  0.738034  0.712970           0.764867   \n",
       "44   450  0.760585  0.735565  0.734686  0.709743           0.760585   \n",
       "45   460  0.760172  0.735632  0.734679  0.709736           0.760172   \n",
       "46   470  0.762448  0.735836  0.734717  0.709774           0.762448   \n",
       "47   480  0.759519  0.733779  0.732674  0.707688           0.759519   \n",
       "48   490  0.718795  0.691334  0.689329  0.664039           0.718795   \n",
       "49   500  0.818541  0.795101  0.792783  0.767156           0.818541   \n",
       "\n",
       "    cumulative-2-gram  cumulative-3-gram  cumulative-4-gram  \n",
       "0            0.001112           0.000644           0.000460  \n",
       "1            0.002631           0.001934           0.001660  \n",
       "2            0.012309           0.007752           0.006308  \n",
       "3            0.088711           0.078672           0.071751  \n",
       "4            0.166140           0.158620           0.140903  \n",
       "5            0.250493           0.247097           0.244367  \n",
       "6            0.300694           0.293869           0.277458  \n",
       "7            0.232031           0.228439           0.212286  \n",
       "8            0.413350           0.403624           0.386366  \n",
       "9            0.490509           0.484345           0.469929  \n",
       "10           0.465294           0.455557           0.438302  \n",
       "11           0.426591           0.422013           0.406961  \n",
       "12           0.495681           0.489819           0.475120  \n",
       "13           0.509432           0.503532           0.488123  \n",
       "14           0.490765           0.485465           0.470692  \n",
       "15           0.513766           0.510584           0.496304  \n",
       "16           0.514459           0.507068           0.492016  \n",
       "17           0.515295           0.507952           0.493441  \n",
       "18           0.497345           0.490229           0.475495  \n",
       "19           0.516939           0.510023           0.495268  \n",
       "20           0.516268           0.509753           0.495430  \n",
       "21           0.516438           0.509727           0.495250  \n",
       "22           0.503945           0.496699           0.482093  \n",
       "23           0.420017           0.416094           0.400905  \n",
       "24           0.547519           0.542213           0.527931  \n",
       "25           0.556275           0.551232           0.536419  \n",
       "26           0.560526           0.554077           0.538916  \n",
       "27           0.566391           0.559318           0.544219  \n",
       "28           0.572210           0.566590           0.551721  \n",
       "29           0.568991           0.563601           0.549201  \n",
       "30           0.585704           0.579942           0.565205  \n",
       "31           0.585952           0.578574           0.563273  \n",
       "32           0.591055           0.581185           0.565065  \n",
       "33           0.624414           0.617322           0.602943  \n",
       "34           0.608144           0.602307           0.588498  \n",
       "35           0.674329           0.671228           0.657971  \n",
       "36           0.714860           0.712049           0.698498  \n",
       "37           0.730305           0.726161           0.712275  \n",
       "38           0.728428           0.724682           0.711176  \n",
       "39           0.716008           0.713679           0.700172  \n",
       "40           0.732778           0.729678           0.715729  \n",
       "41           0.745483           0.742623           0.728975  \n",
       "42           0.745619           0.742698           0.729027  \n",
       "43           0.745922           0.742899           0.729188  \n",
       "44           0.742176           0.739255           0.725691  \n",
       "45           0.742302           0.739283           0.725700  \n",
       "46           0.742869           0.739517           0.725842  \n",
       "47           0.740661           0.737451           0.723778  \n",
       "48           0.698739           0.695012           0.680954  \n",
       "49           0.801820           0.798406           0.784266  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_score_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fe61aeae500>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 936x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(13, 6))\n",
    "plt.plot(bleu_score_eval['Epoch'], bleu_score_eval['1-gram'], label='Eval 1-gram')\n",
    "plt.plot(bleu_score_eval['Epoch'], bleu_score_eval['2-gram'], label='Eval 2-gram')\n",
    "plt.plot(bleu_score_eval['Epoch'], bleu_score_eval['3-gram'], label='Eval 3-gram')\n",
    "plt.plot(bleu_score_eval['Epoch'], bleu_score_eval['4-gram'], label='Eval 4-gram')\n",
    "plt.plot(bleu_score_eval['Epoch'], bleu_score_eval['cumulative-1-gram'], label='Eval cumulative-1-gram')\n",
    "plt.plot(bleu_score_eval['Epoch'], bleu_score_eval['cumulative-2-gram'], label='Eval cumulative-2-gram')\n",
    "plt.plot(bleu_score_eval['Epoch'], bleu_score_eval['cumulative-3-gram'], label='Eval cumulative-3-gram')\n",
    "plt.plot(bleu_score_eval['Epoch'], bleu_score_eval['cumulative-4-gram'], label='Eval cumulative-4-gram')\n",
    "plt.plot(bleu_score_train['Epoch'], bleu_score_train['1-gram'], label='Train 1-gram')\n",
    "plt.plot(bleu_score_train['Epoch'], bleu_score_train['2-gram'], label='Train 2-gram')\n",
    "plt.plot(bleu_score_train['Epoch'], bleu_score_train['3-gram'], label='Train 3-gram')\n",
    "plt.plot(bleu_score_train['Epoch'], bleu_score_train['4-gram'], label='Train 4-gram')\n",
    "plt.plot(bleu_score_train['Epoch'], bleu_score_train['cumulative-1-gram'], label='Train cumulative-1-gram')\n",
    "plt.plot(bleu_score_train['Epoch'], bleu_score_train['cumulative-2-gram'], label='Train cumulative-2-gram')\n",
    "plt.plot(bleu_score_train['Epoch'], bleu_score_train['cumulative-3-gram'], label='Train cumulative-3-gram')\n",
    "plt.plot(bleu_score_train['Epoch'], bleu_score_train['cumulative-4-gram'], label='Train cumulative-4-gram')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('BLEU Score')\n",
    "plt.ylim(0, 1)\n",
    "plt.title('BLEU Score on 5 PRE Token')\n",
    "# make legend smaller\n",
    "plt.legend(fontsize='small')\n",
    "# add number for each 100 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best BLEU Score on Eval: 0.7843 at Epoch 500\n",
      "Train Score: 0.9680\n"
     ]
    }
   ],
   "source": [
    "# get best 4-cumulative-gram row, outuput eppoch and other score\n",
    "best_row = bleu_score_eval.loc[bleu_score_eval['cumulative-4-gram'].idxmax()]\n",
    "best_epoch = best_row['Epoch']\n",
    "best_score = best_row['cumulative-4-gram']\n",
    "print(f'Best BLEU Score on Eval: {best_score:.4f} at Epoch {best_epoch}')\n",
    "train_score = bleu_score_train.loc[bleu_score_train['Epoch'] == best_epoch]\n",
    "print(f'Train Score: {train_score[\"cumulative-4-gram\"].values[0]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1-gram': 0.9768651030864939,\n",
       " '2-gram': 0.9415404542175729,\n",
       " '3-gram': 0.9370405952906978,\n",
       " '4-gram': 0.8396151845702171,\n",
       " 'cumulative-1-gram': 0.9768651030864939,\n",
       " 'cumulative-2-gram': 0.9513911623347994,\n",
       " 'cumulative-3-gram': 0.9455563688405594,\n",
       " 'cumulative-4-gram': 0.894932663509144}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_result_2 = count_bleu_score(model, answers, questions)\n",
    "bleu_result_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q >>> fitra bachtiar penelitian apa \n",
      "A <<< affective computing, affective engineering, intelligent system, data mining, educational data mining\n"
     ]
    }
   ],
   "source": [
    "test_question = \"fitra bachtiar penelitian apa \"\n",
    "outputs = model.generate(test_question)\n",
    "decoded_output = model.dec_tokenizer.decode(outputs[0])\n",
    "print(f'Q >>> {test_question}')\n",
    "print(f'A <<< {decoded_output}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q >>> pak fitra topik penelitian\n",
      "A <<< affective computing, affective engineering, intelligent system, data mining, educational data mining\n"
     ]
    }
   ],
   "source": [
    "test_question = \"pak fitra topik penelitian\"\n",
    "outputs = model.generate(test_question)\n",
    "decoded_output = model.dec_tokenizer.decode(outputs[0])\n",
    "print(f'Q >>> {test_question}')\n",
    "print(f'A <<< {decoded_output}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_question = \"ketua bpj teh saha ieu\"\n",
    "outputs = model.generate(test_question)\n",
    "decoded_output = model.dec_tokenizer.decode(outputs[0])\n",
    "print(f'Q >>> {test_question}')\n",
    "print(f'A <<< {decoded_output}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q >>> sekdep sistem informasi teh saha\n",
      "A <<< satrio agung wicaksono, s.kom., m.kom\n"
     ]
    }
   ],
   "source": [
    "test_question = \"sekdep sistem informasi teh saha\"\n",
    "outputs = model.generate(test_question)\n",
    "decoded_output = model.dec_tokenizer.decode(outputs[0])\n",
    "print(f'Q >>> {test_question}')\n",
    "print(f'A <<< {decoded_output}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(qa_paired_eval)):\n",
    "    test_question = qa_paired_eval['Pertanyaan'].iloc[i]\n",
    "    outputs = model.generate(test_question)\n",
    "    decoded_output = model.dec_tokenizer.decode(outputs[0])\n",
    "    qa_paired_eval.loc[i, 'Predicted Answer'] = decoded_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_paired_eval.to_excel('qa_paired_eval_101024_5PRE.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'FLUENTSOTA_101024_5PRE.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = torch.load('FLUENTSOTA_051024.pth')\n",
    "model.load_state_dict(state_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
