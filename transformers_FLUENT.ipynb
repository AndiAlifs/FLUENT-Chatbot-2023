{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "import torch.utils.data\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "import neptune\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pertanyaan</th>\n",
       "      <th>Jawaban</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>email Fitra A. Bachtiar</td>\n",
       "      <td>fitra.bachtiar[at]ub.ac.id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NIK/NIP Fitra A. Bachtiar</td>\n",
       "      <td>198406282019031006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nama lengkap Fitra A. Bachtiar</td>\n",
       "      <td>Dr.Eng. Fitra A. Bachtiar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Departemen Fitra A. Bachtiar</td>\n",
       "      <td>Departemen Teknik Informatika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Program Studi Fitra A. Bachtiar</td>\n",
       "      <td>S2 Ilmu Komputer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>Apa Manfaat Konseling FILKOM ?</td>\n",
       "      <td>1. Masalah ditangani oleh ahli yang kompeten d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>Berikan informasi mengenai Layanan Konseling</td>\n",
       "      <td>Informasi mengenai Layanan Konseling dapat dia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>Siapa Konselor Bimbingan dan Konseling di FILK...</td>\n",
       "      <td>Ada 2 konselor Bimbingan dan Konseling di FILK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>Siapa Koordinator Konselor Sebaya ?</td>\n",
       "      <td>Koordinator Konselor Sebaya adalah Muhammad Da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>Berikan Rincian Layanan ULTKSP</td>\n",
       "      <td>Rincian Layanan ULTKSP dapat diakses pada taut...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1198 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Pertanyaan  \\\n",
       "0                               email Fitra A. Bachtiar   \n",
       "1                             NIK/NIP Fitra A. Bachtiar   \n",
       "2                        nama lengkap Fitra A. Bachtiar   \n",
       "3                          Departemen Fitra A. Bachtiar   \n",
       "4                       Program Studi Fitra A. Bachtiar   \n",
       "...                                                 ...   \n",
       "1229                     Apa Manfaat Konseling FILKOM ?   \n",
       "1230       Berikan informasi mengenai Layanan Konseling   \n",
       "1231  Siapa Konselor Bimbingan dan Konseling di FILK...   \n",
       "1232                Siapa Koordinator Konselor Sebaya ?   \n",
       "1233                     Berikan Rincian Layanan ULTKSP   \n",
       "\n",
       "                                                Jawaban  \n",
       "0                            fitra.bachtiar[at]ub.ac.id  \n",
       "1                                    198406282019031006  \n",
       "2                             Dr.Eng. Fitra A. Bachtiar  \n",
       "3                         Departemen Teknik Informatika  \n",
       "4                                      S2 Ilmu Komputer  \n",
       "...                                                 ...  \n",
       "1229  1. Masalah ditangani oleh ahli yang kompeten d...  \n",
       "1230  Informasi mengenai Layanan Konseling dapat dia...  \n",
       "1231  Ada 2 konselor Bimbingan dan Konseling di FILK...  \n",
       "1232  Koordinator Konselor Sebaya adalah Muhammad Da...  \n",
       "1233  Rincian Layanan ULTKSP dapat diakses pada taut...  \n",
       "\n",
       "[1198 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knowledgebase_url = 'https://github.com/AndiAlifs/FLUENT-Chatbot-2023/raw/main/KnowledgeBaseFilkom.xlsx'\n",
    "knowledgebase = pd.read_excel(knowledgebase_url)\n",
    "\n",
    "qa_paired = knowledgebase.drop(columns=knowledgebase.columns.drop(['Pertanyaan', 'Jawaban']))\n",
    "qa_paired.dropna(inplace=True)\n",
    "qa_paired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc(string):\n",
    "    punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "    no_punct = \"\"\n",
    "    for char in string:\n",
    "        if char not in punctuations:\n",
    "            no_punct = no_punct + char  # space is also a character\n",
    "    return no_punct.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = []\n",
    "max_len = 90\n",
    "\n",
    "for line in qa_paired.iterrows():\n",
    "    pertanyaan = line[1]['Pertanyaan']\n",
    "    jawaban = line[1]['Jawaban']\n",
    "    qa_pairs = []\n",
    "    first = remove_punc(pertanyaan.strip())      \n",
    "    second = remove_punc(jawaban.strip())\n",
    "    qa_pairs.append(first.split()[:max_len])\n",
    "    qa_pairs.append(second.split()[:max_len])\n",
    "    pairs.append(qa_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq = Counter()\n",
    "for pair in pairs:\n",
    "    word_freq.update(pair[0])\n",
    "    word_freq.update(pair[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_word_freq = 2\n",
    "words = [w for w in word_freq.keys() if word_freq[w] > min_word_freq]\n",
    "word_map = {k: v + 1 for v, k in enumerate(words)}\n",
    "word_map['<unk>'] = len(word_map) + 1\n",
    "word_map['<start>'] = len(word_map) + 1\n",
    "word_map['<end>'] = len(word_map) + 1\n",
    "word_map['<pad>'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words are: 1079\n"
     ]
    }
   ],
   "source": [
    "print(\"Total words are: {}\".format(len(word_map)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('WORDMAP_corpus_KBFILKOM.json', 'w') as j:\n",
    "    json.dump(word_map, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_question(words, word_map):\n",
    "    enc_c = [word_map.get(word, word_map['<unk>']) for word in words] + [word_map['<pad>']] * (max_len - len(words))\n",
    "    return enc_c\n",
    "\n",
    "def encode_reply(words, word_map):\n",
    "    enc_c = [word_map['<start>']] + [word_map.get(word, word_map['<unk>']) for word in words] + \\\n",
    "    [word_map['<end>']] + [word_map['<pad>']] * (max_len - len(words))\n",
    "    return enc_c\n",
    "\n",
    "def encode_reply_with_maxlen(words, word_map):\n",
    "    enc_c = [word_map['<start>']] + [word_map.get(word, word_map['<unk>']) for word in words] + [word_map['<end>']] + [word_map['<pad>']] * (max_len-2 - len(words))\n",
    "    return enc_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_encoded = []\n",
    "for pair in pairs:\n",
    "    qus = encode_question(pair[0], word_map)\n",
    "    ans = encode_reply(pair[1], word_map)\n",
    "    pairs_encoded.append([qus, ans])\n",
    "\n",
    "with open('pairs_encoded_kbfilkom.json', 'w') as p:\n",
    "    json.dump(pairs_encoded, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_encoded_same_length = []\n",
    "for pair in pairs:\n",
    "    qus = encode_question(pair[0], word_map)\n",
    "    ans = encode_reply_with_maxlen(pair[1], word_map)\n",
    "    pairs_encoded_same_length.append([qus, ans])\n",
    "\n",
    "with open('pairs_encoded_kbfilkom_same_len.json', 'w') as p:\n",
    "    json.dump(pairs_encoded_same_length, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'apa tujuan filkom <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_word_map = {v: k for k, v in word_map.items()}\n",
    "' '.join([rev_word_map[v] for v in pairs_encoded[15][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.pairs = json.load(open('pairs_encoded_kbfilkom.json'))\n",
    "        self.dataset_size = len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        question = torch.LongTensor(self.pairs[i][0])\n",
    "        reply = torch.LongTensor(self.pairs[i][1])\n",
    "            \n",
    "        return question, reply\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_Same_Len(Dataset):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.pairs = json.load(open('pairs_encoded_kbfilkom_same_len.json'))\n",
    "        self.dataset_size = len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        question = torch.LongTensor(self.pairs[i][0])\n",
    "        reply = torch.LongTensor(self.pairs[i][1])\n",
    "            \n",
    "        return question, reply\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(Dataset(),\n",
    "                                           batch_size = 50, \n",
    "                                           shuffle=True, \n",
    "                                           pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masks(question, reply_input, reply_target):\n",
    "    \n",
    "    def subsequent_mask(size):\n",
    "        mask = torch.triu(torch.ones(size, size)).transpose(0, 1).type(dtype=torch.uint8)\n",
    "        return mask.unsqueeze(0)\n",
    "    \n",
    "    question_mask = question!=0\n",
    "    question_mask = question_mask.to(device)\n",
    "    question_mask = question_mask.unsqueeze(1).unsqueeze(1)         # (batch_size, 1, 1, max_words)\n",
    "     \n",
    "    reply_input_mask = reply_input!=0\n",
    "    reply_input_mask = reply_input_mask.unsqueeze(1)  # (batch_size, 1, max_words)\n",
    "    reply_input_mask = reply_input_mask & subsequent_mask(reply_input.size(-1)).type_as(reply_input_mask.data) \n",
    "    reply_input_mask = reply_input_mask.unsqueeze(1) # (batch_size, 1, max_words, max_words)\n",
    "    reply_target_mask = reply_target!=0              # (batch_size, max_words)\n",
    "    \n",
    "    return question_mask, reply_input_mask, reply_target_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def create_directory(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "        print(f\"Directory created at {path}\")\n",
    "    else:\n",
    "        print(f\"Directory already exists at {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embeddings(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements embeddings of the words and adds their positional encodings. \n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, d_model, max_len = 50, num_layers = 6):\n",
    "        super(Embeddings, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.embed = nn.Embedding(vocab_size, d_model)\n",
    "        self.pe = self.create_positinal_encoding(max_len, self.d_model)     # (1, max_len, d_model)\n",
    "        self.te = self.create_positinal_encoding(num_layers, self.d_model)  # (1, num_layers, d_model)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "    def create_positinal_encoding(self, max_len, d_model):\n",
    "        pe = torch.zeros(max_len, d_model).to(device)\n",
    "        for pos in range(max_len):   # for each position of the word\n",
    "            for i in range(0, d_model, 2):   # for each dimension of the each position\n",
    "                pe[pos, i] = math.sin(pos / (10000 ** ((2 * i)/d_model)))\n",
    "                pe[pos, i + 1] = math.cos(pos / (10000 ** ((2 * (i + 1))/d_model)))\n",
    "        pe = pe.unsqueeze(0)   # include the batch size\n",
    "        return pe\n",
    "        \n",
    "    def forward(self, embedding, layer_idx):\n",
    "        if layer_idx == 0:\n",
    "            embedding = self.embed(embedding) * math.sqrt(self.d_model)\n",
    "        embedding += self.pe[:, :embedding.size(1)]   # pe will automatically be expanded with the same batch size as encoded_words\n",
    "        # embedding: (batch_size, max_len, d_model), te: (batch_size, 1, d_model)\n",
    "        embedding += self.te[:, layer_idx, :].unsqueeze(1).repeat(1, embedding.size(1), 1)\n",
    "        embedding = self.dropout(embedding)\n",
    "        return embedding\n",
    "\n",
    "class EmbeddingsLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements embeddingsLSTM of the words and adds their positional encodings. \n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, d_model, num_layers = 6):\n",
    "        super(EmbeddingsLSTM, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.embed = nn.Embedding(vocab_size, d_model)\n",
    "        self.lstm = nn.LSTM(d_model, d_model, num_layers=num_layers)\n",
    "        \n",
    "    def forward(self, embedding, layer_idx, hidden, cell_state):\n",
    "        if layer_idx == 0:\n",
    "            embedding = self.embed(embedding) * math.sqrt(self.d_model)\n",
    "        # Pass the embeddings through the LSTM\\\n",
    "        embedding, (hidden, cell_state) = self.lstm(embedding, (hidden, cell_state))\n",
    "        print()\n",
    "        print(embedding.size())\n",
    "        print(embedding)\n",
    "        return embedding, hidden, cell_state\n",
    "\n",
    "class PretrainedEmbedding(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements embeddingsLSTM of the words and adds their positional encodings. \n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, d_model, max_len = 50, num_layers = 6):\n",
    "        super(PretrainedEmbedding, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.embed = nn.Embedding(vocab_size, d_model)\n",
    "        self.pe = self.create_positinal_encoding(max_len, self.d_model)     # (1, max_len, d_model)\n",
    "        self.te = self.create_positinal_encoding(num_layers, self.d_model)  # (1, num_layers, d_model)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "    def create_positinal_encoding(self, max_len, d_model):\n",
    "        pe = torch.zeros(max_len, d_model).to(device)\n",
    "        for pos in range(max_len):   # for each position of the word\n",
    "            for i in range(0, d_model, 2):   # for each dimension of the each position\n",
    "                pe[pos, i] = math.sin(pos / (10000 ** ((2 * i)/d_model)))\n",
    "                pe[pos, i + 1] = math.cos(pos / (10000 ** ((2 * (i + 1))/d_model)))\n",
    "        pe = pe.unsqueeze(0)   # include the batch size\n",
    "        return pe\n",
    "        \n",
    "    def forward(self, embedding, layer_idx):\n",
    "        if layer_idx == 0:\n",
    "            embedding = self.embed(embedding) * math.sqrt(self.d_model)\n",
    "        embedding += self.pe[:, :embedding.size(1)]   # pe will automatically be expanded with the same batch size as encoded_words\n",
    "        # embedding: (batch_size, max_len, d_model), te: (batch_size, 1, d_model)\n",
    "        embedding += self.te[:, layer_idx, :].unsqueeze(1).repeat(1, embedding.size(1), 1)\n",
    "        embedding = self.dropout(embedding)\n",
    "        print()\n",
    "        print(embedding.size())\n",
    "        print(embedding)\n",
    "        return embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self, heads, d_model):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        assert d_model % heads == 0\n",
    "        self.d_k = d_model // heads\n",
    "        self.heads = heads\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.query = nn.Linear(d_model, d_model)\n",
    "        self.key = nn.Linear(d_model, d_model)\n",
    "        self.value = nn.Linear(d_model, d_model)\n",
    "        self.concat = nn.Linear(d_model, d_model)\n",
    "        \n",
    "    def forward(self, query, key, value, mask):\n",
    "        \"\"\"\n",
    "        query, key, value of shape: (batch_size, max_len, 512)\n",
    "        mask of shape: (batch_size, 1, 1, max_words)\n",
    "        \"\"\"\n",
    "        # (batch_size, max_len, 512)\n",
    "        query = self.query(query)\n",
    "        key = self.key(key)        \n",
    "        value = self.value(value)   \n",
    "        \n",
    "        # (batch_size, max_len, 512) --> (batch_size, max_len, h, d_k) --> (batch_size, h, max_len, d_k)\n",
    "        query = query.view(query.shape[0], -1, self.heads, self.d_k).permute(0, 2, 1, 3)   \n",
    "        key = key.view(key.shape[0], -1, self.heads, self.d_k).permute(0, 2, 1, 3)  \n",
    "        value = value.view(value.shape[0], -1, self.heads, self.d_k).permute(0, 2, 1, 3)  \n",
    "        \n",
    "        # (batch_size, h, max_len, d_k) matmul (batch_size, h, d_k, max_len) --> (batch_size, h, max_len, max_len)\n",
    "        scores = torch.matmul(query, key.permute(0,1,3,2)) / math.sqrt(query.size(-1))\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)    # (batch_size, h, max_len, max_len)\n",
    "        weights = F.softmax(scores, dim = -1)           # (batch_size, h, max_len, max_len)\n",
    "        weights = self.dropout(weights)\n",
    "        # (batch_size, h, max_len, max_len) matmul (batch_size, h, max_len, d_k) --> (batch_size, h, max_len, d_k)\n",
    "        context = torch.matmul(weights, value)\n",
    "        # (batch_size, h, max_len, d_k) --> (batch_size, max_len, h, d_k) --> (batch_size, max_len, h * d_k)\n",
    "        context = context.permute(0,2,1,3).contiguous().view(context.shape[0], -1, self.heads * self.d_k)\n",
    "        # (batch_size, max_len, h * d_k)\n",
    "        interacted = self.concat(context)\n",
    "        return interacted "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed Forward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, middle_dim = 2048):\n",
    "        super(FeedForward, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(d_model, middle_dim)\n",
    "        self.fc2 = nn.Linear(middle_dim, d_model)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.fc1(x))\n",
    "        out = self.fc2(self.dropout(out))\n",
    "        return out\n",
    "\n",
    "class FeedForwardLSTM(nn.Module):\n",
    "    def __init__(self, d_model, middle_dim = 2048):\n",
    "        super(FeedForwardLSTM, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(d_model, middle_dim)\n",
    "        self.lstm = nn.LSTM(middle_dim, middle_dim)\n",
    "        self.fc2 = nn.Linear(middle_dim, d_model)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.fc1(x))\n",
    "        out, _ = self.lstm(out)\n",
    "        out = self.fc2(self.dropout(out))\n",
    "        return out\n",
    "\n",
    "class FeedForwardLayerNoReg(nn.Module):\n",
    "    def __init__(self, d_model, middle_dim = 2048):\n",
    "        super(FeedForward, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(d_model, middle_dim)\n",
    "        self.fc2 = nn.Linear(middle_dim, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.fc1(x))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, heads):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.layernorm = nn.LayerNorm(d_model)\n",
    "        self.self_multihead = MultiHeadAttention(heads, d_model)\n",
    "        self.feed_forward = FeedForward(d_model)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, embeddings, mask):\n",
    "        interacted = self.dropout(self.self_multihead(embeddings, embeddings, embeddings, mask))\n",
    "        interacted = self.layernorm(interacted + embeddings)\n",
    "        feed_forward_out = self.dropout(self.feed_forward(interacted))\n",
    "        encoded = self.layernorm(feed_forward_out + interacted)\n",
    "        return encoded\n",
    "\n",
    "class EncoderLayerNoReg(nn.Module):\n",
    "    def __init__(self, d_model, heads):\n",
    "        super(EncoderLayerNoReg, self).__init__()\n",
    "        self.layernorm = nn.LayerNorm(d_model)\n",
    "        self.self_multihead = MultiHeadAttention(heads, d_model)\n",
    "        self.feed_forward = FeedForward(d_model)\n",
    "\n",
    "    def forward(self, embeddings, mask):\n",
    "        interacted = self.self_multihead(embeddings, embeddings, embeddings, mask)\n",
    "        interacted = self.layernorm(interacted + embeddings)\n",
    "        feed_forward_out = self.feed_forward(interacted)\n",
    "        encoded = self.layernorm(feed_forward_out + interacted)\n",
    "        return encoded\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_model, heads):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.layernorm = nn.LayerNorm(d_model)\n",
    "        self.self_multihead = MultiHeadAttention(heads, d_model)\n",
    "        self.src_multihead = MultiHeadAttention(heads, d_model)\n",
    "        self.feed_forward = FeedForward(d_model)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "    def forward(self, embeddings, encoded, src_mask, target_mask):\n",
    "        query = self.dropout(self.self_multihead(embeddings, embeddings, embeddings, target_mask))\n",
    "        query = self.layernorm(query + embeddings)\n",
    "        interacted = self.dropout(self.src_multihead(query, encoded, encoded, src_mask))\n",
    "        interacted = self.layernorm(interacted + query)\n",
    "        feed_forward_out = self.dropout(self.feed_forward(interacted))\n",
    "        decoded = self.layernorm(feed_forward_out + interacted)\n",
    "        return decoded\n",
    "\n",
    "class DecoderLayerNoReg(nn.Module):\n",
    "    def __init__(self, d_model, heads):\n",
    "        super(DecoderLayerNoReg, self).__init__()\n",
    "        self.layernorm = nn.LayerNorm(d_model)\n",
    "        self.self_multihead = MultiHeadAttention(heads, d_model)\n",
    "        self.src_multihead = MultiHeadAttention(heads, d_model)\n",
    "        self.feed_forward = FeedForward(d_model)\n",
    "        \n",
    "    def forward(self, embeddings, encoded, src_mask, target_mask):\n",
    "        query = self.self_multihead(embeddings, embeddings, embeddings, target_mask)\n",
    "        query = self.layernorm(query + embeddings)\n",
    "        interacted = self.src_multihead(query, encoded, encoded, src_mask)\n",
    "        interacted = self.layernorm(interacted + query)\n",
    "        feed_forward_out = self.feed_forward(interacted)\n",
    "        decoded = self.layernorm(feed_forward_out + interacted)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_model, heads, num_layers, word_map, max_len = 50):\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "        self.vocab_size = len(word_map)\n",
    "        self.embed = Embeddings(self.vocab_size, d_model, num_layers = num_layers, max_len = max_len)\n",
    "        self.encoder = EncoderLayer(d_model, heads) \n",
    "        self.decoder = DecoderLayer(d_model, heads)\n",
    "        self.logit = nn.Linear(d_model, self.vocab_size)\n",
    "        \n",
    "    def encode(self, src_embeddings, src_mask):\n",
    "        for i in range(self.num_layers):\n",
    "            src_embeddings = self.embed(src_embeddings, i)\n",
    "            src_embeddings = self.encoder(src_embeddings, src_mask)\n",
    "        return src_embeddings\n",
    "    \n",
    "    def decode(self, tgt_embeddings, target_mask, src_embeddings, src_mask):\n",
    "        for i in range(self.num_layers):\n",
    "            tgt_embeddings = self.embed(tgt_embeddings, i)\n",
    "            tgt_embeddings = self.decoder(tgt_embeddings, src_embeddings, src_mask, target_mask)\n",
    "        return tgt_embeddings\n",
    "        \n",
    "    def forward(self, src_words, src_mask, target_words, target_mask):\n",
    "        encoded = self.encode(src_words, src_mask)\n",
    "        decoded = self.decode(target_words, target_mask, encoded, src_mask)\n",
    "        out = F.log_softmax(self.logit(decoded), dim = 2)\n",
    "        return out\n",
    "\n",
    "class TransformerNoReg(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_model, heads, num_layers, word_map, max_len = 50):\n",
    "        super(TransformerNoReg, self).__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "        self.vocab_size = len(word_map)\n",
    "        self.embed = Embeddings(self.vocab_size, d_model, num_layers = num_layers, max_len = max_len)\n",
    "        self.encoder = EncoderLayerNoReg(d_model, heads) \n",
    "        self.decoder = DecoderLayerNoReg(d_model, heads)\n",
    "        self.logit = nn.Linear(d_model, self.vocab_size)\n",
    "        \n",
    "    def encode(self, src_embeddings, src_mask):\n",
    "        for i in range(self.num_layers):\n",
    "            src_embeddings = self.embed(src_embeddings, i)\n",
    "            src_embeddings = self.encoder(src_embeddings, src_mask)\n",
    "        return src_embeddings\n",
    "    \n",
    "    def decode(self, tgt_embeddings, target_mask, src_embeddings, src_mask):\n",
    "        for i in range(self.num_layers):\n",
    "            tgt_embeddings = self.embed(tgt_embeddings, i)\n",
    "            tgt_embeddings = self.decoder(tgt_embeddings, src_embeddings, src_mask, target_mask)\n",
    "        return tgt_embeddings\n",
    "        \n",
    "    def forward(self, src_words, src_mask, target_words, target_mask):\n",
    "        encoded = self.encode(src_words, src_mask)\n",
    "        decoded = self.decode(target_words, target_mask, encoded, src_mask)\n",
    "        out = F.log_softmax(self.logit(decoded), dim = 2)\n",
    "        return out\n",
    "\n",
    "class TransformerLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_model, heads, num_layers, word_map, max_len = 50):\n",
    "        super(TransformerLSTM, self).__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "        self.vocab_size = len(word_map)\n",
    "        self.embed = EmbeddingsLSTM(self.vocab_size, d_model, num_layers = num_layers)\n",
    "        self.encoder = EncoderLayer(d_model, heads) \n",
    "        self.decoder = DecoderLayer(d_model, heads)\n",
    "        self.logit = nn.Linear(d_model, self.vocab_size)\n",
    "        self.max_len = max_len\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "    def encode(self, src_embeddings, src_mask):\n",
    "        encoder_hidden = torch.zeros([self.num_layers, self.max_len, self.d_model]).to(self.device) # 1 = number of LSTM layers\n",
    "        cell_state = torch.zeros([self.num_layers, self.max_len, self.d_model]).to(self.device)\n",
    "        for i in range(self.num_layers):\n",
    "            src_embeddings, encoder_hidden, cell_state = self.embed(src_embeddings, i, encoder_hidden, cell_state)\n",
    "            src_embeddings = self.encoder(src_embeddings, src_mask)\n",
    "        return src_embeddings, encoder_hidden, cell_state\n",
    "    \n",
    "    def decode(self, tgt_embeddings, target_mask, src_embeddings, src_mask, encoder_hidden, cell_state):\n",
    "        zeros = torch.zeros((self.num_layers, 1, self.d_model), device=encoder_hidden.device)\n",
    "        encoder_hidden = torch.cat((encoder_hidden, zeros), dim=1)\n",
    "        decoder_input = torch.Tensor([[0]]).long().to(self.device) # 0 = SOS_token\n",
    "        decoder_hidden = encoder_hidden\n",
    "        print(decoder_hidden.size())\n",
    "        for i in range(self.num_layers):\n",
    "            tgt_embeddings, decoder_hidden, cell_state = self.embed(tgt_embeddings, i, decoder_hidden, cell_state)\n",
    "            tgt_embeddings = self.decoder(tgt_embeddings, src_embeddings, src_mask, target_mask)\n",
    "        return tgt_embeddings\n",
    "        \n",
    "    def forward(self, src_words, src_mask, target_words, target_mask):\n",
    "        encoded, encoder_hidden, cell_state = self.encode(src_words, src_mask)\n",
    "        decoded = self.decode(target_words, target_mask, encoded, src_mask, encoder_hidden, cell_state)\n",
    "        out = F.log_softmax(self.logit(decoded), dim = 2)\n",
    "        return out\n",
    "\n",
    "class TransformerPreTrainedEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, heads, num_layers, word_map, max_len = 50):\n",
    "        super(TransformerPreTrainedEmbedding, self).__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "        self.vocab_size = len(word_map)\n",
    "        self.embed = PretrainedEmbedding(self.vocab_size, d_model, num_layers = num_layers, max_len = max_len)\n",
    "        self.encoder = EncoderLayer(d_model, heads) \n",
    "        self.decoder = DecoderLayer(d_model, heads)\n",
    "        self.logit = nn.Linear(d_model, self.vocab_size)\n",
    "        \n",
    "    def encode(self, src_embeddings, src_mask):\n",
    "        for i in range(self.num_layers):\n",
    "            src_embeddings = self.embed(src_embeddings, i)\n",
    "            src_embeddings = self.encoder(src_embeddings, src_mask)\n",
    "        return src_embeddings\n",
    "    \n",
    "    def decode(self, tgt_embeddings, target_mask, src_embeddings, src_mask):\n",
    "        for i in range(self.num_layers):\n",
    "            tgt_embeddings = self.embed(tgt_embeddings, i)\n",
    "            tgt_embeddings = self.decoder(tgt_embeddings, src_embeddings, src_mask, target_mask)\n",
    "        return tgt_embeddings\n",
    "        \n",
    "    def forward(self, src_words, src_mask, target_words, target_mask):\n",
    "        encoded = self.encode(src_words, src_mask)\n",
    "        decoded = self.decode(target_words, target_mask, encoded, src_mask)\n",
    "        out = F.log_softmax(self.logit(decoded), dim = 2)\n",
    "        return out\n",
    "\n",
    "class TransformerDecoderOnly(nn.Module):    \n",
    "    def __init__(self, d_model, heads, num_layers, word_map, max_len = 50):\n",
    "        super(TransformerDecoderOnly, self).__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "        self.vocab_size = len(word_map)\n",
    "        self.embed = Embeddings(self.vocab_size, d_model, num_layers = num_layers, max_len = max_len)\n",
    "        self.encoder = EncoderLayer(d_model, heads) \n",
    "        self.decoder = DecoderLayer(d_model, heads)\n",
    "        self.logit = nn.Linear(d_model, self.vocab_size)\n",
    "    \n",
    "    def decode(self, tgt_embeddings, target_mask, src_embeddings, src_mask):\n",
    "        for i in range(self.num_layers):\n",
    "            tgt_embeddings = self.embed(tgt_embeddings, i)\n",
    "            tgt_embeddings = self.decoder(tgt_embeddings, src_embeddings, src_mask, target_mask)\n",
    "        return tgt_embeddings\n",
    "        \n",
    "    def forward(self, src_words, src_mask, target_words, target_mask):\n",
    "        encoded = self.embed(src_words, 0)\n",
    "        decoded = self.decode(target_words, target_mask, encoded, src_mask)\n",
    "        out = F.log_softmax(self.logit(decoded), dim = 2)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdamWarmup:\n",
    "    \n",
    "    def __init__(self, model_size, warmup_steps, optimizer):\n",
    "        \n",
    "        self.model_size = model_size\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.optimizer = optimizer\n",
    "        self.current_step = 0\n",
    "        self.lr = 0\n",
    "        \n",
    "    def get_lr(self):\n",
    "        return self.model_size ** (-0.5) * min(self.current_step ** (-0.5), self.current_step * self.warmup_steps ** (-1.5))\n",
    "        \n",
    "    def step(self):\n",
    "        # Increment the number of steps each time we call the step function\n",
    "        self.current_step += 1\n",
    "        lr = self.get_lr()\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "        # update the learning rate\n",
    "        self.lr = lr\n",
    "        self.optimizer.step()       \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossWithLS(nn.Module):\n",
    "\n",
    "    def __init__(self, size, smooth):\n",
    "        super(LossWithLS, self).__init__()\n",
    "        self.criterion = nn.KLDivLoss(size_average=False, reduce=False)\n",
    "        self.confidence = 1.0 - smooth\n",
    "        self.smooth = smooth\n",
    "        self.size = size\n",
    "        \n",
    "    def forward(self, prediction, target, mask):\n",
    "        \"\"\"\n",
    "        prediction of shape: (batch_size, max_words, vocab_size)\n",
    "        target and mask of shape: (batch_size, max_words)\n",
    "        \"\"\"\n",
    "        prediction = prediction.view(-1, prediction.size(-1))   # (batch_size * max_words, vocab_size)\n",
    "        target = target.contiguous().view(-1)   # (batch_size * max_words)\n",
    "        mask = mask.float()\n",
    "        mask = mask.view(-1)       # (batch_size * max_words)\n",
    "        labels = prediction.data.clone()\n",
    "        labels.fill_(self.smooth / (self.size - 1))\n",
    "        labels.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        loss = self.criterion(prediction, labels)    # (batch_size * max_words, vocab_size)\n",
    "        loss = (loss.sum(1) * mask).sum() / mask.sum()\n",
    "        return loss\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Neptune Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = \"andialifs/fluent-tesis-24\"\n",
    "api_token = \"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJjZTY2YWQ3My04OTBkLTQ2OWUtYTc1Ni1jYjk0MGZhMWFiNGEifQ==\"\n",
    "\n",
    "def neptune_init(name):\n",
    "    run = neptune.init_run(\n",
    "        project=project,\n",
    "        api_token=api_token,\n",
    "        name=name\n",
    "    )\n",
    "    return run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, transformer, criterion, epoch):\n",
    "    transformer.train()\n",
    "    sum_loss = 0\n",
    "    count = 0\n",
    "\n",
    "    for i, (question, reply) in enumerate(train_loader):\n",
    "        \n",
    "        samples = question.shape[0]\n",
    "\n",
    "        # Move to device\n",
    "        question = question.to(device)\n",
    "        reply = reply.to(device)\n",
    "\n",
    "        # Prepare Target Data\n",
    "        reply_input = reply[:, :-1]\n",
    "        reply_target = reply[:, 1:]\n",
    "\n",
    "        # Create mask and add dimensions\n",
    "        question_mask, reply_input_mask, reply_target_mask = create_masks(question, reply_input, reply_target)\n",
    "\n",
    "        # Get the transformer outputs\n",
    "        out = transformer(question, question_mask, reply_input, reply_input_mask)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(out, reply_target, reply_target_mask)\n",
    "        \n",
    "        # Backprop\n",
    "        transformer_optimizer.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        transformer_optimizer.step()\n",
    "        \n",
    "        sum_loss += loss.item() * samples\n",
    "        count += samples\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(\"Epoch [{}][{}/{}]\\tLoss: {:.3f}\".format(epoch, i, len(train_loader), sum_loss/count))\n",
    "    \n",
    "    return sum_loss/count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(transformer, question, question_mask, max_len, word_map):\n",
    "    \"\"\"\n",
    "    Performs Greedy Decoding with a batch size of 1\n",
    "    \"\"\"\n",
    "    rev_word_map = {v: k for k, v in word_map.items()}\n",
    "    transformer.eval()\n",
    "    start_token = word_map['<start>']\n",
    "    encoded = transformer.encode(question, question_mask)\n",
    "    words = torch.LongTensor([[start_token]]).to(device)\n",
    "    \n",
    "    for step in range(max_len - 1):\n",
    "        size = words.shape[1]\n",
    "        target_mask = torch.triu(torch.ones(size, size)).transpose(0, 1).type(dtype=torch.uint8)\n",
    "        target_mask = target_mask.to(device).unsqueeze(0).unsqueeze(0)\n",
    "        decoded = transformer.decode(words, target_mask, encoded, question_mask)\n",
    "        predictions = transformer.logit(decoded[:, -1])\n",
    "        _, next_word = torch.max(predictions, dim = 1)\n",
    "        next_word = next_word.item()\n",
    "        if next_word == word_map['<end>']:\n",
    "            break\n",
    "        words = torch.cat([words, torch.LongTensor([[next_word]]).to(device)], dim = 1)   # (1,step+2)\n",
    "        \n",
    "    # Construct Sentence\n",
    "    if words.dim() == 2:\n",
    "        words = words.squeeze(0)\n",
    "        words = words.tolist()\n",
    "        \n",
    "    sen_idx = [w for w in words if w not in {word_map['<start>']}]\n",
    "    sentence = ' '.join([rev_word_map[sen_idx[k]] for k in range(len(sen_idx))])\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running for experiment 0 with d_model 512, heads8, num_layers5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[neptune] [warning] NeptuneWarning: The following monitoring options are disabled by default in interactive sessions: 'capture_stdout', 'capture_stderr', 'capture_traceback', and 'capture_hardware_metrics'. To enable them, set each parameter to 'True' when initializing the run. The monitoring will continue until you call run.stop() or the kernel stops. Also note: Your source files can only be tracked if you pass the path(s) to the 'source_code' argument. For help, see the Neptune docs: https://docs.neptune.ai/logging/source_code/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/andialifs/fluent-tesis-24/e/FLUENT24-20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andyalyfsyah/.conda/envs/myenv/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 26.00 MiB (GPU 0; 79.35 GiB total capacity; 4.31 GiB already allocated; 4.19 MiB free; 4.42 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 46\u001b[0m\n\u001b[1;32m     44\u001b[0m loss_list_experiment \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m---> 46\u001b[0m     loss_train \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransformer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m     state \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m: epoch, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransformer\u001b[39m\u001b[38;5;124m'\u001b[39m: transformer, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransformer_optimizer\u001b[39m\u001b[38;5;124m'\u001b[39m: transformer_optimizer}\n\u001b[1;32m     49\u001b[0m     torch\u001b[38;5;241m.\u001b[39msave(state, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheckpoint_experiment_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(epoch) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(experiment_id) \u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.pth.tar\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[29], line 22\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(train_loader, transformer, criterion, epoch)\u001b[0m\n\u001b[1;32m     19\u001b[0m question_mask, reply_input_mask, reply_target_mask \u001b[38;5;241m=\u001b[39m create_masks(question, reply_input, reply_target)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Get the transformer outputs\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreply_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreply_input_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Compute the loss\u001b[39;00m\n\u001b[1;32m     25\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(out, reply_target, reply_target_mask)\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[25], line 28\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, src_words, src_mask, target_words, target_mask)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, src_words, src_mask, target_words, target_mask):\n\u001b[1;32m     27\u001b[0m     encoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode(src_words, src_mask)\n\u001b[0;32m---> 28\u001b[0m     decoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_words\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     out \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mlog_softmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogit(decoded), dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "Cell \u001b[0;32mIn[25], line 23\u001b[0m, in \u001b[0;36mTransformer.decode\u001b[0;34m(self, tgt_embeddings, target_mask, src_embeddings, src_mask)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers):\n\u001b[1;32m     22\u001b[0m     tgt_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed(tgt_embeddings, i)\n\u001b[0;32m---> 23\u001b[0m     tgt_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtgt_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tgt_embeddings\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[24], line 14\u001b[0m, in \u001b[0;36mDecoderLayer.forward\u001b[0;34m(self, embeddings, encoded, src_mask, target_mask)\u001b[0m\n\u001b[1;32m     12\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_multihead(embeddings, embeddings, embeddings, target_mask))\n\u001b[1;32m     13\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayernorm(query \u001b[38;5;241m+\u001b[39m embeddings)\n\u001b[0;32m---> 14\u001b[0m interacted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msrc_multihead\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     15\u001b[0m interacted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayernorm(interacted \u001b[38;5;241m+\u001b[39m query)\n\u001b[1;32m     16\u001b[0m feed_forward_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeed_forward(interacted))\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[21], line 30\u001b[0m, in \u001b[0;36mMultiHeadAttention.forward\u001b[0;34m(self, query, key, value, mask)\u001b[0m\n\u001b[1;32m     27\u001b[0m value \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39mview(value\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_k)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)  \n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# (batch_size, h, max_len, d_k) matmul (batch_size, h, d_k, max_len) --> (batch_size, h, max_len, max_len)\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m scores \u001b[38;5;241m=\u001b[39m scores\u001b[38;5;241m.\u001b[39mmasked_fill(mask \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1e9\u001b[39m)    \u001b[38;5;66;03m# (batch_size, h, max_len, max_len)\u001b[39;00m\n\u001b[1;32m     32\u001b[0m weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(scores, dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)           \u001b[38;5;66;03m# (batch_size, h, max_len, max_len)\u001b[39;00m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 26.00 MiB (GPU 0; 79.35 GiB total capacity; 4.31 GiB already allocated; 4.19 MiB free; 4.42 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "d_model = [512, 1024, 2048, 4096]\n",
    "heads = [8, 16, 32]\n",
    "num_layers = [5, 10]\n",
    "epochs = 100\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "with open('WORDMAP_corpus_KBFILKOM.json', 'r') as j:\n",
    "    word_map = json.load(j)\n",
    "\n",
    "transformer_experiment = pd.DataFrame(columns = ['experiment_id', 'd_model', 'heads', 'num_layers', 'train_loss'])\n",
    "loss_history = {}\n",
    "\n",
    "experiment_id = -1\n",
    "\n",
    "for d_m in d_model:\n",
    "    for h in heads:\n",
    "        for n_l in num_layers: \n",
    "            experiment_id += 1\n",
    "            print('\\nRunning for experiment {} with d_model {}, heads{}, num_layers{}\\n'.format(experiment_id, d_m, h, n_l))\n",
    "\n",
    "            run = neptune.init_run(\n",
    "                project=project,\n",
    "                api_token=api_token,\n",
    "                name=\"experiment_1724_\" + str(experiment_id)\n",
    "            ) \n",
    "            run['parameters'] = {\n",
    "                'd_model': d_m,\n",
    "                'heads': h,\n",
    "                'num_layers': n_l\n",
    "            }\n",
    "\n",
    "            transformer_experiment.loc[experiment_id, 'experiment_id'] = 'experiment_{}'.format(str(experiment_id))\n",
    "            transformer_experiment.loc[experiment_id, 'd_model'] = d_m\n",
    "            transformer_experiment.loc[experiment_id, 'heads'] = h\n",
    "            transformer_experiment.loc[experiment_id, 'num_layers'] = n_l\n",
    "\n",
    "            transformer = Transformer(d_model = d_m, heads = h, num_layers = n_l, word_map = word_map, max_len=95)\n",
    "            transformer = transformer.to(device)\n",
    "            adam_optimizer = torch.optim.Adam(transformer.parameters(), lr=0.001, betas=(0.9, 0.98), eps=1e-9)\n",
    "            transformer_optimizer = AdamWarmup(model_size = d_m, warmup_steps = 4000, optimizer = adam_optimizer)\n",
    "            criterion = LossWithLS(len(word_map), 0.2)\n",
    "\n",
    "            loss_list_experiment = []\n",
    "            for epoch in range(epochs):\n",
    "                loss_train = train(train_loader, transformer, criterion, epoch)\n",
    "\n",
    "                state = {'epoch': epoch, 'transformer': transformer, 'transformer_optimizer': transformer_optimizer}\n",
    "                torch.save(state, 'checkpoint_experiment_' + str(epoch) + 'id_'+ str(experiment_id) +'.pth.tar')\n",
    "\n",
    "                loss_list_experiment.append(loss_train)\n",
    "\n",
    "                run['train/loss'].append(loss_train)\n",
    "\n",
    "            transformer_experiment.loc[experiment_id, 'train_loss'] = loss_train\n",
    "            loss_history['experiment_{}'.format(str(experiment_id))] = loss_list_experiment\n",
    "            \n",
    "            run.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "with open('loss_history_transformer_experiment_KBFILKOM.yaml', 'w') as file:\n",
    "    documents = yaml.dump(loss_history, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>d_model</th>\n",
       "      <th>heads</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>train_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>experiment_0</td>\n",
       "      <td>512</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.839085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>experiment_1</td>\n",
       "      <td>512</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>1.912982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>experiment_2</td>\n",
       "      <td>512</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>0.825608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>experiment_3</td>\n",
       "      <td>512</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>1.912182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>experiment_4</td>\n",
       "      <td>512</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>0.830021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>experiment_5</td>\n",
       "      <td>512</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>1.924448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>experiment_6</td>\n",
       "      <td>1024</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.512975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>experiment_7</td>\n",
       "      <td>1024</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>1.580548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>experiment_8</td>\n",
       "      <td>1024</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>0.511592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>experiment_9</td>\n",
       "      <td>1024</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>1.522959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>experiment_10</td>\n",
       "      <td>1024</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>0.50644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>experiment_11</td>\n",
       "      <td>1024</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>1.514691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>experiment_12</td>\n",
       "      <td>2048</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.333919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    experiment_id d_model heads num_layers train_loss\n",
       "0    experiment_0     512     8          5   0.839085\n",
       "1    experiment_1     512     8         10   1.912982\n",
       "2    experiment_2     512    16          5   0.825608\n",
       "3    experiment_3     512    16         10   1.912182\n",
       "4    experiment_4     512    32          5   0.830021\n",
       "5    experiment_5     512    32         10   1.924448\n",
       "6    experiment_6    1024     8          5   0.512975\n",
       "7    experiment_7    1024     8         10   1.580548\n",
       "8    experiment_8    1024    16          5   0.511592\n",
       "9    experiment_9    1024    16         10   1.522959\n",
       "10  experiment_10    1024    32          5    0.50644\n",
       "11  experiment_11    1024    32         10   1.514691\n",
       "12  experiment_12    2048     8          5   0.333919"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_experiment.dropna(inplace=True)\n",
    "transformer_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "with open('history_rnn_150524.yaml', 'r') as file:\n",
    "    history_rnn = yaml.load(file, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA24AAAJcCAYAAACBlPd1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAAsTAAALEwEAmpwYAAEAAElEQVR4nOzdeVzVVf748deHTQTEHULRUFzYdwVLDDS3cgnNsW1cmXIhzSbJcolKyiZHHZekcUTM5au5gOg0puaGmiIoKgqJIopkuSMgKHA/vz+u3J8owkXZsvfz8fAx3M/9fM55n889NPfNOZ9zFFVVEUIIIYQQQghRdxnUdgBCCCGEEEIIIconiZsQQgghhBBC1HGSuAkhhBBCCCFEHSeJmxBCCCGEEELUcZK4CSGEEEIIIUQdJ4mbEEIIIYQQQtRxkrgJIcQfkKIo/1MUZXhVn1vJGAIURblY1eU+zRRFiVIUZWYt1a0oirJMUZQbiqLE10YMD1IUJUxRlJW1HYcQQvwRGNV2AEII8WehKErufS/NgDtA8b3X76iqukrfslRV7Vsd5/7ZKIqSgfazaKOqat69Y8HAW6qqBtRiaNWhK9ATsC1p6/0URRkBLAXyH3irg6qqv1Z/eEIIIcojI25CCFFDVFW1KPkHXAD633dMl7QpiiJ/VKtZhsDE2g6ishRFMazkJc8CGWUlbff5+f5+eu+fJG1CCFEHSOImhBC1rGTKoaIoHyqK8huwTFGUxoqibFEU5cq9qW1bFEWxve+a3fdGhlAUZYSiKPsURZl979xziqL0fcxz2yiKsldRlBxFUXYoirJI36lsiqI43qvrpqIoJxVFGXDfey8pinLqXrlZiqJ8cO94s3ttu6koynVFUeIURXno/5sURVmsKMrsB45tUhTl/Xs/f3iv3BxFUX5RFKWHnrcf4GvgA0VRGpVRr52iKOr9yXQZ93O/oihz77UhXVGU5+4dz1QU5XIZ01SbKYqy/V6sexRFefa+sh3uvXf9Xjv+ct97Uffuww+KouQBgWXE20JRlNh7159RFOVv946PBv4DdFEUJVdRlE8rcX9Kys5QFOWje5/jjXvTLk3ve/9v9+q8fi+GFve953xfu35XFOXj+4o2URTlu3v346SiKD73Xfckn6sQQjxVJHETQoi64RmgCdpRkbfR/vd52b3XrdFOX1tYzvW+wC9AM+AfwFJFUZTHOHc1EA80BcKAv+oTvKIoxsBmYBtgBbwLrFIUpeO9U5ainQ7aAHABdt47/nfgItAcsAY+BtQyqvg/YGhJnIqiNAZ6AWvu1RECdLpXfm8gQ5+470kAdgMfVOKa+/kCx9Hes9XAGqAT0A54C1ioKIrFfee/CXyO9v4nAavutckc2H6vDCvgNeAbRVGc7rv2DSAcaADsKyOWNWjvZwvgVeALRVG6q6q6FBjD/x9R++Qx2/om2vtrD3QApt2LvTvwJfAXwAY4fy8WFEVpAOwAtt6Lqx3w031lDrh3biMglnv9vAo+VyGEeKpI4iaEEHWDBvhEVdU7qqrmq6p6TVXVDaqq3lZVNQftl/UXyrn+vKqqS1RVLQaWo/3ybF2ZcxVFaY024ZihqupdVVX3of0irQ8/wAKYde/ancAW4PV77xcCToqiWKqqekNV1SP3HbcBnlVVtVBV1ThVVctK3OLQJnT+916/ijYJ+RXtc4L17pVvrKpqhqqqZ/WMu8QM4F1FUZpX8jqAc6qqLrt3P9cCrYDP7n2W24C7aJOVEv9VVXWvqqp3gKloR8FaAf3QTmVcpqpqkaqqR4ENwJD7rt2kqup+VVU1qqoW3B/EvTKeBz5UVbVAVdUktKNswyrRFr97I4cl/x68jwtVVc1UVfU62j5Z8vm+CUSqqnrkXrs+utcuu3vt+k1V1X/eiytHVdVD95W5T1XVH+7dvxWA+73jVfG5CiHEU0MSNyGEqBuu3P9FXFEUM0VRvlUU5byiKLeAvUAj5dHPNf1W8oOqqrfv/WhRyXNbANfvOwaQqWf8LYBMVVU19x07D7S89/Ng4CXg/L3pgV3uHf8aOANsuzfNcEpZhd9L5tbw/xOFN7g3UqWq6hngPbQjhJcVRVlz/zQ9faiqmow20Syz/gr8ft/P+ffKe/DY/Z+F7p6qqpoLXEd7/54FfO9PnNAmRM+UdW0ZSj6/nPuO3f8Z6OOgqqqN7vtn/8D799d//l6dJXWff6Bd1+7V3QooL+H67b6fbwOmiqIYVcXnKoQQTxNJ3IQQom54cJTp70BHwFdVVUug273jj5r+WBUuAU0URTG771grPa/9FWj1wPNprYEsAFVVD6uqOhDtFMAY4Pt7x3NUVf27qqpt0U6Ze7+c55j+D3j13jNhvmhHo7hXzmpVVbuiTX5U4Cs9477fJ8DfKJ3olCzkcf89uT+Rehy6e3pvCmUTtPcvE9jzQOJkoarq2PuuLWs0ssSvaD+/Bvcd030GVeT+/tD6Xp0ldd//rJ452qmjWWjb1fZxKquiz1UIIZ4KkrgJIUTd1ADtSM1NRVGaoE0qqpWqqufRPu8VpiiKyb1Rsf56Xn4I7WhJqKIoxoqiBNy7ds29st5UFKWhqqqFwC20U0NRFKWfoijt7j27lo12epymrAruTR28inb634+qqt68V0ZHRVG6K4pSDyhAe9/KLKOC9p9BO9Vxwn3HrqBNPt5SFMVQUZRRaJ/vehIvKYrSVVEUE7TPuh1UVTUT7YhfB0VR/nrvHhoritJJURRHPePPBA4AXyqKYqooihswGqjKfdLGK4pie69PTkV7v0CbVI9UFMXj3ufwBXBIVdWMe+2yURTlPUVR6imK0kBRFN+KKqqqz1UIIZ4WkrgJIUTdNA+ojzZROYh2YYea8CbQBe00t5lov5jfqegiVVXvok3U+qKN+RtgmKqqqfdO+SuQcW/a55h79QC0R7twRS7wM/CNqqq7yqlqNfDivf8tUQ+Yda/e39CO6n0EcC9hPFlR/Pf5DDB/4NjfgMlo74kz2uToSaxGm4hfB7zRLmDCvSmOvdAuSvIr2rZ8hbZ9+nodsLt3fTTa5yZ3VOL6klUn7//X6YHYtwHpaKc/zrwX+w5gOtpR0Etok9vX7mtXT7T94zcgjTJWxCzDIz9XIYT4M1LKfgZcCCGEAEVR1gKpT7AKoXhKKNrNyoMrmQgKIYSoIjLiJoQQQufe1Dx7RVEMFEXpAwxE+0yaEEIIIWqRUcWnCCGE+BN5BtiIdmGJi8DYe8+WCSGEEKIWyVRJIYQQQgghhKjjZKqkEEIIIYQQQtRxdWqqZLNmzVQ7O7vaDuMheXl5mJs/uMiYEFVH+pioCdLPRE2Qfiaqm/QxURNqs58lJiZeVVW1+YPH61TiZmdnR0JCQm2H8ZDdu3cTEBBQ22GIp5j0MVETpJ+JmiD9TFQ36WOiJtRmP1MU5XxZx2WqpBBCCCGEEELUcZK4CSGEEEIIIUQdJ4mbEEIIIYQQQtRxdeoZNyGEEEII8f8VFhZy8eJFCgoKajuUOqNhw4akpKTUdhjiKVcT/czU1BRbW1uMjY31Ol8SNyGEEEKIOurixYs0aNAAOzs7FEWp7XDqhJycHBo0aFDbYYinXHX3M1VVuXbtGhcvXqRNmzZ6XSNTJYUQQggh6qiCggKaNm0qSZsQTxlFUWjatGmlRtMlcRNCCCGEqMMkaRPi6VTZ321J3IQQQgghhBCijpPETQghhBBCCCHqOEnchBBCCCGEXsLCwpg9e3adqUufczIyMqhfvz4eHh54eHgwZswY3XtTp06lVatWWFhYlLpmzpw5ODk54ebmRo8ePTh//nyF8T5YRlUJCAggISGh0tcVFhYyfPhwXF1dcXR05Msvv6yG6B5fVFQUISEhtR1GKWFhYbRs2RIPDw+ef/55fvjhh9oOqRRZVVIIIYQQQjzV7O3tSUpKeuh4//79CQkJoX379qWOe3p6kpCQgJmZGYsXLyY0NJS1a9fWULRVY926ddy5c4cTJ05w+/ZtnJyceP3117Gzs6vt0GpEUVERRkaVT3UmTZrEBx98UCdXL5XETQghhBDiD+DTzSc59eutKi3TqYUln/R3Lvec8PBwli9fjpWVFa1atcLb2/uR5wYEBODp6UlcXBx5eXl89913fPnll5w4cYKhQ4cyc+ZMQDuiFRkZCUBwcDDvvfdeuXWdPXuW8ePHc+XKFerVq0dkZCQODg5P3H4/P78yjwcGBpY6Z+XKlXqVN3XqVLZs2UL9+vXZtGkT1tbWXLlyhTFjxnDhwgUA5s2bx/PPP098fDwTJ06koKCA+vXrs2zZMjp27Eh+fj4jR47k2LFjODg4kJ+fD0BxcTGjR48mISEBRVEYNWoUkyZNemQsiqKQl5dHUVER+fn5mJiYYGlpWW78dnZ2DB8+nM2bN1NYWMi6detwcHAgLCwMCwsLPvjgAwBcXFzYsmULAH369MHPz48DBw7QqVMnRo4cySeffMLly5dZtWoVnTt3rvC+bd68mZkzZ3L37l2aNm3KqlWraN68OR07duTAgQM0b94cjUZDhw4d+PnnnwHKvKdhYWGcPXuW9PR0WrduzbRp0xg5ciR3795Fo9GwYcOGh5L0PxKZKimEEEIIIcqUmJjImjVrSEpK4ocffuDw4cMVXmNiYkJCQgJjxoxh4MCBLFq0iOTkZKKiorh27RqJiYksW7aMQ4cOcfDgQZYsWcLRo0fLrevtt99mwYIFJCYmMnPmTMaNG/dQvREREURERJQZ07lz5/D09OSFF14gLi6uUvdg6dKl9O3bt8Lz8vLy8PPz49ixY3Tr1o0lS5YAMHHiRCZNmsThw4fZsGEDwcHBADg4OBAXF8fRo0f57LPP+PjjjwFYvHgxZmZmpKSk8Omnn5KYmAhAUlISWVlZJCcnc+LECUaOHFluu1999VXMzc2xsbGhdevWfPDBBzRp0qTCdjRr1owjR44wduxYvabFnjlzhr///e+kpqaSmprK6tWr2bdvH7Nnz+aLL76o8HqArl27cvDgQY4ePcprr73GP/7xDwwMDHjrrbdYtWoVADt27MDd3Z3mzZs/8p4CnDp1ih07dvB///d/REREMHHiRJKSkkhISMDW1haAl156iV9//bXMWBYuXIibmxvjxo3jxo0besVfU2TETQghhBDiD6CikbHqEBcXR1BQEGZmZgAMGDCgwmtKznF1dcXZ2RkbGxsA2rZtS2ZmJvv27SMoKAhzc3MABg0aRFxcHBqNpsy6cnNzOXDgAEOGDAFAo9FQWFj4UL33P7t2PxsbGy5cuEDTpk1JTEzklVde4eTJkxWOPgGsXLmShIQE9uzZU+G5JiYm9OvXDwBvb2+2b98OaBOOU6dO6c67desWubm5ZGdnM3z4cNLS0lAURdemvXv3MmHCBADc3Nxwc3MDtPcvPT2dd999l5dffplevXqV2+74+HgMDQ359ddfuXHjBv7+/rz44ou0bdu23HYMGjRI14aNGzdW2O42bdrg6uoKgLOzMz169EBRFFxdXcnIyKjwetBuND906FAuXbrE3bt3dRtSjxo1ioEDB/Lee+8RGRmpS1YfdU9B22/q168PQJcuXQgPD+fixYsMGjRIN9r2qGfXxo4dy/Tp01EUhQ8//JC///3vupHhukBG3IQQQgghRJWpV68eAAYGBrqfS14XFRVVujyNRkOjRo1ISkoiKSmJ/fv3k5KSUql4mjZtCmiTEXt7e06fPl3hdTt27CA8PJzY2NhS7XgUY2Nj3b5choaGurZqNBoOHjyoiz8rKwsLCwumT59OYGAgycnJbN68ucKNmBs3bsyxY8cICAggIiKi1ChTWVavXk2fPn0wNjbGysqK559/Xq9FTkraen8bjIyM0Gg0unPuj/XBz/j+z1/fz/vdd98lJCSEEydO8O233+rKb9WqFdbW1uzcuZP4+HjdyOej7img+4MAwBtvvEFsbCz169fnpZdeYufOneXGYW1tjaGhIQYGBgwfPpz4+Hi94q8pkrgJIYQQQogydevWjZiYGPLz88nJyWHz5s1PXKa/vz8xMTHcvn2bvLw8oqOj8ff3f2RdlpaWtGnThnXr1gGgqirHjh3Tu74rV65QXFwMQHp6OmlpaRWOOh09epR33nmH2NhYrKysSr1X2WfrevXqxYIFC3SvSxZJyc7OpmXLloB2hcUS3bp1Y/Xq1QAkJydz/PhxAK5evYpGo2Hw4MHMnDmTI0eOlFtv69atdYlKXl4eBw8e1MXeo0cPsrKy9G6DnZ2drr4jR45w7tw5va/Vx/33Yvny5aXeCw4O5q233mLIkCEYGhoCj76nD0pPT6dt27ZMmDCBgQMH6u7lo1y6dEn38+bNm3FxcXmc5lQbSdyEEEIIIUSZvLy8GDp0KO7u7vTt25dOnTpVSZkjRoygc+fO+Pr6EhwcjKenZ7l1rVq1iqVLl+Lu7k7nzp3ZtGnTQ+U+6lmvvXv34ubmhoeHB6+++ioRERG6Z71CQ0OxtbXl9u3b2NraEhYWBsDkyZPJzc1lyJAheHh46KZtXr16FVVVK9Xe+fPnk5CQgJubG05OTroYQ0ND+eijj/D09Cw1MjV27Fhyc3NxdHRkxowZugVasrKyCAgIwMPDg7feeku3vP+j2j1+/Hhyc3NxdnbWLRri5uaGRqPhzJkzej3vVmLw4MFcv34dZ2dnFi5cSIcOHSp1DyoSFhbGkCFD8Pb2plmzZqXeGzBgALm5ubppkvDoe/qg77//HhcXFzw8PEhOTmbYsGHAo59xCw0NxdXVFTc3N+Li4pg7d24VtvLJKZXtfNXJx8dHfZx9Kqrb7t27CQgIqO0wxFNM+pioCdLPRE2Qfla1UlJScHR0rO0w6pTaXKZ9y5YtpKen655B+yNKTk4mMjKSOXPm1HYoeklISGDSpEmVXlTmSdVUPyvrd1xRlERVVX0ePFcWJxFCCCGEEEIPJYuP/JG5uLj8YZK2WbNmsXjxYt3Kkn92krgJIYQQQohKGT9+PPv37y91bOLEiaWmswkBsGzZMv71r3+VOvb888+zaNGiCq+dMmUKU6ZMqa7Q/nAkcSuHRqMhMTGRnTt3Ym5ujre3NwYG8ligEEIIIf7c9PnSLQTAyJEjJaGvIpK4PYJGo2HKlCns2rWL7Oxs/ve//xEYGMisWbMkeRNCCCGEEELUKMlAHqFkpK1JkyY0aNAAKysrdu7cqdu9XgghhBBCCCFqiiRuj3D27FmuXLlCUlISGRkZGBgYoNFoSE9Pr+3QhBBCCCGEEH8ykrg9gr29PSYmJqiqiqqq3LlzBwMDgwo3bBRCCCGEEEKIqiaJ2yN4e3vj6+vL3bt3uXPnDpcuXaJ79+66TRCFEEIIIf5swsLCmD17dp2pS59zMjIyqF+/Ph4eHnh4eDBmzBjde1OnTqVVq1ZYWFiUumbOnDk4OTnh5uZGjx49OH/+fIXxPlhGVQkICOBx9jkuLCxk+PDhuLq64ujoqNuwu66IiooiJCSktsMoZd26dTg7O2NgYMCRI0dKvffll1/Srl07OnbsyI8//lgr8cniJI9gYGDAp59+yvnz5/n999959913CQ4OloVJhBBCCCH+YOzt7UlKSnroeP/+/QkJCaF9+/aljnt6epKQkICZmRmLFy8mNDSUtWvX1lC0VWPdunXcuXOHEydOcPv2bZycnHj99dexs7Or7dBqRFFREUZGlUt1XFxc2LhxI++8806p46dOnWLNmjWcPHmSX3/9lRdffJHTp09jaGhYlSFXSBK3cjzzzDM0atSI4uJimjRpIkmbEEIIIWrP/6bAbyeqtsxnXKHvrHJPCQ8PZ/ny5VhZWdGqVatyZx8FBATg6elJXFwceXl5fPfdd3z55ZecOHGCoUOHMnPmTEA7ohUZGQlAcHAw7733Xrl1nT17lvHjx3PlyhXq1atHZGQkDg4OT9x8Pz+/Mo8HBgaWOmflypV6lTd16lS2bNlC/fr12bRpE9bW1ly5coUxY8Zw4cIFAObNm8fzzz9PfHw8EydOpKCggPr167Ns2TI6duxIfn4+I0eO5NixYzg4OJCfnw9AcXExo0ePJiEhAUVRGDVqFJMmTXpkLIqikJeXR1FREfn5+ZiYmGBpaVlu/HZ2dgwfPpzNmzdTWFjIunXrcHBwICwsDAsLCz744ANAm+Bs2bIFgD59+uDn58eBAwfo1KkTI0eO5JNPPuHy5cusWrWKzp07V3jfNm/ezMyZM7l79y5NmzZl1apVNG/enI4dO3LgwAGaN2+ORqOhQ4cO/PzzzwBl3tOwsDDOnj1Leno6rVu3Ztq0aYwcOZK7d++i0WjYsGHDQ0n6/RwdHcs8vmnTJl577TXq1atHmzZtaNeuHfHx8XTp0qXCtlUlyUTKYW5urhv2/v3332s5GiGEEEKImpWYmMiaNWtISkrihx9+4PDhwxVeY2JiQkJCAmPGjGHgwIEsWrSI5ORkoqKiuHbtGomJiSxbtoxDhw5x8OBBlixZwtGjR8ut6+2332bBggUkJiYyc+ZMxo0b91C9ERERRERElBnTuXPn8PT05IUXXiAuLq5S92Dp0qX07du3wvPy8vLw8/Pj2LFjdOvWjSVLlgDajcknTZrE4cOH2bBhA8HBwQA4ODgQFxfH0aNH+eyzz/j4448BWLx4MWZmZqSkpPDpp5/qVjRPSkoiKyuL5ORkTpw4odsb7VHtfvXVVzE3N8fGxobWrVvzwQcf0KRJkwrb0axZM44cOcLYsWP1mhZ75swZ/v73v5OamkpqaiqrV69m3759zJ49my+++KLC6wG6du3KwYMHOXr0KK+99hr/+Mc/MDAw4K233mLVqlUA7NixA3d3d5o3b/7Iewra0bEdO3bwf//3f0RERDBx4kSSkpJISEjA1tYWgJdeeolff/1Vr9gAsrKyaNWqle61ra0tWVlZel9fVWTErQLW1ta66ZJCCCGEELWmgpGx6hAXF0dQUBBmZmYADBgwoMJrSs5xdXXF2dkZGxsbANq2bUtmZib79u0jKCgIc3NzAAYNGkRcXBwajabMunJzczlw4ABDhgwBtHvtFhYWPlTv/c+u3c/GxoYLFy7QtGlTEhMTeeWVVzh58mSFo08AK1euJCEhgT179lR4romJCf369QO0ayVs374d0CYcp06d0p1369YtcnNzyc7OZvjw4aSlpaEoiq5Ne/fuZcKECQC4ubnh5uYGaO9feno67777Li+//DK9evUqt93x8fEYGhry66+/cuPGDfz9/XnxxRcrXGhv0KBBujZs3Lixwna3adMGV1dXAJydnenRoweKouDq6kpGRkaF1wNcvHiRoUOHcunSJe7evUubNm0AGDVqFAMHDuS9994jMjJSl6w+6p6Ctt/Ur18fgC5duhAeHs7FixcZNGiQbrTthx9+0CuuuqZaR9wURWmkKMp6RVFSFUVJURSlZscTq4C1tTUgI25CCCGEEPqoV68eoF0voOTnktdFRUWVLk+j0dCoUSOSkpJISkpi//79pKSkVCqepk2bAtpkxN7entOnT1d43Y4dOwgPDyc2NrZUOx7F2NgYRVEAMDQ01LVVo9Fw8OBBXfxZWVlYWFgwffp0AgMDSU5OZvPmzRQUFJRbfuPGjTl27BgBAQFERESUGmUqy+rVq+nTpw/GxsZYWVnx/PPP67XISUlb72+DkZERGo1Gd879sT74Gd//+ev7eb/77ruEhIRw4sQJvv32W135rVq1wtramp07dxIfH68b+XzUPQV0fxAAeOONN4iNjaV+/fq89NJL7Ny5U694HtSyZUsyMzN1ry9evEjLli0fq6wnUd1TJf8FbFVV1QFwB/T/LasjShK369evo6pqLUcjhBBCCFFzunXrRkxMDPn5+eTk5LB58+YnLtPf35+YmBhu375NXl4e0dHR+Pv7P7IuS0tL2rRpw7p16wBQVZVjx47pXd+VK1coLi4GID09nbS0tApHnY4ePco777xDbGwsVlZWpd6r7LN1vXr1YsGCBbrXJYukZGdn6778R0VF6d7v1q0bq1evBiA5OZnjx48DcPXqVTQaDYMHD2bmzJkPrXr4oNatW+sSlby8PA4ePKiLvUePHpWa6mdnZ6er78iRI5w7d07va/Vx/71Yvnx5qfeCg4N56623GDJkiG4xkEfd0welp6fTtm1bJkyYwMCBA3X3srIGDBjAmjVruHPnDufOnSMtLU2vZ/eqWrUlboqiNAS6AUsBVFW9q6rqzeqqr7q88sorTJ48mTVr1uj+iiKEEEII8Wfg5eXF0KFDcXd3p2/fvnTq1KlKyhwxYgSdO3fG19eX4OBgPD09y61r1apVLF26FHd3dzp37symTZseKvdRz3rt3bsXNzc3PDw8ePXVV4mIiNA96xUaGoqtrS23b9/G1taWsLAwACZPnkxubi5DhgzBw8NDN23z6tWrlf5D/vz580lISMDNzQ0nJyddjKGhoXz00Ud4enqWGpkaO3Ysubm5ODo6MmPGDN0CLVlZWQQEBODh4cFbb72lW97/Ue0eP348ubm5ODs76xYNcXNzQ6PRcObMGb2edysxePBgrl+/jrOzMwsXLqRDhw6VugcVCQsLY8iQIXh7e9OsWbNS7w0YMIDc3FzdNEl49D190Pfff4+LiwseHh4kJyczbNgw4NHPuEVHR2Nra8vPP//MkCFD6N27N6CdAvqXv/wFJycn+vTpw6JFi2p8RUkApbpGkRRF8QD+DZxCO9qWCExUVTXvgfPeBt4GsLa29l6zZk21xPMkcnNzq21vDiFA+pioGdLPRE2Qfla1GjZsSLt27Wo7jDqluLi4Vr40A/zvf/8jIyODsWPH1kr9VeHUqVOsWLGizu3r9ihHjhzho48+qvG902qqn505c4bs7OxSxwIDAxNVVfV58NzqTNx8gIPA86qqHlIU5V/ALVVVpz/qGh8fH/VxNhisbrt37yYgIKC2wxBPMeljoiZIPxM1QfpZ1UpJSXnkEuV/Vjk5OTRo0KC2wxA1YNasWSxevJhVq1bRtWvXGq27pvpZWb/jiqKUmbhV5zNuF4GLqqoeuvd6PeBVjfVVK1VVK3xoVAghhBDiz2D8+PF4eHiU+rds2bLaDkvUQcuWLXuor4wfP16va6dMmcL58+drPGmrq6ptOwBVVX9TFCVTUZSOqqr+AvRAO23yD+fbb79l/vz5vPDCC0ycOLG2wxFCCCGEqFWLFi2q7RDEH8TIkSNLPZ8mHl917+P2LrBKURQTIB34Q35qJfuFyJYAQgghhBBCiNpQrYmbqqpJwEPzM/9oGjduzO3btyVxE0IIIYQQQtSK6t7H7alQslzq1atXdfuACCGEEEIIIURNkcRND40aNQK0UyavXr1au8EIIYQQQggh/nQkcdPD/RsUynRJIYQQQvxZhYWFMXv27DpTlz7nZGRkUL9+fd2KhmPGjNG9N3XqVFq1avXQ3oNz5szByckJNzc3evTowfnz5yuMt7r2LwwICOBxtsu6du0agYGBWFhYEBISUuq9u3fv8vbbb9OhQwccHBzYsGFDVYVbJezs7OrcYImhoaGuD5VsyF7TqntxkqdC48aNdT9L4iaEEEII8cdib29PUlLSQ8f79+9PSEgI7du3L3Xc09OThIQEzMzMWLx4MaGhoaxdu7aGoq0apqamfP755yQnJ5OcnFzqvfDwcKysrDh9+jQajYbr16/XUpS143E2165fv36ZfagmSeKmh0aNGqEoCqqqSuImhBBCiFrxVfxXpF5PrdIyHZo48GHnD8s9Jzw8nOXLl2NlZUWrVq3w9vZ+5LkBAQF4enoSFxdHXl4e3333HV9++SUnTpxg6NChzJw5E9COaEVGRgIQHBzMe++9V25dZ8+eZfz48Vy5coV69eoRGRmJg4PDE7ffz8+vzOOBgYGlzlm5cqVe5U2dOpUtW7ZQv359Nm3ahLW1NVeuXGHMmDFcuHABgHnz5vH8888THx/PxIkTKSgooH79+ixbtoyOHTuSn5/PyJEjOXbsGA4ODuTn5wPaZGP06NEkJCSgKAqjRo1i0qRJj4zF3Nycrl27cubMmYfei4yMJDVV25cMDAxo1qxZue2KiooiNjaW27dvc/bsWYKCgvjHP/4BaEcac3NzAVi/fj1btmwhKiqKESNGUL9+fY4ePcrly5eJjIzku+++4+eff8bX15eoqCi97ukrr7xCZmYmBQUFTJw4kbfffpvIyEiOHz/OvHnzAFiyZAmnTp1i7ty5rFy5kvnz53P37l18fX355ptvMDQ0xMLCgnfeeYcdO3awaNEitmzZQmxsLEZGRvTq1avGRpKfhEyV1IOhoSFNmzYFZMRNCCGEEH8eiYmJrFmzhqSkJH744QcOHz5c4TUmJiYkJCQwZswYBg4cyKJFi0hOTiYqKopr166RmJjIsmXLOHToEAcPHmTJkiUcPXq03LrefvttFixYQGJiIjNnzmTcuHEP1RsREUFERESZMZ07dw5PT09eeOEF4uLiKnUPli5dSt++fSs8Ly8vDz8/P44dO0a3bt1YsmQJABMnTmTSpEkcPnyYDRs2EBwcDICDgwNxcXEcPXqUzz77jI8//hiAxYsXY2ZmRkpKCp9++imJiYkAJCUlkZWVRXJyMidOnNDtjVZeu8ty8+ZNAKZPn46XlxdDhgzR6/ttUlISa9eu5cSJE6xdu5bMzMwKr7lx4wY///wzc+fOZcCAAUyaNImTJ09y4sQJvUevIiMjSUxMJCEhgfnz53Pt2jX+8pe/sHnzZgoLCwHtJt+jRo0iJSWFtWvXsn//fpKSkjA0NGTVqlWA9vPx9fXl2LFjODo6Eh0dzcmTJzl+/DjTpk0DIDY2lhkzZpQZR0FBAT4+Pvj5+RETE6NX7FVNRtz0NHHiRExNTbGxsantUIQQQgjxJ1TRyFh1iIuLIygoCDMzMwC9nu0pOcfV1RVnZ2fdd6e2bduSmZnJvn37CAoKwtzcHIBBgwYRFxeHRqMps67c3FwOHDjAkCFDgP+/v+6D7n927X42NjZcuHCBpk2bkpiYyCuvvMLJkyextLSssC0rV64kISGBPXv2VHiuiYkJ/fr1A8Db25vt27cDsGPHDk6dOqU779atW+Tm5pKdnc3w4cNJS0tDURRdm/bu3cuECRMAcHNzw83NDdDev/T0dN59911efvllevXqVW67H6WoqIiLFy/y3HPPMWfOHObMmcMHH3zAihUryr2uR48eNGzYEAAnJyfOnz9Pq1atyr2mf//+KIqCq6sr1tbWuLq6AuDs7ExGRgYeHh4Vxjt//nyio6MByMzMJC0tDT8/P7p3786WLVtwdHSksLAQV1dXFi5cSGJiIp06dQIgPz8fKysrQDsQM3jwYAAaNmyIqakpo0ePpl+/frrPbcCAAY/s4+fPn6dly5akp6fTvXt3XF1dsbe3rzD+qiSJm5706VhCCCGEEH929erVA7RT8Ep+LnldVFRU6fI0Gg2NGjXSjdDk5OTQoEGDSsVTEoe3tzf29vacPn0aH5/ytxresWMH4eHh7Nmzp1Q7HsXY2BhFUQBtklDSVo1Gw8GDBzE1NS11fkhICIGBgURHR5ORkUFAQEC55Tdu3Jhjx47x448/EhERwffff6+bbloZTZs2xczMjEGDBgEwZMgQli5dWuF199+D+9tX0mbQjkqVdc3j9oXdu3ezY8cOfv75Z8zMzAgICNDVERwczBdffIGDg4Nu9FFVVYYPH86XX375UFmmpqa659qMjIyIj4/np59+Yv369SxcuJCdO3eWG0vLli0BbQIdEBDA0aNHazxxk6mSQgghhBCiTN26dSMmJob8/HxycnLYvHnzE5fp7+9PTEwMt2/fJi8vj+joaPz9/R9Zl6WlJW3atGHdunWA9sv5sWPH9K7vypUrun1409PTSUtLo23btuVec/ToUd555x1iY2N1IzYlKvtsXa9evViwYIHudUkCmp2drUsG7n/eq1u3bqxevRqA5ORkjh8/Dmj3E9ZoNAwePJiZM2dy5MiRSsVRQlEU+vfvz+7duwH46aefcHJyAiA6OpqPPvqoUuVZW1uTkpKCRqPRjYxVlezsbBo3boyZmRmpqakcPHhQ956vry+ZmZmsXr2a119/HdCOCq5fv57Lly8DcP369TJXBC0Z8XzppZeYO3duhf3pxo0b3LlzB9B+Dvv379fds5okI25CCCGEEKJMXl5eDB06FHd3d6ysrHRT0J60zBEjRtC5c2dAO3Li6ekJ8Mi6Vq1axdixY5k5cyZ37tzhjTfewN3dvVS5Jc95PTh1cO/evcyYMQNjY2MMDAyIiIjQbfUUGhrK6tWruX37Nra2tgQHBxMWFsbkyZPJzc3VTc9s3bo1sbGxXL16FVVVK9Xe+fPnM378eNzc3CgqKqJbt25EREQQGhrK8OHDmTlzJi+//LLu/LFjxzJy5EgcHR1xdHTULdCSlZXFyJEj0Wg0ALpRpUe1G7TL6t+6dYu7d+8SExPDtm3bcHJy4quvvuKvf/0r7733Hs2bN2fZsmWAdhEYfaaQ3m/WrFn069eP5s2b4+Pjo1uopCr06dOHiIgIHB0d6dix40OLyfzlL38hKSlJtwK8k5MTM2fOpFevXmg0GoyNjVm0aBHPPvtsqetycnIYOHAgBQUFqKrKnDlzAO0zbgkJCXz22Welzk9JSeGdd97BwMAAjUbDlClTaiVxUyrb+aqTj4+P+jj7VFS33bt306FDBxYuXMjvv/9OSEiI7j8wQlSF3bt3VzhFQognJf1M1ATpZ1UrJSUFR0fH2g6jTqnsVMmqtGXLFtLT03XPoD1t3nrrLebOnUvz5s1rOxS99OvXj0mTJtGjR48qL7um+llZv+OKoiSqqvrQXF4ZcdOTiYkJJ06cAODSpUuSuAkhhBBC/MmULGLxtNJ324PadvPmTTp37oy7u3u1JG11lSRuemrSpAlGRkYUFRXp5s0KIYQQQvwZjR8/nv3795c6NnHiRN0iEULow9fXV/fsWIkVK1boVp98lEaNGnH69OnqDK1OksRNTwYGBjRv3pxLly7JXm5CCCGE+FNbtGhRbYcgngKHDh2q7RD+UGRVyUqwtrYGZBNuIYQQQgghRM2SxK0SSpaD/e2332o5EiGEEEIIIcSfiSRulVAy4paTk0N+fn4tRyOEEEIIIYT4s5DErRKeeeYZ3c8yXVIIIYQQQghRUyRxq4SSETeQxE0IIYQQfz5hYWHMnj27ztSlzzkZGRnUr18fDw8PPDw8Sm1UPXXqVFq1aoWFhUWpa+bMmYOTkxNubm706NGD8+fPVxjvg2VUlYCAAB5nn+Nr164RGBiIhYUFISEhpd67e/cub7/9Nh06dMDBwYENGzZUVbhVws7OjqtXr9Z2GKX06dOHRo0aPbQlxLlz5/D19aVdu3YMHTqUu3fvVlsMsqpkJbRs2ZJRo0ZhbW1Nx44dazscIYQQQvyJ/PbFF9xJSa3SMus5OvDMxx9XaZl1kb29PUlJSQ8d79+/PyEhIbRv377UcU9PTxISEjAzM2Px4sWEhoaydu3aGoq2apiamvL555+TnJxMcnJyqffCw8OxsrLi9OnTaDQarl+/XktR1o7i4mIMDQ0rdc3kyZO5ffs23377banjH374IZMmTeK1115jzJgxLF26lLFjx1ZluDoy4lYJFhYWBAUF8dxzz9GoUaPaDkcIIYQQotqFh4fToUMHunbtyi+//FLuuQEBAUyaNAkfHx8cHR05fPgwgwYNon379kybNk133pw5c3BxccHFxYV58+ZVWNfZs2fp06cP3t7e9O7dm9TUqklg/fz8sLGxeeh4YGAgZmZmunMuXryoV3lTp07F3d0dPz8/3eysK1euMHjwYDp16kSnTp10+9/Fx8fTpUsXPD09ee6553Ttzc/P57XXXsPR0ZGgoCDdugrFxcWMGDECFxcXXF1dmTt3brmxmJub07VrV0xNTR96LzIyko8++gjQbnnVrFmzcsuKiopi0KBB9OnTh/bt2xMaGqp77/6RxvXr1zNixAgARowYwdixY/Hz86Nt27bs3r2bUaNG4ejoqDtHH6+88gre3t44Ozvz73//Wxf/e++9pztnyZIlTJo0CdBuIt65c2c8PDx45513KC4u1sX597//HXd3d37++WemTJmiG1X94IMPKoyjR48eNGjQoNQxVVXZuXMnr776KgDDhw8nJiZG77ZVloy4CSGEEEL8AdTGyFhiYiJr1qwhKSmJoqIivLy88Pb2LvcaExMTEhIS+Ne//sXAgQNJTEykSZMm2NvbM2nSJDIyMli2bBmHDh1CVVV8fX154YUX0Gg0j6zr7bffJiIigvbt27Nz507GjRvHzp07S9UbEREBUGoqZIlz587h6emJpaUlM2fOxN/fX+97sHTpUvr27VvheXl5efj5+REeHk5oaChLlixh2rRpTJw4kUmTJtG1a1cuXLhA7969SUlJwcHBgbi4OIyMjNixYwcff/wxGzZsYPHixZiZmZGSksLx48fx8vICICkpiaysLN3o2c2bNytsd1lKrps+fTq7d+/G3t6ehQsXlnokqCxJSUkcPXqUevXq0bFjR959911atWpV7jU3btzg559/JjY2lgEDBrB//37+85//0KlTJ5KSkvDw8Kgw3sjISJo0aUJ+fj6dOnVi8ODB/OUvfyE8PJyvv/4aY2Njli1bxrfffktKSgpr165l//79GBsbM27cOFatWsWwYcPIy8vD19eXf/7zn1y7do3Ro0eTmpqKoii6exIbG0tCQgKfffaZPreSa9eu0ahRI4yMtCmVra0tWVlZel37OCRxE0IIIYQQZYqLiyMoKEg3+jRgwIAKryk5x9XVFWdnZ92IVtu2bcnMzGTfvn0EBQVhbm4OwKBBg4iLi0Oj0ZRZV25uLgcOHGDIkCEAaDQaCgsLH6r3UYmLjY0NFy5coGnTpiQmJvLKK69w8uRJLC0tK2zLypUrSUhIYM+ePRWea2Jionv+ydvbm+3btwOwY8cOTp06pTvv1q1b5Obmkp2dzfDhw0lLS0NRFF2b9u7dy4QJEwBwc3PDzc0N0N6/9PR03n33XV5++WV69epVbrsfpaioiIsXL/Lcc88xZ84c5syZwwcffMCKFSvKva5Hjx40bNgQACcnJ86fP19h4ta/f38URcHV1RVra2tcXV0BcHZ2JiMjQ6/Ebf78+URHRwOQmZlJWloafn5+dO/enS1btuDo6EhhYSGurq4sXLiQxMREOnXqBGhHL0u28zI0NGTw4MEANGzYEFNTU0aPHk2/fv10n9uAAQP06uO1RRK3SoqPj2fv3r3cvHmTzz//HEVRajskIYQQQog6o169eoB2Cl7JzyWvi4qKKl2eRqOhUaNGumfUcnJyHpqyVlE8JXF4e3tjb2/P6dOn8fHxKfe6HTt2EB4ezp49e0q141GMjY113wsNDQ11bdVoNBw8ePChKYshISEEBgYSHR1NRkYGAQEB5ZbfuHFjjh07xo8//khERATff/89kZGRFcb1oKZNm2JmZsagQYMAGDJkCEuXLq3wuvvvwf3tu/+7cEFBQZnXPG5f2L17Nzt27ODnn3/GzMyMgIAAXR3BwcF88cUXODg4MHLkSEA7dXH48OF8+eWXD5Vlamqqe67NyMiI+Ph4fvrpJ9avX8/ChQsfGsHVR9OmTbl58yZFRUUYGRlx8eJFWrZsWely9CXPuFVSVlYWe/bs4dixY+Tm5tZ2OEIIIYQQ1aZbt27ExMSQn59PTk4OmzdvfuIy/f39iYmJ4fbt2+Tl5REdHY2/v/8j67K0tKRNmzasW7cO0H45P3bsmN71XblyRfecU3p6OmlpabRt27bca44ePco777xDbGysbsSmhIODQ2WaS69evViwYIHudUkCmp2drfuSHxUVpXu/W7durF69GoDk5GSOHz8OwNWrV9FoNAwePJiZM2dy5MiRSsVRQlEU+vfvz+7duwH46aefcHJyAiA6Olr37Ju+rK2tSUlJQaPR6EbGqkp2djaNGzfGzMyM1NRUDh48qHvP19eXzMxMVq9ezeuvvw5oRwXXr1/P5cuXAbh+/XqZK4KWjHi+9NJLzJ07t1L96X6KohAYGMj69esBWL58OQMHDnyssvQhiVslyZYAQgghhPiz8PLyYujQobi7u9O3b1/dFLQnLXPEiBF07twZX19fgoOD8fT0LLeuVatWsXTpUtzd3encuTObNm16qNyIiAjd817327t3L25ubnh4ePDqq68SERFBkyZNAAgNDcXW1pbbt29ja2tLWFgYoF1BMDc3lyFDhuDh4aGbPnf16lVUVa1Ue+fPn09CQgJubm44OTnpYgwNDeWjjz7C09Oz1OjT2LFjyc3NxdHRkRkzZuie88vKyiIgIAAPDw/eeust3ajSo9oN2mX133//faKiorC1tdVN2fzqq68ICwvDzc2NFStW8M9//hPQLgKjzxTS+82aNYt+/frx3HPPlbnQy5Po06cPRUVFODo6MmXKFPz8/Eq9/5e//IXnn3+exo0bA9opnDNnzqRXr164ubnRs2dPLl269FC5OTk59OvXDzc3N7p27cqcOXMA7TNuM2bMKDMWf39/hgwZwk8//YStrS0//vgjoL2Xc+bMoV27drpn56qLUtnOV518fHzUx9mnorrt3r1bN3x95swZ3ao1H330Ec8991wtRiaeFvf3MSGqi/QzUROkn1WtlJQUHB0dazuMOqWyUyWr0pYtW0hPT9c9g/a0eeutt5g7dy7Nmzev7VD00q9fPyZNmkSPHj2qvOya6mdl/Y4ripKoqupDc3nlGbdKkhE3IYQQQog/pwc3X37arFy5srZD0MvNmzfp3Lkz7u7u1ZK01VWSuFWShYUFZmZm3L59m99++622wxFCCCGEqHHjx4/X7UdWYuLEibpFIoTQh6+vL3fu3Cl1bMWKFbrVJx+lUaNGnD59ujpDq5MkcaskRVGwsrIiIyND9+CjEEIIIcSfyaJFi2o7BPEUOHToUG2H8Icii5M8hpLpkjJVUgghhBBCCFETJHF7DM888wygTdzq0uIuQgghhBBCiKeTTJV8DO7u7oB25K24uBgjI7mNQgghhBBCiOojGcdj6NSpU5XsYyKEEEIIIYQQ+pCpkkIIIYQQQi9hYWHMnj27ztSlzzkZGRnUr18fDw8PPDw8GDNmjO69qVOn0qpVKywsLEpdM2fOHJycnHBzc6NHjx6cP3++wngfLKOqBAQE8Dj7HMfHx+va7O7uTnR0NACZmZkEBgbi5OSEs7Mz//rXv6o65CdWXffycZXXh2qSjLgJIYQQQvwBxH1/mquZuVVaZrNWFvj/pUOVllkX2dvbk5SU9NDx/v37ExISQvv27Usd9/T0JCEhATMzMxYvXkxoaChr166toWirhouLCwkJCRgZGXHp0iXc3d3p378/RkZG/POf/8TLy4ucnBy8vb3p2bMnTk5OtR1yjVBVFVVVMTCo3PjVo/pQTZIRt8f0008/sWzZMrZu3VrboQghhBBCVJvw8HA6dOhA165d+eWXX8o9NyAggEmTJuHj44OjoyOHDx9m0KBBtG/fnmnTpunOmzNnDi4uLri4uDBv3rwK6zp79ix9+vTB29ub3r17k5qaWiVt8/Pzw8bG5qHjgYGBmJmZ6c65ePGiXuVNnToVd3d3/Pz8dKuPX7lyhcGDB+setSnZ/y4+Pp4uXbrg6enJc889p2tvfn4+r732Go6OjgQFBZGfnw9AcXExI0aMwMXFBVdXV+bOnVtuLGZmZrp1GAoKClAUBQAbGxu8vLwAaNCgAY6OjmRlZZVbVlhYGKNGjSIgIIC2bdsyf/58QDsS5eLiojtv9uzZhIWFAfr3hfLk5ubSo0cPvLy8cHV1ZdOmTQDMmDGjVL+ZOnWqbuTw66+/plOnTri5ufHJJ5/o4uzYsSPDhg3DxcWFzMzMSt3LukJG3B7Tf//7X9LS0vDw8KBPnz61HY4QQgghnnK1MTKWmJjImjVrSEpKoqioCC8vL7y9vcu9xsTEhISEBP71r38xcOBAEhMTadKkCfb29kyaNImMjAyWLVvGoUOHUFUVX19fXnjhBTQazSPrevvtt4mIiKB9+/bs3LmTcePGsXPnzlL1RkREAJQ5je3cuXN4enpiaWnJzJkz8ff31/seLF26lL59+1Z4Xl5eHn5+foSHhxMaGsqSJUuYNm0aEydOZNKkSXTt2pULFy7Qu3dvUlJScHBwIC4uDiMjI3bs2MHHH3/Mhg0bWLx4MWZmZqSkpHD8+HFdkpWUlERWVhbJyckA3Lx5s8J2Hzp0iFGjRnH+/HlWrFjx0IJ6GRkZHD16FF9f3wrbl5qayq5du8jJyaFjx46MHTu2wmsq6gtNmzYt93pTU1Oio6OxtLTk6tWr+Pn5MWDAAEaNGsWgQYN47733dP0mPj6ebdu2kZaWRnx8PKqqMmDAAPbu3Uvr1q1JS0tj+fLl+Pn5kZiYWOl7+SR9qKpI4vaYrK2tSUtLk73chBBCCPHUiouLIygoSDf6NGDAgAqvKTnH1dUVZ2dn3YhW27ZtyczMZN++fQQFBWFubg7AoEGDiIuLQ6PRlFlXbm4uBw4cYMiQIQBoNBoKCwsfqvdRzx3Z2Nhw4cIFmjZtSmJiIq+88gonT57E0tKywrasXLmShIQE9uzZU+G5JiYm9OvXDwBvb2+2b98OwI4dOzh16pTuvFu3bpGbm0t2djbDhw8nLS0NRVF0bdq7dy8TJkwAwM3NDTc3N0B7/9LT03n33Xd5+eWX6dWrV7ntBvD19eXkyZOkpKQwfPhw+vbti6mpKaC9r4MHD2bevHl63YuXX36ZevXqUa9ePaysrPT6DlxRX6gocVNVlY8//pi9e/diYGBAVlYWv//+O3Z2djRt2pSjR4/y+++/4+npSdOmTdm2bRvbtm3D09NT18a0tDRat27Ns88+i5+fn67+ytzLJ+lDVUkSt8dUsgn3lStX0Gg0lZ4nK4QQQgjxNKpXrx4ABgYGup9LXhcVFVW6PI1GQ6NGjXTPF+Xk5NCgQYNKxVMSh7e3N/b29pw+fRofH59yr9uxYwfh4eHs2bOnVDsexdjYWDcd0dDQUNdWjUbDwYMHdQlTiZCQEAIDA4mOjiYjI4OAgIByy2/cuDHHjh3jxx9/JCIigu+//57IyMgK4wJwdHTEwsKC5ORkfHx8KCwsZPDgwbz55psMGjRIrzLuvwcl7TMyMkKj0eiOFxQUlHnN4/aFVatWceXKFRITEzE2NsbOzk5XR3BwMFFRUfz222+MGjUK0CZ6H330Ee+8806pcjIyMnR/KIDK38vH7UNVTbKNx1SSuBUVFXH9+vVajkYIIYQQoup169aNmJgY8vPzycnJYfPmzU9cpr+/PzExMdy+fZu8vDyio6Px9/d/ZF2Wlpa0adOGdevWAdov58eOHdO7vitXrlBcXAxAeno6aWlptG3bttxrjh49yjvvvENsbCxWVlal3nNwcKhMc+nVqxcLFizQvS5JQLOzs2nZsiUAUVFRuve7devG6tWrAUhOTub48eMAXL16FY1Gw+DBg5k5cyZHjhwpt95z587pkqPz58+TmpqKnZ0dqqoyevRoHB0def/990tds3DhQhYuXKh326ytrbl8+TLXrl3jzp07bNmyRe9r9ZGdnY2VlRXGxsbs2rWr1OqeQUFBbN26lcOHD9O7d28AevfuTWRkJLm52kV8srKyuHz58kPlVvZePk4fqg4y4vaYmjVrxs2bN8nLy2PHjh385S9/kVE3IYQQQjxVvLy8GDp0KO7u7lhZWVXJPrZeXl6MGDGCzp07A9qRk5KpbY+qa9WqVYwdO5aZM2dy584d3njjDdzd3UuV+6jnk/bu3cuMGTMwNjbGwMCAiIgImjRpAkBoaCirV6/m9u3b2NraEhwcTFhYGJMnTyY3N1c3PbN169bExsZy9epVVFWtVHvnz5/P+PHjcXNzo6ioiG7duhEREUFoaCjDhw9n5syZvPzyy7rzx44dy8iRI3F0dMTR0VH3nF9WVhYjR47UjXB9+eWX5bZ73759zJo1S9fub775hmbNmrFv3z5WrFiBq6srHh4eAHzxxRe89NJLpKam8vzzz+vdNmNjY2bMmEHnzp1p2bJlpZPairz55pv0798fV1dXfHx8SpVvYmJCYGAgjRo1wtDQENAmySkpKXTp0gXQbiuwcuVK3fslKnsvy+tDNUmpbOerTj4+Purj7FNR3Xbv3l1q+Fqj0RASEsLq1atRVZVnnnmGgQMHMmvWLEnexGN5sI8JUR2kn4maIP2saqWkpODo6FjbYdQplZ0qWZW2bNlCenq67hm0p02/fv3YuHEjJiYmtR1KhTQaDV5eXqxbt+6h7RyqQk31s7J+xxVFSVRV9aF5mDLi9hgSExOJj4/HxMQERVGoX78+O3fuJDExsUr+EiWEEEIIIeqeksVHnlZVPdWxupw6dYp+/foRFBRULUlbXSWJ22M4e/YsGo0Gc3Nzbt++zbVr12jWrBnp6emSuAkhhBDiqTd+/HjdfmQlJk6cyMiRI2spIvFHc+3aNXr06PHQ8Z9++qnC1SadnJxIT0+vrtDqLEncHoO9vT2GhoZYW1tz9epVbGxsyM/Pr5WHFIUQQgghatqiRYtqOwTxB9e0aVPdQi1CP/JA1mPw9vYmMDCQoqIiLC0tyc/Pp3v37hVuSCmEEEIIIYQQj0NG3B6DgYEBs2bNIjExkfT0dNq2bYu3t7csTCKEEEIIIYSoFpK4PSYDAwM6deqke6ZNVVV++eUXOnTooNt8UQghhBBCCCGqggwRVYGsrCw+/PBDPvjgA+ridgZCCCGEEEKIPzZJ3KpAo0aNyMjIAGDdunWV3phRCCGEEOKPICwsjNmzZ9eZuvQ5JyMjg/r16+Ph4YGHh0epzZWnTp1Kq1atsLCwKHXNnDlzcHJyws3NjR49enD+/PkK432wjKoSEBDwWAMD8fHxuja7u7sTHR0NQGZmJoGBgTg5OeHs7My//vWvqg75iVXXvXxc165dIzAwEAsLC0JCQkq9l5iYiKurK+3atWPChAnVmgfIVMkqYG5uzssvv8z69etJSUnh5MmTuLi41HZYQgghhHiK7Ir6N5fPV+0S6FbPtiVwxNtVWmZdZG9vX+YKhv379yckJOShvcA8PT1JSEjAzMyMxYsXExoaytq1a2so2qrh4uJCQkICRkZGXLp0CXd3d/r374+RkRH//Oc/8fLyIicnB29vb3r27ImTk1Nth1wjVFVFVdVKrU1hamrK559/TnJyMsnJyaXeGzt2LEuWLMHX15eXXnqJrVu30rdv36oOG5ARtyozcOBA3S7z69atq+VohBBCCCGqRnh4OB06dKBr16788ssv5Z4bEBDApEmT8PHxwdHRkcOHDzNo0CDat2/PtGnTdOfNmTMHFxcXXFxcmDdvXoV1nT17lj59+uDt7U3v3r1JTU2tkrb5+flhY2Pz0PHAwEDMzMx051y8eFGv8qZOnYq7uzt+fn78/vvvAFy5coXBgwfr1kYo2f8uPj6eLl264OnpyXPPPadrb35+Pq+99hqOjo4EBQWRn58PQHFxMSNGjMDFxQVXV1fmzp1bbixmZmYYGWnHaAoKCnRrMNjY2ODl5QVAgwYNcHR0JCsrq9yywsLCGDVqFAEBAbRt25b58+cD2tHM+wcrZs+eTVhYGKB/XyhPbm4uPXr0wMvLC1dXVzZt2gTAjBkzSvWbqVOn6kYOv/76azp16oSbmxuffPKJLs6OHTsybNgwXFxcyMzMrNS9NDc3p2vXrpiampY6funSJW7duoWfnx+KojBs2DBiYmL0atvjkBG3KtKoUSN69uzJf//7X44cOcLZs2ext7ev7bCEEEII8ZSojZGxxMRE1qxZQ1JSEkVFRXh5eVW4/ZGJiQkJCQn861//YuDAgSQmJtKkSRPs7e2ZNGkSGRkZLFu2jEOHDqGqKr6+vrzwwgtoNJpH1vX2228TERFB+/bt2blzJ+PGjWPnzp2l6o2IiAAoNRWyxLlz5/D09MTS0pKZM2fi7++v9z1YunSpXiMoeXl5+Pn5ER4eTmhoKEuWLGHatGlMnDiRSZMm0bVrVy5cuEDv3r1JSUnBwcGBuLg4jIyM2LFjBx9//DEbNmxg8eLFmJmZkZKSwvHjx3VJVlJSEllZWboRn5s3b1bY7kOHDjFq1CjOnz/PihUrdIlciYyMDI4ePYqvr2+F7UtNTWXXrl3k5OTQsWNHxo4dW+E1FfWFijbaNjU1JTo6GktLS65evYqfnx8DBgxg1KhRDBo0iPfee0/Xb+Lj49m2bRtpaWnEx8ejqioDBgxg7969tG7dmrS0NJYvX46fnx+JiYmVvpdlycrKwtbWVvfa1ta2wiT4SUjiVoUGDRrE1q1bKS4uZt26dUyZMqW2QxJCCCGEeGxxcXEEBQXpRp8GDBhQ4TUl57i6uuLs7Kwb0Wrbti2ZmZns27ePoKAgzM3NAe33p7i4ODQaTZl15ebmcuDAAYYMGQKARqOhsLDwoXof9WXbxsaGCxcu0LRpUxITE3nllVc4efIklpaWFbZl5cqVJCQksGfPngrPNTExoV+/foB2z9/t27cDsGPHDk6dOqU779atW+Tm5pKdnc3w4cNJS0tDURRdm/bu3cuECRMAcHNzw83NDdDev/T0dN59911efvllevXqVW67AXx9fTl58iQpKSkMHz6cvn376kaNcnNzGTx4MPPmzdPrXrz88svUq1ePevXqYWVlpRtRLE9FfaGixE1VVT7++GP27t2LgYEBWVlZ/P7779jZ2dG0aVOOHj3K77//jqenJ02bNmXbtm1s27YNT09PXRvT0tJo3bo1zz77LH5+frr6K3sv6wJJ3KqQlZUVL7zwAjt37uTAgQNkZWXRsmXL2g5LCCGEEKLG1KtXD9BunVTyc8nroqKiSpen0Who1KiR7hm1nJwcGjRoUKl4SuLw9vbG3t6e06dP4+PjU+51O3bsIDw8nD179pRqx6MYGxvrpiMaGhrq2qrRaDh48OBD0+xCQkIIDAwkOjqajIwMAgICyi2/cePGHDt2jB9//JGIiAi+//57IiMjK4wLwNHREQsLC5KTk/Hx8aGwsJDBgwfz5ptvMmjQIL3KuP8elLTPyMgIjUajO15QUFDmNY/bF1atWsWVK1dITEzE2NgYOzs7XR3BwcFERUXx22+/MWrUKECb6H300Ue88847pcrJyMjQ/aEAnuxe3q9ly5alptFevHixWr/7yzNu5Si6eYdrK09hkqP/Na+++iqKoqCqKhs2bKi+4IQQQgghqlm3bt2IiYkhPz+fnJwcNm/e/MRl+vv7ExMTw+3bt8nLyyM6Ohp/f/9H1mVpaUmbNm10awioqsqxY8f0ru/KlSsUFxcDkJ6eTlpaGm3bti33mqNHj/LOO+8QGxuLlZVVqfccHBwq01x69erFggULdK9LEtDs7Gzdl/yoqCjd+926dWP16tUAJCcnc/z4cQCuXr2KRqNh8ODBzJw5kyNHjpRb77lz53TJ0fnz50lNTcXOzg5VVRk9ejSOjo68//77pa5ZuHAhCxcu1Ltt1tbWXL58mWvXrnHnzh22bNmi97X6yM7OxsrKCmNjY3bt2lVqdc+goCC2bt3K4cOH6d27NwC9e/cmMjKS3NxcQDuV8fLlyw+VW9l7+Sg2NjZYWlpy8OBBVFXlu+++Y+DAgY9Vlj5kxK0cirEBBadv0riJ/htqt2rVihdeeAFzc3Patm3LmjVrsLe3x9vbu1Kr1wghhBBC1DYvLy+GDh2Ku7s7VlZWdOrUqUrKHDFiBJ07dwa0IyclU9seVdeqVasYO3YsM2fO5M6dO7zxxhu4u7uXKvdRzyft3buXGTNmYGxsjIGBARERETRp0gSA0NBQVq9eze3bt7G1tSU4OJiwsDAmT55Mbm6ubnpm69atiY2N5erVq5Ve7n3+/PmMHz8eNzc3ioqK6NatGxEREYSGhjJ8+HBmzpzJyy+/rDt/7NixjBw5EkdHRxwdHXXP+WVlZTFy5EjdCNeXX35Zbrv37dvHrFmzdO3+5ptvaNasGfv27WPFihW4urri4eEBwBdffMFLL71Eamoqzz//vN5tMzY2ZsaMGXTu3JmWLVtWOqmtyJtvvkn//v1xdXXFx8enVPkmJiYEBgbSqFEjDA0NAW2SnJKSQpcuXQDttgIrV67UvV+isvcSwM7Ojlu3bnH37l1iYmLYtm0bTk5OfPPNN4wYMYL8/Hz69u1bbStKAih1ac8xHx8fta5tYJ29NYNbuy/wzCRvjK3NK74A7ao/H330Ebt27aK4uBhDQ0MCAwOZNWuWJG+iTLt3765wioQQT0r6magJ0s+qVkpKCo6OjrUdRp1S2amSVWnLli2kp6frnkF72vTr14+NGzfqVkqvyzQaDV5eXqxbt+6h7RyqQk31s7J+xxVFSVRV9aG5vJJFlEMtLOTumW2ohnDrpwt6X3fkyBF27dqFlZUVLVu2xMrKip07d5KYmFiN0QohhBBCiOrUr1+/pzZpA21i+kdI2k6dOkW7du3o0aNHtSRtdZVMlSzHnfR0rn67EMPnRmJwwofC3/P0GnU7e/YsxcXFGBgYUFxczK1bt9BoNKSnp1fJFAMhhBBCiNo0fvx43X5kJSZOnMjIkSNrKSLxR3Pt2jV69Ojx0PGffvqpwtUmnZycSE+v2s3o/wgkcSuHaceOFI59HSViNbzsxa2fLtD0jYqnK9jb22NoaMjNmzc5d+4chYWFWFlZVfggrBBCCCHEH8GiRYtqOwTxB9e0aVPdQi1CPzJVshynrp3iTbNVnO1gzp3T28g/fpXC3/MqvM7b25vAwECys7PJzc3lzp07mJub6zZQFEIIIYQQQojKkMStHI5NHBnc4VU+7XmV27cOoxbfIft/Zyu8zsDAgFmzZrF06VKGDBmCq6srzZo14/DhwzUQtRBCCCGEEOJpI4lbORRF4X2fj7BuaM9nva9x99wu8lNucvdSboXXGhgY0KlTJ+bMmYOtrS2KohAZGUlhYWENRC6EEEIIIYR4mkjiVo6U3Hz84k/j23w8159txPo2h6DoDlf/s0fvMho0aMAbb7wBwKVLl6p8Y0IhhBBCCCHE008St3K0MzPF71Yyu1Vz5gXM43vX61y6/TPFuRbc2nFI73L69u2Lra0tAGvWrCE7O7u6QhZCCCGEqDZhYWHMnj27ztSlzznXrl0jMDAQCwsLQkJCSr2XmJiIq6sr7dq1Y8KECbrNtSdPnoyDgwNubm4EBQVx8+bNUtdduHABCwsLve6FnZ0dV69erfC8yhoxYgTr169/rGtDQ0NxdnbG0dGxVLvrgt27d9OvX7/aDqOUqKgomjdvjoeHBx4eHvznP/+plThkVclyZB9ewYTlX7DVpwd5Pl/xyfNhTMkLJyq9C9fXJGPm2Q6jCpYrBTAyMiI4OJiwsDBu377NypUrGT9+fA20QAghhBBPi5ubz3L314oXSasMkxbmNOpvX6Vl1jWmpqZ8/vnnJCcnk5ycXOq9sWPHsmTJEnx9fXnppZfYunUrffv2pWfPnnz55ZcYGRnx4Ycf8uWXX/LVV1/prnv//ffp27dvTTelShw4cID9+/dz/PhxALp27cqePXsICAio3cBqSFFREUZGlU+Bhg4dysKFC6shIv3JiFs5YuLy+Yl2dE44RET6eQbYD6C39yB+NN+FYVMXfp3yBWpxsV5leXt74+3tDUBqaqo86yaEEEKIP4Tw8HA6dOhA165d+eWXX8o9NyAggEmTJuHj44OjoyOHDx9m0KBBtG/fnmnTpunOmzNnDi4uLri4uDBv3rwK6zp79ix9+vTB29ub3r17k5qaqnf85ubmdO3aFVNT01LHL126xK1bt/Dz80NRFIYNG0ZMTAwAvXr10n259/Pz4+LFi7rrYmJiaNOmDc7OznrHsGDBAry8vHB1ddXFnpeXx6hRo+jcuTOenp5s2rQJgIyMDPz9/fHy8sLLy4sDBw4AoKoqISEhdOzYkRdffJHLly/ryp8yZQpOTk64ubnxwQcflBuLoigUFBRw9+5d7ty5Q2FhIdbW1uVeExAQwIcffkjnzp3p0KEDcXFxgHYk6v5RzH79+rF7924ALCwsmDx5Ms7Ozrz44ovEx8cTEBBA27ZtiY2N1eu+xcfH06VLFzw9PXnuued0faJbt26lthLo2rUrx44de+Q9jYqKYsCAAXTv3p0ePXpw6dIlunXrhoeHBy4uLrr21HUy4laOIeNGsuKtGH4ttsD25GpOdZjG333+zqQrE+m+9w4G+S25+u23NB83Tq/yRo8eTefOnenduzeGhobVHL0QQgghnia1MTKWmJjImjVrSEpKoqioCC8vL90foh/FxMSEhIQE/vWvfzFw4EASExNp0qQJ9vb2TJo0iYyMDJYtW8ahQ4dQVRVfX19eeOEFNBrNI+t6++23iYiIoH379uzcuZNx48axc+fOUvVGREQAMGbMGL3alpWVpXuUBcDW1pasrKyHzouMjGTo0KEA5Obm8tVXX7F9+/ZKTRlt1qwZR44c4ZtvvmH27Nn85z//ITw8nO7duxMZGcnNmzfp3LkzL774IlZWVmzfvh1TU1PS0tJ4/fXXSUhIIDo6ml9++YVTp07x+++/4+TkxKhRo7h27RrR0dGkpqaiKIpuWmdsbCwJCQl89tlnpWLp0qULgYGB2NjY6JJBR8eK9ykuKioiPj6eH374gU8//ZQdO3aUe35eXh7du3fn66+/JigoiGnTprF9+3ZOnTrF8OHDGTBgQIV1Ojg4EBcXh5GRETt27ODjjz9mw4YNjB49mqioKObNm8fp06cpKCjA3d2djz/+uMx7CnDkyBGOHz9OkyZN+Oc//0nv3r2ZOnUqxcXF3L59G4Dg4GDGjBmDj4/PQ7Fs2LCBvXv30qFDB+bOnUurVq0qjL+qSeJWjoZGhZiamHK52IB3Tv0f020HEBXoy+c9wllzZjEv8xzXl8+k4YCBmNi2rLC8Vq1a1cqHLIQQQgjxOOLi4ggKCsLMzAxAry/bJee4urri7OyMjY0NAG3btiUzM5N9+/YRFBSEubk5AIMGDSIuLg6NRlNmXbm5uRw4cIAhQ4YAoNFoypy5pG/CVhnh4eEYGRnx5ptvAtpn6iZNmoSFhUWlyhk0aBCgnYG1ceNGALZt20ZsbKwuASwoKODChQu0aNGCkJAQkpKSMDQ05PTp0wDs3buX119/HUNDQ1q0aEH37t0BaNiwIaampowePZp+/frpng8bMGBAmZ/XmTNnSElJ0Y0i9uzZk7i4OPz9/fVuQ0ZGRoVtNjExoU+fPoC2L9SrVw9jY2NcXV31uh4gOzub4cOHk5aWhqIous99yJAhfP7553z99ddERkYyYsQI4NH3tKSdTZo0AaBTp06MGjWKwsJCXnnlFTw8PAAe+exa//79ef3116lXrx7ffvstw4cPf+gPBzVBErdyFPyWSWtLC05k3+DaxXq0ytxEypX2ODZvQuCrr1Cw8CLGHfpy4/u1WL//fqXK1mg0JCYmcubMGdq1a4e3tzcGBjJzVQghhBB/bPXq1QO0WyOV/FzyuqioqNLlaTQaGjVqpJsal5OTQ4MGDZ44zpYtW5aaAnnx4kVatvz/f4iPiopiy5Yt/PTTTyiKAsChQ4dYv349oaGh3Lx5EwMDA0xNTR9a9ORBJffB0NBQdw9UVWXDhg107Nix1LlhYWFYW1tz7NgxNBrNQ1M8H2RkZER8fDw//fQT69evZ+HCheUmFdHR0fj5+emSz759+/Lzzz9XmLiV1QYjIyM0Go3unIKCAt3PxsbGuvt2f1+oTD+YPn06gYGBREdHk5GRoXsOz8zMjJ49e7Jp0ya+//57EhMTgUff00OHDun+UADaqZZ79+7lv//9LyNGjOD9999n2LBhj4yj6X1rWgQHBxMaGqpX/FVNMoVyFFrYcVoZjoHGgJM5zxByfjUfxfwPVVXp2NKRm24aTFp24uqm/6Levat3uRqNhpCQEF555RWmTp3KuHHjmDJlSqmOL4QQQghR27p160ZMTAz5+fnk5OSwefPmJy7T39+fmJgYbt++TV5eHtHR0fj7+z+yLktLS9q0acO6desA7ZfzY8eOPXEcNjY2WFpacvDgQVRV5bvvvmPgwIEAbN26lX/84x/ExsbqRgBBOwKZkZFBRkYG7733Hh9//LEuaevRo0eZUy0fpXfv3ixYsEC3ouPRo0cB7SiTjY0NBgYGrFixguJ76yl069aNtWvXUlxczKVLl9i1axegHZHMzs7mpZdeYu7cuRXem9atW7Nnzx6KioooLCxkz549uqmSw4YNIz4+Xu822NnZkZSUhEajITMzs1LX6iM7O1uXTEdFRZV6Lzg4mAkTJtCpUycaN24MPPqePuj8+fNYW1vzt7/9jeDgYI4cOVJuHJcuXdL9HBsbq9fU0uogiVs5GjQxxerZhpiYtOKqkSnN7t7A3eQEy5Z8D4BLV18ATIxbkfPTT3qXm5CQwPr16yksLKSgoICGDRuyc+dO3V8LhBBCCCHqAi8vL4YOHYq7uzt9+/alU6dOVVLmiBEj6Ny5M76+vgQHB+Pp6VluXatWrWLp0qW4u7vTuXNn3aIT94uIiNA95/YgOzs73n//faKiorC1teXUqVMAfPPNNwQHB9OuXTvs7e11K0WGhISQk5NDz5498fDwqHAapkaj4cyZM7qpePqYPn06hYWFuLm54ezszPTp0wEYN24cy5cvx93dndTUVN1IUVBQEO3bt8fJyYlhw4bRpUsXQDsC2a9fP9zc3OjatStz5swBtAnGjBkzHqr31Vdfxd7eHldXV9zd3XF3d6d///4AHD9+nBYtWujdhueff542bdrg5OTEhAkT8PLy0vtafYSGhvLRRx/h6en50Cidt7c3lpaWjBw5UnfsUff0Qbt378bd3R1PT0/Wrl3LxIkTAW0ymJCQ8ND58+fPx9nZGXd3d+bPn/9QEllTlLq0b4OPj49a1s2qTQk/ZHBg/VYK87bganENd7tLhNR/l0+7v4SjhwPnwvZw5/whKEzAcfU6vcpcs2YNn376KdevXwe0m3Q3aNCAKVOm6B5+FX8uu3fv/tMswytqj/QzUROkn1WtlJSUWvvrfl1VVVMlq1JycjKRkZG6pOmP6NatW4wePVo3slnX/frrrwQEBJCamlotjxvVVD8r63dcUZREVVUfWiFFRtzKkXM3h7TGRzAwtkNR4cyN5lgX38Cl2e9sXDCHO7fzMevQBANrZziSzJ30dL3Ktbe3x8LCAisrK0D7i3Lr1i3atm1bnc0RQgghhBDVwMXF5Q+dtIF2SuofJWn77rvv8PX1JTw8/E+1RkS1tlRRlAxFUU4oipKkKErdGkrTQ87dHL44/QnFFoWYGNugUsj+IifGZH5PSvvWfPPxlzToYIW5QUM0ljZcWhWlV7ne3t4EBgZiYmKCRqPh7t27GBgYlHrwUQghhBCirho/fjweHh6l/i1btqy2wxJ/ID/++ONDfSgoKEiva4cNG0ZmZqZupdE/i5pYVTJQVdWrNVBPlWth0YKOjTtyoekpnr3uSGHRJWJvdOKr5stxaJlNYfIZfozfT2es+NXZCeuYWDSTP8aggtV/DAwMmDVrFomJiezfv5+NGzdiaWnJ3LlzmTNnDsbGxjXUQiGEEEKIylu0aFFthyD+4Hr37k3v3r1rO4w/lD/P2OJjCmwdSJJlHAbG2k0v2+blsL/Ymbez1nPa4XnS41ZCQ2Ma2PlhnHeH6//Vb7UlAwMDOnXqxHvvvcc777yDoihkZGSwatWq6myOEEIIIYQQ4g+oukfcVGCboigq8K2qqv9+8ARFUd4G3gawtrZm9+7d1RxS5VjeseSyxQVUMxOMb1likHuFSLUPS4v/iUPrTNRTxfxyIxN7o1akNTPk+rfzSW7avFJ1PPPMM5iampKVlcWKFSuwtramfv361dQiURfl5ubWub4vnj7Sz0RNkH5WtRo2bEhOTk5th1GnFBcXyz0R1a6m+llBQYHe/82s7sStq6qqWYqiWAHbFUVJVVV17/0n3Evm/g3aVSXr2kpUqqqyZNUSsm2zsLzpxK3bP2Pb2Jb9N50ZnhXLZ+2GY/tbMh2bvUjWc974xsZj17w59Z2dK1VPhw4dWL58OWPHjpVn3f6EZBU2UROkn4maIP2saqWkpNS5FRRrW11cVVI8fWqqn5mamuLp6anXudU6VVJV1ax7/3sZiAY6V2d91UFRFFzMXDhkugPFqB0oCoF3fyVS7YNV8Q3aPnuVy3nJqICz61+4YwS/RC2sdD2tWrVi2rRpkrQJIYQQos4KCwtj9uzZdaYufc65du0agYGBWFhY6DbLLpGYmIirqyvt2rVjwoQJuo2bJ0+ejIODA25ubgQFBXHz5s1S1124cAELCwu97oWdnR1Xr1b9cg8jRoxg/fr1j3VtaGgozs7OODo6lmp3XbB792769etX22GUsnfvXry8vDAyMnroni9fvpz27dvTvn17li9fXq1xVFvipiiKuaIoDUp+BnoBydVVX3Vyq+/GeYsUjMybYajW47dfTtL4mQ7sL3bmrd/+y5WGllwtukmrnBYkuJqi/BhHcW7uY9en0Wg4fPgwK1as4PDhw2g0mipsjRBCCCHEn4epqSmff/55mUnW2LFjWbJkCWlpaaSlpbF161YAevbsSXJyMsePH6dDhw58+eWXpa57//33dZt1/9EcOHCA/fv3c/z4cZKTkzl8+DB79uyp7bBqzIMbeeujdevWREVF8cYbb5Q6fv36dT799FMOHTpEfHw8n376KTdu3KiqUB9SnVMlrYFoRVFK6lmtqurWaqyv2rQzbYe5iRl5tr9jcqMDl/KO87ce7kSs7sbc4sVYtjPj8plfaJ7ZCPNXBmFydDXp30fRflRIxYU/QKPR8OGHH7Jx40Zu3rzJs88+y4svvsisWbP+VPtUCCGEEKK0//3vf/z2229VWuYzzzxTYQISHh7O8uXLsbKyolWrVnh7ez/y3ICAADw9PYmLiyMvL4/vvvuOL7/8khMnTjB06FBmzpwJwJw5c4iMjAQgODiY9957r9y6zp49y/jx47ly5Qr16tUjMjISBwcHvdpobm5O165dOXPmTKnjly5d4tatW/j5+QHaJeZjYmLo27cvvXr10p3n5+dXapQlJiaGNm3aYG5urlf9AAsWLGDz5s0UFhaybt06HBwcyMvL49133yU5OZnCwkLCwsIYOHAgGRkZ/PWvfyUvLw+AhQsX8txzz6GqKu+++y7bt2+nVatWmJiY6MqfMmUKsbGxGBkZ0atXr3JHAhVFoaCggLt376KqKoWFhVhbW5cbf0BAAL6+vuzatYubN2+ydOlS/P39iYqKIiEhgYULtbPN+vXrxwcffEBAQAAWFhaMHTuWH374ARsbG7744gtCQ0O5cOEC8+bNY8CAARXet/j4eCZOnEhBQQH169dn2bJldOzYkW7dujF//nw8PDwA6Nq1K4sWLaJdu3Zl3tOoqCg2btxIbm4uxcXFrFmzhqFDh3Lr1i2KiopYvHgx/v7+j4zDzs4O4KHv4j/++CM9e/akSZMmgDbh37p1K6+//nqFbXsc1ZYJqKqarqqq+71/zqqqhldXXdXNSDHCv6U/iWa7wbg9GgOF4hNJGDVpTZFqQEuTy/yefxZU6N7hLc49o3Bt9arHGnZOTEzkv//9Lzk5ORgZGZGTk8POnTtJTEys+oYJIYQQQpQjMTGRNWvWkJSUxA8//MDhw4crvMbExISEhATGjBnDwIEDWbRoEcnJyURFRXHt2jUSExNZtmwZhw4d4uDBgyxZsoSjR4+WW9fbb7/NggULSExMZObMmYwbN+6heiMiIoiIiNC7bVlZWdja2upe29rakpWV9dB5kZGRuuQ2NzeXr776ik8++UTvegCaNWvGkSNHGDt2rC6pCg8Pp3v37sTHx7Nr1y4mT55MXl4eVlZWbN++nSNHjrB27VomTJgAQHR0NL/88gunTp3iu+++48CBA4B2Kmh0dDQnT57k+PHjTJs2DYDY2FhmzJjxUCxdunQhMDAQGxsbbGxs6N27N46OjhW2oaioiPj4eObNm8enn35a4fl5eXl0796dkydP0qBBA6ZNm8b27duJjo4uM66yODg4EBcXx9GjR/nss8/4+OOPARg9ejRRUVEAnD59moKCAtzd3R95TwGOHDnC+vXr2bNnD6tXr6Z3794kJSVx7NgxXQIYHBxMQoL+W09nZWXRqlUr3etH9aGqUhP7uD0VAlsH8tHZqfjXH0JRjgFpe3fR769jOfLf9rjmnGV7YT2KNEWYnS/mcm8v2ixP5Gr8Ppr7Pjp7L8vZs2cxNTWlWbNmXLt2TfeXgPT0dDp16lRNrRNCCCFEXVcbU/Pi4uIICgrCzMwMQK9RkpJzXF1dcXZ2xsbGBoC2bduSmZnJvn37CAoK0o1YDRo0iLi4ODQaTZl15ebmcuDAAd1myxqNhsLCwofqHTNmzBO29mHh4eEYGRnx5ptvAtpn6iZNmoSFhUWlyhk0aBAA3t7ebNy4EYBt27YRGxurS+QKCgq4cOECLVq0ICQkhKSkJAwNDTl9+jSgfc7q9ddfx9DQkBYtWtC9e3dAu/Koqakpo0ePpl+/frrnwwYMGFDm53XmzBlSUlK4ePEioB0liouLK3fE6cE2ZGRkVNhmExMT+vTpA2j7Qr169TA2NsbV1VWv6wGys7MZPnw4aWlpKIqi+9yHDBnC559/ztdff01kZCQjRowAHn1PS9pZMjLWqVMnRo0aRWFhIa+88ooucfvPf/6jV1y1Rebe6alry64oxipFtrkYmdiReflXfJzbc9igIy6F6Zi2N+dywXmuH/sNv79+wO16kLJ0XqXrsbe3x9DQkNatW1O/fn1UVeXGjRvcvn276hslhBBCCFHF6tWrB2inlZX8XPL6cZ4v0mg0NGrUiKSkJJKSkti/fz8pKSlPHGfLli11yQvAxYsXadmype51VFQUW7ZsYdWqVdx79IdDhw4RGhqKnZ0d8+bN44svvtBNEyxPyX0wNDTU3QNVVdmwYYOuXRcuXMDR0ZG5c+dibW3NsWPHSEhI4O7du+WWbWRkRHx8PK+++ipbtmzRJUuPEh0djZ+fHxYWFlhYWNC3b19+/vnnx2qDkZFRqbUYCgoKdD8bGxvr7tv9faEy/WD69OkEBgaSnJzM5s2bdeWbmZnRs2dPNm3axPfff69LrB91T4FSU1u7devG3r17admyJSNGjOC7777TK54HtWzZkszMTN3rB/tQVZPETU8NTBrQyboTyQ1+BuMO3FHg2vEkLtVviwEqDVoV8Hv+eUzzVdpZOPJL52dodOAUBdevVKoeb29vAgMDuXr1KhYWFhQVFdG0aVP+97//8euvv1ZT64QQQgghHtatWzdiYmLIz88nJyeHzZs3P3GZ/v7+xMTEcPv2bfLy8oiOjsbf3/+RdVlaWtKmTRvWrVsHaL+cHzt27InjsLGxwdLSkoMHD6KqKt999x0DBw4EYOvWrfzjH/8gNjZWNwII2hHIjIwMMjIyeO+99/j44491K1X26NGjUtPkevfuzYIFC3SP1hw9ehTQjjLZ2NhgYGDAihUrKC4uBrSfxdq1aykuLubSpUvs2rUL0I5IZmdn89JLLzF37twK703r1q3Zs2cPRUVFFBYWsmfPHl1yM2zYMOLj4/Vug52dHUlJSWg0GjIzMyt1rT6ys7N1iVDJ1MgSwcHBTJgwgU6dOtG4cWPg0ff0QefPn8fa2pq//e1vBAcHc+TIkceKr3fv3mzbto0bN25w48YNtm3bRu/evR+rLH1I4lYJga0DSTTdg2G9NqDCLz9sprW9HzdVcxrdus6tYu1SrxcP/0rrv/4N4yJIjKzckrkGBgbMmjWLxYsXM336dL7++mscHR3Jz8/niy++KPWXDCGEEEKI6uTl5cXQoUNxd3enb9++VfLYhpeXFyNGjKBz5874+voSHByMp6dnuXWtWrWKpUuX4u7uTufOndm0adND5Zb3jJudnR3vv/8+UVFR2NracurUKQC++eYbgoODadeuHfb29rrpqCEhIeTk5NCzZ088PDwqnIap0Wg4c+aMbiqePqZPn05hYSFubm44Ozszffp0AMaNG8fy5ctxd3cnNTVVN1IUFBRE+/btcXJyYtiwYXTp0gXQ7jfWr18/3Nzc6Nq1K3PmzAEe/Yzbq6++ir29Pa6urri7u+Pu7k7//v0BOH78OC1atNC7Dc8//zxt2rTBycmJCRMm4OXlpfe1+ggNDeWjjz7C09PzoVE6b29vLC0tGTlypO7Yo+7pg3bv3o27uzuenp6sXbuWiRMnAo9+xu3w4cPY2tqybt063nnnHZzv7dfcpEkTpk+fTqdOnejUqRMzZsyoVB+oLKUu7dvg4+OjVuaBwJpSspnob3m/0XN9T8ZlzeLuiWjMuUr3L+aRuuxveBqe4cRtD9oUv81lUwO6fN6TH/t4Y3ZX4YVdj5fFl1i+fLluNaNu3brxwQcf6IaexdNBNqwVNUH6magJ0s+qVkpKil4LR/yZ1MUNuJOTk4mMjNQlTX9Et27dYvTo0bqRzbru119/JSAggNTU1GpZeb2m+llZv+OKoiSqqurz4Lky4lYJz5g/g2MTR840Ogr1OpKtKcJSU8wJ43bYqNfRPNeG3wsysb5jQGGhSlGgH1aX8sk6+WTDxn/96191D002bty4Tm2SKIQQQgjxZ+fi4vKHTtpAOyX1j5K0fffdd/j6+hIeHv6n2i7rz9PSKhLYOpB9xv/DwLgNAGmbN1LYyBWAq9dzuKtmYmpoyvaYY7gMHg3AqQ2RT1SngYEBkydPZsqUKQQHB/+pOqgQQggh6p7x48fj4eFR6t+yZctqOyzxB/Ljjz8+1IeCgoL0unbYsGFkZmbqVhr9s5DtACqpe6vufJP0DfVsG1CcYsnZpET8Rk/i7HYbnv3tF+w6GMIlKDxwkjZ/+SvbWtfHaO+TP6hpaWnJ888/D2jnUScmJnL27Fns7e3x9vaWZE4IIYQQNWbRokW1HYL4g+vdu3e1LuTxNJJv+5XUoXEHWpi3IKt5Kph05PLtXFzatOCggRM+d1IoCuzGrcLr2KqGnMq8SdELnbC5mM/FX6pmA22NRsOUKVN45513+PDDDxk7dixTpkwptRSrEEIIIYQQ4ukiiVslKYpCYOtA9pj8FwNjW1QF8lJOcrZee+pzl4Rfz6IxOE/zes+weeVOnO9Nl0zeUDUb+iUmJrJt2zauXLlCQUEBubm57Ny5k8TEqkkMhRBCCCGEEHWPJG6PIbBVINeML1G/SVMAsuIPYdW6M3dVQzRpJ2jduSFGBsZYp5+mWRsvfm1ZH4M9VbOvxdmzZ1EURbeJ4Y0bN7h8+TJnz56tkvKFEEIIIYQQdY8kbo/By9qLBiYNuPbsVRSDhvyafhZ/TyeOqB1wvZmKSUBXNGoxLQyNWL89leIXOtHq/G0y0p58VMze3h4jIyPs7e2pX78+qqpy69Yt0tPTq6BlQgghhBBCiLpIErfHYGxgjH9Lfw4b7UExfIYrubdoZ9+WROOOOBWfJ+nKQTC9zjP1W5OxdTtOg0YBcDJ66RPX7e3tTWBgINeuXcPS0hKNRkPTpk05cOAA27dvf+LyhRBCCCEeJSwsjNmzZ9eZuvQ559q1awQGBmJhYUFISEip9xITE3F1daVdu3ZMmDBBt+XS5MmTcXBwwM3NjaCgIG7evFnqugsXLmBhYaHXvbCzs+Pq1asVnldZI0aM0O3zW1l9+vShUaNG9OvXr9RxVVWZOnUqHTp0wNHRkfnz51dFqFUmICCgzA2ya5OdnR2urq54eHjg4/PQ1mtVShK3xxTYOpCz9ZIxNLLmLkXcuX6NmxbaXdRPJ+6noactjU2eoWn2Ge5aOXP5GVOUXYeeuF4DAwNmzZrF4sWLmTp1KlFRUXTq1AlFUVi4cCGHDx9+4jqEEEIIIZ4WpqamfP7552UmWWPHjmXJkiWkpaWRlpbG1q1bAejZsyfJyckcP36cDh068OWXX5a67v3336dv3741En91mDx5MitWrHjoeFRUFJmZmaSmppKSksJrr71WC9HVnuLi4se6bteuXSQlJVV7UimJ22Pq2qIrihEYWpgDkLlnJ56unbimNqDpr2cx8bBHURSaG5myOfowRd068ey526SnH3niug0MDOjUqRNDhw6lX79+fPLJJ5iYmKDRaJg1axapqalPXIcQQggh6pbTpz8n8cgbVfrv9OnPK6w3PDycDh060LVrV3755Zdyzw0ICGDSpEn4+Pjg6OjI4cOHGTRoEO3bt2fatGm68+bMmYOLiwsuLi7MmzevwrrOnj1Lnz598Pb2pnfv3pX6rmNubk7Xrl0xNTUtdfzSpUvcunULPz8/FEVh2LBhxMTEANCrVy+MjLS7Zvn5+XHx4kXddTExMbRp0wZnZ2e9Y1iwYAFeXl64urrqYs/Ly2PUqFF07twZT09PNm3aBEBGRgb+/v54eXnh5eXFgQMHAO1oWEhICB07duTFF1/k8uXLuvKnTJmCk5MTbm5ufPDBBxXG06NHDxo0aPDQ8cWLFzNjxgzdNlNWVlbllrN7924CAgJ49dVXcXBw4M0339SNWt4/0piQkEBAQACgHSUdPnw4/v7+PPvss2zcuJHQ0FBcXV3p06cPhYWFFcYP2qTbx8cHZ2dnPvnkEwB27tzJK6+8ojtn+/btur3htm3bRpcuXfDy8mLIkCHk5ubq4vzwww/x8vJi3bp1zJ8/HycnJ7p06VLnEldJ3B6ThYkFvs/4cqH5dUDh4tGjeDh15GcDZzrnp3DL/BcwLOaZ+nbcTtiFw6CRGADHN1bN6pL3c3R05MMPP8TAwABDQ0MKCgo4fPgwa9as4fDhw7JVgBBCCCEeS2JiImvWrCEpKYkffvhBr5k9JiYmJCQkMGbMGAYOHMiiRYtITk4mKiqKa9eukZiYyLJlyzh06BAHDx5kyZIlHD16tNy63n77bRYsWEBiYiIzZ85k3LhxD9UbERFBRESE3m3LysrC1tZW99rW1pasrKyHzouMjNSNruXm5vLVV1/pEgV9NWvWjCNHjjB27FjdyF94eDjdu3cnPj6eXbt2MXnyZPLy8rCysmL79u0cOXKEtWvXMmHCBACio6P55ZdfOHXqFN99950uobt27RrR0dGcPHmS48eP6xLk2NhYZsyYUak4z549y9q1a/Hx8aFv376kpaVVeM3Ro0eZN28ep06dIj09nf379+tVz86dO4mNjeWtt94iMDCQEydOUL9+ff773//qFWt4eDgJCQkcP36cPXv2cPz4cQIDA0lNTeXKlSsALFu2jFGjRnH16lVmzpzJjh07OHLkCD4+PsyZM0dXVtOmTTly5AivvfYas2bN4ujRo/z888+6/pSQkEBwcHCZcSiKQq9evfD29ubf//63XrE/LtmA+wkEtApgRcNoehg2IyvrEj2feYZTxh3pd/cgsSe28Vy7gdicbEu9rANcbzSRW81NMdhzCCr+Q0ilde7cmUmTJmFra8u///1vdu3aRXFxMYaGhgQGBjJr1izZpFsIIYT4A+vQYXqN1xkXF0dQUBBmZmYADBgwoMJrSs5xdXXF2dkZGxsbANq2bUtmZib79u0jKCgIc3PtrKVBgwYRFxeHRqMps67c3FwOHDjAkCFDAO2etmWNyowZM+YJW/uw8PBwjIyMePPNNwHtaNGkSZOwsLCoVDmDBg0CtGsVbNy4EdCOAMXGxuoSuYKCAi5cuECLFi0ICQkhKSkJQ0NDTp8+DcDevXt5/fXXMTQ0pEWLFnTv3h2Ahg0bYmpqyujRo+nXr5/uubUBAwbo9Xnd786dO5iampKQkMDGjRsZNWoUcXFx5V7TuXNnXQLs4eFBRkYGXbt2Lfeavn37YmxsjKurK8XFxfTp0wfQ9pmMjAy9Yv3+++/597//TVFREZcuXeLUqVO4ubnx17/+lZUrVzJy5Eh+/vlnvvvuO7Zu3cqpU6d4/vnnAbh79y5dunTRlTV06FDdz25ubrz55pv07t2b119/HQAfHx/+85+yB1/27dtHy5YtuXz5Mj179sTBwYFu3brp1YbKksTtCXRp0YWvG8zBwLAH2XdOoQD1n/GAC8u5kfILpt7WmP2Si7mBIVs37KVTNx/abtzH6YxEOth5V3k8AQEBHD58mF27dmFlZYWBgQEajUa3z1unTp2qvE4hhBBCiPuVbFlkYGCg+7nkdVFRUaXL02g0NGrUiKSkJABycnLKnOZXWS1btiw1BfLixYu0bNlS9zoqKootW7bw008/oSgKAIcOHWL9+vWEhoZy8+ZNDAwMMDU1fWjRkweV3AdDQ0PdPVBVlQ0bNtCxY8dS54aFhWFtbc2xY8fQaDQPTfF8kJGREfHx8fz000+sX7+ehQsXsnPnTv1vxH1sbW11SWZQUBAjR46s8Jr7P+P722dkZKSb9VVQUFDmNQYGBhgbG+vur7595Ny5c8yePZvDhw/TuHFjRowYoatj5MiR9O/fH1NTU4YMGYKRkRGqqtKzZ0/+7//+r8zySv6IAPDf//6XvXv3smHDBubMmcOJEyd002bLUtJnrKysCAoKIj4+vtoSNxmCeQKtG7SmScOGGJhYoFGKuXLyBM97evKLakv7G+fRtM4G4Jn67dAkx9ExaASGKpyIjqy2mM6ePUtxcTEGBgbk5uaSnp5OcXGxbBcghBBCiErr1q0bMTEx5Ofnk5OTw+bNm5+4TH9/f2JiYrh9+zZ5eXlER0fj7+//yLosLS1p06YN69atA7QJz7Fjx544DhsbGywtLTl48CCqqvLdd98xcOBAALZu3co//vEPYmNjdSOAoB2BzMjIICMjg/fee4+PP/5Yl7T16NGjzKmWj9K7d28WLFigeybs6NGjAGRnZ2NjY4OBgQErVqzQLZjRrVs31q5dS3FxMZcuXWLXrl2AdkQyOzubl156iblz5z7RvXnllVd05e7Zs4cOHToAEB8fz7BhwypVlp2dHYmJ2q2wNmzY8NgxleXWrVuYm5vTsGFDfv/9d/73v//p3mvRogUtWrRg5syZusTTz8+P/fv3c+bMGUD7fGHJSOb9NBoNmZmZBAYG8tlnn5Gdna17Fq4seXl55OTk6H7etm0bLi4uVdnUUiRxewKKouBn48e1BnkAXNi7h/bt2hFv5IRX4Wkyc/di2NiEVhb2GN0+x/n6z5LdpB7K7oO6X9KqZm9vj6GhIbdu3SI1NZVr165x9epV2rRpUy31CSGEEOLp5eXlxdChQ3F3d6dv375VMnvHy8uLESNG0LlzZ3x9fQkODsbT07PculatWsXSpUtxd3enc+fOuoU87lfeM252dna8//77REVFYWtry6lTpwD45ptvCA4Opl27dtjb2+ueZQsJCSEnJ4eePXvi4eFR4TRMjUbDmTNnaNKkid73Yfr06RQWFuLm5oazszPTp2unwo4bN47ly5fj7u5OamqqbjQoKCiI9u3b4+TkxLBhw3RT/XJycujXrx9ubm507dpV9+xWec+4+fv7M2TIEH766SdsbW358ccfAe0iJxs2bMDV1ZWPPvpINz3wwoUL1K9fX++2AXzyySdMnDgRHx8fDA0NK3VtRdzd3fH09MTBwYE33nhDNwWyxJtvvkmrVq1wdHQEoHnz5kRFRfH666/j5uZGly5dylzgpri4mLfeegtXV1e6du3KhAkTaNSo0SOfcfv999/p2rWrrl++/PLLummf1UGprgTicfj4+Kh1bW8G+P8r5pRlS/oWotatpcuRXOyatmDwN4v44p8z+DjnX0R1eI2B9T8g51Am68/No9DpFZ67vZ9Gmw9gtHUljq2rfrqkRqNhypQp/PTTT1y8eJE7d+7QtGlTpk2bptdwt6gd5fUxIaqK9DNRE6SfVa2UlBTdl0+hVVVTJatScnIykZGRpRa8eJpMnjyZv/71r7i5udV2KHoJCQnB09OT0aNHP3YZNdXPyvodVxQlUVXVhzaFkxG3J+Rn48fFxudQjKy4fOM6AB3a+1CgGlM/6xJG7QwxwJhm9e0xOHsI+1eGYaSB4zHVM12yZJ+3iIgIZs2aRffu3XF0dGTjxo16r9IjhBBCCCH05+Li8tQmbQBff/31HyZp8/b25vjx47z11lu1HUqVk8TtCTWr3wwb6+YYGjbmdnEuRQX5eLm4kGjQEY/bZ8ltfAIMwN6yLQZ3fuWkpjm5DU1g98/VNl2yZJ+3kSNH8s0339CoUSMAvv32Ww4ePFgtdQohhBDiz2P8+PF4eHiU+rds2bLaDks8JYKCgh7qXyXTOSuSmJjI3r17Sy2a8rSQVSWrgK+NL/n1rmJ8RyVrXxytA7rzg7EjIXfXse3sHjxaDcf219bwu8rhTVsJ8PfCYetBTmUm4tz6oVHQKvXMM8/wySef8NFHH3Hnzh2+/vprwsPDcXBwqNZ6hRBCCPH0WrRoUW2HIJ5i0dHRtR1CnSQjblXAz8aPjObXADi7Px4jIyPuNHUGIOPUrxh3qI9hYWPMTFpiknWE1v3exKQIkjbXzF+m2rdvz5QpUzAwMODOnTtMnDiRb775RjbnFkIIIYQQ4g9CErcq4GPtQ0qri6CYcTEjEwA/F1+uqA1pff0qec8cBxQcGtuiFN3kUE59blsYV+t0yYdi9PFh7NixpKSkkJSUREREBOPGjWPKlCmSvAkhhBBCCFHHSeJWBSxMLGjV2hoDw2bczL8JQIcO7Ykzdue5u8lcyNuBYmpEu2faAQb8sm0bhV29cPwln2MXD9dYnE2bNsXIyAhPT0+effZZrKysdJtzCyGEEEIIIeouSdyqiG8LXzRGRhSqedy+fJlmzZrxi5krlko+R47dxKiDIUbFttQzaYHJlZO0eOkv1L8Lhzf9u8ZiPHv2LObm5hgbGwPaRUw0Gg1paWk1FoMQQgghhBCi8iRxqyJ+Nn5ct9BuxJ32vx0oioJj+87cUuvT8vIt8p49SnEedGzcAEUtYPelQvIbmtJg60Fu3b1VIzGWbM5dMjVSo9GQnZ3Ntm3buHPnTo3EIIQQQog/rrCwMGbPnl1n6tLnnGvXrhEYGIiFhQUhISGl3ktMTMTV1ZV27doxYcIE3SMskydPxsHBATc3N4KCgrh582ap6y5cuICFhYVe98LOzo6rV69WeF5ljRgxgvXr1z/WtX369KFRo0b069ev1HFVVZk6dSodOnTA0dGR+fPnV0WoVSYgIIC6tufzqFGjsLKywsXFpdTx69ev07NnT9q3b0/Pnj25cePGE9cliVsVcW/uzmk77S9l+tGTAPh4+rDX2JMX7h4jo2gfAC7tnECpT9b+3ZgOHoD7mWK27VteIzF6e3sTGBjI77//TlZWFmfOnAHg6tWrzJw5k7t379ZIHEIIIYQQNcXU1JTPP/+8zCRr7NixLFmyhLS0NNLS0ti6dSsAPXv2JDk5mePHj9OhQwe+/PLLUte9//779O3bt0birw6TJ09mxYoVDx2PiooiMzOT1NRUUlJSeO2112ohutpTXFxc6WtGjBih6zf3mzVrFj169CAtLY0ePXowa9asJ45PErcqYmJoQlO3FigGDbl89TIALVu2JM3MlSZKLkdTVdQWeRgbd8Tc1AaT7LM07PcmxQZwfdWqGlmkpGRz7sWLF/Phhx+ybNky3njjDRRFISkpiVmzZlFUVFTtcQghhBCi8qanXSToaFqV/puedrHCesPDw+nQoQNdu3bll19+KffcgIAAJk2ahI+PD46Ojhw+fJhBgwbRvn17pk2bpjtvzpw5uLi44OLiwrx58yqs6+zZs/Tp0wdvb2969+5Namqq3vfN3Nycrl27YmpqWur4pUuXuHXrFn5+fiiKwrBhw4iJiQGgV69eGBlpd83y8/Pj4sX/f59iYmJo06YNzs7OesewYMECvLy8cHV11cWel5fHqFGj6Ny5M56enmzatAmAjIwM/P398fLywsvLiwMHDgDa0bCQkBA6duzIiy++yOXLl3XlT5kyBScnJ9zc3Pjggw8qjKdHjx40aNDgoeOLFy9mxowZGBhoUwQrK6tyy9m9ezcBAQG8+uqrODg48Oabb+q+094/0piQkEBAQACgHSUdPnw4/v7+PPvss2zcuJHQ0FBcXV3p06cPhYWFFcYP2qTbx8cHZ2dnPvnkEwB27tzJK6+8ojtn+/btBAUFAbBt2za6dOmCl9f/Y+/O46Ks9geOf54ZdpBNBNlUZJFFdhVcUNHct9DUzN28lbtWLnWz/JV7pZWalrumaWoiarmiiYoiICgCiiCyqAjIvsPM7w+uczMXUBGte96vV68XzJznnPMcjtPznbN5MXjwYAoLC1X1nD17Nl5eXuzatYvvvvsOZ2dn2rZtW6vAtWPHjhgbGz/0+r59+xg9ejQAo0ePVvWt5yECtzrkY9kGSdKluCIXpVKJJEk4t+xMMZpYZhZQZH+RsltK7E0UgIKDweco9vPAOzyPsBun6qWO9w/nHjp0KO3ateOTTz5RDe1euHCBr7766pm+bRAEQRAE4Z8nIiKCHTt2EBUVxW+//caFCzVvqqahoUF4eDjvvfceAwYMYNWqVcTExLBp0yays7OJiIhg48aNnD9/nnPnzrF27VouXrz4xLLeeecdVqxYQUREBPPnz2fixIkPlbtmzRrWrFlT63tLT0/HyspK9buVlRXp6ekPpduwYYNqdK2wsJAlS5aoAoXaMjExITIykgkTJqhG/hYsWECXLl0ICwvjxIkTzJw5k6KiIkxNTTl69CiRkZHs3LmTqVOnAtVnm129epXY2Fi2bNmiCuiys7PZu3cvV65c4dKlS6oAOSgoiE8//fSp6pmYmMjOnTtp1aoVvXr1qtU+CBcvXuSbb74hNjaWpKQkzpw5U6tygoODCQoKYsSIEfj7+3P58mW0tbU5ePBgreq6YMECwsPDuXTpEn/88QeXLl3C39+f+Ph4MjMzAdi4cSPjxo1TzS47duwYkZGRtGrVimXLlqnyatiwIZGRkbz55pssXryYixcvEhoaqupP4eHhjB8/vlb1ui8jIwNzc3Og+lzljIyMp7r+UcQB3HXIx9yHfVohaBSVkBF5mcbebnh5tuZ0mBv+FVFEyNRwq+iAu1tLotPzyQkPocXk6dz6Ywynf1qBz6ed6r3OmpqafPrpp8ydO5erV69y+vRp7ty5g4+PD3Z2dnh7e6u+dREEQRAE4eX5wt6q5kR1LCQkhICAAHR0dADo379/jdfcT+Pq6oqLi4vq4bV58+akpqZy+vRpAgIC0NXVBWDgwIGEhISgUCgeWVZhYSFnz55l8ODBQPUa/UeNyrz33nvPebcPW7BgAWpqagwfPhyoHi2aMWMGenp6T5XPwIEDgeplK7/++itQPQIUFBSkCuRKS0tJSUnBwsKCyZMnExUVhVwu59q1awCcOnWKYcOGIZfLsbCwoEuXLgAYGBigpaXF22+/Td++fVXr1vr371+rv9eflZWVoaWlRXh4OL/++ivjxo0jJCTkide0adNGFQB7eHiQnJxMhw4dnnhNr169UFdXx9XVlaqqKnr27AlU95nk5ORa1fWXX37hxx9/pLKyktu3bxMbG4ubmxsjR47kp59+YuzYsYSGhrJlyxYOHTpEbGws7du3B6C8vJy2bduq8ho6dKjqZzc3N4YPH06PHj0YNmwYUH2s1rp162pVr0eRJAlJkp75+vtE4FaHHI0dWWtWiFUSxB09TWNvNxo1akSivgfd713g4g0DWujfQk+3NQba18ktiifDwJS8ZiY0PRLLnffv0Fivcb3XW1tbm//7v//jo48+4uDBg5w+fZo9e/ZgZmZGly5dWLx4sQjeBEEQBEGoFU1NTaB6ls/9n+///ixLMhQKBYaGhkRFRQFQUFDwyGl+T8vS0vKBKZBpaWlYWlqqft+0aRMHDhzg+PHjqofu8+fPs3v3bmbNmkVubi4ymQwtLa2HNj35q/vtIJfLVW2gVCrZs2cPLVq0eCDtvHnzMDMzIzo6GoVC8dAUz79SU1MjLCyM48ePs3v3blauXElwcHDtG+JPrKysVEFmQEAAY8eOrfGaP/+N/3x/ampqqg3xSktLH3mNTCZDXV1d1b617SM3btzgq6++4sKFCxgZGTFmzBhVGWPHjqVfv35oaWkxePBg1NTUUCqVdOvWjZ9//vmR+d3/EgHg4MGDnDp1ij179rBs2TIuX76smjb7NMzMzLh9+zbm5ubcvn27xmmntSGexuuQTJIh72AJyEhLvKF63dmtB2WoYZ2ZT7FDJGVpEo6NywGJg1t/wXTUGKyzlAQHfvvS6q6rq0tAQAAFBQVoaGhQXl6OhoaGOOdNEARBEP6HdezYkcDAQEpKSigoKGD//v3Pnaefnx+BgYEUFxdTVFTE3r178fPze2xZ+vr62NjYsGvXLqA64ImOjn7uepibm6Ovr8+5c+dQKpVs2bKFAQMGAHDo0CGWLl1KUFCQagQQqkcgk5OTSU5OZvr06Xz88ceqoK1r166PnGr5OD169GDFihWqNWEXL14EIC8vD3Nzc2QyGVu3blUtYenYsSM7d+6kqqqK27dvc+LECaB6RDIvL4/evXuzfPny52qb119/XZXvH3/8gYODAwBhYWGMGjXqqfJq1qyZ6hlyz549z1ynR8nPz0dXVxcDAwMyMjL4/fffVe9ZWFhgYWHB/PnzVYGnr68vZ86cUW3MV1RUpBrJ/DOFQkFqair+/v58/vnn5OXlqdbCPa3+/fuzeXP1BoSbN29W9a3nIQK3OtbGri0ySZ/conuq1zw823BO3ZUulRe5phVD+e1CXNs5IddoQeW1UHT8elKiq46053cqFLVbkPki3J+Lq62tjampKQ0bNkShUJCUlPTS6iQIgiAIwsvj5eXF0KFDcXd3p1evXrRu3bpO8hwzZgxt2rTBx8eH8ePH4+np+cSytm3bxvr163F3d6dNmzaqjTz+7Elr3Jo1a8b777/Ppk2bsLKyIjY2FoDvv/+e8ePHY2dnh62trWot2+TJkykoKKBbt254eHjUOA1ToVBw/fr1R25S8Thz586loqICNzc3XFxcmDt3LgATJ05k8+bNuLu7Ex8frxoNCggIwN7eHmdnZ0aNGqWa6ldQUEDfvn1xc3OjQ4cOqrVbT1rj5ufnx+DBgzl+/DhWVlYcPnwYqN7kZM+ePbi6uvLRRx+ppgempKSgra1d63sD+Oyzz5g2bRqtWrVCLpc/1bU1cXd3x9PTE0dHR9566y3VFMj7hg8fjrW1NU5OTgA0atSITZs2MWzYMNzc3Gjbtu0jN7ipqqpixIgRuLq60qFDB6ZOnYqhoeET17gNGzaMtm3bcvXqVaysrFi/fj1Q3ZZHjx7F3t6eY8eOMWfOnOe+b6k+djOsrVatWilftbMZ4L875tRGSn4Kuyd8grKykCnrfkKjQfW3NJtXvc/ozPXMNXuTUbm+WPj58MfOdcTdvYbM2Z+OyjS0dh7izqbP6OrzcrZevXDhAhMnTsTY2Bh1dXWUSiUZGRmsXr26Tj6ohcd7mj4mCM9K9DOhPoh+Vrfi4uJUD59CtbqaKlmXYmJi2LBhwwMbXvyTzJw5k5EjR+Lm5vayq1IrkydPxtPTk7fffvuZ86ivfvaof+OSJEUolcpWf00rRtzqmHUDa4oNKoFy4n8/rXrdybMfFchpkplPgfV5ytLl+PlUIFe3pzLuNKYDqztW6pZnX/j4vO6f85adnc2tW7fIyMigS5cutGzZku+//568vLyXVjdBEARBEIRXVcuWLf+xQRvAl19++bcJ2ry9vbl06RIjRox42VWpc2JzkjomSRJqXqZwNJ/rF6JxG9IdAFdPX8JPONO1LJJQvWaYxWRh9O5UnMOWcTmjgl17j9CmjT3OZxJIvBOHbeP6/3bt/jlvERERJCUl0bx5c9zd3Vm0aJFqu9XPP/+8ThZXCoIgCILw9zVp0qSHtn2fNm1arTazEISaBAQEcOPGjQdeW7JkCT169Kjx2n/y3gwicHsBXDt1Jf5oMnczbqle09bWJsW4NW0zNrA6vTutNKOoqBiNXwct4oKaUx53moYj34bzczi39UtsZ254KXW/f87b/amRVVVVGBgYANXnncyaNYs33niDwsJCbG1txXEBgiAIgvA/aNWqVS+7CsI/2N69e192FV5J4on7BfCxaotc0qakIg+F4r9rCFu0GoACiaaZeeQ1PkdZQi7a3abj1rAQmbKc3y/cIMdSn4YHwygqL3qJd/BfcrmcadOm8frrr6NUKgkJCWHUqFF88cUXTJw4kTlz5qi2ehUEQRAEQRAE4cUQgdsLYKJtgkJbQqHI5k5Miup1F4/2RKm34DVFJJd17lJ8/Q4YNaW9f0PU1JugiA9BGjCApneqOPHb6pd4Bw+SJIlx48bRvn17srOzUVNTIycnB21tbXFcgCAIgiAIgiDUAxG4vSDazQ2BKq4c+e8GJerq6qQ28sFRlsrFW65kF/2BorwKjS4z8DTJRVKWEZqhRYmWjKKfd/Eq7fgpSRI2NjaYmJggk8moqqri2rVrFBQUiOMCBEEQBEEQBOEFE4HbC2LX3R+Am9cSHnjdsfVgAGyycshrFEpZUh7oW9C+mw0a6hYoEs+S7d8a58v5RMWdqPd6P4mtrS1GRkY0b94cSZJQKBTcvXuXhg0bvuyqCYIgCIIgCMI/mgjcXpC2nr2QKdUoKC4kP7tE9bqdWzti1G3ppozgonohOSFxKJVK5J2m49UoG0lZSoxaC2QKiN/w7Uu8g4fdPy6gvLwcIyMjKisr6dWrF126dHnZVRMEQRAEoR7MmzePr7766pUpqzZpsrOz8ff3R09Pj8mTJz/wXkREBK6urtjZ2TF16lTVbKeZM2fi6OiIm5sbAQEB5ObmPnBdSkoKenp6tWqLZs2akZWVVWO6pzVmzBh279791NfdvHkTLy8vPDw8cHFxUR1aXlxcTJ8+fXB0dMTFxaVODoyuay+qLZ+HXC7Hw8MDDw8P+vfv/0LLEoHbC6KnoQe6ChQViZzdFKJ6XS6Xk2baDjfZDS7e8iKr8jdKYrJBrxFte7uhoW5KVWok6W5WNDtxjZTMhCeUUr/uHxewevVq5s2bx6+//spPP/0kdpUUBEEQBOGVpaWlxRdffPHIIGvChAmsXbuWhIQEEhISOHToEADdunUjJiaGS5cu4eDgwKJFix647v3336dXr171Uv+6Zm5uTmhoKFFRUZw/f57Fixdz61b1Tugffvgh8fHxXLx4kTNnzvD777+/5NrWr6qqqqe+Rltbm6ioKKKioggKCnoBtfovcRzAC+QwdjDxq3ZyNfocfnmd0DXQBKCF7zDYsxWbrBzutj+L0VF/tB27IGs/hTaHRnM6TUls4w50u7SDcx+Mw2rzH8ikVyM4+utxAX928+ZN1qxZQ8uWLXFwcBBHBQiCIAhCHfq//VeIvZVfp3k6W+jzWT+XJ6ZZsGABmzdvxtTUFGtra7y9vR+btnPnznh6ehISEkJRURFbtmxh0aJFXL58maFDhzJ//nwAli1bxoYN1UcfjR8/nunTpz+xrMTERCZNmkRmZiaampps2LABR0fHWt2jrq4uHTp04Pr16w+8fvv2bfLz8/H19QVg1KhRBAYG0qtXL7p3765K5+vr+8DIVmBgIDY2Nujq6taqfIAVK1awf/9+Kioq2LVrF46OjhQVFTFlyhRiYmKoqKhg3rx5DBgwgOTkZEaOHElRUfUO4ytXrqRdu3YolUqmTJnC0aNHsba2RkNDQ5X/nDlzCAoKQk1Nje7duz9xJPDP15WVlal2B9fR0cHf31+VxsvLi7S0tCfe16ZNmwgKCqK4uJjExEQCAgJYunQpAHp6ehQWFgKwe/duDhw4wKZNmxgzZgza2tpcvHiRu3fvsmHDBrZs2UJoaCg+Pj5s2rSpVm36+uuvk5qaSmlpKdOmTeOdd95hw4YNXLp0iW+++QaAtWvXEhsby/Lly/npp5/47rvvKC8vx8fHh++//x65XI6enh7vvvsux44dY9WqVRw4cICgoCBkMhk9e/astxHm2hBP1S9Qb78RoCVRWR5N6J9G3Zq1bMc19aZ0J5xLuTZkmGyj4Ew66BjTpm8HNNUbUnX3CukBnXENy+LQylkv7yZqKSMjgz59+rB69WpmzpzJe++9J44KEARBEIS/uYiICHbs2EFUVBS//fYbFy5cqPEaDQ0NwsPDee+99xgwYACrVq0iJiaGTZs2kZ2dTUREBBs3buT8+fOcO3eOtWvXcvHixSeW9c4777BixQoiIiKYP38+EydOfKjcNWvWqKb91UZ6ejpWVlaq362srEhPT38o3YYNG1Sja4WFhSxZsoTPPvus1uUAmJiYEBkZyYQJE1SBwIIFC+jSpQthYWGcOHGCmTNnUlRUhKmpKUePHiUyMpKdO3cydepUoPpss6tXrxIbG8uWLVs4e/YsUD0VdO/evVy5coVLly7xySefABAUFMSnn376yPqkpqbi5uaGtbU1s2fPxsLC4oH3c3Nz2b9/P127dq3x3qKioti5cyeXL19m586dpKam1nhNTk4OoaGhLF++nP79+zNjxgyuXLnC5cuXiYqKqvF6qP67REREEB4eznfffUd2djZDhgxRBcgAGzduZNy4ccTFxbFz507OnDlDVFQUcrmcbdu2AVBUVISPjw/R0dE4OTmp2jI0NLRWbVlaWkqrVq3w9fUlMDCwVnV/VmLE7QWSJAmH0QO59sMeYiPD6FDYCS09dSRJIt28A/4p2/gscQIubRZxN/wkut5DkbedgO/BwfyRqs4lZUekFtFY/nCQ6769sGtd8z+elyU2NpasrCw0NDSoqqoiNzeXY8eOERER8cjROUEQBEEQnk5NI2MvQkhICAEBAejo6ADUag3P/TSurq64uLhgbm4OQPPmzUlNTeX06dMEBASoRqwGDhxISEgICoXikWUVFhZy9uxZBg+u3uBNoVCoHsz/7L333nvOu33YggULUFNTY/jw4UD1mroZM2agp6f3VPkMHDgQqN4v4NdffwXgyJEjBAUFqQK50tJSUlJSsLCwYPLkyaoA49q1awCcOnWKYcOGIZfLsbCwUO0xYGBggJaWFm+//TZ9+/alb9++QHX7Pe7vZW1tzaVLl7h16xavv/46b7zxBmZmZgBUVlYybNgwpk6dSvPmzWu8t65du2JgYACAs7MzN2/exNra+onX9OvXD0mScHV1xczMDFdXVwBcXFxITk7Gw8OjxnK/++471UHdqampJCQk4OvrS5cuXThw4ABOTk5UVFTg6urKypUrH3gmLSkpwdTUFKhexjRo0CDgwbbs2rWrqs89qS1v3ryJpaUlSUlJdOnSBVdXV2xtbWus/7MQI24vWF//MaApo6IsivOb/zvq5tCu+gOgW3EIx1L6k2G7mbwjN0BLH+8BPdFWN0BKDkHr/a8p1pJxZ8YHlOXnvpybqIWMjAwaN26s+odbWFhIWloaMTExL7lmgiAIgiDUJ03N6qUhMplM9fP93ysrK586P4VCgaGhoWod0ZkzZ4iLi3vuelpaWj4wFTAtLQ1LS0vV75s2beLAgQNs27YNSZIAOH/+PLNmzaJZs2Z88803LFy4kJUrV9ZY1v12kMvlqjZQKpXs2bNHdV8pKSk4OTmxfPlyzMzMiI6OJjw8nPLy8ifmraamRlhYGG+88QYHDhygZ8+etW4DCwsLWrZsSUjIf59R33nnHezt7VXTV2t7b3+9v/ttBtVB6aOuedY+cvLkSY4dO0ZoaCjR0dF4enqqyhg/fjybNm1i48aNjB07Fqhu69GjR6va+urVq8ybNw+oXgMpl8uBB9vy0KFDtWrL+32mefPmdO7cmYsXL9Z4zbMSgdsLJkkS9sP7g7KYS2EXKC+p7oyWju2JNGrHRLUgriTaclOtkFu3d1F+qxDJ5x06Wt8CZQmhazeR9f6/MMwu4/zUUa/U2W5/Zmtri7q6OnZ2dhgZGaFUKikvL+fgwYPcu3fvZVdPEARBEIRn0LFjRwIDAykpKaGgoID9+/c/d55+fn4EBgZSXFxMUVERe/fuxc/P77Fl6evrY2Njw65du4Dqh/Do6Ojnroe5uTn6+vqcO3cOpVLJli1bGDBgAACHDh1i6dKlBAUFqUYAoXoEMjk5meTkZKZPn87HH3+s2qmya9euj5xq+Tg9evRgxYoVqme7+w/8eXl5mJubI5PJ2Lp1q2rDjI4dO7Jz506qqqq4ffs2J05UHxtVWFhIXl4evXv3Zvny5TW2TVpaGiUl1Tue5+TkcPr0aVq0aAHAJ598Ql5enmqN2H179+7lo48+qvW9AZiZmREXF4dCoVCNjNWVvLw8jIyM0NHRIT4+nnPnzqne8/HxITU1le3btzNs2DCg+m+ze/du7t69C8C9e/e4efPmQ/n+uS0XLVpUY1vm5ORQVlYGQFZWFmfOnMHZ2bmubvMhInCrB/26vw0acsrLLhK25b8Hctu+uZoCuS5fqq1hx9WxZNrtIutgNEp1HVq+/iatGpUjr7jFlSPXCe/fgkbnEoj/cdlLvJPHu39UQGZmJtra2mhqatKwYUNKS0uZPXs2GRkZL7uKgiAIgiA8JS8vL4YOHYq7uzu9evWqk+UPXl5ejBkzhjZt2uDj48P48ePx9PR8Ylnbtm1j/fr1uLu706ZNG/bt2/dQvk9a49asWTPef/99Nm3ahJWVFbGxsQB8//33jB8/Hjs7O2xtbVVr2SZPnkxBQQHdunXDw8OjxmmYCoWC69evY2xsXOt2mDt3LhUVFbi5ueHi4sLcuXMBmDhxIps3b8bd3Z34+HjVlNKAgADs7e1xdnZm1KhRtG3bFoCCggL69u2Lm5sbHTp0YNmy6mfFx63LiouLw8fHB3d3dzp16sSHH36Iq6sraWlpLFiwgNjYWNVxAevWrQOqN4fR19ev9b0BLF68mL59+9KuXTvVdNm60rNnTyorK3FycmLOnDmqDWbuGzJkCO3bt8fIyAionsI5f/58unfvjpubG926deP27dsP5fvntuzRo0et2rJVq1a4u7vj7+/PnDlzXmjgJr1KIzitWrVShoeHv+xqPOTkyZN07tz5ufIIPLiGxC0H0NTuxLs/vo+6RvWQ7B9B39Ap8jO+qRxIXoty+lbp4txqIdrORrBlAEHnjUi4l0O5gR3N75zEObGMpj/9hL7n43d0elkUCgUREREkJSVhY2PDhQsXVNvqOjk5sWTJkgeGzYX/qos+Jgg1Ef1MqA+in9WtuLg4nJycXnY1XikFBQU0aNDgZVfjATExMWzYsEH1oP9PM2LECJYvX06jRo1edlVqpW/fvsyYMaNWm6s8Tn31s0f9G5ckKUKpVLb6a1ox4lZP+vd6B9TllJdFE7n1jOp1v75TCTbyY5LaPi4ntCHFLIw7J06iVEgwaD39bM5hamiHRt51kpp0IFsPrk95j6q/HAT5Krh/VMDQoUNp06YNEydO5I033sDQ0JDp06ejVCq5cOECO3bs4MKFC2LHSUEQBEEQ/hFatmz5jw3aAH766ae/RdCWm5uLg4MD2trazxW0varErpL1RCaTYTOoGzd2HCIi5AKtRndAriZDJpNh1f8r7m3rxfzytSy4OgQz6/U0PO2DfmdrpMHreXPzYNZVjYfMaM609qbviQjiZkzEZf1PSK/wOWmSJDF69Ghef/11GjRowJw5czhx4gRVVVXI5XL8/f1ZvHixOOtNEARBEP5mJk2axJkzZx54bdq0aarNIAThefj4+KjWjt23detW1e6Tj2NoaKjahfOfSDwx16MB/d8DNTmlZZeI2v7fDzsHG0d+azEVR1kqPlnXuVAlI+3KDqoKysGmI+pdPmSU+Tbk2l5oZebym09TZKEXubN61Uu8m9ozMDAgIiKCEydOYGpqipaWFlpaWgQHBxMREfGyqycIgiAIwlNatWqVaoe++/+JoE2oK+fPn3+of9UUtP0vEIFbPZLL1WgywB+lIpuw4HAUVf+dKjhswCR+NenGBLUgImM7kNp0NzlHqxfO0uEDdB28GGZ1CJmmBxpFahxraULuiu+59/PPL+lunk5iYiJVVVXk5eWRlJREQkKC6mdBEARBEARBEJ5MBG71LGDgJJDLKSmPIXrHf3eY1NLQQNPvY+6omzBXsYX9KT6k5K6l7GY+yGQwcC1mRgX0tr2JXMOFCrkBfzgZkvF/n5O7Z89LvKPasbW1RS6Xo1QqkSQJhUJBZmYmN27ceGWPOBAEQRAEQRCEV4UI3OqZmpo6Vn38UFZlEHY0EqXiv0FLH3cvfrSdip3sFm63sogyjCX14F4UZZWg2xAGb6QFB/FyMEam3oIijYb84WhC+idzyXvEtrivkvvHBZSVlWFkZERlZSUNGzbk9OnTrFu3TgRvgiAIgiAIgvAEInB7CQIGTwGZnKKKOGJ2nn7gvXE9R/NToz6Ml/9GZGwHbtgs487Bk9VvNvGF1+bhV7mQJva+yDW9KdI04KSTGTc//pi8gwfr/2ZqSSaTsXjxYlavXs1nn33Gpk2b6NChA5IkERQUxJdffklFRcXLrqYgCIIgCIIgvJJE4PYSaGhoYtG9LcrKdM4cvkx5SbnqvaaGBqS4TyJNw5T3y39h3/WeJGh+TG50fHWCdlOQWvQigInY+/ijpu1PiboufzhakPTRHPIPH3lJd1WzPx8X0L9/f7766iusrKwACAkJYd68eYSEhIjjAgRBEAThFTVv3jy++uqrV6as2qTJzs7G398fPT09Jk+e/MB7ERERuLq6Ymdnx9SpU1UzgGbOnImjoyNubm4EBASQ+5djmFJSUtDT06tVWzRr1oysrKwa0z2tMWPGsHv37qe+7ubNm6oDtl1cXFSHlhcXF9OnTx8cHR1xcXFhzpw5dV3l5/ai2vJ59OzZE0NDQ/r27fvA6zdu3MDHxwc7OzuGDh1KeXn5Y3KoPRG4vSQDh01DqSajuDyME0sfnOY4s21b5jl8iJUsi5GZJzl1twVXbk6i7N49kCQIWI1MvzG980bh094GDd0BlKnrcMrBkviPZlMQHPyS7urpNGrUiKVLl+Lo6IhSqWTHjh2MGjWKpUuXMnHiRObMmSOCN0EQBEEQnouWlhZffPHFI4OsCRMmsHbtWhISEkhISODQoUMAdOvWjZiYGC5duoSDgwOLFi164Lr333+fXr161Uv965q5uTmhoaFERUVx/vx5Fi9ezK1btwD48MMPiY+P5+LFi5w5c4bff//9Jde2flVVVT31NTNnzmTr1q0PvT579mxmzJjB9evXMTIyYv369c9dPxG4vSSaWtq0GT8GZVUW8YnXyLx6W/WeulzGCN9+TGsxh9ayq7S9kUZMmYzoMxOoqqwAbSMYHYRk3hLf9LF0c0lCo8EQKtT1OGNrTtScWRT+8cdLvLvaa9CgAfPnz8fS0pLi4mIcHR2xtLTE1NRUHBcgCIIgCH/2+xzY2Kdu//u95lGVBQsW4ODgQIcOHbh69eoT03bu3JkZM2bQqlUrnJycuHDhAgMHDsTe3p5PPvlElW7ZsmW0bNmSli1b8s0339RYVmJiIj179sTb25sePXoQHx9f62bT1dWlQ4cOaGlpPfD67du3yc/Px9fXF0mSGDVqFIGBgQB0794dNbXq4459fX1JS0tTXRcYGIiNjQ0uLi61rsOKFSvw8vLC1dVVVfeioiLGjRtHmzZt8PT0ZN9/9itITk7Gz88PLy8vvLy8OHv2LABKpZLJkyfTokULXnvtNe7evavKf86cOTg7O+Pm5saHH374xLpoaGigqakJQFlZmepLch0dHfz9/VVpvLy8HrjvR9m0aRMDBw6kZ8+e2NvbM2vWLNV7enp6qp93797NmDFjgOqRwgkTJuDr60vz5s05efIk48aNw8nJSZWmNl5//XW8vb1xcXHhxx9/BGDDhg1Mnz5dlWbt2rXMmDEDqD5EvE2bNnh4ePDuu++qgjQ9PT0++OAD3N3dCQ0NVbVl27Zta2xLgK5du9KgQYMHXlMqlQQHB/PGG28AMHr0aFXfeh4icHuJOvoPRN2qIZVl5zm4LOiBDTq6WJvj6fkG/7aZwmuySMxiNEmWrhN7enZ1OmMbGH0Aen2JU+lmAhpvQcvgTarUjQlrZkbov2dTEHziJd5d7WlqatKpUyfMzMxUH5IymQyFQiGOCxAEQRCElygiIoIdO3YQFRXFb7/9xoULF2q8RkNDg/DwcN577z0GDBjAqlWriImJYdOmTWRnZxMREcHGjRs5f/48586dY+3atVy8ePGJZb3zzjusWLGCiIgI5s+fz8SJEx8qd82aNappf7WRnp6uWrIBYGVlRXp6+kPpNmzYoBpdKywsZMmSJXz22We1LgfAxMSEyMhIJkyYoBr5W7BgAV26dCEsLIwTJ04wc+ZMioqKMDU15ejRo0RGRrJz506mTp0KwN69e7l69SqxsbFs2bJFFdBlZ2ezd+9erly5wqVLl1QBclBQEJ9++ukj65OamoqbmxvW1tbMnj0bCwuLB97Pzc1l//79dO3atcZ7i4qKYufOnVy+fJmdO3eSmppa4zU5OTmEhoayfPly+vfvz4wZM7hy5QqXL18mKiqqxuuh+u8SERFBeHg43333HdnZ2QwZMoT9+/er9k3YuHEj48aNIy4ujp07d3LmzBmioqKQy+Vs27YNqA6gfXx8iI6OxsnJSdWWoaGhtWrLR8nOzsbQ0FD1XPu4vvW01J47B+G5DP9oMZsmvcu9wkiifz2PxyBf1XvvONrwSdkIvirN4cPbW9kR3p3U9r+he8WG5i2nVB8T4PMOOHTHOmgKQxXz+VX2bwrzjnDJUqLo809od3Ukjd57F0mSXuJd1sze3h51dXUUCoUqaMvKyqKwsPBlV00QBEEQXg29Ftd7kSEhIQQEBKCjowNA//79a7zmfhpXV1dcXFwwNzcHoHnz5qSmpnL69GkCAgLQ1dUFYODAgYSEhKBQKB5ZVmFhIWfPnmXw4MEAKBSKR25o9t577z3n3T5swYIFqKmpMXz4cKB6Td2MGTMeGE2qjYEDBwLVu2z/+uuvABw5coSgoCBVIFdaWkpKSgoWFhZMnjxZFWBcu3YNgFOnTjFs2DDkcjkWFhZ06dIFAAMDA7S0tHj77bfp27evaq1V//79H/v3sra25tKlS9y6dYvXX3+dN954AzMzMwAqKysZNmwYU6dOpXnz5jXeW9euXTEwMADA2dmZmzdvYm1t/cRr+vXrhyRJuLq6YmZmpjpc28XFheTkZDw8PGos97vvvmPv3r1AdSCakJCAr68vXbp04cCBAzg5OVFRUYGrqysrV64kIiKC1q1bA1BSUoKpqSkAcrmcQYMGAQ+2ZdeuXVV97kltWZ9E4PaSNTQxx/b110gMPMLpoJM49fZGU1td9f4Xbg6MLn2PTaW5jMnZz7bzvUhq+w3aRk0wtxxQncioGYwKolHERob9toBfZO+TnxdDolksOQd20T4uFrvFi5H954PwVXT/uIDg4GAUCgU5OTmoq6sTGBiImZnZQws+BUEQBEF4Nd2fhieTyVQ/3/+9srLyqfNTKBQYGhqqRmIKCgoempr2LCwtLR+YCpiWloalpaXq902bNnHgwAGOHz+u+gL8/Pnz7N69m1mzZpGbm4tMJkNLS+uhTU/+6n47yOVyVRsolUr27NlDixYtHkg7b948zMzMiI6ORqFQPDTF86/U1NQICwvj+PHj7N69m5UrVxJcy/0OLCwsaNmyJSEhIappfe+88w729vYPTDmszb399f7+PGhQWlr6yGuetY+cPHmSY8eOERoaio6ODp07d1aVMX78eBYuXIijoyNjx44Fqtt69OjRD61VhOo1kHK5HHiwLX/++WfWr19f67b8s4YNG5Kbm0tlZSVqamoP9a1nJaZKvgIGvDkFuY42ZaVh/LZ4xwPvSZLEj62c2eH9AUHafgyv/J17ke7Exc8mJ+f8nxNCq3HoT93PCK/fMTO2Qk2nB/f0dDmcfp2zw4ZQUQdDtC/Kn48LmD17Nv/3f/+Hp6cnAD/88AObNm0SZ70JgiAIQj3r2LEjgYGBlJSUUFBQwP79+587Tz8/PwIDAykuLqaoqIi9e/fi5+f32LL09fWxsbFh165dQPVDeHR09HPXw9zcHH19fc6dO4dSqWTLli0MGFD9pfihQ4dYunQpQUFBqhFAqB6BTE5OJjk5menTp/Pxxx+rgrauXbs+1XS4Hj16sGLFCtXzzcWLFwHIy8vD3NwcmUzG1q1bVWuxOnbsyM6dO6mqquL27ducOFG9JKawsJC8vDx69+7N8uXLa2ybtLQ0SkpKgOopi6dPn1YFj5988gl5eXkPrDuE6mmaH330Ua3vDcDMzIy4uDgUCoVqZKyu5OXlYWRkhI6ODvHx8Zw7d071no+PD6mpqWzfvp1hw4YB1X+b3bt3q9YF3rt3j5s3bz6U75/bctGiRc/czyRJwt/fX7Xr5+bNm1V963mIwO0VIEkSA+bOAypITgwnIyHjgfe15DK2tXFlfpvPOKXmzqDCYIquNiE66l/k5oY/mJmhNVpjt/PWiAZ0NItAXX8I5RrGnNeEA2PeoigsrN7u62n9+biAUaNGsXjxYgwNDQHYs2cPS5cuJTQ0VBwXIAiCIAj1xMvLi6FDh+Lu7k6vXr1UU82eN88xY8bQpk0bfHx8GD9+PJ6enk8sa9u2baxfvx53d3fatGmj2sjjz560xq1Zs2a8//77bNq0CSsrK2JjYwH4/vvvGT9+PHZ2dtja2qrWsk2ePJmCggK6deuGh4dHjdMwFQoF169fx9jYuNbtMHfuXCoqKnBzc8PFxYW5c+cCMHHiRDZv3oy7uzvx8fGqKaUBAQHY29vj7OzMqFGjaNu2LVA9Atm3b1/c3Nzo0KEDy5YtAx6/LisuLg4fHx/c3d3p1KkTH374Ia6urqSlpbFgwQJiY2NVxwWsW7cOqN4cRl9fv9b3BrB48WL69u1Lu3btVNNl60rPnj2prKzEycmJOXPm4Ovr+8D7Q4YMoX379hgZGQHVUzjnz59P9+7dcXNzo1u3bty+ffuhfP/clj169KixLaH6i4jBgwdz/PhxrKysOHz4MABLlixh2bJl2NnZkZ2dzdtvv/3c9y29SqMYrVq1UoaHh9ecsJ6dPHmSzp07v/Bytiz8kMzoePT0O/LOjzMfWpeWVFzG66fD2XJ2Ck7KFEKauSBvlo2Hx3qMjHwezjArgdxts9iX0IV7uckoKq5iXFiO3+uvYzt+wiu/7g0gIyODzz77jLS0NOLi4iguLsbMzAx1dXX8/f1ZvHgxMtnf//uH+upjwv820c+E+iD6Wd2Ki4vDycnpZVfjlVJXUyXrUkxMDBs2bFA96P/TjBgxguXLl9OoUaOXXZVa6du3LzNmzKjV5iqPU1/97FH/xiVJilAqla3+mvbv/8T7D/LWzEXIZRoUFkRwZsfDO0I219HkxzbujPT6klQa0S45FkViQ6KixnHv3pmHMzSxx3DSTkb2u0uHxpmo6fhzT0+L3w7/zpEJI6kqKKiHu3o+ZmZmfPnllxgZGZGdnU1VVRU5OTk0aNBAHBcgCIIgCMIroWXLlv/YoA2qt9L/OwRtubm5ODg4oK2t/VxB26tKBG6vEDV1dTpOfBuURUT89jslhQ+fsO5rqMdnbTwZ6PYNNzCnY+plyq6YEx39L7KzTz0iUw1kPb6g9YSxjLQPwtDIj0p1fWLu5fLLGwOI/WYJiv/Mc35VNWjQgB49eqCjo4MkSZSWlqrOHRHHBQiCIAhC/Zs0aRIeHh4P/Ldx48aXXS3hH8LHx+eh/nX58uUarzM0NOTatWuq9ZD/NGJXyVeMl18fIrb/Qv69OHbN/4FRi6c8lOaNxsbcaeXB65or2Bo+h55ZF9gf2ZYoxTu4u6/GxMT/4Yxt/TGe5saYwKmci9DgQqYztwxjyTp9hpS9gbiNfYfGbw1HpqFRD3f59Fq0aIGFhQUKhUK1u1RZWVmttqkVBEEQBKFurVq16mVXQfgHO3/+fM2J/geJEbdX0FuLlyNXapB1M4wLvz16zd/kpmYsbe3GyHbLOST3oV9BKCXnmxJ5cQKZmccenbFuQ+Rv/UT7YR0Y2fwkDY3aUaFuxJXGDTn6y8+c7epP5i+7UT7DVr0vmre3N126dEEmkyGTycjIyKBLly54e3uTkpLCvXv3XnYVBUEQBEEQBOGFESNuryBdA2PcenXm4qGjhPz0I+oyCY+e3g+lCzAzwtrHlVEai8g+v5jhJUc4HNqKsKoZtPb6ClPTHg9nLknQ+m0aOvVj1InFRJ+qJCSzLVlcIFtPk7wVX9No1ffYfjAD4z69kf5zrsXLdv+4gIiICJKSkmjevDne3t4UFRXx+eefU1ZWRp8+fQCwtbXF29v7H7FpiSAIgiAIgiCACNxeWV3GTiU//x6JZ8M5sWUtGpIS5x4PbS5DKwNdDvm0ZJj6p2SGGzM9ZwenzrnyR/mn+HrdxcpyOJL0iABGzxRZv2V4tk3A9sBXHLngTWpeJvEWSpIqFVT836doLfuWJpMnYjKgH5K6+sN51LP7xwX8eXvgP/74gzt37hAXF8eBAwcwMjLC2NiYLl26/GN2nBQEQRAEQRCEF/5UK0mSXJKki5IkHXjRZf3TvD5tHpbtPFFUpXF4y3qu/v7o+b5NtDU55OPMmQ7v82/ziXRQxtAsQsHBkJ+4eHEUJSVpjy/ExB79MT8waNZr9Gopoa33GuUa+pyzs+S8kZwrSxcQ2bkbt3/6GUX5w5ulvGx9+vShe/fu3Lt3D3V1dYqKiigoKODo0aNix0lBEARBEAThH6M+hiOmAXH1UM4/0pvTvqBhWzcUlan8/tMWEg88Ytt/oIGanJ89Hajwe5eJth/jLiUSEB/PqeMQfHog6ek/86Qz+6SmbXGc/Q1jJzSnpZUHatqdKNEyJsLGnDONdbm8ajmRfl1IW7fxldqFUpIkTE1NsbCwQEtLC6jeCjYlJYXg4OCXXDtBEARB+GeZN28eX3311StTVm3SHD16FG9vb1xdXfH29n7g+SAiIgJXV1fs7OyYOnXqQ89KX3/9NZIkkZWVBUBeXh79+vXD3d0dFxeXWu2kqaenV2OaZ9G5c2ee5fzjiooKRo8ejaurK05OTixatOgF1O7Zbdq0icmTJ7/sajxg3rx5WFpaqna4/O23315KPV5o4CZJkhXQB1j3Isv5pxszfSE6vk5UVd5k/88/k7Tn+CPTqckkljo3w6vTKPq5ryJb3ZDpRfvRPK3LvuCtXIwaTWnprccXJElot+pPj8UfMmp8C9ztvFHX7UalZiMuNzHldBMjojb/SESnLiQtXUZ5cvKLueGnZGtri46ODk5OThgbG6NUKqmqquLAgQNs2LCByldwsxVBEARBEOqHiYkJ+/fv5/Lly2zevJmRI0eq3pswYQJr164lISGBhIQEDh06pHovNTWVI0eO0KRJE9Vrq1atwtnZmejoaE6ePMkHH3xA+Ss4I+lJdu3aRVlZGZcvXyYiIoIffviB5Ffkma4+POtz4YwZM4iKiiIqKorevXvXca1q50WvcfsGmAU89thxSZLeAd6B6sOWT548+YKr9PQKCwtfer0cPXoTci8L3WvJ7N8TiGtcDLIO7o9M6wAMNrRiYuuVvHZzLx/e2kKb6+psS+tI8q0ADHX6ItEBSZKeUKI+al1b0So7hYzL9iSnt0ZZfIWrFkquKSUsju7j5u7taBmZIWvvS6m3F0pd3Rdy7zVRKBTY2dkRGRmJUqlEU1MTTU1NKisrCQoKwtraGrlczrVr17h16xYWFhY4ODi8UuvfXoU+JvzziX4m1AfRz+qWgYEBBQUFAHwT/Q0JeQl1mr+9gT3T3ac/Mc2XX37J9u3badSoEZaWlnh6eqrq9Fe9e/fGzc2N0NBQioqK+OGHH1i2bBlXrlxh4MCBfPrppwCsXLmSrVu3AjBq1CgmTZr0xLKSkpL44IMPyM7ORktLi5UrV+Lg4EBZWRnq6uqPrQ+AnZ0dAAUFBTRp0oTi4mKysrLIyckhNzcXFxcXCgsLGTx4MLt27aJDhw4ATJkyhc8++4xhw4ZRWFiIpqYm5eXlZGdnk5+fz507dzA0NKSkpISysrIntuHMmTM5dOgQWlpa7NixA1NTU7Kyspg+fTqpqakALFmyBF9fX8LDw5k9ezZlZWVoaWmxevVq7O3tKSkpYcKECcTExODg4EBhYSFFRUXk5uYyadIkLl68iCRJjBgx4okjVqWlpeTl5ZGTk0NeXh5qampIkvTENmzZsiXDhg3j0KFDVFRUsGXLFhwcHFi4cCF6enpMnToVqD5/7ZdffgFg4MCBtG7dmvPnz+Pl5cWIESNYuHAhmZmZrFu3jlatHt674X79ysvLKSgo4Pfff2fp0qVUVFRgbGzMunXrMDExwcvLi2PHjmFiYoJCocDT05Pjx6sHNh7VpgsXLuTGjRskJydjZWXFrFmzmDBhAhUVFSgUCrZu3arqJ/dVVVWp2qQ2/exZlZaW1voz84UFbpIk9QXuKpXKCEmSOj8unVKp/BH4EaBVq1bKzp0fm/SlOXnyJK9CvTp37sySxRMh6gYxsTL6GRrQbMLIR+782Bl4W6nkSGZLhl/oxAeXvmRC2SHOn29BWNMLtPdMxNZuBgb6jw7+HjAIKnKz2b9zGwmXXNDIv0F6wyTSjRsgKcH43ElMjx+iuasHloPeQK9Dh3rfzKRz584P7DjZuHFjVqxYwcSJE2nSpAlz5szhxIkTVFVVIZfL8ff3f6U2L3lV+pjwzyb6mVAfRD+rW3FxcTRoUP39t4aGBvI63u1ZQ0NDlf+jREREsHfvXi5dukRlZSVeXl74+vo+9hq5XI6enh6RkZF8++23vPXWW0RERGBsbIytrS1z5swhOTmZ7du3c+HCBZRKJT4+PvTo0QOFQvHYst5//33WrFmDvb09wcHBzJw5k+DgYNWXtQ0aNGDNmjUAvPfee4+9n927d+Pt7Y2JiQnJyck0adJEdS/29vb8+uuvNGjQgH379tG0aVPatWuHJEno6enRoEEDPvjgA/r370+LFi0oKChg586dGBgYPLGNi4qK6NixI19++SWzZs3i559/5pNPPuHdd99l5syZdOjQgZSUFHr06EFcXBze3t6cPXsWNTU1jh07xoIFC9izZw9r167FwMCAq1evcunSJby8vNDV1SUxMZG7d+8SGxsLVC8ZeVJ7jBw5kiNHjuDg4EBxcTHLly+nadOmT7wHSZKwtLQkKiqK77//ntWrV7Nu3boH2h+qN5K7PzU0KSmJPXv24OLiQuvWrQkMDCQ0NJSgoCC+/fZbAgMDH1mWlpaWql9269aNwYMHI0kS69at4/vvv+frr79m1KhR7Nu3j+nTp3PkyBE8PT2xsbHhrbfeemSbampqkpCQwOnTp9HW1mbKlCm8//77DB8+nPLycqqqqtDW1qZ3796sW7cOCwsLCgoKVPelqanJ2rVr2blzJ61ateLrr7/GyMjoiW1WW1paWnh6etYq7YsccWsP9JckqTegBehLkvSTUqkc8QLL/EeTJImZs1eycMF76MQkEhSqxD3kEq1nvoXuI761kCSJHqZGvNa7P9tcWnMw+EdmpfyAR0oSW2/7c8HuQzyaG9Cs6RgaNeqBTPb4YEvdsCED351KcWkh2379gdtxZuje0UdWdotseRLZDXKIy7yJzreLMV1SgX1rHxxGjUPL3v5FNonKo3acXLJkCZIkceHCBU6cOIGpqSl3797FyMiI4OBgIiIiHkgvCIIgCK+y2W1m13uZISEhBAQEoKOjA0D//v1rvOZ+GldXV1xcXDA3NwegefPmpKamcvr0aQICAtD9z0ydgQMHEhISgkKheGRZhYWFnD17lsGDBwPVM20qKioeKvdJARvAlStXmD17NkeOHHliuuLiYhYuXPjIdIcPH8bDw4Pg4GASExPp1q0bfn5+6OvrPzY/DQ0N+vbtC1SfS3v06FEAjh07pgq2APLz8yksLCQvL4/Ro0eTkJCAJEmqez116pRqZMvNzQ03Nzegul2TkpKYMmWKatO2J7VHWFgYcrmcW7dukZOTg5+fH6+99hrNmzd/YrsMHDhQdQ+//vrrE9MC2NjY4OrqCoCLiwtdu3ZFkiRcXV1rPTUzLS2NoUOHcvv2bcrLy7GxsQFg3LhxDBgwgOnTp7NhwwbGjh0LPL5Nobo/aWtrA9C2bVsWLFhAWloaAwcOxP4/z6uPW7s2YcIE5s6diyRJzJ07lw8++IANGzbU6h7q0gsbblAqlR8plUorpVLZDHgTCBZB2/OTy+TM/ngVOW6NqKi8QYSUws7FP5P4wb+puHv30ddIEqOaWfDJ6E/Z3OdXjum2YXzlEUbGRXP7tyJ+2bOB34/3Ijl5DRUVOU8sX0dLj3+99QGffjGTKd8Ow3egHYYtPFAzfgM17c6U6DYn2UCXo9cus272FHa90Ze41SuozK/7oeWa3J8KmpiYSFVVFffu3SMlJYUrV66Qn59PUlJSvddJEARBEP7pNDU1geovVe//fP/3Z1lfpFAoMDQ0VK0vOnPmDHFxT7fvXVpaGgEBAWzZsgVbW1sALC0tSUtLeyCNpaUliYmJ3LhxA3d3d5o1a0ZaWhpeXl7cuXOHjRs3MnDgQCRJws7ODhsbG+Lj459Ytrq6uuqZRC6Xq9pAoVBw7tw51X2lp6ejp6fH3Llz8ff3JyYmhv3791NaWvrE/I2MjIiOjqZz586sWbOG8ePHPzH99u3b6dmzJ+rq6piamtK+fftabXJy/2/553tQU1NDoVCo0vy5rn/92/+5X9S2H0yZMoXJkydz+fJlfvjhB1X+1tbWmJmZERwcTFhYGL169QIe36aA6osCgLfeeougoCDVKFtNG9qZmZkhl8uRyWT861//IiwsrFb1r2uvxjwx4aloyDX4/OP1mE/qT4mOjBz5VfbfusOxEe+TvX49yscsktWWy5jaui1tp+/ju/br2KffmW5EMuXucexCbhO84zCb9wwjNvZjCguv1VwPHX18Xx/J2/M+YOrXrzN4iDWOzZuh23Ao6jo9KdexI0Um8dvJw6weM5hfxg7m2t7dVFXV72Yhtra2yOVy8vLygOrdlO7evcupU6dUrwmCIAiC8LCOHTsSGBhISUkJBQUF7N+//7nz9PPzIzAwkOLiYoqKiti7dy9+fn6PLUtfXx8bGxt27doFgFKpJDo6utbl5ebm0qdPHxYvXkz79u1Vr5ubm6Ovr8+5c+dQKpVs2bKFAQMG4Orqyt27d0lOTlatiYqMjKRx48Y0adJEtZYqIyODq1evqkaqHB0dn6odunfvzooVK1S/R0VFAdU7V1paWgLVOyze17FjR7Zv3w5ATEwMly5dAiArKwuFQsGgQYOYP38+kZGRTyy3SZMmqkClqKiIc+fOqeretWtX0tPTa30PzZo1U5UXGRnJjRs3an1tbfy5LTZv3vzAe+PHj2fEiBEMHjxYNYX4cW36V/eX1kydOpUBAwao2vJxbt++rfp57969tGzZ8llu57nVS+CmVCpPKpXKvvVR1v8KmSRjeMd/MWnVD1S0b0GlModYo3z2/H6BmIA3KQw5/dhrjTXUmdptMP2n/8z2N0/xWZPplGhoMa40mJFx4dz85Rw/bZ7JoRPjycw6jlKpeGxe90k6hlj0HkrvL2bz7ld96TnEDqtmbdA0fgd13d5UajclraiU/Ts2sXJoP3aMe4PonzZQlJdbh63yaN7e3vj7+6Ojo4OBgQGVlZU0bNiQmzdvMmnSJM6cefQRC4IgCILwv87Ly4uhQ4fi7u5Or1696mSJgZeXF2PGjKFNmzb4+Pgwfvx4PD09n1jWtm3bWL9+Pe7u7rRp04Z9+/Y9lO+aNWtU67r+bOXKlVy/fp3PP/9ctZ373f/MUvr+++8ZP348dnZ22NraqkZuHmfu3LmcPXsWV1dXunbtypIlSzAxMSErK+uJxy49ynfffUd4eDhubm44Ozur6j5r1iw++ugjPD09HxiZmjBhAoWFhTg5OfHpp5/i7e0NQHp6Op07d8bDw4MRI0aotvd/XHtMmjSJwsJC1dqzsWPH4ubmhkKh4Pr16xgbG9f6HgYNGsS9e/dwcXFRbRhTl+bNm8fgwYNV6xL/rH///hQWFqqmScLj2/SvfvnlF1q2bImHhwcxMTGMGjUKqN5c59ath3dgnzVrFq6urri5uXHixAmWL19eh3dZe9LTdrIXqVWrVspnOY/iRfs7LLSOSDrP78t/RPtuBpKkh21WJW6GEgb9+qLfuzdqjRo99tpKhZIDd3MIunCMjtcDGZgXjD4l5Cj1CJPbk9nQEKe2PXB3G4Ga2uMXMD9KaVEFl0/fJPrEdUpzoKriOlLJRZSVd6mUKUGpxFhdhk1LF+xfH455C2dksrpdeA3VQ+f3Ny9p1KgRZ8+e5fz5/x5o3q5dO3x9fcnIyMDW1hZvb+963bjk79DHhL8/0c+E+iD6Wd2Ki4vDycnpZVfjlfLnTSNeFQcOHCApKUm1Bu3vKCYmhg0bNrBs2bKXXZVaCQ8PZ8aMGYSEhLyQ/Ournz3q37gkSRFKpfKhDSxE4FYLf5f/CSmUCn7a8yMZe0OQVeYhk/QwLlJgnZmGjVMLjPr1p0G315A/phMqlUrO5Bbyw7VENK8dp9ftEF4rPo8BxRQrNYmU23LXsDkeXd6jeUu/p65fdnoh0afSib9wC0WRAkXVHSiNQl5yg1J5CUgSGiiwsWiI++tDsPLrg/SCgielUklISAhr1qwhPz+fuLg48vPzsbKyQk1Nrd53nfy79DHh7030M6E+iH5Wt0Tg9rBXMXAT6tfixYtZvXo127ZtUx3fUNdE4FYDEbjVjez8LDZ/s4Kq67eQld0FqgAZBiVKLPJysGnphsWA12nQuTMyDY1H5nG7rJygu7nsu3UXveun6X3rD3oWhdKYHCqUcmJlTbita4el52CcOg5E7Sm2/1cqlWSlFRIXkUHUhRvIs+UoFSUoyuPQKLxMiZSNQgZ6leXY66vR0s8XkwFjkDVsUnPmTyknJ4ePP/6Yn3/+GXt7exo3boxCoSAjI4PVq1fX266Tf7c+Jvw9iX4m1AfRz+rWqxq4PWqpwbRp0x6YtvaiiMDtn2Hjxo18++23D7zWvn17Vq1a9ZJq9CARuNVABG51q6KqguDzIUQfOo88JQ+pLA2lIhcArQoFDcvKMbd1oFnP3lh26/HY4Cu5pIzAjBwC72SjnRRJ7/STdC0Kw5kUADLR57pGc9SsO2PtNxzTJnZPNVJVlFfGhXNJnAuNQ+uuDmpVUFkWilphNGXySlAqMS0oxlYqwtbJEoOer6PZaQiShvZztxHAzz//zP/93/+ptoKF6vni48aNY9KkSTUcVF43/q59TPh7Ef1MqA+in9WtVzVwe5lE4CbUh1cxcHuR57gJL5m6XJ0e7brQo10XCooL+f1UCIkhyWjfKqK8Io10jXTSM1II37wG2abVmBgYYenhjVWrNpjZ2KFv0ghJJqOZtibTmzVmerPGxLVsTtDd15iRncfdm0l0SQulS+55/Mouo58YRWXid1yXWZCj2QIta090HTtiaudJgwYNHhsA6Rpo0rmHE517OFFeWsnB38JIPN0Kda1OVEnJlJWfIFNSchddwpNLMf5qIw0Xf49lYy2adOqA/utvIzN98tkjT2JnZ0eDBg1QKBTIZDIUCgVVVVXs2bOHO3fuMHnyZBo3bvzM+QuCIAiCIAjC8xKB2/+IBjp6DOnZC3pC+t07HDsZxu24PDRvaSKvyEZReYuc/GQy/wjm4qnqbW7V1NQwamyBcZNmGFtYYWxpRUMLK963smR2c3NyPOw4k9OOk/cKmJeYitWNaLpmn6ND5SU8q06ice04XPuKLAy4pGZFhZ4tak1aoefgh7lNiwfO07hPQ0uNgIHtUL6uJDkmixMHJEpSmlFuXEq6zlEoiadcU5eMKj1iK0E6GoX+/ncwVavAsnljbPoNxLh9f1Cv/Wjc/V0ng4ODVcGbkZERurq6REdHM2nSJNq2bYuFhQX29vb1vnGJIAiCIAiCIIjA7X+QpWljRg/pD0BxWQmnwi9wJUqPskRndItMUFbdRV6ajFZhPFXxiaQmJ3NV7U+BiiRh1swWG6/WeHu2oreDHTJHa26WeHPq3ht8lZhA4o27NM5Mwy0/AXflddwVidjmXoHcILgEqWpmxKlbIxm2QLNpawwdO9LYqilqatVdUpJJ2Lg1wsbNn6y0Ai4eS0HjQj+Uir7caHaJGJPjGBUZ0TtPB+n2LZLKNUhIK+Lk6q3of7MWK3kFNk1NaNKxI9od+iM1bAaPGfGTyWQsXrxYtetk8+bNcXR0ZMuWLfz+++9ERUVx/PhxNDQ0aNy4MT179qzXjUsEQRAEQRAEQaxxq4X/lfn6SqWSuNQEzpyLJie6DJ3sxkjIkCoSaJx5AbP0aMrUlBRoaZBt2IAcreo1cVraOth4eNO8tS9N3b3Q1queD1xWdpe41F85fPUSkXctyM42xSI3G1dlEm7yJNzliTRW5gBQiYx0eWPytZpCIxc0m7XGqEV7GppZqgKkorwyLp9MI/pEKpWlCtL0E4i0PMo9bW1GOoyiX0kRKUeCuHnrDllKCaUkoVFZRaPCIqylIppa62Po5YW2Xy/kLTqAulaNbbJ9+3amTZuGJEmqqZ5aWlps2bKFTp061Vnb/6/0MeHlEv1MqA+in9UtscbtYWKNm1AfxBo34ZUmSRLOTRxwbuIAQ+BeVgEhwZdIC2/KbXV7UqwGkqFzEakiDK+CQtxuVZCXW8BdfR2uF5wkLjQECWhkYoppczsaOTpj0rQtE9sOorTqMrdu7yTj7kni7tmxMaMPkXfsMarKxVPjBi4NUnCTJeJechnD5FBIXkfVSRlZkjEFOs2oauSMZlNvnH0649m9PbGnbxN5VA2rOHsyddM4XriZjTplBPQeyRz/vlSVFJF04ggJJw+TeusW6Up9zucpMTwYheEv5zFRFmFhIsfExQ5t345otOmFZNzsoVE5mUyGlZUVSqWSO3fuoFQqyc3N5d///jcHDhzA0NDwJfylBEEQBOHlmDdvHnp6enz44YevRFm1SXP06FHmzJlDeXk5GhoafPnll3Tp0gWAiIgIxowZQ0lJCb179+bbb799YE3+119/zYcffkhmZiYmJibk5eUxYsQIUlJSqKys5MMPP6xxJ009PT0KCwuf8u5r1rlzZ7766itatXro+f6JKioqGD9+PJGRkVRWVjJq1Cg++uijOq/fs9q0aRPh4eGsXLnyZVdFZdeuXcybN4+4uDjCwsIeaPNFixaxfv165HI53333HT169Hhh9RCBm/BYxiYNGDCkPcrBSm4n5hFzOhXNSC0U5W1J0S3mnOd1SvRv01pPl+4lEiWxCaSmp5BVVEJ8xm1iws6q8tJQU8eokSlGTYfjbFKCk+kF3jTbRmyJDeezfDiaNYAqpQwDDWhmWkQjo3Scy5JwLbyOW8E1zJLDIXkL/AF5kj7G2jb4tXAiX+ZEXJIlJtfGkq+VTWTBPnxvbGW69zRG9R+ES/9BKKqquJUQT+L5s6RGhnEz4w43lIYAaF/KwTB0J8Zlm2isXYZFCyv0uvRFu9twJB19bG1tUVNTw9TUFBMTE5KTkykrK8Pd3V0VtN0/3DsxMfGlHN4tCIIg/G+4s3AhZXHxdZqnppMjjT/+uE7zfNWYmJiwf/9+LCwsiImJoUePHqSnpwMwYcIE1q5di4+PD7179+bQoUP06tULgNTUVI4cOUKTJv89jmjVqlU4Ozuzf/9+MjMzadGiBcOHD0fjMccrvYp27dpFWVkZly9fpri4GGdnZ4YNG0azZs1edtXqRWVlpWppTm21bNmSX3/9lXffffeB12NjY9mxYwdXrlzh1q1bvPbaa1y7dg25XF6XVVYRgZtQI0mSsLAzxMLOkIphVSRFZZISn41evA4VN90oAn6XlVLSxAbrrsb4WZpjUphO3pVLZF67yr3baeRX5FGYm09SSgrl6vc7szmalPKa7hl66J0kV67JzWJrYvOcuKLVnNt6jkQ5N+ampRaZ+Rk4FybSqvAabfLjcMqPp2lqNACt5JDbWJ8MLGmb05xL2S1ZV/k562OsWNhpJu2bOWHl6IKVowuM/heVFRXcvZHIrWtxpF8M5/b1eG6XlnEFUE+rotGqHZguWU8TIzlNvbzo4GBLSHwCCqUSQ0ND2rRpw6effgpUB21z5szh0KFDSJKEhoZGvR/eLQiCIAgv0oIFC9i8eTOmpqZYW1vj7e392LSdO3fG09OTkJAQioqK2LJlC4sWLeLy5csMHTqU+fPnA7Bs2TI2bNgAwPjx45k+ffoTy0pMTGTSpElkZmaiqanJhg0bcHR0rFX9PT09VT+7uLhQUlJCWVkZ9+7dIz8/H19fXwBGjRpFYGCgKnCbMWMGS5cuZcCAAarrJUmioKAApVJJYWEhxsbGtQoC7s/U0dbWZt++fZiZmZGZmcl7771HSkr18UrffPMN7du3JywsjGnTplFaWoq2tjYbN26kRYsWlJSUMHbsWKKjo3F0dKSkpASAqqoq3n77bcLDw5EkiXHjxjFjxozH1kWSJIqKiqisrKSkpAQNDQ309fWfWP9mzZoxevRo9u/fT0VFBbt27cLR0fGhEc+WLVty4MABAHr27Imvry9nz56ldevWjB07ls8++4y7d++ybds22rRpU2O77d+/n/nz51NeXk7Dhg3Ztm0bjRo1okWLFpw9e5ZGjRqhUChwcHAgNDQU4JFtOm/ePBITE0lKSqJJkyZ88sknjB07lvLychQKBXv27HngWKi/etx05X379vHmm2+iqamJjY0NdnZ2hIWF0bZt2xrv7VmIwE14Kuqaclr4NKaFT2PAhaLcMuKvpBAWFUPpDXXyz2hxhByUZkpeGzKC1i7V31JV3rtHWXw8pfFXyYsIJzM6iqKKMoo01Skza0SpzAiZsgLNokQclIlUqstJ0LHjSrYTFbrGBNiZ0dS3J/FSN77IL+ZqUSl6lQW4FiTQtvAarfPjaJEfTwsO4s9BhmcYcVmqYGfO2yxr3JqveszGxsgCADV1dSwcHLFwcKRV3wAACrKzSI+/QtK509yICueWUQOilEoMLybQOa8Qt+ICivS0aNHRn7ZvjUK3YUOgeopFcHAwubm5VFZWYmpqytGjRxk8eHC9Hd4tCIIg/G94GSNjERER7Nixg6ioKCorK/Hy8npi4AagoaFBeHg43377LQMGDCAiIgJjY2NsbW2ZMWMGycnJbNy4kfPnz6NUKvHx8aFTp04oFIrHlvXOO++wZs0a7O3tCQ4OZuLEiQQHBz9Q7po1a4DqB/fH2bNnD15eXmhqapKeno6VlZXqPSsrK9VI3L59+7C0tMTd3f2B6ydPnkz//v2xsLCgoKCAnTt31vhFbVFREb6+vixYsIBZs2axdu1aPvnkE6ZNm8aMGTPo0KEDKSkp9OjRg7i4OBwdHQkJCUFNTY1jx47x8ccfs2fPHlavXo2Ojg5xcXFcunQJLy8vAKKiokhPTycmJgaA3NzcJ7bHG2+8wb59+zA3N6e4uJjly5djbGz8xHuA6pHLyMhIvv/+e7766ivWrVv3xPTXr19n165dbNiwgdatW7N9+3ZOnz5NUFAQCxcuJDAwsMYyO3TowLlz55AkiXXr1rF06VK+/vprRowYwbZt25g+fTrHjh3D3d2dRo0a8dZbbz2yTaF6dOz06dNoa2szZcoUpk2bxvDhwykvL6eqqgqA3r17s27dOiwsLGqsG1Sf+3s/8IcH+9CLIAI34bnoGmri3d4e7/b2KJVKzt24wOHgs+hEN+X4iuscahJGrze9adHcBrV27dBt146G48ZiU1lJ6ZUrFJ09S9HZUIrPR0FFBQotLfLcnEk30EAj+xpOeVcpVdck7m4LjlxyoImFPssHd8Te2ojLBSVE5bcgqqCYXfnF3Cwtx7zsLgOyz9D31gn8iqLxz62iMDeJiOsnOGbmwRuDF2JkaPXQfTRoaIJj+044tu+EUqEgI+k6SZEXSAo9wfVbd8DCBK3KCvIuRhB98hQNFUp027QhWiYnLzubsrIyAG7fvk1ZWRnr16/H1ta2Vh+EgiAIgvCqCgkJISAgAB0dHQD69+9f4zX307i6uuLi4oK5uTkAzZs3JzU1ldOnTxMQEKA6FmjgwIGEhISgUCgeWVZhYSFnz55l8ODBQPVsl4qKiofKfVLABnDlyhVmz57NkSNHnpiuuLiYhQsXPjLd4cOH8fDwIDg4mMTERLp164afn98TR6w0NDTo27cvUH0E0dGjRwE4duwYsbGxqnT5+fkUFhaSl5fH6NGjSUhIQJIk1b2eOnWKqVOnAuDm5oabmxtQ3a5JSUlMmTKFPn360L179ye2R1hYGHK5nFu3bpGTk4Ofnx+vvfYazZs/+UzcgQMHqu7h119/fWJaABsbG1xdXYHqkc6uXbsiSRKurq4kJyfXeD1AWloaQ4cO5fbt25SXl2NjYwPAuHHjGDBgANOnT2fDhg2qdYaPa1Oo7k/a2tXHRbVt25YFCxaQlpbGwIEDVaNtv/32W63q9bKIwE2oM5Ik0bZ5G9o2b0NCZiK/7jmBxmULjiy9zj770/Qb6oOTlUN1WjU1tN3d0XZ3x2TCBBRFRRRHRFB05gxaZ85gFJaIo0wiy9qC2+baaBdcwjP/EvmZDZifGIOrjyuzR/TH11BPVX52eSVncgs5lNWCYdaDoCyfbpnnCLh9gvaF4XRK34fimyDuaVmia9cRTdsOYN0GjG3hT9+WSTIZje0caGznQLshwynKzSE5OpLrp49wIyaWm40M0VZUYH7zCtKNTDRv38ZKXZ0sNTVK/pPPlStXGD9+PD169CAgIICbN2+KNXCCIAjC/wRNTU2geoOv+z/f/72ysvKp81MoFBgaGhIVFQU8225/aWlpBAQEsGXLFmxtbQGwtLQkLS3tgTSWlpYkJiZy48YN1WhbWloaXl5ehIWFsXHjRubMmYMkSdjZ2WFjY0N8fPwTp/2pq6urNjyRy+WqNlAoFJw7dw4trQd3uZ48eTL+/v7s3buX5OTkGndpNTIyIjo6msOHD7NmzRp++eUX1TTUR9m+fTs9e/ZEXV0dU1NT2rdvT3h4eI2B2/2/5Z/vQU1NDYVCoUpTWlr6UHp4sC88TT+YMmUK77//Pv379+fkyZPMmzcPAGtra8zMzAgODiYsLIxt27YBj29T4IHzg9966y18fHw4ePAgvXv35ocfflBtWPM0LC0tSU1NVf1+vw+9KOLpUXgh7BvZMvu98Qz81I1K5yy0rzfm8MJEvlixhpjbsQ+ll+nqotexI2YffYTtgQPYnQjG+vPPsXdyxTsuldcu38A1NZNmJXm0zQlD+9BG5kycyu8Hf+f+kRYNNdTob2rI985NudKhJWu93dD1HMJUj4W06HCAoS2/Yq3pQFKUuihi9sC+ibCyFcqlNvDTIDi5GG5fgr8ckaFraIRLp64M+PcSJm7YSe/JH2DZ0ombRkbcc7fHollj8tSUaJWXoV9YiI2aGrrl5VSUl7N//37at2/PkCFDWLp0KRMnTmTOnDkPfMgJgiAIwquqY8eOBAYGUlJSQkFBAfv373/uPP38/AgMDKS4uJiioiL27t2Ln5/fY8vS19fHxsaGXbt2AdXHF0VHR9e6vNzcXPr06cPixYtp37696nVzc3P09fU5d+4cSqWSLVu2MGDAAFxdXbl79y7JyckkJydjZWVFZGQkjRs3pkmTJhw/fhyAjIwMrl69qgp4arvm7r7u3buzYsUK1e/3A9O8vDzVw/+mTZtU73fs2JHt27cDEBMTw6VLlwDIyspCoVAwaNAg5s+fT2Rk5BPLbdKkiWqaaVFREefOnVPVvWvXrk811a9Zs2aq8iIjI7lx40atr62NP7fF5s2bH3hv/PjxjBgxgsGDB6s2A3lcm/7V/XN7p06dyoABA1Rt+bT69+/Pjh07KCsr48aNGyQkJNRq7d6zEiNuwgvV1MyKGVOHcTP1Nvt/PofxFQd+v3aNUx2ieGfQkMcu6FU3N8fwjTcwfOMNlFVVlF6+jPnpM9ifPElW/FVSGhqgpqgidssqLu3eQseAN/Ds0gMtveoROA2ZjM7G+nQ21meJozV/3Mhmw10531p6cc9JjqRU0Dorhq53wvAtuorzrWvoXT+OdHIRmDhAyzfA9Q1oaPtAvTS0dXDy88fJz5+y4mKSzp/C9nggp8NiyCwoxlxPg1ZqGpSkZhJ25w4R6upkZmZia2eHhYUFCoWC4OBgIiIixBo4QRAE4ZXn5eXF0KFDcXd3x9TUtE7+3+Xl5cWYMWNUD7jjx49XbSDyuLK2bdvGhAkTmD9/PmVlZbz11lsPrT973JqulStXcv36dT7//HM+//xzAI4cOYKpqSnff/+96jiAXr16qTYmeZy5c+cyZswYXF1dUSqVLFmyBBMTE7Kysnjas5G/++47Jk2ahJubG5WVlXTs2JE1a9Ywa9YsRo8ezfz58+nTp48q/YQJExg7dixOTk44OTmp1v+lp6czduxY1ZfCixYtemJ7TJo0ibFjx+Li4oJSqWTs2LG4ubmhUCi4fv36Uy3zGDRoEFu2bMHFxQUfHx8cHByeqg1qMm/ePAYPHoyRkRFdunR5IDDs378/Y8eOfeA4hse16V/98ssvbN26FXV1dRo3bszH/1k/+rg1bnv37mXKlClkZmbSp08fPDw8OHz4MC4uLgwZMgRnZ2fU1NRYtWrVC9tREsQB3LUiDhOtO4nXbrFvyzk0swwpMsii10gvXFvaPVUeZUlJ5AUFkfnrr9yqKCXZxIB8HU0kmQynDp1p2fk1rJxaIv1lOqJCoSTqaAoHTiRzyUIisnkBxbrV3+LolxTinnGN4YXn6VhxCaP8OCSUYO5RHcC5DASDxw99lxUXkXTmKNdPBnEj6Q4VChlqiiouXLrGoRupuFpZoW1pidzAgPRbtxgzZgyTJ09WTZkUfUyoD6KfCfVB9LO6JQ7gftireAD3gQMHSEpKUq1B+zuKiYlhw4YNLFu27GVXpVbCw8OZMWMGISEhLyT/V/EAbhG41YL4n1DdUiqV7DxwiJSjpeiWG6DnXMWgkX7oGT08H/mJ+SgUFIVHcHnlN5TFXeOugRa3jBpQJZPRwLghzp1ew7mjP8YWD25GkpVWwKF1V8i7U8wFqwjOt7iHtWUAsWXqVCKhU1ZK6zsxDL4bTOeqy5iUpaBEgqbtkDyGg/MA0NR7TK2gsqyMmyd+4fofBzkecZOfw+NooKmOZpUSDYWCArk6pk2a4Na2LW+//Tbl/5lS2a9fP7H+TXihxGeZUB9EP6tbInB72KsYuAn1a/HixaxevZpt27bRoUOHF1KGCNxqIAK3/y03sm/yw+bdmCe4IJPJ8e7ZlDY9bFHTePoh5py0dDZ/+TUNL17Hovw2acb6ZDfQRgmY27XAuWMXWrTzQ7tB9a5PlRVVnN2byOXgNHI0swm230TvtgHYWA7kQEYOwTkFlClBu7KCdumRDMo4SueySIwV2SjUdMAlAJnXSGjiC/9ZcPwolYU5TBk1iOCzEZSUKVBKcnQ01NFUKtFUKMmoqKRKQxNNPT0aNmwozoATXijxWSbUB9HP6tarGrhNmjSJM2fOPPDatGnTHpi29qKIwO2fYePGjXz77bcPvNa+fXtWrVr1kmr0IBG41UAEbv97KhWVrDm9nqTDRdhme6BpIKPHWDesHZ9tG/3dgTtZdyKTrgmRdLkTxR1dDW5ZNCIfJTK5Gs08vGjh2wHbVj5o6uiSGn+P/T9eprK4ggjr31H3LGP5a4uQy3U5cS+fg5l5HMnMpVChRLuqkoE3jjLkzu94VsWiQQWlulZIXiPQbD0a9B995odCoSAiIoLE+BgaFt9EIz2OX45f4UjCHdJy8lCTScgB0wZ6aBuZ8OPmTfi0a/ccrSoIjyY+y4T6IPpZ3XpVA7eXSQRuQn0QgVsNROD2vysiI4Kvgr7HJbYrRuVmBEz3wsLe6Jnyio88zYwjF7mZacHkwgt0S47mXsYtblmYcse4AcUV5cjV1Gjq5omDbwesnL05uC2JnPhcbjW4ToTLYb4bsAgHo+oFtmUKBSE5hfxy5x4H7+aiANqU3WNw/C90yD1FM9JRIFFo7IqOS0/UbDuBVWtQ03x8JZVKVi36N58v/Y6ysnKqlNWjdlUKBd0tGvNJt9ew7dWfBp07oSbOghPqiPgsE+qD6Gd1SwRuDxOBm1AfROBWAxG4/W/LL8/n30c/xexYG4yrzHjjg9aYNn38gZZPkncniS/2rmPPzbZYapezxk0XgyNBFJw+Ta66jAxTY+4Y61NcVYlMLqepmydqBk4kXdKnUl7JCbufGd/7TQIcHjxo9HZZOVvSs9l6K5usikqaacgZlHeVjrHbsS68jDl3kQClmhaSdRto5lf9n6U3qGk8kNeFCxeYOHEiurq6JFyNp7Qwn9Kycsz0GzDAsyX2ejqY5xZh09gKS/8u6HfpgoatreosGEF4WuKzTKgPop/VLRG4PUwEbkJ9EIFbDUTgJpRWljI5aAZ2f3TBUNaQITN9MLbQrfnCRygvyWf73s/45morisob8ElvZ4Z7Nqb47FkKT5yk4I8/uFdSxG2jBmQ0MqIYBZpaOpRruKEheRJldQbj9pos6Pwx6nL1B/IuUygIupvL+rQsogqK0ZPLeE1HnSZJUTSN/R07KQ1HrSwMSm5WX6CuA7ZdwCUAHHqCph4KhYI5c+YQHBxMfn5+9eGUGhp0b+vGaEc5cVE3uFmsR2puPsX38vAoq6JrY0sMu/jToHNndFq1QtLQeMSdC8Kjic8yoT6Ifla3ROD2MBG4CfVBBG41EIGbANUjbxP3TMM9dACGmoYMne2Dvon2M+WlUFRx7sgXLIrR4XKWC4PdGrF0WGskSUJZVUXJpUsUnvyDghPB3ElPJamRIXcNdJEpJXQU5mSa2RLhE8/3Axdirmf+yDIi84vYkJbF71l5FFUp0JNJOJcVYnQ9FoesZDpbKvBokINuygkovANqWmD3GrgEoLDrRkTMNdWuku7u7hQWFmJsbIyitIAP3h7C/qOnyS4sR1tDk5ZmDZnRyAzr7HzUdXXR7dCBBv6d0fP3R67/bKOTwv8O8Vkm1AfRz+qWCNweJgI3oT68ioGb2LpOeOXoa+izfMBSwrx3U1BSyJ5lFyjKLXumvGQyOe16zuO7Tmb0bnaUXZcyWRQUDYAkl6Pj6YnpjOnYBgXRZv9B+r49kZ4mTbAsLKZISkcn8xSv77zDrn+N4syhLY88XNNLX5eVzk250r4lW11t6G9mxHUdfQ47tWZNhzf40LAzb2e34VvDmcT6LqPCbTikhcOet5F97UDrxG9400VGaxdbNDQ0VAdfRlyOJ+RqJlW6Jmjo6VOurOLirQz2q0uccrcmtZkmeedOcWv2HBLadyBtyhTyDx1GUVr67I0vCIIgCE8wb948vvrqq1emrNqkOXr0KN7e3ri6uuLt7U1wcLDqvYiICFxdXbGzs2Pq1KkP/X/+66+/RpIksrKyAMjLy1N90eri4sLGjRtrvA89vccfIfQ8OnfuzLMMeGRnZ+Pv74+enh6TJ09+4L3y8nLeeecdHBwccHR0ZM+ePXVV3TrRrFkz1d/iVSGXy/Hw8MDDw4P+/fvXfMFzUHuhuQvCM2qk04ivAhYwrXwO/lGj+HV5OINntkFLT73mix/BpvVoPtE1objiDD+GtsdUX4fx/g4PpFG3sMBo8GCMBg/GubKSrLNnOLdrJ9fv3ESh0CR+5RaS1vxEI2c3jLy8aWBqho6hEboGhugaGqHdQJ9uJgZ0MzFgqUJJWF4Rv2flclBTnZPGZpxSKvjp3l3ss+V0s/ahi4US6/wIZPH7cS44APHfVq+Fs3sN7LqRmJBAZWUlWlpaFBcXI9fSo7S0lPCcQowa6lEo6aNto4ez1l0aF0sUhJ2m4OgxZLq6NOjWDf1+fdH18UFSE//MBUEQ/glCfrlGVmphneZpYq2H3xCHmhP+jZmYmLB//34sLCyIiYmhR48epKenAzBhwgTWrl2Lj48PvXv35tChQ/Tq1QuA1NRUjhw5QpMmTVR5rVq1CmdnZ/bv309mZiYtWrRg+PDhaPyNli5oaWnxxRdfEBMTQ0xMzAPvLViwAFNTU65du4ZCoeDevXsvqZYvR1VVFXL50x1Lpa2tTVRU1Iup0F+IETfhldVUvykLBn7CcefN5GQWEfhdBOUllc+cn4VzHz5t64iXaRTzDyewLzL1sWklNTUadexEvxXf887a7eg36UiJtgm5cjXiEmI5vWsbv69axp4Fc9kyawqr3xnBj5PGcnLrejKSriOXoJ2RHl/YWxHRzoVD3g5MaGJGVWMLgh08+LeJPYMzDBl7x53dTssIcZwHHWeBUgknF8O6LtiGzkS9MJ3mjbRxdrRHV1cXSZLQbGDIpTItYjWNKGtkTVCaNotSlPyor815T1OuNtUi9uwJYidO4FqnTtyZv4Ci0FCU5eXP3HaCIAjC/64FCxbg4OBAhw4duHr16hPTdu7cmRkzZtCqVSucnJy4cOECAwcOxN7enk8++USVbtmyZbRs2ZKWLVvyzTff1FhWYmIiPXv2xNvbmx49ehAfH1/r+nt6emJhUX1kj4uLCyUlJZSVlXH79m3y8/Px9fVFkiRGjRpFYGCg6roZM2awdOnSBzYFkySJgoIClEqlammDWi2+IP33v/+Nu7s7vr6+ZGRkAJCZmcmgQYNo3bo1rVu3Vp2LFxYWRtu2bfH09KRdu3aqdigpKeHNN9/EycmJgIAASkpKgOpgY8yYMbRs2RJXV1eWL1/+xLro6urSoUMHtLS0Hnpvw4YNfPTRRwDIZDJMTEyemNemTZsYOHAgPXv2xN7enlmzZqne+/NI4+7duxkzZgwAY8aMYcKECfj6+tK8eXNOnjzJuHHjcHJyUqWpjddffx1vb29cXFz48ccfVfWfPn26Ks3atWuZMWMGAD/99BNt2rTBw8ODd999l6qqKlU9P/jgA9zd3QkNDWXOnDk4OzvTtm1bPvzww1rXpz6Ir+KFV5pLQxc+HjidRZUreC1+LPtXRTFgquczHdIN0LzVKL4oWs6Mc9f5YJcCIz1NOjqYPvEaXUMD/vXlLI7uu8bV31KgIhTz4mAcrhdQpqxCaW+H5O3J3apyLv6+n4gDezEyt8SxfScc23fC2MISD30dPPR1+MTWguiCEvZl3GOvupzDDRtzVKHASk1GmztFvOXdk9ZDzFG/GYL3tSP4X95F8LVoFMgxbmCKb8/uaOs24O7du2Tl5rE69BzFxUUY6xtQdSebpHwDutg2odIcMAc1ZRUGocEYHz2ISRVYtmqNoX8XdDt2RM3o2Y5bEARBEF6OlzEyFhERwY4dO4iKiqKyshIvLy+8vb2feI2Ghgbh4eF8++23DBgwgIiICIyNjbG1tWXGjBkkJyezceNGzp8/j1KpxMfHh06dOqFQKB5b1jvvvMOaNWuwt7cnODiYiRMnPjDlEWDNmjUAvPfee4+t2549e/Dy8kJTU5P09HSsrKxU71lZWalG4vbt24elpSXu7u4PXD958mT69++PhYUFBQUF7Ny5E5nsyeMgRUVF+Pr6smDBAmbNmsXatWv55JNPmDZtGjNmzKBDhw6kpKTQo0cP4uLicHR0JCQkBDU1NY4dO8bHH3/Mnj17WL16NTo6OsTFxXHp0iW8vLwAiIqKIj09XTV6lpubW+v2+LP7182dO5eTJ09ia2vLypUrMTMze+J1UVFRXLx4EU1NTVq0aMGUKVOwtrZ+4jU5OTmEhoYSFBRE//79OXPmDOvWraN169ZERUXh4eFRY303bNiAsbExJSUltG7dmkGDBjFkyBAWLFjAl19+ibq6Ohs3buSHH34gLi6OnTt3cubMGdTV1Zk4cSLbtm1j1KhRFBUV4ePjw9dff012djZvv/028fHxFBYWqoK7oKAgwsPD+fzzzx+qR2lpKa1atUJNTY05c+bw+uuv11j3ZyUCN+GV52vuy8QBeayp3ErXhFEcWhdD73ddkcmfbcDYpdMMPi/5Nx+Ga/Pu5nPsmtiJlpYGNV7XbYADxia6nP4JbujbE9QpkIVSWxR7f6Ni/VYaGRjg1bsXWXbNSLweT+ienwndvR2z5vY4tu+Ia5fuaOroqoK4T+0siSoo4ddbmexSVLJbrTGB9yppnnSRnvomjOm4kMWvrybi0DaSjq6leXEU3nYRVHX4kAO3Tfj+hx/Jzs7G2tqaZs2aoVAoSM/IoO20udiam3LnwiHuXD7HreR0EvSMSEBCln4dox8uY7x8KRYW1jTp3AXDHj3QaNr0mdpSEARB+GcLCQkhICAAHR0dgFqt4bmfxtXVFRcXF8zNqzf3at68OampqZw+fZqAgAB0dat3jR44cCAhISEoFIpHllVYWMjZs2cZPHgwAAqFgoqKiofKrSlAuXLlCrNnz+bIkSNPTFdcXMzChQsfme7w4cN4eHgQHBxMYmIi3bp1w8/PD/0nbBCmoaFB3759AfD29ubo0aMAHDt2jNjYWFW6/Px8CgsLycvLY/To0SQkJCBJkupeT506xdSpUwFwc3PDzc0NqG7XpKQkpkyZQp8+fejevXut2uOvKisrSUtLo127dixbtoxly5bx4YcfsnXr1ide17VrVwwMqp+jnJ2duXnzZo2BW79+/ZAkCVdXV8zMzHB1dQWqR0STk5NrFbh999137N27F6ie1pqQkICvry9dunThwIEDODk5UVFRgaurKytXriQiIoLWrVsD1aOXpqbVX9zL5XIGDRoEgIGBAVpaWrz99tt07dpV1ef69+//2L5/8+ZNLC0tSUpKokuXLri6umJra1tj/Z+FCNyEv4UezXqQ0yeHwH27kS4N5o/tV+k8wvGZzzRr0/1z/q9sBrMuajHyhz8InNaVpg1rPnbAu70l+oaaHPj+It5XhjHJZRuLNi/CLrGE3N27Kdy9B52KClq7utKudwC3GmhzLeI8f2xdT9i+3bQfMgLXrt2RyeRIkoSnvg6e+k3xv30DHQ8ntiSmckRqxHcyNdZE3cC97BJDrb0Z8vVwNO5EwbF5yI7OIcCoGbl+7bl27Zrq20KZTIZCoeDQ4cMMHz4cl0ETcBk0ASrLKQ3fQdqxDaSm5ZKiaUJCAyMSqgqRHQ3E5NefcTSzosXI0TTo3FmsiRMEQRCei6amJlD9/6X7P9//vbLy6Zc8KBQKDA0NVeuInmW3v7S0NAICAtiyZYvqodrS0pK0tLQH0lhaWpKYmMiNGzdUo21paWl4eXkRFhbGxo0bmTNnDpIkYWdnh42NDfHx8bRp0+axZaurq6ueV+RyuaoNFAoF586de2jK4uTJk/H392fv3r0kJyfXuEurkZER0dHRHD58mDVr1vDLL7+wYcOGp2ofgIYNG6Kjo8PAgQMBGDx4MOvXr6/xuj//jf98f39+Riv9y8Zpz9tHTp48ybFjxwgNDUVHR4fOnTuryhg/fjwLFy7E0dGRsWPHAqBUKhk9ejSLFi16KC8tLS3VujY1NTXCwsI4fvw4P//8M+vXr39oZPevLC0tgeoAunPnzly8ePGFBW5ijZvwt/Gm45t4d2lOuOUhYs/cJmz/jWfOSyaT07n3V8x1OUWFsoRh3weTWVC7nSvtXUwY9pEvcrkuPS6P45MdX/FH41ysli/H7tQfmH38EcqyMgqWfIn+/KV0UWgxaMS/MDa35Ni6Vfw0exopMZcerI8EvkYN+L6VM3H+3qy3N8dXA6K1DfgwpxLn4Ajev6XJtUG/wPA9oNGAlqlbMCUbWUn1wmGFQoEkSZw5c4bp06fz+eefs3fvXnbs/pXLcieaf3Qc/1nfMrqXERMdQhnQNAHX5g3Ib2jAqdIcfl6xlGP9enNn1SoqX7EdmwRBEISXo2PHjgQGBlJSUkJBQQH79+9/7jz9/PwIDAykuLiYoqIi9u7di5+f32PL0tfXx8bGhl27dgHVD+HR0dG1Li83N5c+ffqwePFi2rdvr3rd3NwcfX19zp07h1KpZMuWLQwYMABXV1fu3r1LcnIyycnJWFlZERkZSePGjWnSpAnHjx8HICMjg6tXr9K8eXMAHB0dn6odunfvzooVK1S/3w9M8/LyVMHApk2bVO937NiR7du3AxATE8OlS9XPEllZWSgUCgYNGsT8+fOJjIx8qnrcJ0kS/fr14+TJkwAcP34cZ2dnAPbu3ata+1ZbZmZmxMXFoVAoVCNjdSUvLw8jIyN0dHSIj4/n3Llzqvd8fHxITU1l+/btDBs2DKgeFdy9ezd3794F4N69e9y8efOhfO+PePbu3ZtFixbV2M9ycnIoK6t+fszKyuLMmTOqNnsRnuqrdUmSZICeUqnMf0H1EYQnet/7fSbnTib+dCj8BtoNNHDzt6r5wkeQq2vQp+9y8iunMP9yf0asPs7uqd1ooFXzzpWNrRrwr3kdWLcolB7x49hUvpOErolM8ZyE8ahRGI0cSWlMDLm795B/8CCKffto49qSgp79CYs8x64vPsaudVs6jRiHYeMHz4dTl0n0sTKjj5UZRRWVbI25yrbUe/xcqM728Gu4apszot+vDGxzDP+kaQTHhaOQaSDTaoCLszN5ChlVSiWbN28mOzsbHR0dTExM6NmzJ4sXL0bWvBPamVexC12FXfQOOtuWc1XWmvBUAy4VlhIXfADrX3fi0tITq9Gj0fb0fOaRTUEQBOHvzcvLi6FDh+Lu7o6pqalqqtnz5jlmzBjVKNX48ePx9PQEeGxZ27ZtY8KECcyfP5+ysjLeeuuth9afPW5N18qVK7l+/Tqff/65ao3SkSNHMDU15fvvv2fMmDGUlJTQq1cv1Y6SjzN37lzGjBmDq6srSqWSJUuWYGJiQlZW1iOPDHqS7777jkmTJuHm5kZlZSUdO3ZkzZo1zJo1i9GjRzN//nz69OmjSj9hwgTGjh2Lk5MTTk5OqvV/6enpjB07FoVCAaAaVXrSGrdmzZqRn59PeXk5gYGBHDlyBGdnZ5YsWcLIkSOZPn06jRo1Uh13kJiY+MTpoI+yePFi+vbtS6NGjWjVqhWFhXW3I2rPnj1Zs2YNTk5OtGjRAl9f3wfeHzJkCFFRURj9Zz2/s7Mz8+fPp3v37igUCtTV1Vm1ahVN/7JUpKCggAEDBlBaWkpVVRXLli0DHr/GLS4ujnfffVc16+n+xiYvSo0HcEuStB14D6gCLgD6wLdKpfLLuq6MOIBbqI2C8gJGHhiJY+RrWGc70/1tF+xbPXnh7JOU5t5l/f6ZLIsdhHtjLbZN6Ip2LTc/KSupYO2SMKQ7ZURYHoZW9/jafylGWv/d+ENRUkLegQNkr/mBivR01N1cueXrTVTUBRRVlXj1HkBFIwu6du/x2HKqqqo4eiGcDfE3iDGx4J6uPhqSRB8jLTqf34LiyinsKq/hbVJCVjF8GaXPutAs1DW1kdSqtyjW0NBg3bp19Ojxp3IKM+HSTojajjLjCullxoQXuJGUVYVSqaRxXhFN9AyxH/ImZgEDkf5G2x0LDxOfZUJ9EP2sbokDuB/2Kh7AfeDAAZKSklRr0P5pRowYwfLly2nUqNHLrkqt9O3blxkzZtC1a9dnzuNVPIC7NoFblFKp9JAkaTjgBcwBIpRKpVsd1hkQgZtQeyn5KYzcP4puMW/TMN+KvlPcsXY0fub8Cu/c4PtDn7M6fiC+1ppsercrmmq1C96qqhRs/i6Skqv5JBtdIdr1N77sthj3Rg9+E6isqCA3MJDs1WuouHULpXtLEh1tuRYfg1xLm5Z+nWnR1g9LJxdkskeXXVxczImTJ/k97hrXLWxIbNyEAiS0ZTLaNtBkgOImHbLDOPXrLhYFxqBQQlYJKNW0KVXIcHBowezZs3njjTcezFiphDuXIGo7XN5Ffl4hF/PtuJRlTLmi+n39SgVWNnbYDRhIk1Y+aP5n8bjw9yE+y4T6IPpZ3RKB28NexcBNeDXk5ubSpk0b3N3dVVNrn9XfNXC7AngA24GVSqXyD0mSopVKpfsTL3wGInATnkbY7TCm/D6NIVdn0qCsIQHve9GoybP/AytIvc43R75ifUI//Jurs/bt11Cr5c6VSqWSwF3xpAXfIk8ri6NO63in4xjecnzroWmGyvJycgMDyVqzhspbtylxb8mlRobk5d2jsrwMXSNjHHzb06JtRyzsWyA9Ypvhu3fvcujQIRJuJJPbzI5yB2fiZZpcLa6eZy2/Fkv5twtoZqiBXv5tbt+5y51CcHVoxmdLvuO1Xn1RKBRERESQmJiIra0t3t7e1VsaV5ZDwhGI2k7VtSPcKdQmsdSN5Ew52VWVKGQyJMDUqik2bXzx7NUfHf2ad+UUXj7xWSbUB9HP6tarGrhNmjRJde7YfdOmTVNtBvEiicDtn8/Hx0e1duy+rVu3qnafrA9/18BtKjAbiAb6AE2An5RKpV+d1fg/ROAmPK1frv7C16e+ZeTVT9CR9Bg0yxuDRs8+ElSQnMjSwyvYeqMbvVqosWp0d2Sy2q/vOn02jfM/XUWinGMOG2np2Yx57eaho/5wnZTl5eTuDSTrh+oATqtzJ4r69CTx6hVuRIVTVVFBg4aNcGjbAcd2HTFrbvdAEKhUKrl69SpHjx5VrWVr7ulFua0jUWVVbF/4ORlhoaBUYiqrpLtZBe7at5napQn4fcCcPQmc+OMUhYWF6Orq0qVLl+o1cH8OFAsy4MJauLAeSu5RpO5GQoolN6/fIltbnVxdbdTU1GjdrjOtho1C3fjZRz2FF098lgn1QfSzuvWqBm4vkwjchPrwtwzcHkWSJDWlUvn0+7nWQARuwrNYcG4Bv0cFM/zqR+jp6TJ4diu09GreYORxChJu8MXR1fyS0omAlnKWDe/xVJtzXEvKYde3FzEoUxLW5CC5TtdZ7r8cW8NHbw2rLC/nwrx56B86DFVVNHz3HfTeGsaNy1FcPXuK5OiLKKoqMTK3+NOh3v/dkEWhUHDjxg0uXLjA1atXUSqV2NnZ4e3tTXLWPbZHxXBUQw+dFi4s171F/5iVhJ89xcRDVTRobENsSjZq6upoaWmxceNG/Pwe8Z1MeTFEb4fQ7+FeIpUa1uQWtSYt8hZRUgXZDXTQKynDrUpOE8eWaLm2RNvVFS0XF2R/2eZYeHnEZ5lQH0Q/q1sicHuYCNyE+vC3DNwkSZoGbAQKgHWAJzBHqVQ++fTCZyACN+FZVCoqmXBsAinXMxkQOxULWyP6TXVH/owHdAPkxybxybFNBN3yYZgHLBza+6mCt+zcUr5bfB7T3CpumFzmrMMvLPJfSCfrTo9Mf/LkSdo7OpKxZAkFvx9CvUkTGn/yb/Q6dqS0sJCEsLPEnzlJypXL1SNoNrY4te9Ei3YdadDQRJVPXl4ekZGRREZGUlBQgIGBAV5eXujbO7I0s5AT9wpw0dWk74lNbF21ivLSEjJLJFDTpLRSwqWlK+++9x79+vXD0NDw4amUANcOQehKuHkGNPWpbDma+EwLzvxxksLSYixKK2mRlI52RSUyAwMaTZyA0bBhYmOTV4D4LBPqg+hndUsEbg8TgZtQH/6ugVu0Uql0lySpB/AuMBfYqlQqveqwzoAI3IRnl1eWx/DfhmOcYoNPXACu/lZ0HOrwfHlGJjLrjx0czvDg7TZK5g7s+1TXl1ZUsnBZGKY3SsjVzeJIix/5d/dZ9Gj28O6Rf+5jhWfOkPHFfMqTk9F7rSuNP/oI9f+c51J4L5uroSHEn/mDO4kJIElYObnQZsBgbDy8VflVVVVx9epVLly4wI0b1efdNTI1pdDJnW1qDUiPuYz6qiW4GWtQcDuZW3fvkVemxNVcC8NG5sgNLChUaJKVnY1MJkMul+Pv7//gVMr0SDjzDcTuAw09KrzGE57ThLCDBwHw8GhFkyvXKQ0NRb1pE0w/+IAG3bqJowVeIvFZJtQH0c/qlgjcHiYCN6E+/F0Dt0tKpdJNkqRvgZNKpXKvJEkXlUqlZ53WGhG4Cc8nKS+Jtw6+RZe0N7FMcsN/pCPO7S2eK8/cc9eZfnovJ7OcmdS+gpn9Xn+q6xUKJV9ujkItLBuZrII/bH/m7QGD6Wfb74F0f+1jivJy7m3aTNbq1aBU0nDcWIxGjkTN6L/HDOTcTif+zCmu/HGMvLsZ2LVui//of6HfyPTBe8jNJS4ujri4OFJSUiiXqxHj4Ebw3j1URoXTWF2OiYYcJ4sGNCaL+IQkcksquZyhQFNTE2trK8ysbcnIzGL16tUPn+GTEQunvoQre0Fdh3ynkZy8rk1CRDh6xia4OrlifOQEyuuJaLfyxmz2bLTrcXGx8F/is0yoD6Kf1S0RuD1MBG5CfXgVA7fazCWLkCTpCNAbOCxJUgNAUSc1FYQ61NygOQs6LOCA6UbKzO/xx/ar3L6e+1x5Gvra8XXr12lrdJ1VZ9RZFLjjqa6XySRmj/WkyZu25MjU6HZtDL9tiWRnzJO3qJVpaGDyzr+wPXgAvU6dyPp+Ndf9u3Dn8y8oT00FwMjckrZvDGPMsjV0GDaa5EuRbHx/Auf3/kJlRcV/78HQkLZt2zJu3Dg++OADAnr2YFBpzv+zd97hUZRdH753syW994T0kF4ghh6qVOlgwYqCDduLn/X1tYti710UFRUFBQGl994J6aQ30utuNtvn+2MhgpQESCLI3Ne11ya7M89zZvZcM/vbc55zuLNXHAGz5tA45RZMc57g7oUreXNlJm/8vAufqH4IUhkSkx6nlkKkhVsw1+VTsHEhqKtPN9YrGq7/Bh7YC5HjcEz7gon6z5g+JgRnd1d279zMendbSqdPoKmkmKLrb6D8sccxlJdf0LkUEREREfnneeGFF3jrrbcum7k6ss369etJSkoiLi6OpKQkNm3a1PbewYMHiYuLIywsjIcffviMJtpvv/02EomE2tpawLIkYcKECSQkJBATE9PWoPp82Nvbt7vNxTB06FAuJuBRV1fHsGHDsLe358EHHzztPb1ezz333EPPnj2JjIzk119/7SxzO4WgoKC2z+JyYcyYMTg7OzN+/OmZWYWFhfTt25ewsDBuvPFG9Hr9Jc8l68A2s7C0AygQBEEjkUjcgK6v9SoichGMCBjB7PhZfGt6g7tb57H68zSufzoZB9eLL5DhNiScD7Rj+c/hdXy+JxiN7htevP6O06svtsP1Q4IZGOvFJx/uI7Yyheyvy/hw3Hc8dO3t591P7uuL//vvocvLo+7rb2hYsoSGxYtxGD0Kt7tmYRMXi0wup+/k64kaNIQt333FjsXfkbF1A8Nn3kvQKemTAA4ODiQnJ5OcnMz0lhbuyMrm86OZbPEJ5IajhYx0teeF8Ggef/ldcmbPRqlQYOsgw6yqQtpSQXDeQrY8+C2D+vdBFjUOIseDZ6RlcI8ImPYVDHkStr9N4NHvCbQyUxkbxoHGQNLzMsnwcyEotid+27agWrcO+xHDse3VG5vevbGOjEAi68glSUREROTqZPPCL6guLujUMT0DQxg2855OHfNyw93dnZUrV+Lr60t6ejqjR4+m/MSPh/fffz9ffvklffv2Zdy4caxZs4axY8cCUFpayrp16wgICGgb6+OPPyY6OpqVK1dSU1NDREQEt9xyC4oraB23tbU1L7/8Munp6aSnp5/23rx58/D09OTYsWOYzWbq6+v/ISv/GUwmE1ZWHevje5LHH38cjUbD559/ftrrTz75JHPnzuWmm27ivvvuY8GCBdx///2XZF+73zwFQTAD/sD/JBLJW8AAQRCOXtKsIiJdyAOJD5Ac2Jufg99Crzew+rM0DHrTJY3pPiqcMLX4pQABAABJREFUD+JHM8ypmO8Pe/LEj19gMhna3/EUfN1sefn5Idhf64m9zh3jb+48/fkCzOb2K7sqw8LwfXUeYRvW43bXnbRs30HR9ddTfMdM1Nu2IQgCju6eTHz0v0x7+kUAfn3teVa88yrNtdVnHdPOzo5rrkniw5uv5w1TPX0LMtha08jgvdn87ujFkJEjMQsC5Y06qgRXhs94CPXo93j7WAAP/JDFN2//j5/u78X++RMwN5adcrLCYcpn8OABGPUK3hGxjPc/xqyQfSQ6l1Jaf5ztwV4cjPEjI+MQaR++R/otM8js25fiO++k5oMPUe/YiUmtvqDzKyIiIiLSNcybN4+ePXsyaNAgcnJyzrvt0KFDmTt3Ltdccw1RUVHs37+fqVOnEh4ezv/+97+27d555x1iY2OJjY3lvffea3eu/Px8xowZQ1JSEqNHjyY7O7vD9vfq1QtfX8vSiZiYGFpbW9HpdFRUVNDc3Ey/fv2QSCTcfvvtLF++vG2/uXPn8sYbb5y2NlsikaBSqRAEAbVajaurK7IO/Oj4zDPPkJCQQL9+/aiqqgKgpqaGadOmtf2gerIv3r59++jfvz+9evViwIABbeehtbWVm266iaioKKZMmUJraytgERszZ84kNjaWuLg43n333fPaYmdnx6BBg7A+S9Xnr7/+mqeffhoAqVSKu7v7GducysKFC5k6dSpjxowhPDycJ554ou29UyONS5cuZebMmQDMnDmT+++/n379+hESEsKWLVu46667iIqKatumI0yePJmkpCRiYmL44osv2uz/z3/+07bNl19+ydy5cwFYtGgRffr0ITExkXvvvReTydRm5//93/+RkJDA7t27eeqpp4iOjqZ///489thj7doxYsSIM1IqBUFg06ZNTJ8+HYA77rjjNN+6WNr1NIlEMh9IBn448dLDEomkvyAI/73k2UVEugArqRWvp7zOTU03sT3iZwak3cjm77IYOSvmogtjSCQSXMeG8ZZJwjNpG1ma3oPWbz/lvdtmIz9Lj7bzjXPH9Fhyknz46ZP1+B8O5snnF5Gc3LG1eHIvLzwfewy3++6j8edfqP/uO0rvuRdlZCTu996Dw6hRBCUmcfubH3Nw1TL2/PYzhYcO0LP/IOKvHYtvz8gzzoG1tTVTxo+nV1ERP/25hnVOXiwQBBzG38r1Q0cRpaoj4kR7gWeffRbBNYQNWVn8nNqCtdSM2/bVXPdHJPNffRlp/wdAduJXR7dQGPBQ2zxOqiqGlR+kf8Eeju49zOF8I5UuDuBy4mInCNioKrFZuxzbFUuw0xsJ9O2B9+Ah2KekYB0Tc9Zm5CIiIiJXC/9EZOzgwYMsXryYI0eOYDQa6d27N0lJSefdR6FQcODAAd5//30mTZrEwYMHcXV1JTQ0lLlz51JUVMQ333zD3r17EQSBvn37MmTIEMxm8znnuueee/jss88IDw9n06ZNzJkz57SUR4DPPvsMgPvuu++ctv3666/07t0bpVJJeXk5/v5/tdfx9/dvi8T9/vvv+Pn5kZCQcNr+Dz74IBMnTsTX1xeVSsXPP//cbgZOS0sL/fr1Y968eTzxxBN8+eWX/O9//+ORRx5h7ty5DBo0iJKSEkaPHk1WVhaRkZFs374dmUzGhg0b+O9//8uvv/7Kp59+iq2tLVlZWRw9epTevS11Ao8cOUJ5eXlb9KyxsbHD5+NUTu737LPPsmXLFkJDQ/noo4/w8vI6735Hjhzh8OHDKJVKIiIieOihh+jRo8d592loaGD37t2sWLGCiRMnsnPnTr766iuSk5M5cuQIiYmJ7dr79ddf4+rqSmtrK8nJyUybNo0bbriBefPm8eabbyKXy/nmm2/4/PPPycrK4ueff2bnzp3I5XLmzJnDDz/8wO23305LSwt9+/bl7bffpq6ujlmzZpGdnY1arW4TdytWrODAgQO89NJLHTqXdXV1ODs7t4n6U33rUuhIXtI4IPFE5A2JRPItcBgQhZvIZYuT0on3hr3Hbatvo0dkGBxIws3fnqQxQRc9pkQiwXV8KK+ZwTptK8uPhaL7+nM+nnknSqXzBY0VEezGf+dN4/n3viawIJTsDc0sdylkckpwh/a3srfHbdZduN52K02r/qDuyy8pn/soiuBg3O6+G6cJ4+k75QaiBg1l3+9LyNy+hcxtm3DvEUj8tWOIShmGtd3pOfdBQUE8dvcskrduZcXBzewNT2CBkyfOTj5MdHTG3Kzhueef58MPPmDXrl0olNYIEgk1ZiULU9X4v/o0945ahHLS2xAy9EyjHbwgchzWkePoMw6STSY0JWk0HttHU2EmjceLaaxtoLHFTJ3OmjJBQY7Qgsufv+G3aCH+yHEeMAD7lEHYDRyIrJ1fAUVERERELp3t27czZcoUbG0tP1JOnDix3X1ObhMXF0dMTAw+Pj4AhISEUFpayo4dO5gyZQp2dnYATJ06le3bt2M2m886l1qtZteuXVx//fWApX+pwXBm1kt7AiUjI4Mnn3ySdevO39FKo9Hw6quvnnW7tWvXkpiYyKZNm8jPz2fkyJGkpKTg6Oh4zvEUCkXb+qekpCTWr18PwIYNG8jMzGzbrrm5GbVaTVNTE3fccQe5ublIJJK2Y922bRsPP/wwAPHx8cTHxwOW81pQUMBDDz3Eddddx6hRozp0Pv6O0WikrKyMAQMG8M477/DOO+/w2GOP8f333593vxEjRuDk5ARAdHQ0xcXF7Qq3CRMmIJFIiIuLw8vLi7gTRctiYmIoKirqkHD74IMPWLZsGWBJa83NzaVfv34MHz6cVatWERUVhcFgIC4ujo8++oiDBw+2FVhrbW3F09NSzM3Kyopp06YB4OTkhLW1NbNmzWLEiBFtPjdx4sQO+X5X09EFJc7AySRXp64xRUSkc4lwjeDFAS/yxNYnuCs4kD2/g5uvPUHxF/+FXyKR4DwxlOfMAtbpu1hc2JPZXy3g0ztvxt7W54LGUijkzHv8bl7++SPsdwSTvziT5/OO8dwdo7CSdiwyKFEocJ46BadJE1GtW0ft519Q8d//UvvRR7jdPRunqVO5dvYDDL71LrJ3buXohrVs+uZztv2wkIj+KcRfOwaf8Ii2KJxcLufaa68lJiaG31es4EBRFsVBEfxsNPLd8Tp6WCsIk9vh6eePUiqhuroaMzK0Emu+LfFgz6ICXigYT9jAqRz0upH8KtVfPeD+9oukxMoKu+BE7IIT8Tv1DU09VKWjPrKKrM1rSG/wIN3OkyyJBO+cVHy3bMRd3Yptr164P/gAdgMGiC0GRERERC4jlEolYEm1O/n3yf+NRuMFj2c2m3F2dubIkSPAxVX7KysrY8qUKXz33XeEhoYC4OfnR1lZ2Wnb+Pn5kZ+fT2FhYVu0raysjN69e7Nv3z6++eYbnnrqKSQSCWFhYQQHB5OdnU2fPn3OObdcLm+7T1lZWbWdA7PZzJ49e85IWXzwwQcZNmwYy5Yto6ioqN0qrS4uLqSmprJ27Vo+++wzfvnlF77++usLOj8Abm5u2NraMnXqVACuv/56FixY0O5+p37Gpx7fqfdmrVZ71n0u1ke2bNnChg0b2L17N7a2tgwdOrRtjtmzZ/Pqq68SGRnJnXdaynIIgsAdd9zBa6+9dsZY1tbWbevaZDIZ+/btY+PGjfz0008sWLDgjMhuR3Bzc6OxsRGj0YhMJmvzrUulI3lHrwGHJRLJwhPRtoPAvEueWUSkGxgbPJY7Yu7gO4/5yD1NrP86g8YqzSWNKZFIcJkUxpMxA7jDpontpZHM+vIHGpvzL3gsqUTKczc+hGlQEa0KFe57pdz3xsdUNqsuzCYrKxzHjiV42W/4f/oJMg8PKl98ifxrR1L3zUJkUiviR4zh1tfe5dbX3iM6ZRjH9u7kp2cf4/snHyZ1/Wr02ta28Xx8fLh79mzuHdiXGfWl3Lp9FcOzDiCvqWS93IF8vYlyB2fcIqLw8fNDLpdj6+qDEDaSHuOf4qmPlzLntsm88dyjzLlnFk899RRmcweL0dq6QvBg7Ke8QfILy5k5zotbgg4T69lEras9+0N92donhjRVHcfuu5eSO2bSeuJmLiIiIiLSuQwePJjly5fT2tqKSqVi5cqVlzxmSkoKy5cvR6PR0NLSwrJly0hJSTnnXI6OjgQHB7NkiaUisyAIpKamdni+xsZGrrvuOubPn8/AgQPbXvfx8cHR0ZE9e/YgCALfffcdkyZNIi4ujurqaoqKiigqKsLf359Dhw7h7e1NQEAAGzduBKCqqoqcnBxCQkIAiIyMvKDzMGrUKD788MO2/08K06amprYv+QsXLmx7f/Dgwfz4448ApKenc/SopeREbW0tZrOZadOm8corr3Do0KELsuMkEomECRMmsGXLFgA2btxIdHQ0AMuWLWtb+9ZRvLy8yMrKwmw2t0XGOoumpiZcXFywtbUlOzubPXv2tL3Xt29fSktL+fHHH5kxYwZgiQouXbqU6mrLuv/6+nqKi4vPGPdkxHPcuHG89tprF+RnpyKRSBg2bBhLly4F4Ntvv2XSpEkXNdapdKQ4yU9AP+A34FegP1B0yTOLiHQT/0n6D0l+vfmhx+sIUjN/fpaGXnvhv/idikQqwXlyGI9EX8N9Sg17K6K446sVVDdktr/z38eSSOjjHce9z4+k0aOGxKJoXn7zM5akbr2osRyGDSNw8U8ELPwGRWgo1a+/TuGEiah3WBY9e4WEMfKeB7nvs28ZefeDIJGw4auP+fy+29n49afUllouZFZWViQnJ3PXXXfx1Nz/MDc5gfsay5jVUEpwUBCaqipyjleQ1aKl56Rp/N/zLzLzrlmku45mszoMT08PPM3VNBan8ceiTzjw/XOWaNqF4BqCZMaPeN/3E9dGmbkvcBPj4414Bfcg117JluhgdjRUcHDWnZTcPwdtzrELPmciIiIiIuemd+/e3HjjjSQkJDB27Ngze3le5JgzZ86kT58+9O3bl9mzZ9OrV6/zzvXDDz+wYMECEhIS6NOnD7///vsZ43722Wdt67pO5aOPPiIvL4+XXnqJxMREEhMT277Af/LJJ8yePZuwsDBCQ0PbKkqei2effZZdu3YRFxfHiBEjeP3113F3d6e2tvaMVgLt8cEHH3DgwAHi4+OJjo5us/2JJ57g6aefplevXqdFn+6//37UajVRUVE899xzbev/ysvLGTp0KImJidx6661tUaVznQ+wLI949NFHWbhwIf7+/m0pm6+//jovvPAC8fHxfP/997z99tuApTjM+dJBz8b8+fMZP348AwYMaEuX7SzGjBmD0WgkKiqKp556in79+p32/g033MDAgQNxOdH/Njo6mldeeYVRo0YRHx/PyJEjqaioOGNclUrF+PHjiY+PZ/To0bzzzjuAZY3bc889d1ZbUlJSuP7669m4cSP+/v6sXbsWsJzLd955h7CwsLa1c5dKuw24z7qTRFIiCEJA+1teGGIDbpGuol5bz02rbsKtPoCUwzcTnOjBmHtiLznFTjALNCw5xnfpmbxvkBPuUsLXdw3C3yP+gsY56WNms8CCLzaiPyKl3DGX6r5lvDfhSewVF98DRr19B1WvvIK+uBiH0aPxeupJ5KdcQAVBoCI3m9R1f5KzezsmoxH/6FgSRo4jvE9/rGTy08bTaDRkZ2fz559/suNYHscj46nuMwQrqYShUiMRR/ey7Juv8ff3p6Qgj8qKMrStGoYESHh5hD3xg8YiSbgBeo4BuU3HD8RsgsOLYNPL0FJDU9AkUlWBpB3ORduixl5vJLC6gch+Kfg+8jCKgE6/RF3xiNcyke5A9LPORWzAfSaXYwPuVatWUVBQ0LYG7d/GrbfeyrvvvouHh8c/bUqHGD9+PHPnzmXEiBEXPcbl2ID7YoVbqSAI5191eBGIwk2kK8mqy+KONXcwtG4qgZl96Dc55JKKlZxEMAvU/5zD75lZzDNa4WNfw8KZiYT5nb/q1qn83cd2bc7nwC8FqBUNbIn6hf+Oe4ShASkXbaNZr6d+wQJqP/scpFLc59yP2x13IPlb3xlNcxPpm9dzdMNqmqqrsHVyJum6yfQaOwG5QnnGuAaDgZKSEnblF7FYbeCIkwfanCz077yEv5MjQouaxsZGtFotcT1DcJaqiLKu46YIHUYrOwrkEYQmDCRp9I1IfeJB2oHeKdpm2P4WHFgIuiYMMgdylIM4XKKguroemcmMX6Oa8B4heMfEYRMdhTIyCkVgAJIL7M3yb0O8lol0B6KfdS6icDuTy1G4iVweNDY20qdPHxISEtpSay+Wf5NwEyNuIlcka4vW8tiWx7ij8r/YFHsx/sEEAmPcLnlcwWSm7odstuQe4xmzgINCzde3hxMf3K/9nTm7j5XnNbL0wwOYDQY2hn/H6MFDebD3PZcUJdSXlVP12muoN25EERKC93PPYtfvTBsFs5mi1EMcWr2CotRD2Lu5M/D6W4geMhzpecRVUUMj72YVsPCD99Ec3o/MYEBpMuLr4U6QlydWUimC2UxW2mFaVI04yUw4yI0MD5Yxf5wH0sB+ENgfAgeCby+QnSkW2zDqoWgbZK2E7D8Q1DVU6l052BJHbpUZM2BtMOLZ1IJnswZ3M9iF90QZFYl1ZBTWsTFY9+yJRC4/9xz/MsRrmUh3IPpZ53K5CrcHHnigre/YSR555JG2YhBdiSjc/v307dsXnU532mvff/99W/XJ7uCKEm4SiWQlcLY3JcBwQRDsOsHW0xCFm0h38PGRj/nq0Nfckz8Peast1z99DU4eHe/Fdi4Eo5na7zI5UFTA44IOqcTEZzf7MSCy/UjZuXxM3aDlh7cPYKzVc8h3PTZ9jbx97Ssorc4jaDqAassWql6Zh6GsDPvhw3G+fjr2KSlIztJEtDTjKNt+XEhl3jHc/ANIuXkmIb2Tzysgm/QGXl2zkRVH0qj28EXWMwplcwMOW9eh27GZ6twcrJVKJBIJsZHhNNVW8OmsZJIVBVCbg1kQOFglI18eRWi/cSRNvg+p3XkEttkEpXshcwVkrURTX0mB2pX8Vn+Kmu0wmkEmkeCJFe5VdXjUNKA0mpAolVhHRmIdH49NfBzWsbEoAgP/tf3ixGuZSHcg+lnncrkKt38SUbiJdAdXmnAbcr5JBEG48MoJ7SAKN5HuwCyY+b8t/8f+3FRuzfwfzm52THviGuTKS0+jM+tN1H6TQVZ5MY9K1WiMct6b5sboXsPOu9/5fMyoN7Hs63Sqj9Rx3CGPnMRdfDrlTTxsLy3P3KzVUrdgAQ0//Iipvh4rD3ecJk7EeepUlCdKJZ9EEARy9+5kx+LvaKg4jl9kDINvmYlvz/a/TNToDWyorOP3wjL268zUbPiTlu++QGrQY6dU0jsxgcbKSp588kmmTJnC/JefJ23fNvLycpHomrEyGxgWomD+3WOQxkyEyPFgf55jFwSoOALFu6DsAMbSA5QeV5GvciVf7YbaaBG9fm4uBNp54HG8CmNmFkKrpaqm1NER2z7JeD76KMoTlcL+LYjXMpHuQPSzzkUUbmciCjeR7uCKEm7/BKJwE+kuNAYNt62+DUrsGJ4xk/AkT0bOiumUfmBmnZHaBekUVZUzV15PlcaB+RPsmN5/5Dn36YiP7d5UzL4lueitWtgVuZx5Mx4n2i36ku0V9HrU27bR+Nsy1Fu3gsmEdUI8zlOm4njdOKxOuWiZjEbSN69j15If0TQ1Epbcn+SJ007rBXc+zGYzn/z2Oy89/RRaB0e0EinIlSgbarj7uRcZH+TP8089SVpaGkqlEmdnZ7ycbdE0VPHpBDuSHapBIoWAARAzGeKmg41L+weprobygwil+6nJOkBubjlZ9c40GWyQy6SEJyUTFtkLtxYNurQMmteswdzaitvsWbjfey/Sv/XYuVIRr2Ui3YHoZ52LKNzORBRuIt2BKNzaQRRuIt3JcfVxZvwxg4SyEUTkDmLAtDB6jeycpZvmViM1Xx6lqq6aR22Ok9/owf9GK5k1bNRZt++oj5UWNfLTe/ux1Uo42GM9188YzriQ0Z1iM4Cxtpamlato+u03dLm5SJRKHMeMxvnGm7DpldgmzvTaVg7+sZwDK5ehb9XgFRJOrzHjiRgwGFk7a8bMZjNPPfUUGzZsoFnTSqPRhJB4DbL7H8N8eD+mhZ/QWpSPg50dklP2ufeee3j+vmnI89ZYUiJrskBmDdGTIWkmBPSDjgpvQytC5grKN35PZk4FOc0e6M0y7B3tiBoyioiEazB+/wPNK1Yi79ED7+eewz5l0EWf18sF8Vom0h2Ifta5iMLtTEThJtIdXI7C7d+5kENEpAP42vvyztB32O6xjCa/Unb/lkdxRl2njC21keE+Kw5PJw8+1vkR51HGy2sNfLR+2yWN2yPImYfmDUHjI+Oa0tFs+zyP97Z/ilnoYHPrdpC5u+N250yCV/xO0JIlOE2dgmrDRopvvpnCSZOp//FHTGo1Cmsb+k+bwb2fLmTEXfdj0Lay5pN3+WLOTHYs/h5VXe0555BKpcyfP5/PP/+ceS++wOqffqDs+wV86mHNsNgo5PfOxeDhTYO1HS0GI2azGYPBwNZt27jz6XdYqY5jf58PWez1NPtth2POXAXfjIGP+8LujzvWK05ugyThRvwfXcWo15Zw38z+jA+txNNcwoGVv7HolWfYZKil4YHZ6GRWlN59N2Vz52Koqu6U8ywiIiLSVZjNZvbv38/ixYvZv38/ZvOl3x/s7c9sSZOTk9PWOywqKop77rmHtWvXtvVJs7e3JyIigsTERG6//Xa2bNmCRCLhq6++ahvjyJEjSCQS3nrrrbPO+9577/Hdd98BMHPmTIKDg0lMTCQpKYkXX3zxko/rVLZs2cL48eMBS8+u+fPnd8q4QUFBxMXFtZ2XXbt2UVRURGxs7DnnP8nMmTPbGjgPHTq07XwmJiYyffp0AF544QVsbW3b+tKB5fOqq6tr29bb2xs/P7+2//V6fdu2Go2G6667jsjISGJiYnjqqafa3tPpdNx4442EhYXRt29fioqKAFi/fj1JSUnExcWRlJTEpk2b2vYZM2YMCQkJxMTEcN9992EymQB47LHHTttO5OI4sxKBiMhVRJJXEv/r9z/mGV9jZusLrPk8jUlze+Ed7HTJY1vZyfGYHQefp/J2q4lnvLN5a2MEav0enhzX96LTMm3sFDz+3BC+WngEn3090S5RMafkCZ6Z+Ag9HDqnS4dEIsEmLhabuFi8HnuMpj/+oGHxYqpeepnqt97G6brrcL7pRmxiYkgcfR0Jo8ZRnHaEw2tWsnf5L+z7fQnhfQaQOPo6/KPO7JcnlUpJTk4+rbnq1PhopsaDalhfph/ewa4dO2mVuaHVtOBs74idgwONjY0sWLCA8vJyTCYTVlZWDBt8A/NnJCI98j2s/S9seAGiJkCvWyF4SPstBlxDkI9+noiR/yMibyMtuxeSc+gomfUqdh+vRuJohU+/SDz276Zp/Hh8Hn4Y5+ung9mMYDaD0YhgNiMYjXDiBiXz9u6UtFsRERGRC+FkRsPmzZv/ukYOG8b8+fORdnLRpYcffpi5c+cyadIkANLS0oiLi2P0aEsWyNChQ3nrrbe45hpL0GDLli3Exsbyyy+/MHv2bAB++uknEhISzjq+0Wjk66+/5tChQ22vvfnmm0yfPp2amhr69u3L7bffTnBwcKceF8DEiROZOHFip423efNm3N3d2/4/KYAulB9++KHtfJ6Ku7s7b7/9Nq+//nrba25ubhw5cgSwiDt7e3see+yxs4772GOPMWzYMPR6PSNGjGD16tWMHTuWBQsW4OLiQl5eHosXL+bJJ5/k559/xt3dnZUrV+Lr60t6ejqjR4+mvLwcgF9++QVHR0cEQWD69OksWbKEm266iYceeoi7776b4cOHX9Sxi1hoV7ido7pkE3AA+FwQBG1XGCYi0l1M6zmNYw3HWGR6lbvyXuSPj44y9fHeuHhfeuFUK0cF7nfHwZdpzGvW8rLfIT7b3hu1bj8vTU5GKr24L/cSiYS77+zF6rBijvycQcTO4dzTOJebhk7g1qhbsepIP7QOIrWzw+WGG3C+/nq06ek0LF5M08qVNC5ZgnVcHE6TJuE4dgxB8b0Iiu9FY1UlR9b9QfrmdRzbswMnL29ihowgZsgIHN09253PQalk9VdfcPDgQZbs3ssaQUllVAJHjxzAfctqpMXF+Pn6IpVKMZvN/Lp8BWERUdx11xpkdTlw8Fs4uhjSfwV7b4idBvHXg0/i+VMppVbQcxR2PUfRe0YLvYt2UnfwT7IOHiGrUsZxP3fSBTNe332J3/vv4K5u5VyjyQMCcJowAacJ41EEBV3MaRcRERE5Kxs3bmTDhg1nfa+iooK1a9fi4eFBYGAgZrOZTZs2sWLFCvbu3XvWfa699tqLalJcUVGBv79/2/8dKdMeGBhIc3MzVVVVeHp6smbNGsaNG3fWbTdt2kTv3r2RnaXasVZr+eppZ2e5T7/00kusXLmS1tZWBgwYwOeff45EIuGDDz7gs88+QyaTER0dzeLFi2lpaeGhhx4iPT0dg8HACy+80CY+T7Jw4UIOHDjARx99xMyZM3F0dOTAgQNUVlbyxhtvtEW73nzzTX755Rd0Oh1Tpkzp9ChgR7nrrrtYuHAhTz75JK6urhe0r62tLcOGWQqoKRQKevfuTVlZGQC///47L7zwAgDTp0/nwQcfRBAEevXq1bZ/TEwMra2t6HQ6lEoljo6OgEV46/X6th8xAwMDqauro7KyEm9v70s95KuWjkTcCgAP4KcT/98IqICewJfAbV1jmohI9/F48uPkN+Xzk/AGtxz7LyveP8K0J5Kwd7n0ohQyZ2s8H0jEarENzx7X8FbAdhbtS6FFf4A3r09CZnXxv4KOTQkkwNeBFe8fZHT63fxk/II1hWt4ceCL9HTpecm2n4olCheHTVwcXk8+SdPvK2hcupSqV16h6rXXsBswAKcJ43EcMYKht81i4PW3kLtvF+lbNrDrlx/YteRHAmLiiR16LWF9+iNXnvvcnhqRewNYmp7D2/oYslTNtP70DVq1hhAHO8wmE3V1dXz++efs3LmTsWPHMnLkkxS4TCB/x3JCdRkk7fkc6Z6PwS0c4m+AuOvBtZ1faBV20HMUbj1HMWgGDKwvonzbEjJ37yZHKnDc1QE79ITZWREeFI5DQAISa3skMivMWh2qjRuo/eQTaj/+GJuEBBwnTsBx3DhkLh0opCIiIiJyHqqqqkhPTz/re+Xl5Wg0GjQaDUDbD1y5ubnn3Odi+2LNnTuX4cOHM2DAAEaNGsWdd96Js7Nzu/udjML06tWL3r17o1Sevb3Nzp07SUpKOu21xx9/nFdeeYW8vDwefvhhPD0tPwY++OCDPPfccwDcdtttrFq1igkTJjB//nwKCwtRKpU0NjYCMG/ePIYPH87XX3/d1qz52muvPa/NFRUV7Nixg+zsbCZOnMj06dNZt24dubm57Nu3D0EQmDhxItu2bWPw4MFn7D9s2DCsrKxQKpXnFNAd4ZZbbsHGxgaAkSNH8uabbwKW1Mi77rqL999//5LEY2NjIytXruSRRx4BLP7Uo4clk0cmk+Hk5ERdXd1p0cNff/31jM9x9OjR7Nu3j7Fjx7aJXIDevXuzc+dOpk2bdtE2Xu10RLgNEAQh+ZT/V0okkv2CICRLJJKMrjJMRKQ7kUllvDX4LWaoZrA66gvGHL2XFR+kMvWx3ljbXXqDZqmtHPeZMSjW2jH3aAu2IX+y7Mg41LoDfHhzUvsDnIeYUFc8nx3It6/tY2zW/WwSFnFD/Y3MjpvFPfH3oLBSXLL9f8fK0RHX227F9bZb0R47RvOqP2hetYrjTzyJxNoah+HDcZwwnqiBg4gePJym6koytm4iY+tG/vzobRQ2tkQMSCFu+Ci8Q3u2m1Y4PTaCqdHhvFJXxusSKNCZKNY3Y6NRY0ACSmvq6+tZtGgRzz77LFqtFgcHB2xtbRk++BZLKmX6Utg8z/Lw7wMxUyB6Ejj5tXu8Etcg/Cc/jv9kGN7aQt7a70nfsonUihZSMwoIKDpMbIQHYUMnII+bhOutt2CoqqJ51R80rVhB1cuvUPXafOxTUnAcfx32KSlYnfhVUkRERORC8PLyOmN91Enc3NyoqKjA1tbSm9RsNiOVSgkPD6e+/uzrf728vC7KjjvvvJPRo0ezZs0afv/9dz7//HNSU1PPKcROcsMNN3DjjTeSnZ3NjBkz2LVr11m3q6ioOKNgw8lUyYqKCiZPnsyuXbsYMGAAmzdv5o033kCj0VBfX09MTAwTJkwgPj6eW265hcmTJzN58mQA1q1bx4oVK9rW1Wm1WkpKSs5r8+TJk5FKpURHR1NVVdU2zrp169qiT2q1mtzc3LMKt7+nSp6Nc90HT339XKmSYEldTUxMPGc6ZHsYjUZmzJjBww8/TEgHW+FkZGTw5JNPsm7dutNeX7t2LVqtlltuuYVNmzYxcqSlqranpyfHjx+/KPtELHREuNlLJJIAQRBKACQSSQBwcpWq/ty7iYhcWThbO/Ph8A+55c9bONxrBQkHJvDHx6lM/E8v5IpLTz2USCU4jQ1G7juFe7a2YBOxlB+zpnPXwn3cHnxp1V09PGx54MUBfP3aPkZk38a24CA+Fz5nffF6XhzwIomeiZds/7mw7tkT60d74vGfR2g9fJimVatQrV5D859/InVwwK5/f+xSBpE8aBj9p91EaWY6GVs3kLVjC2kb1+IZHErCyHFEDRyC/Dxl96VSKf+7bQbNaYdZuuoP6vUGNFYypKPGk588gMI925EXHkNdVY2NtRK9Xo9KpWLp8lVcP+M2ku+8CxpLIX0ppC2FtU9bHv59LAIuehI4t79GUGZjR+Tk+4icfB/N1VVkrPyW9F17+POQHuWRxUQ6fURwiA8+fUbjNn0qbrPuQpuTQ/PKlTStXIV682awssImMRH7lBTsB6egjIoS18SJiIh0iBEjRpwztfHkGrdNmzZRXl6OVCpl+PDhTJw4sU24dCa+vr7cdddd3HXXXcTGxpKenn5GlOzveHt7I5fLWb9+Pe+///45hZuNjU1bSuTfsbe3Z+jQoezYsYPevXszZ84cDhw4QI8ePXjhhRfa9vvjjz/Ytm0bK1euZN68eaSlpSEIAr/++isRERGnjXlSkJ2NU8XoyWrsgiDw9NNPc++99573eDuKm5sbDQ0Np71WX1/fruA7ibOzMzfffDMff/zxRc1/zz33EB4ezn/+85+21/z8/CgtLcXf3x+j0UhTUxNubm4AlJWVMWXKFL777jtC/9b7FcDa2ppJkybx+++/twk3rVbbFjEUuTg6Itz+D9ghkUjyAQkQDMyRSCR2wLddaZyISHcT5hLGaymv8cjmR/Dp3wNhRwJrv0hn7P1xWF1CSuOp2CZ4EupxD7esfQeb2O/5JuMWKmtl9B9gwMn24qN7Ng4KZj/bjx/fPMCQwhTMqmBqY77j9tW3c1v0bTzU6yGsZV3Xj0wilWKblIRtUhLeTz+NeudO1Js2od6+A9WJX+OU4WHYDUphcMoght5yJzl7d5G6/k/Wf/EhW79fQPTg4SSOGoeb/9nbMkilUt544w1uvPFG8vPzcXZ2pkGuZGNVHVnXzyBr03paS0vQGs1YIaA0mbExGCgoKLAUQnHugXnAIxxUDiL/yE5CzYUk6Q8gXfcMrHsG/JIs7QUixoFrCLSzmN/R04v+s56g351mStKPkr76F9JT00g9KMDBtbgoluHrpsA3Mhbf0ZMIfeQRtGnpqLdvo2XrNmree4+a997DysMd+4GDsB+cgt3AgVg5XXpxHBERkauPk1V7Dx48SEFBASEhISQlJXV6YRKANWvWMGLECORyOZWVldTV1eHn134GA1jWpFVXV2Nlde4fRaOiosjLyzvre0ajkb179/LQQw+1iTR3d3fUajVLly5l+vTpmM1mSktLGTZsGIMGDWLx4sWo1WpGjx7Nhx9+yIcffohEIuHw4cOnrdnqKKNHj+bZZ5/llltuwd7envLycuRyeVv65oUSHh7O8ePH20rDFxcXk5qaSmJiYofHePTRR0lOTsZoNF7Q3P/73/9oamo6reInWIq0fPvtt/Tv35+lS5cyfPhwJBIJjY2NXHfddcyfP5+BAwe2ba9Wq1GpVPj4+GA0Gvnjjz9ISUlpe//YsWNcf/31F2SbyOm0K9wEQfhTIpGEA5EnXso5pSDJe11lmIjIP8XwgOE8kPgAHx/5mEeGPk/xZtj8fTYjbo9CcpHFRP6OwteeyBueZvLqZ7BJWMBnqbOY8eUevp/VBzf786eZnA+ljYxbnriGZR8eYXi+hHX75+LZfwvfZX7HtrJtvDLoFRI8zl7BqzORKBQ4DBuGw7BhCIKAPi8P9Y6dtGzfTsOiRdR/8w0Sa2s8rxvHjLn/pVrVyNH1q0nbuIYja1fhHxVLwsixhPUZcEZfuLNVpJwB1NbW8ltzJS+uX4XB1g613kCLWkWrTMELtVoO7kllmp8Hb859mF27dmFvb4+joyPDhw9n/uMLkWavhMzlsP5Zy0NuB56R4BkFntF/Pdt7nVHkRCKVEhifSGB8IgadlqqCPI4f3s7xo3spKKsmY3M2bM5GaWXGz9+NxLFTCXpoCaa6uhPnZRuqzZtpWr4cpFJsEhKwSxmEfUoK1jExSLrgS5eIiMi/k7NdIy8VjUZzWiGSRx99lLKyMh555BGsT2RKvPnmmx0uOjFgwIB2txk7diy33XZ6GYWTa9y0Wi0jR45k6tSplmJdd99NbGws3t7ebcdtMpm49dZbaWpqQhAEHn74YZydnXn22Wf5z3/+Q3x8PGazmeDgYFatWtXRU9HGqFGjyMrKon///oAlCrho0aIOC7ecnJzTzum7777LokWLuPPOO9Fqtcjlcr766iucTvkh79Q1bu7u7mcUqXF3d2fKlCm8++67HT6OsrIy5s2bR2RkJL179wYsawZnz57NrFmzuO222wgLC8PV1ZXFixcD8NFHH5GXl8dLL73ESy+9BFhSR0+u9dPpdJjNZoYNG8Z9990HgMFgIC8v75ypniIdo0MNuCUSyQAgiFOEniAI33W2MWIDbpHLBUEQ+L+t/8fGko08J/+Ayq0mEkcGMHBaWKfOYzaaObrxQbY2FfPxkXsJdHfkh9n98HS8tMiYUW/ij8/SKMusZ6ONnuMBhci8lqIy1jIzZiZzEuegtLp4gXgpmDUaNPv3o9q4iaZlywBwnnET7vfcg14hJ33zeo5uXENTVSXWDo5EDxpK7PBReAQEtT/2iTSh9evXo9Vq0ZlM2EXFYjVzDpVObhhyMmn670PIzGZsZTJsrJUoFAo++eQTxo4daxmkvgAKt0F1NlRnQnUWtJzSv83GBYJSoPcdEDqs3XYDgiDQmHuI4zuWUZF5mPwKPWqjEldbI0nJUURNno3cNwbBaKT1aBotO7aj3rYd7YlCAlYuLtgNGoR9yiDsBg5EdiJN5WIQr2Ui3YHoZ53L1dyAe8qUKbzxxhuEh4ef9rrYgPvKY9myZRw6dIiXX375nzalw1yODbjbFW4SieR7IBQ4AphOvCwIgvBwp1h7CqJwE7mc0Bg03Lb6NipUFfzX9AHFu5oZdH04CSM6p1faScxmI3t/e4jDFPDB4fvxcnbgx7sH4Od8aXngJoOZdQsyKDhSQ5W9hN+tGrEOXYNGuYtQp1DmDZpHjHtMJx3FxWE4fpzaTz+l8bdlSJRKXG+/Dbe77kJqb09x2hHSNq8nf/9uTEYj3mE9iRs2iogBg1GeWHh/Nsxm8xlpQoIgkH68khcXLOSPjz/AKAhgMiIXBGQmIxE9ezJ27FhGjRqFXC6nuLiY0NDQv1KMWmr/EnGVaZDzJ2jqwCnA0i+u160dKnICYGoo59iKzzmw/SDVKgk2VnoS/c0kjhiBbfKNlhRNwFhXR8uuXai3b6dlx05M9fUgkWDTuzeOY8bgMGoUcq8LS8kRr2Ui3YHoZ53L1SzccnJyqKqqOqPghyjcrjyWLFnCyJEjO1R59HLhShVuWUC00JHQ3CUiCjeRy41ydTkzVs3AWenC3RXPU5LWyJh7YgntdXE57Odiy6Yt+NQfYguref/IfTjbOfDTPQMJdLu0XnJmk5nUjWXs+6MQo9FMmqPAJptU7AJ+wyxVMTtuFvfF34fc6tIrZ14KusJCaj/8yFLQxNERt9mzcb31FqS2tmiam8javoX0zeuoLS1GplQS0S+F6MHD8Y2IOiOV8nzs37+fOXPmYOPsQmZFpaXKWlMT7oGBxPh6U1JYSGNjI97e3m29bc7auNaog+w/4NC3ULAFJFIIGwlJd0D4aLBqf/mwIAiUHdjCgd++p6CgGiuJmSjHamLDHPC6Zgyy2IngEQkSCYLZjDYzC/XWLajWrkN37BhIJNgmJeEwdgyOo0Yh8/Bod07xWibSHYh+1rlczcLtXIjCTaQ7uFKF2xLgYUEQKjrVyrMgCjeRy5H9lfu5Z909DPAayNAjd1BX1sLkub3wDum8AhJbtmxh8IAUChf9yDbHH3g79S5slA78dE8KYZ727Q/QDuoGLTuX5pF3sBqJg4w1ymaOeSxB7nyIEMeefDTiPXo4dm4k8WLQZmVR8/4HqLdswcrdHY8H5uA8fToSuRxBEKjMO0ba5nVk79yGQduKTKHELzKaHjHxBMTE4xUShvQ8i91PrbhmNpvRCQKagBBqw6IxbFmPOTsdZ3s7kk/k4FdVVfHpp5+ef61IfSEc/h4O/wDqSkvT7163QO/bwSWoQ8ddf7yMQ8t/IGPnToxGM1YSM17WKnxdrPCNjsd34BTsIoe0FUvR5efTvGYNqjVr0OXmgVSKbXIyjuPG4TR5EtJzlOMWr2Ui3YHoZ51LVlYWkZGRYuXZUxCFm0h30B1+JggC2dnZnSrcNgOJwD5Ad8pEEzvD4FMRhZvI5cqSY0t4afdL9HUewOD9t2NoNTPtiSScvc6dsnchnPQxk0pP6der2eXzDfPTb8TKyoEf7h5MtG/n9Pwqzaxn28/HaKzSIPjZ8L10Py0+i7CWS3ljyKsMDxjeKfNcKppDh6l+521aDxxEERSEx9y5OIwa2fbFRa9tpTjtCKUZRylNP0ptaTEAChsb/KNiCYhNILzvQBzdz4xCnS2V8lBdI3e9/QGZi75BameHj7MzntYKDE2NPPDAAxw7dozx48fTv39/UlNTyc/PPz2VEsBkhNy1cPBbyFsPghlChlmicBHXgaz9fnqtahVlmWkcTzvA8fQDVFXWYzJb3nNSGvD1dSWk/7WEjJqBwsbie7rcXJrXrKV59Wr0BQXIvLxwv+9enKdNQ6I4fU7xWibSHYh+1rkUFhbi4OCAm5ubKN5OIAo3ke6gq/1MEATq6upQqVQEBwef9t6lCLch55hs66UYezZE4SZyObO6cDXP7HiGcEk01x6+G2tbBdOfSMLG4dIbXJ/qY4YaDZVf7GJ/6He8nDUKI458P2sQiQGulzwPWNa+Hd5QwsE/ixCAbM9W1rm/j5VtObdHzWTuNY8gk3akU0jXIggC6s1bqH7nbfR5+dgkJOD5+GPYnqUilaapkdLMNErSUynNOEpDxXFkcgVJ4yfTZ9L0NpFzPvbv389td99NrdIOlVRm6dVTX4NP72SsivJwU8hR11Sj1+txcHBALpefO5WyqcwSgTv0HTSXga07JM6A3jPBveMFbowGA9XZhzm++w+OZx2lrEpDq0mOTGomONiTiBFTCBk4Grm1NYIgoNm3n5oPPqD14EHkvr64z7kfp0mTkJxIJxWvZSLdgehnnYvBYKCsrOycPc2uRrRabVs1SxGRrqI7/Mza2hp/f3/kf1v2cdHCrTsRhZvI5c6hqkM8svkR3Jt6MCptNh49HJk099IbdP/dx3RFTVQvOExG9O/871gizXoX3pgWy+TeIZd4BH/RXNfK9p9zKTpai9FdzrdOv2Dw3EKcW28+GPE27jYda/rZ1QhGI03Ll1PzwYcYq6uxHzYMz/97FGXYuQVQY2UFu5b8QNaOLdg6OTPwhluJHTayw2mUOqMRlcGETXwiqvBo6nbvwFhZgangGFYyGUorKV4uLiiVShYuXEifPn3OMagJ8jfBwYWQsxoEEwQOhJgpEDUBHDpWOrttuNZmjq9bQM6ODeSWG2gxKZBJISQiiJ7XTiXkmgHIlEpaduyk5oMP0KalIQ8MwOOBB3C87jq2bt8uXstEuhzxninS1Yg+JtId/JN+dsHCTSKR7BAEYZBEIlEBp24kwVJVsnNyt05BFG4iVwLFzcXM2TAHZYk7I7JvJzjBgzH3xiG9hB5vZ/MxzdEa6n7MorT3Pp4rUJLXGMLsgZ48fd01WHVSPzlBEMjaVcH2n48hSCWsdMmgJOArHJUOvDf8LZK9O68P0KVibm2l/tvvqPvqK8waDU4TJ+J8ww3Y9Eo8Z/pQZd4xtnz/FeXZmbj5BzD0tlkEJSade46zpFFKpVKO1Tfy8JNPs3nJYkwSCWYkSBCQarWEhYXx/DP/ZcqUKcjlcg4ePHj2VEpVFRz5AVJ/gtpjgAQC+kP0JIuI62BVyjZba/MoX/MFOXv3kFtnjcakwEoqwdvXDd/wCHwT+uHUoEH1xVfosrNRhIZS268fve6cidzPT0y5EukyxHumSFcj+phId3BFCbd/AlG4iVwpNGgbeGTzIxhS7RlUNJ24oX6k3Njzor8Mn8vHVNvKaPqzkNb+pcwry2ZLaV8GBCv59LYhONl2XiXIhsoW1i3IoLZUTb6rhg0B74FNDQ/3fphZsXddVl/yjQ0NlhYCS5YitLaiCA7GacoUnCZNOmt5fEEQyN23i+0/LKSxqoKghN4MufUu3DvQF+5U9u/fz/3334+trS1FlVVU1dZi0OuRBYcRfcds+lmZKd24lsKCAhQKxflTKauzIfN3y6M6w/Kafx+IngiR17W1BOgQZhPm/M2Urf+WgoxsytU2VGvtMWOZ09Vegoe1NbaF9TiXVmFjMCHz8cGuTzK2ffpg26cPcn//y+ozFrmyEe+ZIl2N6GMi3cEVK9wkEokV4MXpDbhLOtVCROEmcmWhM+l4dsezNG5RklAxjL5TgrlmdHD7O56Fc/mYIAg0rSlCvbUMc3gzC63X8W36cHycrPj6ziH09Oq8RbMmg5ndy/JJ3VSKzl7CEq8lqD23M9hvOG8OeQ1beecUYuksTOoWVGvX0PjbMloPHgSpFLtBA3GeOhX74cOR/q0wh9Fg4MjaVez5bTG6lhacvX3wCAjGPSAIj8AgPAJDcPLwRPJ3kXWCv1ekBPDqEYA2JJzSSbfQkJVB67sv46RU0lpeioOdHdbW1nz33Xf079//3AdSm3tCxC239IgDcA6EkKGWBt/BQ8C2g+sbzWZoLMJQdpTK9P0cz8ulvKKR441SdGYZIOBvIyFI5oJTZgFCfT0AMm9vbPskY5+Sgv3gwVg5dV7FVJGrD/GeKdLViD4m0h1ckcJNIpE8BDwPVAEn6pshCIIQ39lGisJN5ErDLJj56NBHFP6mJ6yuNwNnhJI4JPCCx2nPxzSp1TT8mofJRs3W2N95c/8gDIId792YzOhYn0s4gjMpSqtl03dZtGqMbHZNJyfkS3ztQlg47lN87Dt3rs5CX1xM47JlNC3/HWNlJVZOTjhOmIDztKlY/63EbquqmaMb1lBVmEdtSRENlRVw4joot7bBPSAQ75BwwpL74x8dg1T617q4c6VSakxmnvhiAd++9x46G1uMxQVIEUCnw83Pn/HjxnHr5InI5XLKysrOTKM8SX0B5G6Ags1QuB30KkACvokWIRcyDIIGgfTC1lQK+lbq0new/5dPKSlVozYqsLexIqpXH4LtvZCkZ6DZu8/S5Fsmwzb5GhyGj8BhxHDkvr4X8YmIXM2I90yRrkb0MZHu4EoVbnlAX0EQ6rrKuJOIwk3kSuWXrCUc/LaaHo2RDL0jnNj+ARe0f0d8zFCjoW5RFoaaZo4NWM0rR4MobA7koWGBzB0Zc0lr7P5OS5OOjQszKc1qoMq+hU3Bn6Cxb+a9oe8xOPDyWff2dwSTiZbde2j67TdUGzYg6PVYR0fjNG0qTuPHnzWSZNBqqS0rpqa4iNqSImpKCqnMy8Wo12Hr5Ex434FE9BuIX9TpIu7vnEylxMaW0uPHaWpsRK/TYRUcjsTOHqGkAFTN2NnY4OnizKSJE3n99dfPFG8nMRmh/KBFxBVsgbL9YDaCWzgMfQpiprb1desoW7ZsYXBCGPk/v0ra/qMUqp2QSCQEx8QQN2YK3lI5mi1bUW3ahD4/HwBlVBQOI0ZgP3Qo1j3Dz2gxICLyd8R7pkhXI/qYSHdwpQq3zcBIQRCMXWXcSUThJnIlszx7Bfu/rsRHFcKIuyOJ6u3f4X076mNmvYnG3/NpOVhJfeJOXq/Wsut4H6b3cuPNG/p26jolwSyQtrWMvSsK0GlNpHru5mCPFUwLf4BnhtzeafN0FabGRpr++IPGX39Fl5mFRKHAYeRInKdNxbZfv3OmRIJFzBUcPsCx3dspOHzgdBHXfxB+kdFniLi/p1JKJBJ6RkTg0zOSlX+upigjDZNcDhIpErkcN1dXvvjsMyYPHdy2/zkLmwBomyF3HWx/G6ozwSMKhj0NkRM6LOBO8zNVJU1r3iJt6ybSG9xpMSpQWisJTLyGkN598HP1wLRvP6qNm2g9fNgSlZTJUAQFogwP/+sRFoYiIADJeSp2ilxdiPdMka5G9DGR7uBKFW4LgAjgD05vwP1OO/tZA9sAJZa1cUsFQXj+fPuIwk3kSufP7DXs/aoSd40vo+6PJiKuY+LtQn2s5UAljb/no/bM4CNlDisLhjOzvyfPT7ym04tMaJr17P09n8ydFWhkGvYE/obW253vpr6Im51Np87VVWgzM2n89TeaVq3C3NSE3M8P11l34TJ9ersRJIuI28+x3TvaRJy1gyOBsQkEJvQiKL43Dm6W1gnnSqVctGgRL7/8MhKJhMraWowOTuhkcuxumklKSgpjtY0sfut1qqursba2Pn9hE7MZMn6DLfOhLhe842DYM9BzDLTz2Z/Vz9TVmLa/R+Hm38hvtKdQ40aLwVL4xicklOBr+hEY0hPbsgr0eXnocnPR5eZiKCtrSzGVKJUoIyOw698fuwEDsE1MFCNzVzHiPVOkqxF9TKQ7uFKF21nFliAIL7aznwSwEwRBLZFI5MAO4BFBEPacax9RuIn8G1iXvZG9X1TipHNn7IMxhEe1L94uxscMlS3U/ZBFsy6d151y2Vg6gEeG+zF3VOLFGd4OVUXNbF2cTU2Rmkr7Qnb5HmLuyEcZHxfaJfN1BWadDtWGDTT88COthw5ZmlQ/8ABOkyYikbXfdPykiCs8fJCio4doabAU93DzDyAwvhdB8b3wj45Frjy9Yef+/fuZM2cOnp6WqpdGo5GS48cJmv0gGdG9qVvwMbqVS7FWyLFTKHBzc0MikfDNN9+cu0ecyQjpSy0CrqEQfHvDkCchdDjIzi6azutn2mbI34SQs4bqo9soqLGiQO1KpdYekGDv5EjPAUOJHDQE79CeCK2t6PILLELu2DFajxyhNS0NTCYktrbYJl+D/cCB2A0YgCI0VKxaeRUh3jNFuhrRx0S6gytSuHXS5LZYhNv9giDsPdd2onAT+bewMXsrez+rxNboyPj/xBEWdn7xdrE+ZtYZaVhyjJrSPbxkW8auiiSevS6QWSmxF2n5+RHMAjl7K9nwSzq0SshyO4pdUhSvThqNzOrC1lv9kwiCYGlS/f77aNPTUQQF4f7QgziOHXveFMq/j1FXWkxR6iGKjh6mPCsDo0GPlVxOUEISkQNSCE3qi9za+ow0SqlUyvDhw5k/fz71rVpG3XwrqRvXI8gVSAUBudmIYDAQEhzM+PHjGTx4MCEhIZSWllJXV0d4ePhfqZQmg6U33NY3oakE5HaWAiahwyzFTDwi2iJxHfYzswnKD8GxNWjS11FYWEmeyo3CFldMghRnZzsi+g0k6tpJuPX4qxiPSaVCs3cvLbt20bJzF/riYgBkXl44TZyI68w7kLm5XfDnJXJlId4zRboa0cdEuoMrSrhJJJL3BEH4j0QiWcnpDbgBEARhYgcmtQIOAmHAx4IgPHmWbe4B7gHw8vJKWrx4cXvDdjtqtRp7e/t/2gyRK4ysujyat7ogFxQEDAN313OX7r8kHxPANVeCvD6X/8prOVwTx+xYM4P8O69VwN8xGQRyjtRjynekwbaK7QGZPBA1DGdl5/WW6xYEAWVqKnYrViI/fhyDnx8tEyagS4hvN+3w75iNBtQV5TQVF9BQcAxDixqpTIZTUBiuYZHY+weQl1/A8ePH8fX1pWfPnm1pkNnZ2bzzzju0yhXUqNToVSokeh2evn44WUkwm83IZDIaGxuRSCQoFAqSk5O577772saQmA241h/Ctf4wLg2p2LYeB0CncKPBJYF61wTK5aHIXXtc8GlSamtwrT+Mbe1RakvKyK+3o6TFGQEJznbgFeiNQ1gCEo9gzIq//FhaV4cyKwtFWjrKo0dBJkOTkoJm5EjMLs4XbIfIlYF4zxTpakQfE+kO/kk/GzZs2AULtyRBEA5KJJIhZ3tfEIStHZ1cIpE4A8uAhwRBSD/XdmLETeTfxvb0vez9vBKkMOX/ehEacPZqk53hYy0HKinYvIInhBZyGsL4eEY0Y+O7No0x60gJ677KQi/Rsj50OXPHPcDYnmdcZy57BJOJ5tVrqP3wQ/TFxSijonAcOxaHa0egDLmAZtgnxzObKcvOIGfXNnL27ESrakZpa0dYn/5EpwynR0zcaamDp0bkTGYzjQYjTW6etLq441BbjadOg1ndjJubGyqVCo1Gg0ql4uGHH+bGG28kKCjozLVwjSWQv/mvqpStDZbXHf3BPwn8rgH/ZPBJAMUF9OgTBKjLoyVjPTm7tpGdW0NFi2Wto0xiwsNGh4eTFR6ejnj6euMeGIrCIwidJJi6RUtoWrECiVSK07SpuM2+G4W/3wWfX5HLG/GeKdLViD4m0h1cURG3LjDgOUAjCMJb59pGFG4i/0Z2pR1kz+cVGBU6ZjzZnx5eZ/bF6iwf0+Y3krNiCXNbDZSo/VlwewJDIi+8r9yFUF/Rwk/v7MaoNrE59CeC46J449pHkVtdYdE3QDAaaVq+nIaff0GbZmmGrQgKwuHaEdgPH4FNYkKHUylPYjIaKUlPJWfXNnL37UbfqiEoMYlhd9yNq+9fKbR/L2yS0Ks3S2saeXXHfgp++QFF2iFigwJwkcvQarXs3r2bHj160KdPH+Li4nB2dkYmkxETE3NmRUqzCSpSydu0iDCbRktrgcYSy3sSK/CKAf9rIGAABKeAg/cFnDSBppw9lB7YQk1JCTWVdVTXa9AZ2jbARdFKkIOauKHDcOp1G3WLltL0228IZjNOEyfids/dKIMvrnm9yOWHeM8U6WpEHxPpDq5I4SaRSMKB14BooG3FvSAI5/0ZWiKReAAGQRAaJRKJDbAOeF0QhFXn2kcUbiL/VrYd2M+hr+totWtk5tPD8XH1PO39zvQxQ42Go0t+4OE6qNV68MPsZK4J7tqoRqtaz7IPD9FQrOGA/xrygzL5dMwbxLhHd+m8XYmhqgr1pk2oNmykZe9eMBqxcnfHYdhQHK+7Dtu+F95+wajXk7p+NbuW/IBRr6P3uEn0m3oTSttzR7x0ZjPzVm/krcfmYnRyxV5mhU1LM00FecTHxiKzsiI3N5fW1lYUCgX29vYMGzaMTz/9FMXfKjue5mfqakufuLIDFiFXfuhEw2/AvScEpUDwYMuz3YWtSxMEAVVdDdVFhdTkZ1GVk0ZRVg4mM/jYthCXHEfIiLtR/bqSxp9/QdDrcRg9Gvd77sY6+sr1GREL4j1TpKsRfUykO7hShdsO4HngXWACcCcgFQThuXb2iwe+BawAKfCLIAgvnW8fUbiJ/JtZv3032T+qaXKp5P6nx+Pm4NL2Xmf7mKnFwIFfvuOhEitaDI7MmxrPpF5dW9nPZDCzcVEWuXuryHNJY3P499wadxsP974fhdWVXRrepFKh3rYN9caNqLduw9zSgiIkBJebb8Zp8iSsLjAHvqWxge0/fUvGlg3YObsw+JY7iRo09JzRPLPZzGNPPsmydetp1BtoMRiRuHkgc3DErr4Gdd4xrBVyBJMJk8kEwJAhQ7jnnnuIj4/H39+fQ4cOsXLlSiZMmHBmRA4sUbnKo1C4DQq3Q8lu0Kst73nGWERc5DhLVM6q/Qqcf0fT3ETWnz9xdMOf1KvMyKUmIiP9iB51K/KdB2j8aTHmlhbsBg3C7Z67sU1OFitRXqGI90yRrkb0MZHu4EoVbgcFQUiSSCRpgiDEnfpaZxspCjeRfzur1m6naJmOeq8SHnlqOk42jkDX+JhgNLN76Xf8t6CVouYAhvd04LXpffBytG5/54udUxA4vK6E3cvyqbSuYV3MB7i6uPPW0FeJcY/psnm7E7NOR/Pq1TT8+BPao0eR2triOGkirjffjDI8/ILGqsjLYdM3n1OZdwyfnpGMuPM+vELCzj7vKamUvoFBaEMj2FjTyPfvvEnFbz+DIGAlAZlEglmnJSQhkQlTpmGtamTH9u2UlJSg1Wrx8vJixIgRZ+8RdyomAxw/AoVboWg7lOwBoxZsXC0CLmoihAwFmfKCjlkQBI7v+YO03xaQU6rFKFjh7mqLZ49ArBu0SA+lY1Nbh1tkNJ733oP90HMLWpHLE/GeKdLViD4m0h1cqcJtFzAIWApsAsqB+YIgRHS2kaJwE7ka+O23zVSsE6jpkcvjj92KndKuy3xMEASK163kk+K1LCsaiVKu4H/XxXJjco8ujWYUHKlh7YIM1GYd24OWUuS5j7ti72JO4pUffTuV1rQ0Gn74keY//0TQ67FNTsbllptxuPbaDvWFA0shk4ytG9n+07dompuI6J9C7NBrCYhLQCq1anf/ffv2Mev++zHa2FPT2IBapULf2IDt9Fuwv/VuyM5A9e4rSE1GDDXVyAQBpULOAw88wJw5c/D29m4Thfn5+YSGhp49IqdvgbyNkLUCjq0FXTMoHKDnKIiaAGEjQXlhkUdd/m6yF7/Jsbxq6vQ2tBhPEYGCgK3eiIMEfMJCiBl2Ha7Rsch9fcXm3pc54j1TpKsRfUykO7hShVsykAU4Ay8DjsCb52ukfbGIwk3kamHxog3U7ZBSGZbJ04/cxb6d+7rUx2r37mdz8YssKBxJdkMY/UPcmD8tjkA3u66bs0zNum8yaChvId++hF09v8LNzZXXh7xKrHvX9Jn7pzA2NND06680/LQYQ3k5itBQPP7ziEXAdVAg6zQt7PntZ9I2rUXX0oK9iytRKcOIHjwc9x7nLjBzth5xKUOHcdNTz5CnN/Hrz4vZ9MUntGq1GBobkQASnRZnV1c8HR0IDg6mpaWF2tpaFAoFVlZWDBs27PwROaPOklKZtQKy/wBNnUXE9b4N+twDrhdYaKSpDGqPoTueTUNxDg3lpdRX11FdYaBOY0uTQokE8GpqIai2CQ87exQ9AlD4+yP380cRHIQyNBRFSAhS666LKIt0DPGeKdLViD4m0h1cccLtRB+21wVBeKwrjTuJKNxErhYEQeD7L9ejOiSjIjaVITGxjBw2skvnbM4sJD3zIdZonFmaewNm5PzfyAjuGhSMlbRrom9mk5kjG0vZ/XsBOrORPQF/kO2zhTtj72BOrzkorS4sze5yRzCZUG3YSM1776EvLMQmIQGP/3sUuz59OjyGUa+n4NA+MrZupPDIQQSzGc/gUGIGDydy4BBsnZzP2OfvFSlPjZjt37+fOXPm4O7uTl75cRpatTRUVyENCMHa3g5FXQ3qkiJkVla4uLjg5+eHWq3mgw8+YPjw4e0LT5PRsh7u0HeQ8ZtlrVzEOOh3v6UR+KVEdk1GhMZi6nf+yZHNW8is0KAXrHA2tRLaosK7QY/QpLe0KACQSpH38EcZGoYyLAxlWCjKnj1RRkSI6+W6EfGeKdLViD4m0h1cUcJNIpHIBEEwSiSSPYIg9OtyCxGFm8jVhWAW+OaDtbRmK8iN2Mb8h57CWta10QJtaT3pOx6nyOkwvxx7gH2V3iQHufDl7dfgbNt16WeN1RrWLsyktqCZcptqtkd8iZOnLfNSXiHBI6HL5v2nEIxGGpcto/ajjzFWVWE3ZDCejz6KdcSFZZhrmhrJ3rmVjG2bqC7MR2plhU94JIHxiQTG9cI7NByp1fnTKU+NyDU3N+Po6EjK0KEET7uJRVt3kLpsKYb0I8gUCtzc3XGUSmhubmbgwIF4e3vj6OiIu7s7giAwYMAA+vbte+5IXHMF7P8KDn5jicJ5xVkEXOw0kF+6bxu0rWSt+5XDa/+ktrYZaysj8U7H8UCD0eCA0eSMUavE0GjAWNeExGRCKgh4BAXjNftuHEaPRtLO+RK5dMR7pkhXI/qYSHdwpQm3Q4Ig9JZIJJ8CfsASoOXk+4Ig/NbZRorCTeRqw2Q0s+CtteiL5BRF7eOJ2bPxtPNsf8dLwFCrIefP+VT6/siRmol8kXEtga52fDerDz5ONl02ryAIZO6qYMvPxzDqjRz228IR/z+5Pe5W5iTO6XLR+k9g1mppWLSI2i++xKxS4ThhPB4PP4zC37/9nf9GbUkRWTu3UpR6iOqiAhAElLZ29IiJJzAukcD4RJy9fc8aWToZkTtbVckV23dy37330ihIMDk6YSOzwqGxnueeeIw/ly9nx44dqFQqZDIZtra2DB8+nK+++gr781XSNLRC2hLY8ylUZ4KdB8TfCDFTwC/p0qJwWHypLDONQ6tXkH9gL+2l/FuZBdxUGnxkCiKn3YTvzTcjVf67or2XE+I9U6SrEX1MpDu4UoXbN6e8LAASQBAE4a7ONlIUbiJXIwa9ic9eW4G0wolC38PMvG8MsZ5dW4HR1GKg4NevKfV5j7ymBD5Iux1HayXfzepDmKdDl87d0qRj1cIMarMaaVA0syf4ZySBal4e9DKJnoldOvc/hampibovv6T++0UIOh3W0dHYDRqE3aCB2CYmXnCxDU1zEyXpqZSkHaE47QjNNdUAOHv50Pu6ScQNG4XsLGOe7Vp2akSuXm+gzmjGGJ+E/6w5mF98jOq0VJRKJWazGb1ej8FgIDk5mTvuuINJkybh7u5+bkMFwVKVcu8XkLsOzAZw6gHRkyB6sqXp9yWKOHV9HeqGegTBjGAWEPQahLp8qM1FqMlFV51P8XE1+Y2uqATLjwOOOj2Bfp5E33w7vv1HdKgIjEjHEe+ZIl2N6GMi3cGVJtzKgHc4IdROPJ9EEAThnc42UhRuIlcrmzdvRlNlT9EWFced8ki5M5gxkV275k0wmCj99Q8KHV6m0ODEB0f/gxkFX89MpneAS/sDXCI5h6r5c1EmCo2ZcscCdgUtZXzytTzY68F/ZfQNwFBZSdOyZah37KT1yBEwmZDa2mLbrx92gwZiP2gQioCACxpTEAQaqyooPnqErO2bOX4sCzsXV5InTCP+2tHIlX+dy3Ndy05dIxccHIwhLJIvy2tZvngxLYu+xEmpxKpFBUYjra2teHh4IJPJcHFxYcaMGQQGBtLa2kpYWNjZK1ICtDZCzmrIXA75m8CkB0d/i4iLmdIpIu6ctDYilO6j7uhmcrYeIq/MQJ3cBkEiQSmY8HFWEJgQR+DwKbhH9BLbD1wi4j1TpKsRfUykO7jShFsF8CmnC7aTCO01074YROEmcrVy0scObMtl9+IimhW1uE1p5d7Bd3ZpUQXBLFC34QjHmp+hxLqWD1KfokFryye39mZYRNembAKYTGZ+/CGD6t1VKAUJ2Z57qIg+yrPDn/7XRt9OYlKpaNmzh5YdO2nZsQNDeTkAisBA7IcOxX7YUGx7976gaJwgCJRmpLHn158ozUzD1smZpOsmkzhqHAob2wu+li3bvoM5cx6g0d4JMwJmVTNUVuAUEIidgwNWgoDS2oba7AxkgoCdUkH//v2ZP38+3t7eWJ1rPZm2ySLiMpb9JeJcgiDuBktKpfvZe9l1GiYjjRuWkvndD5TWNFNna02rUg6AQjDh42RNQEI8QaOuxyMsWhRyF4h4zxTpakQfE+kOrjThdkgQhN5dbtkpiMJN5GrlVB8rzqnh908OYjAaaByawTNT/tPlEaiWtEqyjzxPsftePjzyf5Sq3Hjr+gQm9/Lr0nlPklPSyJefHSGg3ohZauSw33pih/sw55r7sZN3XcuCywVBENAXFdGyYyfqbdvQ7NmDYDAgtbfHbuBAi5AbnILMza3DY5ZlZ7Dn18UUHz2Mtb0DSeMm0WLvwojRozs8xsk0yvUbN9Go12NAgmef/njcdAfHdu2gtqgQ7a6tSFzcLD8w6LSY8nPwGzuRmIGDiHF3I97NmV5+3gQGBODgcJY0XG2TpaXA0V8saZWC2bIOLv5GiJkK9h4dtvdiMOt0aFNTqV63jNLUQ1Q0a6mzsUZzQsgpzSb8zDoClODjaIvC2RmpsxtWrh5YufsgC++FPDAMK0fHLrXzSkK8Z4p0NaKPiXQHV5pwOywIQq8ut+wUROEmcrXydx9rrNbw47vbMDZaURC/k2fueAAP2679AmuobCH3z48o8F3EJ0fvI7M+iP9dF8XslJAunfckOqOJN5dmULPzOD0NClSKBnKCdzBqZF+mR09DLpV3ix2XA+aWFlr27EG9ZQvqLVsx1tSARIJNfDyOEyfgNGkSVucrDnIKFXk57Pl1MQWH9mOltGbQDbeQOHo8MnnHzuf5Wg0s+vEn5r/xBs7e3mhMZiqOH6e2uBCZbw/M7p7IwyOR9+qDTCLBuSCHZHtrpvaOJzgoiICAANzd3U+PKDdXQPpSOPozVKaBxArCRlhSKQP6W6JyXVzWXzCZ0GWmUb36F0oOHaJMa6BKrsQolSIzmfBo1uDd1IKHSoPM/Nf9U6q0Qu7uhNzXF3lQT2QBQSiCgrDr37/Dn9W/BfGeKdLViD4m0h1cacLNVRCE+i637BRE4SZytXI2H9O1Gvnpg620FEo4FryL/z54N152Xl1qh1ljoOTX5eS6vsHnOVM5UB3PjD49eOa6aOyVsi6d+yQbMqt454ejXKMy4KW3Rq1ooCTkMBOuG8zosJFXXT8uQRDQZmai3rIF1YaN6LKykNja4jR+PC4zbsI6KqpD41QV5LHik/doLi3C0cOLQTfeSuTAIZeUBniyR5ynpydSqZSamhoKCgqIiIjA3skJlcHEsZwsmhsaMSoUoLTBIbE3w8dPJKKmHAeZFSaTCaPRSFxcHEOHDsXFxcUiDKsyIe0XOLoEmsssE9p7QY8+0KMfBPQD73iQdV0bi5MY9XpK0lPJ3beb/P27aVWrkFpJ8fdyI8TajJ+qHCqPY2jQYGiRYdBYYdafOK9WEuwi/bDv1wv74SNQRF4Dtq5dLkD/ScR7pkhXI/qYSHdwRQm3fwJRuIlcrZyzaITJzLKv91B5UEtOxDaev+8h3Gw6ni53MQgmgZo1+8nR/o8fa6JZU3Qt/i62vHV9An1Dunbuk1Q2afnvb0fJT69liNmEV6sdGnkz1eFZXD95JH0CzriWXTW0pqXR8NNimv/4A0GnwyYhAecZN+E4dmy7Je63bNlCsKsz2374huqifDyDQhl8y50ExidelC2nVqQ0m81IpVKGDx/O3XffzcaNG/n111/Zv38/CoUCiURCq8mMQaHE9tnXcegZifVnb9G0ZyeCQY9UKiU4OJjRo0fj6emJu7s7Hh4euLu50kOhwrEpC0r3QskeaCy2GCCzBt/e4NsLvKLBMxo8IkFhe1HH07FjNnE8O4vc/bvJ3bcLVW0NMoWS0KQ+RPW5hiB3sKpJx1R0GF1mBursOlSlUvTNJ1IvnQzY9zDhEOmKdWwMkpAUS6Nyj8h/jZgT75kiXY3oYyLdgSjc2kEUbiJXK+fzMcEssPjjHdRnGMiM38Crs57ESenU5TapDpWSnfUMB60rWJh5L1UaG+4aGMzjoyOwlndP+fStx2p4eVUm2uNqrpUa8Gh2pFWmRh1ZzE3TxxDpHd4tdlyOmJqaaFq+nIafFqMvKsLKyQnHiROxiYtFGRaGIiQEqfXpayNP+plgNpO9cys7fv6e5ppqghJ6k3LzTDyDLjwt9ryplIsW8dJLLyGRSFCr1RiNRpydnbnzqf9y0NaF359/GpNWi1zVhL2tHUrMPHD//QQEBFBTU0NTU1PbPAEBASQmJhITE4NS33BCxO21PFelg1F7YksJuIacEHIx4B0HYdd2SgPwvyOYzZQfyyJ7x1Zy9uxAq2rG2t6Bnv0GEjVoKH4R0ZYIsbYRffo+VJs2ot51CE3ucTALyOzAKVCFc7AGhZczBA60iLigQeARBVdoURTxninS1Yg+JtIdiMKtHUThJnK10p6PmQxmFr2zjeZCA9l9NvD6rc9ir+j6dTO6kmayt7xEmfcfrMy/hzXFPQn1sOPtGxJJ7OHc5fMDGExmFu0p5t31x3DU6Bkl1+FW50qrTI3DSDWzJ9yI1VXch0sQBDR799Lw02JUmzaBwWB5QypF3sMfZVg4yrAwlOHhpBr0DJ4ypW1fo8HAkbWr2Pvbz2g1LXgEBOERGHzaw9bx4n8k+HsqZUtLC01NTXz22Wfk5+fz6uuvU1ZTi0qjwSQAeh2OAYH0GZTC9GFDGdE3mZycHPbt24darcbOzg6FQkF0dDSJiYkEBgZaRKLZBPWFUJ1hSbE8+VxfAAiWBuB97oXkWZY0xS7AZDRYWjLs2ELegT0YdTqsHRyxd3HFxsHR8nB0wsbBEWuZHElZGdIjqcj3HEBqNmMT5IRzoAoH93Ks5ALYuIBPInjHglec5dm9J1hd/ms9xXumSFcj+phIdyAKt3YQhZvI1UpHfEyvNfL9/G2oq/UcG7iBt258GRuZTZfbZmrScWzFBxz3+YK8hiF8k3sDNWojc4aG8tDwcBSy7okK1LfoeXf9MX7YW0yQzMhIrQFHlSvVAbnMvHsMwR6B3WLH5YxgMKAvLkaXl4cuN+/Ecy764mIwmRDkcrweeRjXmTORyP5as6hVqzm8diXHj2VTU1xIS8Nfy5vtXVzxCAzGPTAYJw8vHD08cXT3xNHD47QecWfjXKmU8+fP5+DBg8yZMweFQoFKpaKqro4mlQplcDhaW3sEQUBWXoSVRoOXuxvODg4kJyczevRoMjMz0ev1ODs7k5iYSHR0NB4eHmeuf9RroHQP7PnU0gBcbgu9boV+c8A1uFPP/WnTalvJ37+H0sw0WlXNaJqbaVVZHlq1ytKY/AQyhQJ3O0ecKmtwLKvAxSzglhSOY08rZNoihNoizHojZqMEwSzHbOuL2dYHqVsQDjPuxapHTJcdx8Ui3jNFuhrRx0S6A1G4tYMo3ESuVjrqY5pmPYte246qWUPx8G28NXkeCquuL85g1psoXvEThY6voTO6s7rhZVakqYj2ceSL25Pwd+m6NUV/J6dSxUurMtidW8s462YiqjxpsW4kaLKCG4dMuOqKl3QEs16PPj+frBdexDo1FWV0FD4vv4xNzNm/9Guam6gpKqSmuICa4kKqiwupLy/FbDKdtp2Ng2ObkPMO60nCyLEobU9v33CuVMqzibpevXoxaNAg1u3YxZ7UIxRnZWGykiEPCcPR1ga75iY+/eQTUhLiKCws5ODBg+zatYuGhgZ8fX0ZNGgQoaGhBAUF4erqerovVGfBro8sFSsFE0RNhAEPg39Sp5/v82E2mdC2qGltbqKmpIjjOVmUZ2dSU1yIIJiRAA46Ay4qDU4aLU4aHfY6w1kbqkrlZlx72eIy7Tpk10wBn16XRXqleM8U6WpEHxPpDkTh1g6icBO5WrkQH2uqaeXH+TtpNjRROWovb4yb1y2l8gWzQOXGjeQYn0CQGaizfp+XNhqwVcj4blYfenqdpUdXV9kiCPyRVsFLKzNRqOqZ0KrAVmdPQ1Qu9901HU+Hrm2dcKWyZcsWeuv1VL78Mqa6elxnzsTjoQeR2rQfuTWbTajr62murUZVU01zbQ3NNdU011bTVFNNw/EyrO3sSbpuMr3GTkRp276YP9/6uI8//pi33noLqUKBbY9AKnUGGqsqsb3hDpyO7CU+OBCrinKK83LRarUYjUb8/f0ZMmQIEokER0dHgoODCQ4Oxs/PDzc3N8vYzRWw73PY/zXomixFQaydLWvgZKc+lCC3Abcw6DkanAMu9fSfF32rhuO5OZRnZ1KelU7FsWyMRkvaq0wux8PbD88egXgFheIVFo59XQl1n32C+lABEpkZl1ANrkl2yHuPhYjrIDjFcgz/AOI9U6SrEX1MpDsQhVs7iMJN5GrlQn2splTFkjf3UmdVTcvYDOZd+1K3rfNqOJRKetlD6G0rkdnN4/FNLuiMZr6emUxSoEu32HASldbAO+uP8dPOAkYJTUQ0+VJvf5w+t/gxutewbrXlSuCkn5mam6l+8y0alyxB3qMHPi++gN2AAZc0dlVBHrt//Yn8A3stAm78FHqNmdAhAXc2/r4+zmw2U1JRSfztd7F66VJUTU2YCnNRKJU4Ojnj4OSIxGDg+flvEOrpTllRIUVFRWg0GgAUCgW+vr5/PdwdcSlciaRgKxhbwaC1FDgx6iz/G3VgaAVds8Ugz2iLgAsfDf7JYNW17THMZhP15WVUFeRRmZ9LVWEeNYUFGA16y/HY2OLbMxIvdy9sU1NRbNmJDAGnEC1uEY0o3Oyg5xiInniiOEvXp1WfRLxninQ1oo+JdAeicGsHUbiJXK1cjI+V5zSw/INDVNoUoRqVwbxhL2Mnt2t/x06gpaico4fvQ+OUiYz7ef5gElXNOj65tTfDIjy7xYZTSS9v4n/L09GUlDC6xQGZSUZLYjGzb54qRt9O4e9+1rJvH5XPPoe+uBinyZNxue1WlOHhSBUXn35bVZDHrqU/UnBwH9b2Dlwzfgq9xoxHYXNhAu5c6+MefvhhVq9ezWffLCQjLQ2TXG4pbAIIeh3yyBish44iYMoN+ClkSLPSkRXn08PJgRA7a1orjmM6kfJpbW2Nj48Pnp6ebQ8PDw+sT1bjFASoy4Nja+HYGijZDWajJUIXPtIijHqOAWX3NNg2m0zUlZdSlZ9LRV4Ox3OyqC21tEaQSqW4KGxwLK/ARd1KD18b3JyOY+dWj8LF2mJv9ESL8Oxie8V7pkhXI/qYSHcgCrd2EIWbyNXKxfpY/uFq1nyeRoVjAdl9NvDu6Lfo4dCj8w08C/oGFWmb5tLoshl0I3j72C0cq2rhresTmNzLr1tsOBWzWeCn/SW8vyqdFE0jIS0+NFvX4nOtFbeMnYj8CqjG19Wczc/MOh21n3xK3YIFYDSCXI4yPAzr6GhsYmKwjo5GGRFxRmuB9qjMz2X30h8pOLQfa3sHYoeNJKJ/Cl4hYR1eh3i+VMo9e/Ywa9YsBEGgqbkZrU6PTq/DPyIKz5hYrnn8f6x+81VK9+xCZzAgAMpr+hP6wKNEWsvoYdDi3FCHXWUprZUVGE5W4wScnJzw8PDA09OToKAgQkNDsbKyAm0T5G+CY+ssxU40taCwh9ip0Ot28L+m23uxtapVVBzLpjw7g/KcLCrzcjAZjUgFAa9GNT3qVXhbS3DwUGPn3oCtrwSryBGWRuYeEZZKlS5B0IkRe/GeKdLViD4m0h2Iwq0dROEmcrVyKT6Wu7+Kdd9kUG97nC3x3/PqyJfo69O3cw08B2a9kWOr36bc/kvM2jC+KH6S/SUanp8QzZ0Du65q3/moVet49c8sDh/MYoROjovWlQa3MobeGMWg+OR/xKbLhfP5maGyktbDh9FmZqLNyESbmYmpsdHyppUVyvBwHMeMwWniBOS+vh2eszLvGHuW/ULh4f2YTSacvXzo2X8QEf1T8AgMvuhiMn+PyBkMBkJCQoiOjiY2NpaePXu2pVrWNzaSfewYRkEg6oZbMA0eSZmbN8a8HEzHS4kJC2NCcm+uEXQo62uprq6murqa2tpaTCYTtra2xMbGEh8fj5+fn8Vms9nSQ+7wIsj4DQwaS++13rdB/E1g1z3N6v+O0WCgKj+XnN3bydy6EV2rBjupFX7VDfhV12NjMmPrJWDrqsLWQ4eNmwGptdyyls+954lHODj4gL0X2HuCtdMFCVLxninS1Yg+JtIdiMKtHUThJnK1cqk+VpRWy+ov0lDJ6/k96kPmDLqbmyNv7pYKi4IgUL51Obm65zCYlfxY8gpbCk08OCyM/xvV8x+r8rinoI7/LTuKY20hA1WeKI3WaMIquPn2a/H39PlHbPqnuRA/EwQBY0WFRchlZtKybx+tBw6CRIJtnz44TZqEw6hRWNl3LD23Va0ib/9ucnZtpyQ9FcFsxsXHj4gBKUT0T8G9x4W3czhfRG7x4sW88cYb+Pn5UVhYSE1NDVqtlrCwMHx8fMjLL6BB1YxZoUSntMaUkIz93Q/T096Gse5OjPFwItZGQWFBAampqeTk5GAymXBzcyM+Pp74+HhcXE6s6dQ2W8Tboe+h/ABI5RB5HcRNtwgiRz+wdrzg47tUjHo9eft3k7Z5PSVpRwDwdXLFv64ZRWExmM1IJKD0csDGU4a1YzM21pUoFEZsZQbkUrNlIJm1RcDZe1kedu6WPnPWzpZnG+fT/t52MIvBI0Z3+/GKXD2I38tEugNRuLWDKNxErlY6w8eO5zWy6uNUNKj4NeJdhscP4pm+z3RLuwCAhoxU0gsfpFVZzfLCl/mzwI4ZfQJ4eVIMMqt/pkS53mhmwY5CPtuQQR9TJXGNQZikRhz76rn1pnEoL2Et15XIpfqZvqyMphUraPr9dwzFJUisrXEYORKnyZOw69cPiVXH0u00zU3k7dtNzu5tlGakIwhmfHpGkjhyHD37DULWCZ/LqcVNdDod9fX1lJeX07NnTwDS0tJQKBRIJBIkEglyGxvu+PBzsv1C2N2kxmgy41R4jJ5NdQyJieSm/snU5OeRmppKcbFlXVmPHj3aqlb6+vri4OBgafx9+HtIXQytf/XDQ+kETv7g5Hfi2R98e0HwkE5NUzwXTdWVpG/ZQPrm9ajr6zq0j0JmhZ29NfY2EuzkJuystNihxltRSw9ZBZgN595ZbmcReHYeJx4n/nb0hbAR4BrSSUcmcjUifi8T6Q5E4dYOonATuVrpLB+rLVOx4v0jaAyt/Br+Lv7B7rw77F3cbdwv3cgO0FpVzdFdD6ByPMTa/LksKQjm2igvPpzRCxtF91S9PBtlDRpeXJnJgexsRpp0BDYF0+xYzYDbAhkS1/8fs6u76Sw/EwSB1iNHaPr9d5r/XI25uRmZpyeO112H08QJKCMjOxxpbWlsIHvnVlLXr6ahohxrB0dih15LwrVjcfa++MjouYqbPPnkk7z99tssXLgQQRAwmy1RJTs7O1577TVuvPFG6nR6ZtxzHwf37kFtFjBLpCh6JdN37hOkuDmRJJdgXZxPQWYGVVVVnLyPOjo6tok4P28P/CQ1KFuroKkMmsstz02l0FT+l6iz94b46y3pld6xF328HT8vJsqzMtCq1QgICGYBEDDrDehLS9AVFNCam4uqtASdVILO3g6jizNahYxWbStGvaWqZUBcIoOn34CXjyu0NkBr44nnBgrS9xPi5QgtNScetZZnTa2luAuAdzxET4KYKeAW2uXHLfLvQvxeJtIdiMKtHUThJnK10pk+1lilYcX7R1CrW/kz4nO0nvV8PfprAhy7tg/VSUytOjLWPkuN469sL5zOt7mDSQxwZsEdybja/bMRrg2ZVTy/Mh07VR6jG/2wMlvR0Dub2TdMp4dj9xR1+SfpimuZWadDvXkzTStXod62DQwGFGGhOE2YiNP465D7daxQjSAIlKSnkrruT/IO7EEQBIISepM4ahzBva5BehFRqXOlUp6Mxrm7u6NWq6mvr0cul/Pll1+SnJzM/v37mTJlCnq9Hjs7O2R2dqi0eiL/+xIFIVHoBQErwUxoeSH+dVVc4+9DkrcnNZUVlJeX09DQAFgqPQYFBREdHU1kZCT29qdUc9SpIW+DpSF47jqLoPGKhfgbIe56cPxn03lNzc2ot21HtXEDLdu2Y25pAVtblAP6c9zbndS8TLStGiIHDmHgjbfh7OXdtu85/cxshqYSyFoFmcuhbL/lda+4EyJusmV9nYhIO4jfy0S6A1G4tYMo3ESuVjrbx9QNOla8f5imWg1bIn+gyaecb8d8i5edV6fNcT4Es0DRpoUUGz5gX2MQX6bdiZ+zDd/PHkgP14vr69VZtOpNfL4tnx+2HGN4i4aAVneKXNPoMV7G7OQ7sZX/s/Z1JV19LTM2NKBau5amFStpPXQIAJtrknCaMBGHa0cgc+tYwQ5VfS1pG9eStnEt6oZ6bJ2c8Y+Oo0d0HD2iY3H163FJayfPFY2bP38+UqmU77//noceegil8q8G1lqtlp49e5IyZCi2oeH8uXETeRnptJpMIJFi17sPE558hiHuTvSxkWFTX0tRURFZWVnU11uia4GBgURFRREVFYWTk9NfBrXUWdbIpS62rJGTSC0plIk3Q9SEbu3BdjbMej2avXtRbdyIeuMmjDU1GKRSCjydKfRwRpBKCHf1JClpAE4xMRysrCJl8qT2P6OmMshcYRFxpXstr3nGWARc9GTw6NnFRyZypSJ+LxPpDkTh1g6icBO5WukKH2tV61n1YSrVpSq2RH6PIaCBhWMW4mzt3KnznA9NYSV5O95jlzKND47egVImZ8EdifQO/mcqTp5KrVrHRxtzydqez8AWW1rlKg5Fr+K2UVO5Lvi6f6yoSlfSndcyfVkZzatW0bRiJfqCAgCUUVHYDxyA3YAB2CQlIT1FGJ0Nk9FI/sG95O7dRVlWetvaLFsnZ/wjY/CPjqVHdBxu/gFIpBe2jvJ8hU327dvHrFmzsLKyQqVSoVar0el0xMXF4ezsTGNjI2lpaRYB5upGnU5PaWUl7o8+Q21wBADeCjlDXB24zt2JKGMredlZZGVlUV1dDYCfnx+BgYE4Ojri4ODw10NfhSzjVzi6GBpLQOloaTeQeOs/0m7g7whmM4bjFegL8tHl5dNwLJujhccoEvRYmQWCqxsJqmtCqbRGERx84hGEMjgYRUgIisBApDZnEaLNx/8ScSV7AMHS9Dx6skXIeUR074GKXNaI38tEugNRuLWDKNxErla6ysf0WiMr3j9CdUkzqyO/wD5Ywlejv+q2Rt0AZr2JurWH2VX+Ey9VJtJisOPF0dVMG3ALMplDt9lxLkrqNHz0WwYOR2pxMSk44rsRba8yXhj0HGEuYf+0eZ3KP3EtEwQBXVYW6m3badm5E82RI2AwIFEqsb3mGuwGDsRuQH+UYWFIZLLzjtNYVUFZZjplmWmUZqajqqsBwMbBkR4x8QTExtMjJgEXH99OjcgBxMTEkJKSQlpaGjt37iQ/P5/+/fsjl1v6A5aXlzNjxgwm3X0v+zUGtjWo2FKvoslowlEmZZSbExM9nYk168nPySYrK4uqqqq2ZuCnYmtri6ODPUlurcQYjmBTuB6JsRXcIyxRuISbwMH7jP3+SerKStj+7VfkH7VEWr3sHPE2CrhX1KAsO25pZg4glWITH4/doEHYDRyATVzcmZ97cwVkrYCM5Zam5wiWVgsxky0FXWxcwdYVbN0uuFWByL8D8XuZSHcgCrd2EIWbyNVKV/qYtsXA8ncOU1+t5veID/EPd+WTaz9BaXX+aEen25HXSMby7TyqbqJM58isuN+5a/gkvL0ndqsd5yK1sJ5fv07Hq8ZInU0Fab5bGTwkgXuT7u62ypxdzeVwLTO3tNCyfz8tu3bRsnMX+vx8ACRKJcrwcJSREVhHRGIdGYEyMhIrh7OLe0EQaK6pojQzndKMo5Skp7ZF5Oxd3SxCLiaegNgEHD08L9zO80TkNm/ezAMPPEBwcDBSqRSz2czx48dxcnLCx8eHESNG4OfnR11DA00ePhzzDWZtvYpGowkHKymj3Z2Y4OnMEBd7zDodzc3NqFSq0x719fUUFRVhNpvxdrFjqEcDoc27kVceAomVpYG2VAZG7YmH7vRnl2AY8JAlYmV1bkHc2VQV5rPhlx8x1lZRW1IEgKuPH4Eh4fg7ueJY30Trnj1oj6aBICB1cMCuX78TQm4gCv+/rYk8m4g7FanM0obA1s3SsiDsWoiZCs7//jWrVzOXw7VM5N+PKNzaQRRuIlcrXe1jmmY9y94+RFNDC0sj3iYmKpR3h76LTNp9X+gAzFojZSvyeCQ1m8MmOaMDN/LQcD9ies5FIvlnWgb8nT9X55O2pgh7nQSdlYZS72ymTRrKoPgzrp9XHJfjtcxQWYlm7160Wdloc7LRZedgOlHcA0Du54d1XBz2KYOwG5SC3OvsIkwQBBorj1OSfpSSjKOUZhyltbkJAGcvHwLiEgiMS6RHTDw2DpfWU+1sa+QCAgLQn6i4mJWVRV1dHTY2Njg4ODBq1Cjeeu89djVpWFnTyOqaJhpPROLGezgzzcuF/s72SP8WOdJoNGRlZZGWlkZRUREAEe5WDLIvxkebh0xpCzKlpc/aqc9WSijYDLXHwDnQIuASbwFF96zfPOlnTdVV5B/cR/7BvZRlpmM2GbFxcCQsuR9hcb1wbWymdfce1Dt2YqyoAEARGIhdSgr2g1OwTU4+Pa1SXWNJH9XUWapyaupOedRDQxFUHrVs26MvxE6zCFeH7lnbK9J9XI7XMpF/H6JwawdRuIlcrXSHj6nqtSx76xBqjYbFEfMZFNuHVwa9gvQfEExNmbU899Nhfjfocbeu4/6+edwx8klksu5L4TwfZrOZlRsK2bkxDf9mW6wEGS1ujYwe15uYPj2Qyf+51gaXwpVwLRMEAWN1DbrsLLTZOehystEcPISxqgo4sU7uxBd7m8TEc6ZXCoJAXWkxJempFKenUpaZhr61FSQSvIJDCYhNICAuEb+IKORK6wu28+8RuYSEBA4cOMAXX3zB8uXL23rECYKAXq/n2muvZfr06dx0003ojCYWbN7G70fTSbd3wxgWiZ+NksmeLkz3diHa/sw1YM3NzWRkZJCenk55eTkAXl5ehIeHEx4ejr+/P1an9tEzm+HYatjxHpTts0Sk+t4HybMtaYZdyNn8TKdpoSj1EHn795B/cB8GbSvW9g6EJfenZ7+BeNk5ot29G/XOnWj27kPQapEoFNgmJ2OXMgj7wYNRBAe3nwJbXwDpv0HGMqhKtxR6CRpkEXFhIy295GT/jgj61cyVcC0TufIRhVs7iMJN5Gqlu3yssVrDsrcOoTFq+DHiVcYnjuapPk/9I4U4TE061n1+iFdVZZQabOnrm88bN00k0DOo2205FyazwM87c1i7cS09G71x1nqAUuCaEcH0GhmAwqZ7I5aXypV6LRMEAd2xY6i3baNl23Y0hw+D0WhJsxswAMfRo7AfMeK8xU5MRiOV+bmUpB+hJC2V48eyMZuMSCRSnL29cfMPwM0/EDf/Hrj5B+Dq639RjcAXL17MK6+8gkQioaGhAYPBgFarJSwsjJtuuon/+7//46mnnmLz5s1oNBoMRiMBSck43/0wuwUZJomUCBsF11SXYFVRTmhoKL2TknBQyHCwssLeSoq+uYlj2dnk5uZSUlKC2WzG2tqa0NBQwsPDCQsL+6v1gCBYUgx3vGtpOyC3g6Q7wC8JFHYgtwWFvSUad/Jvpb0lcneRtOdnRr2eotRDHNuzg/yDe9G3nhRx/QhL7odPUCjmrBxatm9HvWNHWzqt3NcXZXQUci9vZN5eyL19kHt7IfP2RublhfTvn1d1NqT/annU5//1utwObJzB2tmSZnnyb5cgSy89r1hLg3Rx7dxly5V6LRO5shCFWzuIwk3kaqU7fazuuJrlbx9GI1HzQ8953HzNDTzU66F/RLyZdUYqF2XxRXkqP2jtsZKYeXiYB/cOH4SV9PL50qQ3mnl32wa2HFlCdG00IfUJCEqBfteF0mtYAFbyyyPNsz3+Ldcyk0pFy67dqLdbhJyxuhqpkxNO48fjPG0q1tHR7Y5h0Gopy87g+LEs6spKqCstoaHyOMKJYiQnBV1QYhLXjJ+Ko7tHh2w72SPO09MTqVSKSqWitLSUAQMGMGvWLOzs7NreLy8v5/jx4+j1euLi4rB3dkFla096Rgaq6iqQy5HY2qNM6ov93Q+fVjnTSWZFgoMNCbZKvNWNKEsLqTiWQ0tLC2CJxvn7++Pn54efnx8eHh5Ia7Jg5/uQthSEM4ui/IUE3HuCbyL4JIJPAvjEg7JjxYQuxM+Mej1FRw9bRNyBvehbNSCR4N4jEP+oGPwiY/B0ckOSlk7Lzh3oi4owVFZhVqnOGEvm6YnzTTfievsdWNmfEr0XBKg4AmUHLI3CtY1/NQ3XNp5oHl4Pqoq/9rF2Bu84y8Mr1vLsESlG6y4T/i3XMpHLG1G4tYMo3ESuVrrbx6qLm1n+7mFaFSoW9ZzH9PjJPJ78+D+SNimYzDQsyyMj4zBv2FSRVh9KhKfAmzcMIt7fudvtOR/NrVoeX/8hucV76Vs2Av+mCHTWOhLGhjB8ZE8kl5HYPBv/xmuZYDaj2bOHxl9/Q7V+PYJejzIyEuepU3GcMB6Zi0uHxzIZDTQcL6e2rIS6slJqigspPLwfkBAzZDh9Jl2Ps/f5G2O31yNu8eLFvPHGG/j5+ZGfn09dXV1bRM7X17et1YBMoUAAlLa2OLi4MPu1t/CNT6TZYCD78BEKCvKpcvOi1D8E4YSgC7ZRECWX4K1qxOV4CcbiAnQ6HQByuRxfX1/8/PwI8HDA28EKJxsZEn0LGDRw6rOmDiqOQkUqqI6fODIJuIVahJxvoqW6o0/CWcXcxfqZUa+nIjebsuwMyrMzOZ6ThUGnBcDJyxv/yBg8AoNx8vTGwcEJWwEk9fUYK6swVFWiTT2KeutWrFxccLv3HlxmzGi35cRp6FRQlQlV/8/eeYdHdZ55+57e1HvvHRUQRfQONrj3mjjFiROnZzdlk91vN9lk4zibnqzjFCdxibEdNzCm9y4hoQZCQr3X0fQ+53x/DMhgAwJTJNC5r2uuM2jOnHnn6Mer8zvP8z5PHfTXQX89DBwHnzPwulwFMXkQV/KBmY0tDEQoJa4rN+NcJjH5kIzbOEjGTWKqMhEa6z1lYsNvqnEb7LyW9r8smTaPHyz4ASq56rqOAwKpcNadXYzsquOdrG38rXUOFk8Id01P5BurckiNnBxr387g8rr5XflbHDh6kJLOWUTbkxnVmYldGMsn7pyDVjU5Uyhv9rnMbzZj3rgR81tv46qvR6ZSEbR8OSFrbiVo0SLkhsvXkWVokIoNb1K3cyuCz0/ewiWU3f0AkUkpF3zPxSpSnh2RA3A6nfT39/PUU08RFhbGtm3b2LZtG0qlEp/PR3JyMoIg8J3vfIcHHniAz33uc+zfvx+dTodKpWLhkqXc92//wTGbkyqLg6MWO0MeHwDZeg0rgtRMd1lRDfTS29NDf3//WAsCjUZDbGwscXFxxMXFERsbS0xMzFiLAwBsg9BbHTBxfdWB55bu0y+ejswllgaMXMIMiCti94EjV0Vngt/PYFvLaSMXMHNOq+WcfXQhoYTFxBEaG0doTBwhIsi3bEN2uAJ1XBxRT3+RsHvuQab6mPOa4A+sm+uvDZjZM1vH8OkdThvahNJARcuslWC4tEbzEh+fm30uk5gcSMZtHCTjJjFVmSiN9TSOsumPdbi9bjZm/JHMojh+tuRnaJWXX6zhamCvHMD4VgNtRev4h0nHzq6lCKKSB2al8JXlWSSEnadx7wSzp/0o6zZsJ7k5g1B3FD1B3aQsS+ILty2f6KF9hKk0l7kaGzG/9Rbm9Rvwj44iU6sxzJ9P8MoVBC1fjjLi8gp02EaNHH3vbWq3bcLrcZM9Zx5l9zxEbHrmZR1nvIjcGWMXHR2Nw+FArVZjNBp57rnnALjnnnvweDwoFApCQ0MBeOGFF5g/fz4QuAnS5fKww2jlvUETh0w2BCBTp+H2mDDWRgQRYTUxMDDAwMAA/f39DAwMjFXElMlkREdHk5KSQlpaGqmpqQR/uCWDbShg4nqqoPcY9FaBLVA8BpmCwai5xDz4K4jOuaxzMx6iKOKyWTEP9GMa7Mc80I95aCCwHezHMjw0luqqUCgI9osYjGbCdHqSb7+L9IceRh8adjUGEkirHDNyNdB1BOxDgWIoibMg55bAI7ZQWit3DZhKc5nExCEZt3GQjJvEVGUiNWYZdvL+H+oY6bZyJOU9FDNM/GbFbwhWT0xzbFfzKMMvncCStI/G5HfZ2LaC3V1zkcsUPDY3haeXZhEdfH170F0K/eZB/rxuM9q6MHS+IAbju/nUZ5eTnpQ00UMbYyrOZaLPh6OqCuv27di278Db2wtyOfrSUoJWriB46VJUKSnnrB+7GA6LmWOb1lO1aQMep4PYjCxy5i4kd95CQmMurSn2xSJyFzN269at4ytf+QrKsyppulwupk2bxsMPP8zSpUuZNm0aVVVVtLS0kJmZSUpRMVtGrLw3ZOKAyYZfhDSdmiXhwZSFBTEn1ECCWsno6OiYkevt7aWzs3PMzEVGRpKamjpm5M4YxnOw9AZMXMdBfOV/Ril4oOQRWPIdCE+9pPNypfi8Xow9XQx3tjN05nGqEYcjsO4PUSRGayA9K4/cZSuJnFN2eamUF0MQoO8YNG2Fps0BYwsQkgjZqwIVLdMXBRqGS1wxU3Euk7j+SMZtHCTjJjFVmWiNed1+dr3UwKmjg7RGVtMz6yi/v/W3ROomJuXH229n5OUGHPYOBsr+Qqd/kB19n2dHayJqhYJPLUjjqcUZhOknX6GA3hEjz/z+TTL7Aql0mul2HnvsFoKDJj7dc6J1NtGIooi7oQHr9u1Yt+/A3dQEgNxgQJOXhzYvD21+Hpq8fDTZWRe9qHc77NTt3ErjoX30NweOE5eZTc68ReTOXfixmn6f4ULGrqKigi9+8YvodDqMRiNGoxGn00lRURFhYWGIojjW702tVqNQKFi2bNlYNG/Y42PLsJmNQyaOmO3Y/YHoVKJGNWbiykIN5Bq0iIJAf38/7e3tdHR00NHRMbZeLjo6mpKSEoqLiwkJ+WhPvANb32WBWA7lfwJRgJmfgsX/CsGXZmyvNnbTKJ3/fJ32fXvotI5iO93OI8zhJkmtJyM7j6jSmeiKi9FkZV2wxcRlYe2HU9vg1BZo2QUeW6BxeuJMyFwGGcsgaRYorn9q+s3AVJ/LJK4PknEbB8m4SUxVJoPGRFGkelsXB99uZlTXR+3MTfzqrmdJCEqYmPH4BKx7uzHvaseYtoHh9HcxevPY0f8Vtpz0EKZT8fMHS1ieN/ma63r9At94cRs0tpJnysarcpG8VM/ddy1BqZy4HnCTQWeTCU9HB/YjR3CfbMR18iTukycRHI7AiwoFmox0lAkJKIKCkQcHoQgORh4UjDzIgCI4GEVoKLrSUmxOB02H99N4aD8DracAiM/KJbtsPmklpUSlpF2Vqq0fjsbJZDJyc3PJy8vj2LFjDA8PU1dXx+zZs9FqtQiCwMDAAP/yL//CXXfdhV6vHzOFTaeakSckYc3I4ajVyRGTjYHTa+OCFHKy9Fqy9Boy9Boy9RoytGoMVjMDnR2cOHGCrq4uZDIZmZmZTJ8+ndzc3LG1cWM6M/fA3p/BsZcChT3KPg8Lvn7N+8hdDFEUGayt5uSW92ltqMfoCFSnDHG4ibY6CPf6iUvNIKy4BF1xEdriYlSJiVf2+/N5Ar30WnYFGqP3HgsYWnVwoMdcxtLAIzpXSqu8RKS5TOJ6IBm3cZCMm8RUZTJprOuEkff/VIPd6+Bo4Tv810PfIif86q5VuRx8Rhem9S2M9h6lf8af8Gj68Rm+xK8Ol9LQZ+PzizP419W5qJWTqyS/IIj8z/sNvHdkLys9GuLNqbiCLJTdlc6ChcUT0n5hMulsMiIKAt6uLlwnG3GdbMDdcBLf4CB+mw3BasVvs4HXe857ZCoVhkWLAgVQli3HarfSdHg/TYf3M9DaDIA+NIzUoumkFE0ntXg6wRFRH3uMF4rGWa1WfvzjH/Pqq69SXFw8tn9XVxdKpZKkpCQKCgpoaGigtbUVhUJxTkROJpPR6fJwxGynyuKg1eGixeGmx33u903UqMgz6JimkhHS34W9pgqn2YRGo6GwsJDp06fT3NzMsmXLPniTsRV2PwO1rwd6x+WuhYI7IXNFoH/cBGIa6KfpyAFO7dvFQFcHZ66JDG4vYXYn4XYXkUoN0XkFRDz8EEHLll35/13nKLTtC5i4ll0w2hb4eVAspC/+4BGedmWfcxMjzWUS1wPJuI2DZNwkpiqTTWOWYSdv/64Ca7+XirSNrLpzJo/lPzohZuMMzhMjGN87Tl/s3zEn70alzmdj37d5rdLK9OQwfvvIDJIjJvYi8MOIosjze1t55v3jLI7tIrc7gjBHLJbQQSIW+Vi5YB6Z4ZdX3OJKmGw6uxER3O6AibNa8Q0NYduxE8vmzfgGBpBpNAQtXhwwcUuXYnc66KirpqP2GJ31NTjMJgAiEpNJLZpO2vRSkqcVo1JfnXVWH+4hJwgCLS0tREdHExYWNtZqQK1Wo9VqCQsLw+/388ILL1BWVnbeYzr8Am1ONy0ONy2nzVydzUmjPVCmXymDbJWceMso6vZmokcHCfJ6CA0N/cgjWhwipuWfaDt2IHOOBhp+Z6+C/DshezVoP5p2eT3xulz0t56it+kkfY0n6Dl5Atfp9XFKQSTWZCU9KJy8p54mZPWqS14XOS6j7dC2N/Bo3QP2wcDPw1IDBi5jKaQtguDJl10wUUhzmcT1QDJu4yAZN4mpymTUmNftZ9ML1XTVmDkRcxD/wh5+tOi/idJ9/GjBlSJ4/Fh3ddF3/D36C15AUNvoEL/Lz/cmIpPBz+4v5tbCi/fZmgheP9rFv71VR36CnFsjRnFX6NE6g+kNOUVXfhWzSqaxInUFBREF19QcT0ad3QyIgoCzuhrL+5uwbNmMf2gYmU5H0MKF6GaWoispQZOXh3Gwn47aY3TUVdPdcByfx41SoyG1aDoZpXPIKJ1NUPjHTyM8X2GTJUuW8PDDD1NVVcW6deuoqqpCq/2gaqzL5WL69Ons2LEDuVxOZWXlWGGTs4umfJhRr4+jZjsVZjvlZjvVVgcuIXA9kea0ssZnI2m4D4vZjMVi4exrDTkihcEmiuStpDhq0XhNiAo1QtoSFPm3BdZ+ReeDYmLbaoiiiGmgj76mk3TW19B0YC9enxed20uqXEXxg4+R9MCDyBRXMf1ZFGGoEdr2BIxc+z5wmQOvRedDxhJIXwJpC8YvdCKKgb58asNNl4IpzWUS1wPJuI2DZNwkpiqTVWOiIHJkfSuVmzvoDT3F4cI3+fcl/8aylGXjv/ka4h10MPhaBT0Rf8QafxiHbC5/qP00x/vcPDEvlX9bm49WNXFryc7H9hMDfOkfVYTr1SzMjCTV7IATNuQuJZ1hDZQnv4cq1s8DOQ/wqcJPXZN+epNVZzcTot+Po7ISy6ZN2PbswdfbF3hBpUKbl4eupARdSQmqaQUMWEZprSqnpbIc6/AQALEZ2WTOnEPGzDnEpKZfdlTnYhUry8vL+dznPodKpcJkMmG1WnG73TzwwAM8//zzfPe732XXrl14vV5cLhdr167lf//3fy9o3s7GIwjUW53sN9l4vrWHEeTkGbR8KSWGO6NCcdltmM1mTCYTw8PDDA0NMTw8jHF4iESxmwKayaeZUAJrzkSlFln89ECPuMSZgR5xERkTakC8bhenjhyk9q3X6entDrRw84lMW7iU4ie/gObDbROuBoI/UKHyTDSu8xD4XIG2AwkzAiYuJCHQb88+GNjaBj7Y+j2B9gQLvxFIUb1aUcIJRprLJK4HknEbB8m4SUxVJrvGTh7qY+fLDdi0o7yT81tuKV7Gt2Z9C71q4lITRa+f0XdbGOh8j4Gil/DIPWwb+HfeqA1hWkIIv3+0lLSoia/keDaVHUZ+s6OZ470Whm1uVCLMcCuZ61GiEWT0RrexN/EfJCXF8D+L/of00PSr+vmTXWc3I97BQVy1tThranBW1+Csr0d0OgFQpaYQ/uBDhNxzNyarmdaqCloqj9DX3ASiiDY4hKS8aSQXFJJUUER0StoVped9OCIniiI5OTl861vfQhTFsTTL4eFh2tra8Hq9PP744zz22GOUlpaiVCovKSK3fddujPnF/L5zkEa7i0SNii8kx/BofASGDxXn8fv9jI6OBszc4CCDjYehp4oE+snQmIj29SL3B6pZog2DvNtg7tMQV/ixz8PVwDI0QPVf/0RDxWFscpCJIuFaPfGpGSTPnU/ynHkER0Vf/Qi6zw1d5YGIXOse6KkE0Q/IwBAVWCcXFPPBVqmDmlfB1AFRubDw61D0wA1fzVKayySuB5JxGwfJuElMVW4EjfU0jbLpD3W4BBfvZv4ebZLAM4ueYVrUtAkdl/1oP0MbjzFY8CLWyHIabXfwh6pbEEU5v3xoOisLJue6kEGri+O9Fk70WjjZZUZoMJM1KqJA5Hj8AWpTt/LVuV/m4dyHr9rF342gs5sd0efD3dyM89gxzBvew1lVhUytJmTNGsIfeRhtSQkOs4n2miq6jtfR3VCHeTDQ3FpjMJCUX0hSfiGJeQVEJCSh0V/ezYkLReTWrVvHs88+S2JiIk1NTZhMJlwuF1lZWSQkJKDT6RgeHqa/vx+NRoNSqTyn1cDZnNGZKIpsH7Hw+85BDpvthCsVfCoxirtjw8nRay6o69HRUWpra6mursY8OkK80szMWMjWGgnq3I7M6wiU05//5UCBk0v5/+H3ga0/EIHy+0DwgeA967kPYgtAF35559Pvp2XdKzRt28ygcRiTRolw+nzoFEpiE5JInDGL6Lx8NIYgtKcfmqCgq7O20W0NpEPqoy6cWur3wYl3YP8vYaAeQpIC5670k4E0yhsQaS6TuB5Ixm0cJOMmMVW5UTRmGnDw3u9rsIw4Kc97h5rQffzLrH/hsfzHJrRwiafPzsgrJxhV7WGw6BWGXDr+3PBtGodUfGV5Fl9fmYNCPvnXeAwM2ln3lzqUHQ7sSjuH094kolDNjxf9N7GGKzegN4rOphKuxkZG163D8u56BIcDTX4+4Q8/TOjttyE3BC6qLcODdJ+op+tEPd0NdZj6+8berwsOISwunrC4BMJi4wk//TwyKRm17tIj4mcXNpHJZJhMJjo6OsjJyUGv159T2ESlUpGYmIggCDz33HPMnj0b+MAUbtiwgTvuuOOciNxRs53fdw6yediMCKTr1KyOCuXWqFBmhxhQnuf/pyiKdHV1UV1dzfHjx3G73ehlbhZqm5juqUDvN+MISsNa+EnUMx8lNDL2AxNpGwqU4O8qh+6j0FsFXsfFT4IhGu74DeStveTzds54/X4cDQ307NxOd3UVgwO9jKoUODTnj24pVWo0QUHogkPIm7+YGbfeflm/s8sfoAjN22HfL6DzIOgioOypQJ+9Ceqx93GR5jKJ64Fk3MZBMm4SU5UbSWMum5dNz9fRe8rEcEED/wx5njXpt/Jf8/9rQlMnBZeP0TdPYW1sZqjsH4yoq3ij7SvsaE1ncU40v3l4+qRs2H0+amsG2fJSA3qbn77gVioy3+frqz/Hmow1V3TcG0lnUw2/zY5lw3pGX12Hu6kJeVAQQcuXEbx8OYaFC1EEBY3tazOO0NfciKm/L/AY6GW0vw/ryHDg4hyQKxTEZ+eRVjyDtJJSYjIykcsvvO7zfIVNli9fzg9+8AOqqqr47W9/y+bNm9GcbkqelZWF0+nkO9/5Dg899BDbtm3j//7v/2hubsblchEWFnbeiFyvy8PWEQtbhs0cGLXhEUUiVApWRIZwS2QoZWEGQpQKNB+K4nm9Xpqamujr68NoNDI6PED8yEHm+CuIYwgbeupk04g1iCT4u9A6A1FK5CqIL4ak2RCTDwpNIE1Qrgi8plCBXAl+L+z8EQzUwYzH4dZnQHNla9ZEvx93UxPDe/dgrKnB1tKMyzSKR6nAq1QiRkUiRITj0KjoG+pHGxzCrNvvCRg4re6KPntcOg/D/l9B06ZAY/DcNTDr05Cx/IZYByfNZRLXA8m4jYNk3CSmKjeaxvw+gd0vn+Tk4X5kcS5ej/014Ql6frn0l6SFpk3YuERRxHawF9P7rZjTdjGQ8SoH+pfw0ok7iA3R8YfHZ1KYOE4ltkmCKIhsXH+Kpm2dqPxwInY/zHTwk9XfI0wb9rGOeaPpbCoiiiLOY8cwvf4Gtl278JvNoFJhmDMnYOSWLUOVkHDe9/o8HsyDA4z299J36iTtNVUMtrUAoA0KJrVoOqklM0grLiU48qPVYS9W2KSiooIvfOELqFQqrFYriYmJGI3GsYjbo48+yvvvv49arUYQBKKjoxEEgT/84Q8sW7Zs7Nhnr49zCCK7jFa2DJvZMWJh1OcfG4tKJsOgkGNQyNEr5AQpFBgUcuaGBfFEYiTRahWiKGK1WLAf34y++i+EDh7BJg+hU4ihiwSGNWnoMueRnp1PZmYmISHjtBvwuWH3T+DAryE0Ge75A6TO/5i/yQt8xPAwzro6XHV1OGtqcdbVIVgsmPRaWnPT6Be86IKCmX3X/UxffRuqsyqAXhNGWqDyb1D9CjhGICwFSp+AGZ+Y1O0HpLlM4nogGbdxkIybxFTlRtSYKIo0HunnwBvNuJxeTiTtozp5Gz9Y/F+sTF05oWPz9Nowv9+Gpb+OvhnP0+CR88f6r2Jxa/nxPUXcPzNpQsd3OThsHl59oRbHCTNupZ3axL3MX1nMZ2c+ctmVJ29EnU1lRJ8PZ3U11p27sO3YgaejAwBNfj7BK1cQdv8DqGJjLnoMh8UcaEFQe4z22mPYR40AxKRnklO2gOyyBUQkJI47lgtF5J555hkEQWDVqlVjrQa8Xi8qlWpsjdzSpUtpamqiq6sLuVx+TuPvM8bQJ4gcMdtosLuw+wTsfj92v4DN/8HzUa+faqsDjVzGfbHhfD45mjzDWZEpjwPUeiwWC62trbS2ttLS0oLdHujFFhUVRXp6Ounp6aSmpmIwXGB9V+dhePspGO2ABV+FZd8H5dXptfdhRFHE09yMZctWLBs3MjDQy6n4SIaDdGg1Wubc9QDTb78LlUaL6PXi7e3F09mFp6sTb0cnnu5u5Fot+jlz0M+ZjTot7eOlrfvccPI9OPrXQAsCuTJQhbLogUB7hpDz3yyYKKS5TOJ6IBm3cZCMm8RU5UbWmNPm4eA/mzl5uB+n3sz21JdZvWABXy39Kkr5xPVhEkURd9Moo5tP0hP2At2xFfy57mnqR5J4fG4K319bgE49uVoGXIzOVhNv/KUS7YgMl8JOS2IND9y3hGW5iy75GDeyziTA3dqGbddOrDt34ayqAoWCkDVriPjkJ9AVFY37flEUGe7qoO3YUZorDtF3qhGAqJQ0csoWkDN3AZFJKRd8/3itBj7/+c+j0Wjo6+vD6/XidDopOj2uuro6iouLCQ0NRRAEBgYG+PKXv0xZWRkpKSnodLpLqlh5yu7iT91DvNFvxCmILIsI5qnkaJaEB5/XsIiiyMDAwJiR6+jowOv1AhAbG0t6ejppaWmkpqai051lAt1W2PJ9qPo7xBbCPc9f80qWoijiPnkSy/vv07ZlMw1KPyPBejTISHJ6ie8eIMThGttfptWiTk7GbzLhGwq0k1DGxARMXNkcDHPmoEpJuXwjN9wMVX+DY6+AM2D0CYoLtGZIKIXEGYGt/uP3HLxSpLlM4nogGbdxkIybxFTlZtBYd+Mou15pwDLooimqAuecdv5n1cQ27IZAyqGjapDuitfpSvsLb7avYlPHUmKCNXxtZTYPzkpGpZj8azrOUFnZx7v/rCB2NAiv3M1QajufeGQ1eSmZ4773ZtCZRABPVxejL7+M6Z9vItjt6GbMIOKJTxK8ciUy5aXdMLEMD9FcfpCmIwfoaWwAUSQiIYnssvmkFJYQn52LSnNpqXpnR+QsFgshISEUFxezcOFCXnvtNcrLy5k/f/6YGevp6UGn0xEREYEoirS3t2M0GlGpVISGhnLrrbeet2LlGUY8Pl7qHeaFnmEGPT5yDVo+lxRNaYieFK2aIOX5b8r4/X56enpob2+nra2Nrq4ufD4fMpmMlJQUpk+fTn5+/gdNyhs3w/qvgMsEs5+EBV+/LimEoijiqqmh6bVXOdHaSB8+RCAqPIq80tnkr1pDcFo6MpksELVrb8dxpBxHeTn28nL8w8MAKOPiCLltLeEPPYQ65cKm/Lz43NBXAz1VgeIuPZUw0vzB6+HpkL44sD4ufQmor98aZ2kuk7geSMZtHCTjJjFVuVk05vP6qdzUwdHNbbjkDupztvPdx58mNyJ3ooeG6PUzvL+aU6P/Qa3o5Z1Tj3PSFEVapJ5vrs7l9qJ45DdA5UkIXNS9s6eZvZvKyTDHIMpEvBmjPPTwMpKSL5w6d7PoTOID/DYb5rfexvjyy3g7O1HGxxPx2KOEPfAAitBLX89pGzXSXH6IpiMH6D5RjygKyBVK4jKzSSooJDm/kITc/ItWPbxQVcmKigqeeuop4uPjkcvlCIJAb28vQUFBhIWFnVOx8owRAfjWt77FF77wBYIv0tjaLQi8M2Di+a5BTtg/iEZFqBSkajWk6tSkaNWk6jQUBOmYHqw7JwLl9Xrp6emhtbWV+vp6jEYjSqWS/Px8SkpKyMjIQO40wrb/DPRDU6hh9mdhwdcCfdKuEw6LmZMH9nB89w4G21uQK5RkzpzDtKUrSC2agVL9QeElURTxtLXhOHIE2/4D2HbvBkHAsGgh4Y88QtDixcgUHzPbwGkKNATvqQpU62zbCx4rKLUB85Z7K2TfAqHjp99eCdJcJnE9kIzbOEjGTWKqcrNpzNhr5/2/H8Pc4aEmeQePf/IWFicvnuhhAeCzuWja+Sx92leoG5nOhq7HaTHKKYgP4Vu35rI05xo0zb1GOD1+frmhnI6j1RSY0lGKaqxRA4QUCxTMTqI4vogI7QfpTDebziQ+QPT7se3Zg/HvL+I4cgR5aCjRX/0K4Q89dMkRuDO4HXZ6Gk/QfaKe7hP19LeeQhQEZHI5semZZM2eR+ltd12wD9mHdXah9XFf+9rX6O7u5tVXX+Wf//wnKpUKp9MZiDadXh/39ttvk5KSct7iJmdH40RR5LjNSavTQ4fTTZfLQ4fTQ4fLTbfLg+/0pU6uQcsnEiK5PzacMNW550UURbq7u6mpqaG+vh6Xy0VwcDDFxcWUlJQQo7DC3p9B7WsBozL7yYCBM1zfrIKhjjaO79lBw/7dOMwm4HRrAYMBjd6AJigIrd6AxhCExhBEVGQ0oc3t+NZvwDc4iCohgbCHHybsvntRRkZe2WB8HujYD01boHFToNE3QFwxZC4HfSSodKDSg0ob2CpPb4NjISz10vrwfQhpLpO4HkjGbRwk4yYxVbkZNSb4BTb9vZr2chMnYw6z4OFMHi54aKKHBZxe63P4CE39/4kjpIV64yO82bKYbpOHOekRfOfWPGamXl4j3omkc8TBv7/1PkJHJwWWVEI94bgVTloiqxhJbSUpM5LCqEKUvUoeX/34RA9X4hrjamhg4KfP4jh8GE1uLrHf/x6GOXM+9vE8Lie9TSfpaain83gdvY0nCI2NY/mnniKjdPZH9j/ffDZexcozPeR8Ph9DQ0N0dXWxcuVKXn311XOM3+DgIAaDgTVr1vC///u/F0ylPBufINLn8bLPaOWl3hGOWR1o5TLuiAnjkwlRzArRf+RmzZn2AzU1NZw6dQpRFImPj6ekpISiBC2Git9D3RsBAzLnczD/q2C4QhN0mfh9PtprqhjubMdlt+F22HHb7YHndjtuhw2nxYLbESjOEhYXT3xYFGGtHQRV1aCSKwhZvZqQ228jaMECZOorbJciijDUGGgx0LQFuo6AKFz8PUFxkDoPUuZDylyInRZo1TAON+PfTInJh2TcxkEybhJTlZtVY6IocuCdJmq29NAeXk/MnR6+WfYNFJfwh/l64O42c2rHrxhMWIcg03LC+31erAxl2Obh4dnJ/NuafEL1l1e5cSI52W/h/ZpeDlZ0EDNiJ8cVjEpUYNYNcSLmAE1RRylIzuET+Z9gafLSSfN7kLj6iKKIdds2Bp/5Kd7eXkLWriHmW99CFR9/xcfurK9hx1+ew9jbTeasuSx74nOExnyw7uty57MLReT+7d/+jfDw8DFjp1araW5uRhRFvF4v9957L3feeSezZs0iLi6OqqqqcYubANRbHbzUO8KbA6PY/AJ5Bi2PXyAKB2Cz2aivr6empoa+vj5kMhnZ2dnMTg8ls/ufyI+/HYgqFT8Ecz4PsQWXfU6vFaIoMtLVQWd9DR111XSdqMfrcoJMRqTWQGj/IFqrHZ1KTUTpTGJWriJq2XKUuqvQR87vA58TvGc/HOBzBbaj7dBxCDoPgaUn8B5NCCSXBUxc1kqILzlvRO5m/ZspMbmQjNs4SMZNYqpys2usdncXe9c1MRDUjm1FAz9e+cMJbdZ9NoLLR/9be+hQ/xJHRAM6/UK2D36Jvx8eJlyv5r/uLOC2ovgbJn0STrdqGLCysbKH44f7iTP6SPQr8MsEOuPqKI95H32MgkfzHuWe7HsIVl9Zo2GJyYvgdDLylxcY+dOfQC4n6qnPE/HpTyPXXFl5e7/PS+XGdzn05qsgQtk9DzLrjntRqlQfaz67WERu3bp1PPvss8hkMnp7exEEYSyVMiEhAVEU6erqwmw2o9VqCQ4OPqfdwIXSLO0+P+8Mmnipd4Tq01G426PD+ERCJHNCDef9Pz8wMEBtbS21tbVYrVY0Gg1zM8OY5TlMUPtmZD4XpC0KROFybwPFxFXWPR9+n4/+5iY66qrprK+m71QTgt937k6iiFapIigiktDUNCISk4mITyQ8IYmIhER0weP0w/s4mDoDbRg6DgaM3NDJwM/DUiD/Tii4CxJnjTUHv9n/ZkpMDiTjNg6ScZOYqkwFjbUeG2LTn2sxqQdpnLedn9/+DNH66IkeFnA6OrG/m87avzGU8xoogfD/5Bf74qjrsbAiL4Yf3l1IYthVuAt9nRFFkYY+KxsPdNB6oI9clwIVMozR3RyIepfRyG7uzr6bx/IfIyXkMqvOSdwweHt6GPjps1i3bkWVlETY/fehnzkTbXHxFZk4y/AQe178M01HDhAen8DyT3+B9lHLVZ3Pzk6lBDCbzXR1dVFcXAxwTnGT8PBwsrKyGBgY4LnnniMzM5N/+7d/o7KyEkEQzttDDqDO6uDls6Jw2XoNjydE8kBcBBHnicIJgkBbWxs1NTU0NDTg9XoJVnhZHNxBofMwOvcQYnACstmfhZmfuu7r4C4VURBwWMzYRo1YhwYwlpdjrKnG2tWJUybi1GlxqJUIZ10raoNDiDht4vIWLCG1aPrVH5h9OLBmrmE9tOwCwQvBCZB/O+Tfye52D0uXrbj6nyshcRaScRsHybhJTFWmisZ6m028+7sqbIKFwzPe4Jm7/4vs8OyJHtYY7k4LA2/spyfl/3BENhCqXUql5xv8akc3Mhn86+pcnpifhuIGqT75Yd7ftosmTxzHdnYzzSHHIMpwhVo4ErORpoijLEpdyCcLPsms2Fk3VIRR4tKxHzrE4C9+iauuDgCZSoW2uBj9rFnoZ81EN2MGiqCgyz5ue3UlO//2PKN9vQTFJTLvznvJnbcQjf4CTa4vgwulUv7kJz+ht7eXX/7yl/zjH/8AIDExkYSEBHp6evjOd75Db28vP/jBD9DpdAQHBxMWFobP5+P5559n9uyPrs+z+/28O2ji5d4RqiwO1DIZt0WH8lhCJKUhBvTnaR3idrvHesR1dHQw0NdLNq2UUU0GnQgyJY6UZehL70eevXpC+59dKoLLhW3PXkyvv471wAFceh3Cgnn4SgqxCX6Mvd0Md3XgsllJKyll0aOfIiYt49oMxmUOrJk78S40bwefC48qFPXsT8LMT0Pk+K1QJCQ+DpJxGwfJuElMVaaSxkZ6bbz966PYbA72573Odx74ErPjPnoBNVEIDi+WfV10df2VobTXUQhBGDT/j9+1xLO7aYiSpFD+594ipiVceqn1ycIZnZkcHv64q4XDu7soscuJEuQIOi/HY/dxLHIXqXGJfHLaJ7kl7RZU8htnjZ/EpeM3mXBUHcNx9CiOyqO4jp8Anw/kcjR5ueinT0c3fTq6kpJLbuLs83qp3vIeRza8jctkRKlSkzl7LtOWrCC1eDryK1hTeSnFTaKiopDJZMhksrGI269//Ws2bNjwQV82AkZr9erVfOlLX6KsrAy1Wn3eVMoTNicv947wzwEjFl+gyEaiRkWGXkOGTkOmXkOmXkumXkOSRo3y9A0dl8tFd3c3HR0dmJrLSenfTL7YRBAOBOR44meiKbobWd5tEJH+sc/J9cLd2sroy69geucdRIcD3fTphH/icfRLl1KzaytH3noNl8NOwaJlLHjocUKirmGbBI8dTm1jaNdzRI9UgOgPtCGY9elAaqryCgusSEichWTcxkEybhJTlammMduoi3d+U4m5z01zdCUrHy7itmm3TvSwzkHw+BkuP0CT6T9x6zsJG1jFKflT/KxpmFGHh0/OS+Obq3MI0d44xubDOhu2uXluVzN79nUxw6EgzadAlIkMRjdTEbkNT/woj+Y/yv059xOqufGMqsSlIzgcOGtqcBytxFFZiau2FsHhAEARFoaupATd9BJ0JSVoi0tQBF04krZr1y7ykhM4vmcnjQf24LLbMIRHkL9wKdOWrCAqOfXqjv0CEblnnnmGrVu38rWvfQ2VSoXZbMbtduPxeCgqKiIsLAy1Wj3WlNvv9583ldLhF9hltNBkd9HicNPqdNPicGP2+cfGYFDIWRUZwm3RYSyPDMZwVp80j8fDqaZGeo++h65jFzliMzGMAOANz0Y57Q5k2ashafakWxN3Nn6rFfPbb2N8+ZVAz8DoaIKWL0c+LZ8TI/3UHNgDiMy49Q7K7n4Q7ceI3F4qu3fvZunMPDj2ElS+COZOMETDjMeh9IkbwhBLTH4k4zYOknGTmKpMRY35vQIHNjZSs6Ubt8JJ2DI3n733/kmXoufzumg6+mP6nP9AZY8juOFLrNOn83qPkUiDhu+tzeOeGYmTbtzn40I66ze7eH5vC9vLe8iwiBR7lWgFGU6DheqonXTE17ImfzWfKfwMcYa46z9wieuO6Pfjbm7BWVONs6YGZ00NnuYWIJBeqZ83l+CVKwlevhxl1Lnrt87Wmc/rpbWqnON7dtBeXYng95OQk0/J6rXklC04p3H0lXChiNzZps7v9+PxeIiPjycqKgq73Y7JZGJwcJCsrKyx/bu7u3nuueeYP3/+hc+PKDLi9dPqcNHidFNpdrBp2MyI14dOLmP5aRO3KjKEYOUHJs7lcnHy5Enaj+1C27GbXFpIpQc5Aj6lHnfCXBS5t6CdtjZQmGMSIgoC9n37GF33Go6KCgSbDQBPVCTN6Ym0e+yoNVrm3HU/M9beedGm7R+Xc+YywQ8tO+HoXwOtCEQhUCAmexVkrgi0GLgB5meJyYdk3MZBMm4SU5WprLH+rlFe+cMOtCMR+BLNPPHF1YRFXfm6mKuN0XiQ4/X/isc7THjnCoYGV/N7WTi1Rjtz0iL44d3TyIu7BtXWriLj6czl9bP1xAD/LO9k6KSJ6S4FSX4FgtxPS+QxapJ2sqJkIU8WPSkZuCmI32LBWVuHff9+rNu34+3uBpkM3YwZARO3aiXq5OQL6sxhNnFi705qd2xmtK8XbVAw05aupGTlrYTHJ16zcZ/P1AmCQFVVFb/97W+pq6sjOTl5bP/y8nLS09O55557mD9/PqWlpZw4cWLcVgM+QeSI2cZ7Q2beHzIx4PGhlslYEhHM2uhQVkeGEqn+IKJmt9s5ceIEzfWV6PrKSfY0kkUHoVgBMCtjMEaW4s9YTvy8hzCEhF2zc/RxEQUBd3MzzupqnMeqcR47xnB/L43xEQyFGFACWXHJTF+9lvhlK5Drr46Ju+BcZu4JROFOvAuDJwI/C4oLNAPPWgEZSydtoRiJyYdk3MZBMm4SU5WprjGfz8evXn4RRXkcSpmS+XdnM2NFGvJJVgTE6zVz6tSP6O9fj4gPjTGbo70P8DdjElaPnyfmpfGNVdkET9L0ycvRWfeogzcre9h6qIu4IR+FXjkqUUZrVDXHkrdJBm6KI4oi7qYmrNu2Y92+HffJQPl2TW4uxrQ08h95GF1pKfLzRNREQaDzeC212zbRfPQwgt9PStF0SlatIXNmGQrl9UsXPLtipVwux+12U15ePpZKKYoiTU1N2O32sQInq1at+khVyg8jiCKVFgfvDZnYOGSi2+VFDswNC2JtdCi3RoWSpP3g3IiiiN1uZ3BgAEtbJcq2XYQOVxLnbkGFDwdauoNLofBekhY8jD5o8rbw8I2O4qyupmvvbupP1NAteBFlEGNzkhMSRdqceQTNLUM3Ywbyj9kv7pLmMktvIBLXvANad4FzFJAFesMV3gulnwRd+Mf6fImpgWTcxkEybhJTFUljgQuXFw6/ROO7ZlJN04hM0bP2qRJCIidfCX63Z5j+3rfpbv8HLqEThzOcjac+y5b+FKKCNXxzVQ73z0xCdZ4KdBPJx+uvJXKodYTXDrRjPmZkukuOChnNUVVUp2xjZfFiycBJ4Onqwrp9B9Yd23FUHUMmCMi0WvSzZmGYPx/D/HlocnM/klJsGzVSv3MrtTu2YB0ZwhAeQeHSVRQtX31OU+9rxYfXx8lkMvLy8igpKeHo0aP09fWNtRqQyWScuWb6+9//zpo1ay7YI+7s4x89epRdxxvoCo+hNi6VJqcHgOJgHWujQrk1OpQcvRb5edL5BLcd87F3cFe+SsTQEdR4sKGnO3Q2ssL7SJ5/H3rDtVtLdjWw9HRT+epLnDhWjsvnJcjlIXXYTJLTR/jSJYTcdhuGRYvOa/IvxGXPZYIf+qqheSec2grd5aAywPRHoewLEJV12d9L4uZHMm7jIBk3iamKpLEP2NDyHn97900WtT5AkF7PvV+fTUTC5EudhIDZHB0up7PmbxjF3bTZYll38jFOmRNIi9TzjVU53FGcMGkih1eqs0GLi1f3tXNydw+5VhEF0BxdSXXydpYXLeTh3IfJjci9auOVuDHZs2kTpRot9kOHsB88iKclsDZOERmJoawMTU426rR01OnpqFNTkGu1CIKftmNHqd2+mbZjlYiIpJWUUrziFjJK51zTKNyF1sd5vV6effZZnnvuOURRxOcLNKp2u938/ve/55FHHhkzfSaTCaVSSVlZGd/73vcIDQ3FYDDw3//93+zateucwief/38/YPOIhU3DZiotgQIwapmMZK2aFJ06sNWqSdFpSNWpSddpCFEqED12TBWv46laR+TIUZT4MBNMY9B8WmPXoAuJICgo6JzHmRYIF4sOXi98Xi+NB/dStfEdBjvaUMhkhDs8RI5aiBFkJC5aQujtt2OYW4ZsnN/3Ff/N7K+Dw3+AutfB74HsW2De04EKldJ6OInTSMZtHCTjJjFVkTR2Lof7DvOjjf/L4prH0Mn0rH46n9y8yblQ/wyukSE69r3MgOxNjroiWN/yCO2WEPLigvnX1bmsyI+Z8AImV0tnXr/AlqM9HNjYRuygFwUirZHVnIqqJDxLzYMF97M6bTUaxcdv7Cxx4/JhnXn7+7EfOoz94EEcR4/i6+v7YGeZDFV8fMDEpaejLZwGM0s5cXgfdTu3YjOOXPco3NmcSaWMjo7G5XJhMpkYHR3l9ddfB+Dpp58mJCSE+vp6RFE8p2Llmcbger0evV5PamoqZrOZ5557bqyHXL/by84RC80ON50uN50uD11OD6NnVawEyDdomR8WxLywIOaGBREp2DEdeRX/sVeJMlVjUUSwU72KGmcCH76qCw0NpaioiOLi4rEm5hOJKIr0NjbQdOQAHbXHGOnuBEDlF4i0OogRZKSVzSPxvgfQTZ9+3nnzqv3NtA3C0Reg4s9gH4KYAih7CpLmQHgaqK9+YRWJGwfJuI2DZNwkpiqSxj6K2W3mj/v/im99AjpvMPrbjTxxy/2T3gw4W4Y4dehnDMS+S+XAXN7reoBus4zpyWF8+5Zc5mdN3ML4a6Gz+mYj7/+zEUWHHa0ox6Nw0xFeR19sE7Nn5fPAtPtJDbm65d8lJjfj6Uyw2/F0dOBua8PT3o6nrR1PWxuetjYEhwO5wUDIHbcTct+99Huc50Th4rNySC2aTkphCfE5+ShV13Y96cVaDbz++us8++yzqFQq2tvbgUDVyKysrLEm4C0tLWi1WmQyGaWlpfT39/Od73yHhx56iM7OThITE6mqqvpIqqXV56fT5aHT6eak3cVhk51ysx2nEOgnl6PXMi/MwPzwIJabqwne+l0YOomYtRLHkv/EqorBZrNhMpk4efIkLS0tiKJIbGwsxcXFFBUVERIyOYop2UaNdNbX0FFdScexo9jtgSqVWo+PCOQk5BeSfvudJMwuG/t9X/W5zOeGun/C4f+DgfoPfh4UBxEZgfYC4emBbVhKoMCJIRrUQVKE7iZGMm7jIBk3iamKpLELc7K7mY2/rUNlMXCsaCMPr13L6tTVEx69uhii10/fjt20OX+CLbiDmsFP8Fb7XPotXhZkRfL9tQUUJFz/i6ZrqTOj1cU/NjTRdHSQFKeATlTikbvoCD+OMsvB6sULWJ6+FKV88vapkrg6fFydiaKI89gxTK+9jmXzZkS3G+20aYQ98ACy+WU0VByi7dhR+ltOIQoCSrWGpPxppBSWkFI0nZjUdGTXICXwQqmUZxc2OdNqYHBwkH/5l38hJSWFqqoqnnvuOfR6PTKZjJSUlLHG4BkZGTzxxBO0t7djtVrR6/UYDIYxU3i+1EaPIFBrdXLIZOOgyUa52Y7dL2BQyHkqIYwvD6xHv/en4HPBvC/D4n8FdSDN3GazUV9fT11dHT09PQCkpaVRUlJCYWEhqmtsgC8VURQx9nbTfrSczv176O9sx0HArMqBqKgYkmbOxiQquP2xT6I6q7H6VRpAII1yuAlG28DYDsbWwHNr30f3V2gCBs4QCfrTZi4mH7JWSm0IbgIk4zYOknGTmKpIGrs4boeXdb86gLXTz96M19EVufj27G8zLWraRA/tori7Rmne8ysGYl/DJ+ipc32fl6qDsbi8PDQ7hX9dnUNk0PWLIF4Pnbm8ft6q7Gb91lZCRhzk+hRo/WocKgttKZWULE3lvsK7idJJJblvVq6GzvxmM+YN72F64w3cjY3I9HpC1q4h8tOfhvg4uk7U01lXTWd9zViqnS4klJJVa5hx6x3oQ659w/iLReM+3EPuw69v3ryZn/zkJ+cUPlEqlSiVSp555hkeeughgIsWPvEJItVWB3/sHmL9oIlghZxvRMl4suF3qOvWQUgirP4RZC4DlR4UapDJGBkZoa6ujtraWoxGIwaDgbKyMmbNmoX+KpXrv5qMnjhOy+vr6KmqYETwYtZpEeQyVGoNuQsWM23pShJzC679zTyPA0bbwdwF9mFwDAfSK+0jga1jGGxDYOkO7B8cH2hBkLUy0IZAqmB5wyEZt3GQjJvEVEXS2Ph4PX42/7GOznojdek7OBT3Hp8o+ARfmvEldMrJV3nyDKJPYGjPYZpNP8IZ3ohMmMd205O8VuVAr1Lw1RXZPDE/DbXy2hcPuJ46EwSRbQ0D/HF3MyOtFub43aS6QvHIXZyMO0zkHHiw9F5KoksmdfRU4vK5mjoTRRFXXR2jr7+O5f1NiF4vkZ/5DFFf/ALy09EWm3GEzuO1nDpygOaKwyg1GkpW3srM2+8hOOLiNwj8Pi9d9bU0V5aj1mrJKJ1NQk4+coXiou87w4WiceO9bjQaeeaZZ3jxxRfHvid8kGqZn5+P0WhkaGjonMImZ0fjzq5oKY9PZHN4Au+PWAlTKvihuov7qv4HxUDdB4OVyQMGTqUDlQ5RpceNmj6nmg6bEpMikti8eRQsuoPQuLRL/RVdN0RBwHH0KMa33qJtzy76gjT0hQfjl8kIjYqhcPlqCpYsJyTq3HV8Xo8bY3cXw10dYw8AQ2g4hvBwDGHhGMIiMISFYQiPICgs4soieZbeQAuC5u2BNgQuc+DcJ80OmLjC+yAy80pOhcR1QjJu4yAZN4mpiqSxS8PvF9j5YgNNRwZw5vXyUuj/khSayA8X/JCZsTMnengXxdNvpWXH7+mP/AeC2o7dfyuvt93D/lY36VEGvr82/5oXMJkonVV1jvJWVTeHKvvIs7jJc+sQZQKnoiqx5LVx15xbuSPjDlSKyZGuJXFlXCud+YxGBn/6LOZ330WVnEzc//t/BC1aeM4+I92dlL/zBg0H9iCXy5m2ZCWz77yPsLj4sX28bhftNVWcKj9Ea2U5bocdlUaL3+dD8PvQGoJImz6TjJlzSC+ZiTbo2pTbP5NqGRERgdlsZmRkhKGhIYqKigBoa2ujpKRkLHrX3t7Oww8/zPz584mJieGPf/wjhw4dQhCEMWP32Pf/Hz/vGGTriIUoJfyvUMNylQ21zwneMw/HB1uXCYztiOYuZGeVNXErDMgiM1FnLYH5X4Og6GtyDj4uezZvpsRuZ/iNf9LW0UxPRCgjQQGzlTKtmITcfEZ6uhju6sTU14soBtItFSoVEQlJyBVK7CYjDrMJwX9uIRiZTE7egsXMe+BRwuMSrmygfh/0VAZMXPN26D0GiJC6AGY8DgV3jaWzSkw+JOM2DpJxk5iqSBq7dERB5MCbzdTs6EIbJWN7+kvUKyt4JO8Rvl76dfSqyZfqcwZRELFUtNJx/AWMCRvxq6202e/jlZPLaRvxsyg7in+/rYDcuGvTXHeidebxCew7NcTGw13YaococClRiQo6wo5jjO/kriUruL3kFikCd4NzrXVmP3yE/v/6Lzzt7YSsXUPMd7+L6kPVEs2D/VSsf5P6XdsQ/AK58xeRUlRCW9VR2qor8XncaIOCyZxVRvac+aQWTcfv89FRd4zWygpaj1XgtJiRyeUk5haQMXMOJStvRa27evPL+VIpFy5cyJo1a3j++ec5fvw4OTk5Y/vX1dURGRlJQkLCWMVKjUaDwWAgPDwcv9/Pn/70J2bPnk2Vxc7P2vrZZbSSqdPwy7xk5oRdxIB6XWDqwNZZS3fNbuzd9YQLI6TRg6hQ4531ebTL/hW01z4F9VI4W2PulhZMb75F33sb6JT56IkKw6GUExoZRXRGNlEpaUQlpxKVkkp4XMI50VRREHDarNhNo9hHjdhNowy2t1K7fTOC30fh0lXMve9hgiOvUmq3pQ9qXoVjL4OxBdTBUHQfzPgkJJZKa+ImGZJxGwfJuElMVSSNXT4dx0fY/cpJbKNuPHkDvBz8C6JDI/mv+f/F3Pi5Ez28iyK4fIzuaqKn82WMqe/jVto5MvwJ3miYhc0jcmdJAl9fmUN61NW9EzuZdGZz+9hc2cPRHZ2E9zkIEgLRNqfeQkpeJDNKc0jMCUcfculNeSUmB9dDZ4LHw8if/sTIH55HptEQ/c1vEP7QQ8g+lOJoM45wdOM71G7bhNftIig8gqw588ieM5+k/MILpkSKgkB/yylaq8ppqapgqL2V8PhEbv/6d4hJy7h63+MSCp+cibjV19eTkpJCWFjYORUrz+Byubjnnnv429/+NnbsP+3cy08PVmCJTuDp5Yv5blYiesX4adlOp5OKigo6q3Yw3fQ+hTThkunpzXiIoBXfJDo+eUJvsJxPY6LXi23PHkbf+CeWA/tR+PxoCwoIvetOQm67DWXUpZsv26iRI2+/Ru32LcjkMqavXsucux+8emsnRRE6D0HVS3DinUD0Mzofpj8S6CUXVwTyS0vXlbh2SMZtHCTjJjFVkTT28fC4fBx+t5W63d2oQ2QczHyTo5o93J9zP9+c+U2C1dcmcnW18I04MW5qoN/6Jsb0TZjxsrv/CTY1F+AV4P7SJL66MpvEsKuzhm+y6qx1yMbv3jlBZ2sNaaKHBGsqGn8gshGZaCBlWiR5c+MnbSN2iXO5njpzt7XR/4Mf4jh8GO20aRjmz0OVkHDOQ24w4LRZsQ4PEZ2S9rEqT3afqGfjb57FabOy7InPUbxyzTU1LhcqbPLDH/6Q4eFhdu7cyX//93+j0+kwm804nU48Hg/f/va3+d73vjf2/m3btuEXRYb8IpZpMyj+6rf4VUEqZReLvn2I4eFhusrfI6rmOZLdJ7Fg4Kh+Bf7iR8jKzScpKem6V6UcT2O+4WEsGzdifnc9rhMnQKHAsGA+oXfdRfCKFWPrI8fDPDjAoX++yom9O1FqNMxceyczb78HreEqps+6LHD8rYCJ6zl9DawJgZS5kDo/kFaZMAOkVPLrjmTcxkEybhJTFUljV0Zfi5ldLzUw2u/An2Xk5fBfEB8ZzfOrnifOEDfRwxsXV4uJ0Y0NDCk3YszegNGnYO/Ql9jYGI8MGY/MSeZLy7KICbmy0teTXWcnei38bGsdBwffJUl3ikRrOtM989EORiAKEJseQsGCBLJmxaDWSm0FJivXW2eiKGLZsIHhPzyPp6sLvN5zXleEhqJMTECTmUXw8mUYFi1GEXT5NwEcFjObfv8L2qsryZm3iNWf/wqaa1iF8WKFTz5s7LxeL0lJSfzlL38hISFhLGJnt9sxGo2EhITg9Avov/F9LNNm8NmECG4Z7aOnve28FSsvhP3EVoRt/0Xw6HGMhFFOCU2KPMJSC0lPTyc9PZ2EhIRLOtaVcDkaczc3Y353PeYNG/D19yM3GNAWFKCIjEQZEYEiIgJlZASKiEiUEeEooqJQp6aeY/BHero4+MY/aDq0D43eQNGKW5hx6x2ERF3ltX/mHug4CB0HAo/hpsDPVfpAcZOMpZC7FqJzpbTK64Bk3MZBMm4SUxVJY1eO3ytwdFM7VZs7kGthd8o6hhNbeX7V82SEXb3UpmuFKIg4KgcY2VXPUMzrmJJ3YfYmsnvwy7x/Uo9CLuOJ+Wk8uSidmOCPZ+BuFJ1Vdhj5n82V1NvfQh1xCK1Pz2L77WT0z4BRDUqNnKyZseTPjyc+M1RaEzfJmEidiYKAb2gYb08P3t7e04/Ac1f9cfxGIzK1GsOCBQSvWkXQsqUowy+9TLsoCFRseIv9614kNDqW27/+HWIzsq7dF7oIFzN269at46c//SkDAwP4TxffcLlcZGRloSkt49jJkygHeknUaglRKy/aP+4jiCKc2oqw83+Q91cD0K9MpsaXTgNZODUxpKWlkZmZSUFBAUHXoLjLx9GYKAg4yiuwbHwPd2sbfqMRn9GIYDZ/ZF95aCj6WbMwzJmNfs4cNLm5yORyBtpaqHj3nzQdOQBA7rxFzFx7F3FZOR85xlXBNgSdB6H9tJE70xw8PD1g4PLWQvJcUEg3sq4FU8q4yWSyZOBFIBYQgT+Kovjri71HMm4SUxVJY1ePkR4bO19sYLDDSn94CxU563n29h9THF080UO7JASPH9uBXobLDzKQ8QqOyONY/TPY1v85Np3woZDLuL04gU/NT6MkOeyyjn0j6UwURfY3D/M/Ww/Q4tyLNqQJUd1JjC2F6SNLSRsqRu5TEhKjYcaKVPIXJqC4hLU7Eteeyaoz0e/HWVWFZds2rNu34+vtA4UC/ZzZBK9ciX7GDJRxcSjCw8e9GdBz8gTv/eZZnGYTSz7xWabfcvukuoFQUVHBF7/4RXQ6HSaTCaPRiN1uH6tYeay2FpdcgajVoYxLRO1ysOw/f8T8OWVk6zVk6tRYGurpbW+/eERupAVOvBtYp9VXA8CoPp3jQiaVrmTM8ghyc3MpLS0lMzPzqkXirmrLCa8X3+go/tFR/CMjePv6cRyrwlFegbcz0CNQHhKCftYs9HNmoysuxo5IfeVh6g/sweN0kJhXwMzb7iZzVhnya7k2zdwDTZuhcRO07QG/B7RhkHNL4BF0VobJmB5PbzVBEFsoReoug6lm3OKBeFEUq2QyWTBQCdwtiuKJC71HMm4SUxVJY1cXQRCp39PDoXeacXvd1CTv4InH7mBxyqKJHtol47d7sezqZODURgazX8WrH8StvJ39g/eyvs6Fze2jNCWMTy1IZ01hHKpLMC03os5EUeRA8wh/3t/KnuZ2tCGnSEnqxCmcIqY/g4KB+cTa0vAHO4leAmUL8kkLS0Muk0zcRHEj6EwURVzHT2Ddtg3r1q142trGXpOp1Sjj4lDFxaGMi0UVG4cqMZHgW1afE51zWi1s/r9f0lpVQUbpbGbedg/JBYUfaw3d1eZ8a+RKSkqYN28er7zyClVVVWi0WtyCSEx+AcahIaIe+yy2hcuxbn0Pz8E9+Lo60CiV6FVKZixazA9//D8UhwZduLiJsQ0a1geMXE8lAKPBuRxxZ3LMk4YmJJrp06czY8YMwi8jynk+rpfGvH19OCoqcFRUYC8vx9vRee7rchk9CTG0hRlwKmQYZAqmpWUz6wtfQpeWfm0H57ZCy86AiWvaDM7R8d8TkQElj0DJwxCWcm3HdxMwpYzbeQbwLvA7URS3XWgfybhJTFUkjV0bbKNudqyrp7vGzKiun7x7wrh/8dqJHtZl4TO6MG1rpnf0FUYy1iMoXSg0M6m1PMpb9aG0jziIDdHweFkqj5SlEBWkueCxbnSdNQ9a+cv+dt6q6sbt8zErx0ZmSjfeHisRtbmE2+MZMnRRm7GD6GwdxTHFlESXMDd+Lkq5lEp0vbgRdeZubcXd3IyvfwBvfz++/n68AwOB7eAgeL3Ig4KI/OxniPjkJ5EbAmvkREGgcuM7HHpzHR6ng5DoGAoWL2fa4hXn9I6bCC6USlleXs6TTz6JQqEIpE9mZDAwMMBzzz1HdkEBK1evpqGuHplKhahQ4tNo8fv9BH32y+gXL6cgLITpQVpC25qIHhlgZl7uRyNypk6ofwuq/wHDjQgKNR26YvbbUmklibT0TLKzs1EqlcjlcuRyOQqF4pzniYmJBAefv8DURGnM29+Pu6kJv8mE32QObM1mvCYTXcP9NDrMGOUiWo+P/KAwpj/4KGG33IpcfY2r4/p9gYinx3b6B6ev7c++xjd3Q+1r0L4v8O+0RTD9Uci/MxCNk/gIU9a4yWSyNGAvUCiKouVDr30e+DxAbGzszHXr1l3z8VwuNpvtmuRoS0icQdLYtWW42017hROdOwRnch/TZyWg1NxY6SJqC4S3uPCpDzKashOvoQ9BCOb4yN3s6CqlbliBWg7356hZmapEfp50mJtFZ1aPyK4uLzs6fZjdIhFaGUWRMnL8doI79CicWoZCO9iX/CaDwR3EKGNYE7aGUn2pFIm7DtwsOhtDEFD29mLY8B7amhr8wcHY19yKc9EiOF1NUfB5MbU1M9J4HEtXOwBB8UlE5k4jPDMHhfrCN1SuN4Ig8Kc//YmqqipEUUQmk1FaWsrnPvc5+vv7+fGPf0x7ezsazQdjdrvdhCckoYqNwx+fhNnrw9FQD6KAXiZj+owZfO9zn0Xz4WicKBJsbSaufwcxg3tR+ezYFWHUUMBRfw5GLhx5k8lkxMTEkJSU9BEDN1k1JooitoZ6+g/vxeJ2ovH6yDA5iMorxL1wIf6EK2zofRXQOgeIHdhNXP9OdK5+/HItQ9HzGI6ag1OXgFMXj6CYPHqdSCZSZ8uWLZsY4yaTyYKAPcCPRVF862L7ShE3iamKpLFrj83h4Fd/fJnQk+nItCK3f7aUtKKr1FT1OuLptmLe0YFx4ACm1J3YoqpAJuJS3c66k7eyr8VPWXoE//tACckR51a8u9l05vb5eb+uj63HB9h3ahib24dOLuc2QzDpgz5wCwTlCuwOf5uj7CUzLJOnpz/NytSVkoG7htxsOjsbZ3U1g7/8FY4jR1AlJBD1la8Qeucd5/SPs44Mc2LfLo7v2cFobzdKtYb8hUuYfdf9hMdN/IU7XLywyZmInFarxW63Y7FYsFqtFBUVERYWhtVqxWq1EhQdzaDXT4/Tg72liagHHue+u+/kyRlF+FtP0dLScu76OK8LGt+H6n8gtuxAJgr40pfjnvFpvMkLEUTw+/0IgoDH46G+vp5jx47h8XhITU1l7ty55ObmIpfLJ73GRFGks66a/X/9I/29XWi8PjIHTeQkphI8Zw6a7Gw0OTkoU1Px+n14HHbcDgdyhYLIpJTrs15SFKHrSCAqevxtcJ8VVwlJDKRVRmRAZCZEZgUqWqqnVkuWKRdxk8lkKuA9YIsoir8Yb3/JuElMVSSNXR/8gp+fbPol/h0xRDoSKbw1liV3TkMmv7GibwCeHhvWnZ1Ymk9hTtuLOWUPXkapsTzBC8dmAzK+f1sBj8z5oFHuzawzj0+gsmOU3Y2D7GocpK3fxmy3kjluFSoR5GECJ2MOcjh4C8mx8Xx5xpdZkrRkUhWUuFm4mXUGgYty+8GDDP3il7iOH0edlUn0175G8IoV56xvE0WR/uYm6ndt48Tenfh9PvIWLGbO3Q8QlZw6gd/g4pxvfdz8+fO5//77aWxs5MCBA9TW1pKYmAiAy+3m4OHD6JJSsIVG4OvuQOF0EKTVEhlk4JZVq/j1r399TiuDyj1baNn1Ipmm/cwMNyOPyoGypwLrr85K23M6nRw7dowjR45gNpsJCwujrKwMu93OypUrJ+T8XA6iKNJ1vI6D616k59RJNCIoPV58chk+uRz/edYLhkRGkbtwKblzFxKTnnl95iivC4YaAsVmjG1gbDn9vAUcI4F9QlPg9l9C9uQ/71eLKWXcZAGl/R0wiqL49Ut5j2TcJKYqksauH6Io8o+6Vzn6Rg9ZQzPRZwk8+vQSNPobs7mpt9+OZWcnjvp+TGk7GM58mxFPOK+2fJPKbg2Lc6J59r5i4kK1U0pn3aMOdjcOsa22j+EGE8VeBUk+BaJMZDCylWORuwjJkvFkyZPMT5yPRkoNumpMFZ2Jooh1y1aGfv1rPG1taLKziXzqKULW3HpOBA7Abhrl6HtvU7P1fbxuF9lz5lN2z4MT1kpgPC4WkTvTIy4mJga5XI7FYqGuro5p06bhE0Rq6urwKpQEmhCIqHw+yhYs4L3XXyMoKIjvfve77Nq1C7/fj0IuZ1lRIs+UmZH3Hws0np7xCZjzOYj4oLiH3++nsbGRw4cP09nZiUKhYPny5ZSVlaFU3hjrV7tO1FGzbROi34/S50fhdCK3WpEZTcgGBpENDeNVyukPDWI4WIcokxGs05M1bToFt95GbGHxxNxocpoCjcE3/1ugr1zRg3DrT8Bw42WsXC5TzbgtBPYBdYBw+sffE0Xx/Qu9RzJuElMVSWPXnzZTG797+RVSj5chGFzc86XZpKZP/mbdF8I7YMe6qwtzUwMDeS9hjazl0MD9vNqwGJVCwQ/umkaY6RTLli2b6KFedzpHHLxa0cmWQ10kmgSKfUr0fhkulZ3GqHK6Y4+TlZ3EkuQlLEpaRIw+ZqKHfEMz1eYz0efD8v77DP/xj3iaW1ClphD1uc8ReuedyD5UlMJptVC1aT3HNm3A7bCTPn0mZfc+TGJu/gSN/vI5X0Ru+fLlfO1rX+MPf/gDf/vb31AqlVjsDlyCgNPpRJmRw4q/vsqioS7e/I/vEhMdTWNjI0FBQfh8Pp5//nkWpWnhyB8Q6t+mssdDC2lkFs1m5op7kKfNHzMKPT09vPXWW4yMjBAVFcXatWvJyJj8vTrHQ7DbcTU24aqvx1R9jLZTJ+n2uxgJCpg4g18kNiyS4PR0QvLyMURFowsO+eAREnpNG8Ljc8O+n8O+X4AmGG59BoofvKnbC0wp4/ZxkIybxFRF0tjE4BN8/HnbP7C+F4LaryXzbj23r1480cO6InxGF5a9XfR3rmcw+2V6fVpeafwax4eDKY5S8N8Pzb3s/m83Cx6fwPaGAf5xuIPek6MUexRk+hTIRRkOrYmm8EpaoqqJSjawOHkxS5KWMC1qmrQe7jKZqvOZKAhYt29n5A/P4zpxAmVcHJGf+QxhD9yPXKc7Z1+3w071lo1UbnwHp9VC+vSZLH7s00SlpE3M4C+TC0Xkzo7GQaC4Q2d3N6UPPsrg3Y9S9967uF77O/ER4ZhbmwHwuFwkZmQyfcFCUvPyqduzna6aw6g8NpQ+B8vSFDyzUhNIp0yZCynzONwvJzyjlE2bNmEymSgsLGT16tWEhIRM5Gm56vgtFkYrymnas5OW1ibMTjseuRzxAun9kUkppM+YRUbpbBJy8lFci2jkwAnY8FXoroDMFYH0yfDJm/p7JUjGbRwk4yYxVZE0NrEca6tj4x9rCB9NwFXQy1Ofv5sg7eSrWHY5+C0eRvc30mH8Dcb4Xexsu5317cux+xQsyYnmqyuymZl6Zb2UbmTah+28WtHJu+XdRJr9TEdNvFNEJspw6a00hlXQHFlFaKKGb876JgsTF0rr4S6RqT6fiaKIff9+hv/wPM7KShSRkYSsXYs2Lw9Nbi6a7Czkpys2el0uqrdu5Mg7r+NxOJm2dCULHnyMoIjICf4WH48LReOeeeYZZDIZf965h+997auYFSr8w4OIDgei14MyPRt5UDCCzYqv7RQylRqFwUBmZgZ6Yz/Pf3UNsw29CO2HqGwz0jIqkJmRwfRVD1HlTmXrsQ4UCgVLly6lrKwMxYdSVW8WRK8Xe1UVozt3Mrp/P/beHjxKBUJiPEJGOkMK6OvpQvD70BgMpBWXklE6m7TpM9GHhF69gQh+qPgL7PgBiAIs/lbAVIckQHA8KG+O1HPJuI2DZNwkpiqSxiYep8fJH59/F+XxGEbCupj5cAJrS1be8BfrgsNL38EttLp+illtZF/rHWzuXYDZI2dBViRfXZ5NWcaNeZF4NXD7/Gyu7+eVw53UtBrJE5QsUOsxmLwggNUwzNG4rUQUKvhm2TfIi8ib6CFPeqT57AMcFRUM/+lPOMorEF2uwA8VCtTpaWhzctHk5aHNz0M+rYDy997i2OaNyJUKZt1+D7PvuBe17hqmvl0jLrY+7oyx27pjBw6vH5kMMvLzKV2wkNaGBo4dPEB3awtqrRavSoMnJQPZyCCPfu0bPPPYQzz92c9w6uRxfHYjepmbZQkunlmpQYjM5YQsm30jkRCdxy233EJm5nUq7DGBeDo6sO3ejXX3bhwVR8Hnwx8Whq20mKGwYLqH+nBYzCCTEZ+dS+bMMrJmzSUiMenqnBtTF2z8Fzi15dyfG2ICJi4kEUITQR8Faj2odKA6vVXqPvh3VDbowq58PFcZybiNg2TcJKYqksYmD5u3HqJxvQlRkNGXX8vjD66hKLZoood1xfhcLire+wU+/ftYlSPsa13L5t4ljHoUlKVH8NUV2czPjLzpL3QuRmO/lVeOdPBWVQ8+p4/FegPT3QrEUS9OlZX6uH0klwXxpXlfIM5w466HvNZI89lHEf1+PJ2duBsbcTU24j7ZiLuxEW9vLwDqrEzi//M/8aQks//Vv9N4aB/60DDmP/AoRctvQX4TRZAuZuz27NnDF7/4RRQKBVqtFl1EJPXdPci+/F30nS2M/P7nBGkD0Zzo6GgEn4c/fvNuFqnqofMQIDIij6ZOyKAveDqJs9ZSMn0GoaFXMdo0SfFbrdgPHMS2eze2vXvxG42Icjnu6UUYU5PocdsZ6ukCIDw+gcxZc8mcVUZCTh5y+RXoSxQDFSjNnWDpBXMPWHoCzy2nn7vM4xxEBnGFkLoQ0hZA6gLQR3z8MV0lJOM2DpJxk5iqSBqbXJiNdl7/8148rRoGDZ34F3fz9IrPkBA0OXowfVx2797N4sUL6al/i86+57HIezjQtopNXSsY8aooTAjhiflp3FGSgFZ181woXi52t4/1Nb28fLiD4z0WslCwSqElyCjgk3tojqkke3Ekn1n4OEHqGzul9logzWeXjt9iwX7wEIPPPou3t5fQu+8m5tvfYsg4xJ6XXqDn5HFCY+PImlVGanEpSfnTUGm0Ez3sa8aFUi3v+u6/8+iTn6dzy3soNRo0oohBrcLlcpGTk8Ott97KrIIMSvX99B5dT2tDDVnhcnISgmiRZWKJm0/svAfJnjbjhqlCeSWIgoCrrg7r7t3Ydu/B3dAAgJCXi2l6Ib2ij+5TJxH8PnTBIWSUziGlqISI+ETCE5KufpETvw98TvA6wes4d+u2QV81tO8PrJvznY5MxxQEDFzaQshaESiIcp2RjNs4SMZNYqoiaWzyIYoix8u72L3uJKJTRl3SbgpWxfDZGZ8hWH39/4BcDc7WmSgKDHRspq35d5hp4XDHUnZ2rqTTrSdCr+LhOSk8PjeVhDDdRY95MyOKInU9ZtZVdLG+uheNw89SuYw0ixKZKKM38hQheVBQlMa8nFlE66MnesiTAmk+u3wEp5Ph5/7AyF//ilyvJ+Yb3yD0gftpPXaU6i3v0d1Qj9/rRaFUkpg3jdTiGaSVlBKdknZO77ibgQtF5I4cOcIjn/ksQwI4bVbkDjtqn5cZxcWEhYUhiiIjIyP4fD78XjcKr535qSp+MnsUvcyFDwUdJHNUyMcUOZMZ85Ywa9assWjfzYy3vx/rtu2Y39uAq6YWZDJUc2ZjmVFEr+Clva4at8M+tr8hLJzwhEQi4pMC24QkEnLz0Rqu8Y0qnxt6qqBjP7QfCDQI9zpAoQmYt/w7IXfNdUurlIzbOEjGTWKqImls8uKye9n2ai2dR82YtANU5b/PEysf4M7MOyd6aJfN+XQmiiLGoX20NvwWs6+KkyO57Gm5g0pzMjKZnNXTYnlifhpl6RFTOo3S7vaxsbaPdRWdnGw3MUtwUuLWofUGjK1FM4wlaoCwdBXTitKYmzOLKN3N3+fofEjz2cfH3dJC/w9+iKO8HG1xMfH/9Z9oCwrwetz0NBynvfYYHbXHGO5sB0AfGkb6jFnkL1hKcmHRlaW8TXLOjsb1WqyYZArElAxyZ80krbudkfZW+vr6yM3NRS6XIwgCjY2NJCUmUJQWTazYT3llDa1DTuRyGS5VOLMXreL/nntuLJXyjGlsaWkhMzPznDTOmwVPezvm9zZi3rAeb0cnMo0G/dKlsHgB7vg4RocGMPZ0Y+zrZrS3B5fNCoBcoSClsITssvlkzZqLPjTs2g/W74WucmjYAA3rA2mXchVkLIGCuyD3NjBcuzXaknEbB8m4SUxVJI1NfrpOGNn6Yi0uk0BDzCGil4h8Z8m/olXeOGlL4+nMZm+hu+El+kffZcCjYE/bavb1z8HqU5EXF8zTy7K4rSgexQVKUU8VGvutrKvo5O2qHpQ2D+kyO7kKGZG2YNTewPobs2YYW0w/0xYmce+CNeiUUydyKc1nV4Yoilg2bGDgp8/iHx0l7KEHCb3jTnQlxWONvW3GETrqqmmvqaK1qhyP04khPIK8+YvIW7CU2Iysm/JGyxljtWHDBm657TaOx6fx684hhj1eMndsYHT9G2SlpY3tf+zYMWJjY0lISMBkMlFXV4dKIUPmsaEQfXhEBXPmzuexT3+eoqIiXnzxRfbs2YPf70epVLJs2TKeeeaZm868QUBnrtpazOs3YNm0Cb/RiCI0lOC1awJ6mzEdmUyGw2JmpLuT1qoKTpUfxDzQj0wmJzGvgOw588iaM4+QqOvQ+1IQoLcKTrwbMHGj7SBTBEzcjE9A3m1XvZqlZNzGQTJuElMVSWM3Bl63nyMbWqje0YVX5qY7u5qvfPIx0iJvjB42l6ozQfAw0PY+Xa0vM0I9R/pmsb1tDd3OMDKiDHxlRRZ3FCegVNx8FzOXg88vUNE+yvaGAbadGKBzxEG0IDIz2EuyTyBoJAilX8VwcDdhpSIPrFlNQlj8RA/7miPNZ1cHv8XC0K9+xejrb4DPhyIsjKAliwlauhTDwoUoggMp216Pm7aqChr276bt2FH8Ph/h8YnkLVhC/qKlhMfd2Gtzz8fZGrP5/DzXNcivtu5i6Jc/Jjk2lswgHSqgra2N++67D0EQ2LVrF8ePH0erPX2zzevAZbdxf5Geex58hHdPydi0aRM6nQ6z2UxoaCiiKPLzn/+cO++8E1EUb9ponOj1Yj94EPP6DVh37EB0uVAlJxN6x+2E3HEHmvT0wH6iyHBnO01HDtJcfpDhrg4AYjOyyZw1h8yZZUSnpl/7mwaiCP21cGI91L4eKIyii4CSh6H0kxBzdRraS8ZtHCTjJjFVkTR2Y2EacLD+lSNYm0RsmlFy14Rz1y3LJv0d7o+jM7uplY6av9PvepeKkUzeP3UfHc5Q0iL1fGlZFnfPSEQ1xQ0cBC5oTg3a2HZigK0nBqjpMqEWRRbpnORYlAQ5QnEp7bizB1l160xm506f6CFfM6T57Orit1qx798fqBa4Zy9+kwmUSvQzZxK0dCnBy5aiPh1lctlsNB05wMn9u+lqqAdRJKmgkBm33E7mrLnXpiHzBHA+jQ243Nz1la9TtXcviAJBKiWLli7jxV/+nFC1ivLycj7/+c9jMBjweDw4nU6Mw4P8x4pQvpg9yN8G8vnRln7sTjdWayA90O/3k5CQQE5ODmazmaGhIbRaLRqNZqw/3c1i3s7gt9mxbtuGZcN67IcOgyiiLSxEnZJ8eo/Tf+dkMixeDz0uK91uOyMuBwDBkdEBE1c6h6RpxShVqms7YEGAtt1Q9SI0vAeCF5JmBwzctHtB8/HX5UnGbRwk4yYxVZE0dmNSfayJLf+oIcgaiRBr474nFpGQMXmbWl+JzjwuE82V/0uv4w2qB4vZdOo+WlzBJIXp+NLyLO4rTUKtvLkuYK6EQYuLLcf72VDTR3mbkRRszJN5STLFIkeBKaabggUJrF26BI3mGl/YXGek+ezaIfr9OGtqsO3ajW33btynTgGgzsggeMVygpYtH0uptI4M07B/NzXbNmEZGiAoIpLilbdSvOJWDGGTd566FC6kMUEQeO/AIV45VkutIRxjWg46pYIVkSHcGRXKnp//hL27dp3bHPzHP0J+6DdUvPIjnt7oRBubyYDVx+joKHa7nZiYGERRZGBgAKVSiUKhIDg4GL1ez7/8y79QWlo6ZuZOnTrF8PAwBQUFN0VEzjswgGXj+1i2bEawWAORLhjbigS2/hEjTpeTkfQkRlKT6TOP4PN4UGl1pJXMIGfuQrLnzL/2Nw7sw1CzLmDihhtBHRSoTqkNAU1IoDLl2PPT/85cFug5dx4k4zYOknGTmKpIGrtxcXnd/ObVvyOriEHvDSF1ZhjLHpyGIfTq5tpfDa6Gzuz2dpqqf8yIayfHe8vYeOpemjw6ksJ0fGdNHrcXx0/6yOP1ptfkZGNtHxtqe2npHmQGIxTbozF4Q/ApvARnypi/sJCM4hjU2hs/IiLNZ9cPT3d3wMTt2om9vCKQUhkREYjErViOYd480GpoO1ZJ9Zb3aK+pQq5QkjN3ATNuvZ347Lwb8v/rpWhMFEUqLQ7eHhhl/ZCJIY8PgwxKBzrJt42wtmgac86qKin01fHdJ9ays74XQaFFbohkzqIVrLnzXv7617+yffv2saInoaGh+P1+5s+fT2FhIV1dXezduxez2YxcLketVjNjxgy+9a1vkZycTHx8PGq1+jqcmYlBcLuxbt3K6LrXcFZWIqjVOBbOYzgxlo6uNuyjRoIiIpl+y+0Ur7wVXdA1rswsioGiJtWvBNbCuS3gtoLr9Nbn/GDfx98KVKw8D5JxGwfJuElMVSSN3fisb3iPjW8dYVrPIpRKBQvuyaJ4SQqySVTI42rqbHS0nKbj/43VfYKmzqX8s+UOWn0qSpPC+Pc7CyhNubHv6F8r2oftbKjpZX11F17zCfIEJ5nmbPTeEFCIpBZGkl0aR1pxFBrdjWnipPlsYvBbLNj27cO2cxe2vXsRrFZkGg1hDz1I9NNPowgLw9jbQ83WjdTv3o7H6SAqOZX4nDxiUjOITk0nOjUNte4q9/C6BlyuxnyCyCGTjbcHR9k4ZMbs85OgUfFQXAQPxUeQpgvcaBO8bipf/TGt+98iQ2xnZqIaee4tVCjn8MWfvkJwcDA2m42QkBDMZjO//e1vKSws5Otf/zpvvPEGqtNpgWq1Gq/Xy+rVq8nOzkYulxMZGYnL5cLj8TBr1iyWL19+U/aUc586xejrb2B+5x0EqxVVRgbm6YWcHOql3zKKUq4gIzaRgpQMQoNCkSnk6EpL0U2ffv1uIvg8AQPntkBQDKgN591NMm7jIBk3iamKpLGbg+bRZv57y09JqJpJkiUHRZybOz49m8TUyVEW/mrrTBQF+gfW09z0LC7vIIc6lvBW61pMPi23F8bynbUFJEdM/ovAiUAURY73WnjjaCfrm7YTITtOti2RDOMMDJ4Q5EoZidlhpBZGkVoYSVjsjXMepfls4hG9XhyVlZg3bMD89jvIg4OJ/tLThD/8MDK1Go/LScO+3TQe2sdQeysuu23svaGxcUSnpBOdmk5MeibxWTmTLrXySjTmFgS2DFt4tW+EPUYrAjA31MAj8ZHcHhOK4XTlTgZPBiI2NesQbAN8d4+cnb06BG04crX+nDVu9957Lzt27Pig8AngcrlIT08nKyuLhIQEamtraW5uxu/3I5PJyM7O5sknnyQtLY3k5GQSExPHjN/NgOB0Ytm0GdPrr+NqaEAUBCwqOe2RIfSGBSPIZURb7KQPmYm0OdEW5BPx6KOE3HYbct3kqMIrGbdxkIybxFRF0tjNgyiK7O/Zz7vv7yautgSNX4d8uomHHllBVEjEhI7tWunM73cxPLKT/vZ36TEeZlPnYra0L0dEyWMzDXxj7QJCdZMvdXSy4PEJ7Dw5wAuVW6m3v0mCIJIxPItMSwlBjhAAgqM0pBdFk1oYSUJOGErV5O3XJc1nkwtXYxODP/0p9oMHUaemEvOdbxO07INiSqIoYh0ZZqij7ZzHaH/v2Fqm4Kho4jNziMvKIT4rl5iMTNTaibu4vloa63V5eKN/lHX9I7Q5PRgUcm6PDiNbryFKrSRKrSJKLpLYvZew2lep3ruR1hEvGVk5zLzjSeQlD0JQDBUVFTz11FNotVosFgsmkwmbzUZRURFhYWGYTCYGBwfJysrC5/PhcDjo7u7m7rvvHqte2d/fD8CSJUu4//77b+rUSptxhJqt71OzfRNOqwW9Vk+MzUFEVx8xcjVRd99N+CMPo06d2IrNknEbB8m4SUxVJI3dnFS0VbHttRpC21OxaIdRLRvh8ZX3EGeIm5DxXA+d+Xx2+pvep/7EFl7sTuJg/2yCVXYenW7j8yvXEhk6Md/9RsFo9/B/h7bxXsfrWMUWQv0KUkwFpIwWkGjJQSmoQCkQmqlk6R3FJGVN7M2A8yHNZ5MPURSx793LwE+fxdPain7uXGK/8220+Rcum+51uRhsb6W/pYm+U430tzRhHhwAQCaTE5mcQk7ZAkpWrbk+zZjP4upnD4gcMdtZ12dk45AJq184737JfjOPjezinv4tpI6eQJQp8GetQF70EN998SA7d+8dK3wya9YsVq1aRXV1NVu2bMHlcpF6lhEpLy8nJSWFBQsWUF1dTVtbG36/H0EQyM3N5T//8z+ZM2cOev2NE22/XHweD42H9tFy9AgddcfwOJ3IgXCbk2iLndTsfFIeeRT9rFkow69/1FcybuMgGTeJqYqksZubw0frOPJaB0qrnlPRRwlZ6OKx2Q+RG5F7XcdxvXVmb+tj164NPNcr47gtAZ3SyZrkPr6wZAE5eaXXbRw3KmaHl22NLWxrrqJmsB6rr5tkr4o0WxJZw6XofMH4Es3MuzOLOSVFEz3cMaT5bPIier2Mvv46w7/9HX6zmdB77iHqqc9fcmTDYTHT39xEX3MTPQ31dJ2oQ6FUkrdgKaVr7yQmLeMaf4MA11Jjoiji8AsMe32MeHwMe30fPPf46HC5qbE6CTae4v6Brdw/sJUEzxB2RRCbZLPp1xUyZ8FtzJpTNlb45ODBg3zta18jJiYGuVyOz+fj8OHDFBYWAlBXV4darUYul6NUKnG5XJSVlTFjxgzKysqYPXs2XV1dN2UPuTP4fV56Gxtoq66kteIwI309AGg9PgxuDwaFkuCwCEISEgnPyiayqJiI4ukor6GxlYzbOEjGTWKqImns5sfn9bPr3Xoadw0hCALHY/ejnGnisZkPMy9+3nVZlD1ROvN0WzlwsJI/t57ioCkOuUxgYVQrn05LYu6MVWhSQ5EpJk8Rl8lKr8nJgeZh9jZ3caDjCLkOJzNHCtH5ghiO6iB5mZY7568iSjexayql+Wzy47dYGH7uD4y+/DKi30/w6tVEPvkkusJpl3WckZ4ujm1+j+N7tuNzu0nKL6R07Z1kzipDLr926byTQWMDbi81VgfVJivetr1Ma32XVQN7MAhOjKowGpJXIObfQW7hLURqtHz3u99l586dCIKATCajoKCARYsW8dZbb3Ho0KGPrI9LTU3lySefxGQysWXLFvr6+hBFEZ1Ox/Lly/nFL34xlk4pCMJN1xzcMjxIW2UF7fv3YBrow2az4vL7zt1JFNEiQxsUjCE2Dn10NLqgELTBweiCgtEGh6APDUUfEoY+NPC4nL5yknEbB8m4SUxVJI1NHaxGFwc3NNF8eAif3EtN3C7sBZ08Pv1Rbk27FZXi2i1Onww6a2rs4Hc797C5KxiPoKY4rIWHtTLWzryD0PmpkoG7RFxeP5vq+/jHwRMouzuYZUlA69fREXYcf2k/y2bNY1HiIkI1odd9bJNBZxKXhndwkNGXXmL01XUINhv6eXOJfPJJDPPnX9bNJJfNRt2urVRveQ/L0CAh0bFMv+U28hcsISgi8qqPezJqTBRFuiyjdNZvRH3yPab17sHgd2JSBlEet4SRjDXYfbEYjEayzjJXZ9bH6XQ6bDYbNpsNo9FIUVERW7duHWscLpPJ6OnpGUunTE9PJz09ncTERE6cOEFXVxcqlYrg4GBWrVo1VjjlZjJ1Po8Hy0AfxuP1jJw8gbmjA0tvNy6zGY9Cjs+gw6tW4/b7EIXzp7tqDIYxI2cIDWPO3Q8Qm5F13n0l4zYOknGTmKpIGpt6mAYcHF7fTEvlMF6li6qEbfRnNPBEySd4KPchlPKrXyZ6MulsxGbjD1u381q1F4tHj17hYoZGwbLSXJbMTiIrJuiG7C81ETQNWHn1QDstR5opserQCmp6g5vpCj+JIV1k5rRCliYvITMs86aO7Ep8fPw2G6bXXsP4t7/jGxpCU5BP1JNPErx6NbLLKFkv+P20HD1C5fvv0nPyOMhkJOVNI3feIrLL5l+16pQ3gsb8Xicd9Ztx1b9DSucOgrxWrAo9u+KWIyv9JMtLVmBQKhEE4ZxonFwuZ+nSpXzlK18hNTWVdevW8eyzzxIfH095eTl+vx+Xy0VERAQGgwGXy8XAwABqtRq1Wk1OTg4ej4fnnnuOmTNn8oUvfIHy8nLkcjkKhYJly5aNmbqbBW9vL5YtW7Fs3oSrphYRkOfnoV68CHlRId6QIJxWCw6TCbvZhMNixmEexWEysfoLXyMx9/xrPSXjNg6ScZOYqkgam7oMd1s5/G4rHXUjeDVODiS+A3km/mPef1AcXXxVP2sy6szp8fHmka1sr6mifiSZYWcgzS86SM38rCgWZEaxJDea2BDtOEeScHr8bKjs5uCWNkKHHcT4AufMqbTRHdqILbafjGlxLM6bx5y4OagV16Zq3WTUmcSlIXg8WNavZ+QvL+BpawOVCkVwMIrgYOShoYFtSDCK4BAUIcGo09PRFhahycpEpjg3NXKku4vGQ/toPLQPY08XMpmcpILCMROnD/n40eAbTmM+D86W3Qwee52YU++h8ztp1qfRmf8gxQs/TURoHJWVlbS2tpKRkXFOVKyiooKnn36a6Oho3G43brebwcFBHn/8cVQqFdu3b+fMtbPf7yctLQ2A//iP/yAjI4Pbb78dURRRq9UYDAb8fj8//elPufvuu1EoFONG5G60iN2HTRyAIjQU3exZGGbPRj9nDprcXGSX8B0k4zYOknGTmKpIGpPobzVz8K1m+prNdMXWsy31Je4puIuvln6VEHXIVfmMyawzv99Ba/NvqDz1Do1DBbR2L6feF82I24daKedrK7L5/OIMVIrJe8EwmajpMvH3nS2cqh0ixecnU1Ci8QbScI26PvojWojM0jB3VglL0hZhUJ2/Ae3HYTLrTOLSEAUB265dOKur8VutCBbr6a0Fv9WK32pBMJkRvV4AZDod2oICdIWFaIuK0BUXoUpOHovwDnd1cPLgXpoO7mO0vxeZXE5a8Qzm3P0ASfmFlz2+G1ljostC29HXEKpeJMtYi1emoCFxGRFlnyZp2hr40NrA80Xkzu4hd8bYRUVFYTQasVgsmM1mvvjFLxIREcH3v/99NJoP2rG4XC6ysrLIyMggNzeX2tpaOjs7zxuRO/PZu3btwu/333ARO29fH/bDR3BUVOAoL8fb3Q2APCQE/cyZ6OfMIeTWW1DFx5/3/ZJxGwfJuElMVSSNSQCIgkjl5g7KN7TiD3byZvpvESOcfGv2t7gt/bYrTnO7EXRms5/iZN2/Y3YcRWPKwNP3RV5TJ7KlZZiC+BB+el8xRUnXf93WjUq/2cWLh9r5x5FOVDYfZXot2XhRDCmQCXL8Mh8DIW0oUlxMK0ljVekiIvRX1mLgRtCZxJUjCgKe9g5c9XU4a+tw1dUFGi17PADI9HpkMhmiz4fo84HfjwhYtWr6woLoig7DI5eRlF9I2T0Pklo845LnuJtFY12dtbQd+DPTWt8h0mtmWBeHedZTZCz8HDJN8Nh+Z6Je54vIfdjYyWQycnNzmTZtGm1tbWzbto2IiAjcbjcWi+Uj/eXq6uooKSkhJCQEQRAYGBggOTkZuVyOxWKhqqoKvV6PRqNBo9Hgdrv5/ve/P9aD7oaKxvX14aiowF5ejqOiAm9HJyl/fQHDvHnn3V8ybuMgGTeJqYqkMYmz6WkcZetfjuNyeGictpcdujcpiy/j+3O/T3po+sc+7o2is0Az2nc5dfLHeIVRQnsWccJyG78ZCWHU7ePJhel8fWUOOvXkbUI92XB6/Lx1rJsX9rfRMmRHKUKhWk2OwkmkVSTIHrhIdCptOOOHmLc6j5WzF3ysz7pRdCZx9RG9XtynTuGsq8fd0hwwYkolMqUKmUKBTKUM/FsuZ+jVdbR6HXSkJeBwOYnNyKbs3gfJmlk2bhrbzaaxYaeDg0feIL76BWabqjGrQmgv+hTZy76GPnj8KrHnM3Yul4t9+/bxox/9iJaWFvR6PUFBQSxcuJC77rqLhoYG1q9fz9GjR1mwYMGY4erp6SEoKIjQ0FB6enpoaWn5SMXLrKwsfvSjH7Fr166xaJzf72fRokX85je/mdTm7Wy8AwMowsORX6DZuWTcxkEybhJTFUljEh/GYfGw7YXjdJ8cRZPv4u+RP8UuWnk472E+W/hZInWXX6ntRtOZ12uh5dQv6O1/DREPbmsCbzU+znZjEikROp65r5j5mRNb+v5GQxBEjrQZqe020ThgpbHfyqlBGyqPnzSspIseMhxRaPw6rJGDzF2TxZL5M5HJLz3ae6PpTGJi8JvN9Hz721j27sW4bBFNcj/moQEik1Iou+dBcuctQq44/82Zm1VjbkFgX80O9Id/w/yBvTjkWupyHiR1+TeJi/l4N+1MJhMvvPAChw8fJjQ0lDlz5jBz5kymTZtGbW0tTz31FPHx8WOpkQMDA9x3333ExsbS3NzMK6+8gsFgwOPx4HA4cDgcFBUV8aUvfYmf//znY73pTp06RX9/P6tXr+aOO+5gzpw5ZGVlUVVVdcNE5D6MZNzGQTJuElMVSWMS50MQRI6+307FxjZCYjS0ztnHWyOvolFoeDTvUT417VOEacMu+Xg3qs58PhtDg9vpa3kbk/swJ0bTefH4Ywy6Iri30MDX18wmOUIvVaH8mPj8Ah1GB439Vk72W9l3ohvlwElm2mIJ9oTjDrEwc3U6C5cWoVBO7gX9EjcWoiAw/NxzDP/u96hysnF++hNU7tvJSHcnupBQcuYuJG/BYhJz8s+Jwt3sGhNFkZrWKux7f0FZxyYEmYyK1NvQz/4MBTlz0aguv1iTzWajpqaGY8eOMTw8jEqloqCggC1btnD06NHzrp873/q6hQsX8rnPfY7Kykp+9atfkZiYiCAIHDt2DLvdTlZWFgkJCYiiSGtrKzabDZ1OR1BQECtWrLhh1seBZNzGRTJuElMVSWMSF6PrpJFtfzmO1+0na2UYW4NfY1PnRvQqPZ8o+ASfLPgkwergcY9zM+jM4zHR37Cejs73ebk7ka0dSxGRY1CJ5CWEkR8fSl5cCPnxweTGhRCkufptFW52RFFk76lhfrWtFt9gNbOssUQ5EvDpXJSsSGb+inzUuguf15tBZxLXF9vevfR869sgCMT/9BmGQg2c2Leb1spyfB43QZFR5M5bRP6CJcSkZ7Jnz54po7Ge/ma6d/2C4lP/RCe4ccnVtEcU4kkqIy5rITGZC0B36W0WRFGkq6uLY8eOUV9fPxZJMxgMLFiwgBUrVpy3quSH19edKYpyJuJms9no6Ohg7ty5WK3WsfVzarV67KZaZGQkf//735k9e/Y5x56sETnJuI2DZNwkpiqSxiTGw252s+ulk3TUjxAcqSVtpYF3+DvbOrcRog7hU9M+xWP5j6FX6S94jJtNZ/b+Hg7te5sDo410ePV0W1PosSdj936QXpUaqefeGUk8PjeFyCDNRY4m8WFEUWR/8zC/2HYM28hhZlljSbJkIyj8BGfIKC5LZ9rMVDQfMnE3m84krg+e7m66v/pV3CcaiHr6i0R96Ut4vR5ajh7h5MG9tFdXIfh9hMXFo0tM5c7PPU1Q+JUV0rmRcFiHOXV8K9a2g4T3HSXX0oQSPwCDoZn4ksqITJ+HJrUMIrPhEgyQ2+3m+PHjHDt2jK6uLgDi4uIoKCigoKCAqKgLp6ILgsC3v/1ttm/fjs/nQ6vVjkXrTCYTP/vZz/j73/+OKIoIp5thx8XF8b3vfY+HHnoIQRC4/fbbaW5uRqVSodVqz4nITQZTJxm3cZCMm8RURdKYxKXS1WDk4FvNDHfZiE4JJmmVin9Y/sye7j2Ea8L5dOGneSj3ofMauJtVZz6bh77D79FregVreDWjzijM7tsw6ZZT06di36lhNEo595Ym8dmF6WTFBE30kG8oRFHkUMsIP9tRztDoLgqdwaSPFhLkCUOQ+RGTbKRPj2LxwhmEhgbdtDqTuPYILhf9P/xvzG+9hSo1hdC77iL0zrtQJyXistk4VXGQxoP76KirRqlUUbJ6DbPvvP+qNfa+URBFkTazkRONB3C0HyJmoJIZ5uOE+m0AOFXBWGKK0abMISStDFnSbDBcfD2wyWSioaGBEydOjJm4mJgY8vPzyc/PRxRFhoaGznkMDw/T29vL6OgomZmZfPrTnyY3NxeZTHZOmwK73Y7D4QDgueeeY/bs2ezdu5c777xzLCJ3xuDdcccdzJo1ix07dnDy5EnUajUqlWpC2hBIxm0cJOMmMVWRNCZxOYiCSFN5P4ffbcU26ia1KJLIpX7+1vs8B3sPEqGN4DOFn+HB3AfRKXVj77vZdSZ4/IwcraCr80VMEbsRlW6C5cV4wx5hfXMmb1cP4vEJrMiL4bOL0pmXESmti7tMDreO8NKhVra3VBErG6DApyfVlEqIOxIBP/aYIYT4UR57+A5Sw1MmergSNyCiKGLdsoXRV9fhOHIEAP2cOYTefTfBq1ejCDKw+d23oaeDE/t2olAop6yBO4PDL3Bk1EJLZz3urnLCB6opshynwNaKgkC0y2pIQBeVgTI8FUKTISwFwk5vQxJBoRo7nsViGTNxHR0d53yWTCYjMjKS6OjosYff72fPnj2Mjo6SkpLCqlWrSExMvGj/uV/96lf88Ic/RKX64HPPVKzU6/VjaZYlJSWo1WoGBgZ47rnnmD59OiqV6rpE5CTjNg6ScZOYqkgak/g4+Dx+and1U7m5A6/LR+68eBRZNl41/4WDgweI1EaOGTitUjtldCYKIta6NrqOv8xI8Ga8hgFkohKZcgUHRtfyVp0ao93LtIQQPjU/jVsL4wjWqsY/sMQYZoeXDbW9/LOym+quARI1/cxUKEgcjSbIGYZDZWEgtZH0eWEsz1tMXkSeZJIlLhtvTw/m9esxvfMO3o5OZDodIatX0ZaezvynnsI00MeRt14PGDilipJVa5h9531T1sCdwS+KNNpdHBseYqijAmVvFQmjDaS7B8j2DmJwDCHjrOt/mRxip0Hxw1D0AATHjr1ktVppbm5GrVYTHR1NREQESuVH17j6/X4qKyvZs2cPdrudvLw8li1bRmdn53n7z1VUVPDFL36RkJAQ3G43TqeToaEhFi5cSFtbGw0NDeh0OmbNmoVMJqOnp4dvf/vbbN68mcjISJqammhvb0epVKJUKj8Skbsaxk4ybuMgGTeJqYqkMYkrwWnzcPT9do7v68XvFVBqFASnyajRH2CP7H10YUo+W/hZYvpjWL189UQP97ohiiLuDsv/b+++4+O87jvff870XgAMegdR2RtIsYmU1SWr2SrudmJbm13HiTfJde7d3WSzN3tzN8ndZLObOLZjx2Vl2XKXZVtdFCmKvZMASILoHTPA9D7z3D8AUZQtiSokCvF76zUvYJ555pkz0E+P5jvnOefgP7GXifCviRQdIGsJkss5OBX6KL/sWUnvlIbJoGNnk4+7VpXxgdYSmdDkXeqeiPLjY0P85NgQ46EUdUTZnNdRESkgr/L0FJxgtPYsa1Y2c1PNTWwo2YBeJ2vwiXdO0zQSx08Q+tnPCP/61+QjEcwtLRQ9+nmct95KcHKcgz/5AR17XkJvNNK2Yxc1K9dQ0bJ8yYe415yMxPnb3jGeC4Qp0ef4Y2+OD1ujWMPDEByAiy/A8FFQelj2AVj9CDTfCUbrlQ9+mVQqxYEDB9i3bx+ZTIa1a9dy44034na737Dfm81Y+VqP3JEjR3j00UdxuVxvWBj8P/7H/8g3vvGNN0x8otfrMZvNZLNZPvvZz7J9+3ZuuOEG/vN//s+X1pjT6/XvKdhJcLsCCW5iqZIaE1dDJp1j+Nw0/WcC9J8OEJlKApBwTdPlOMpUcT9/+eH/QFtR2zy3dO7l0znip8aZ7NxNIP8CkZLDZI1xBsIrOBt7kH39xYxH0pgNOm5qKeauVWXc1FKMzSQh7p3K5WfGwv345WNEjAX094WonE6wMmXCrBmYtA9xpnQPId8Ed628mQca76PaJZdTincnn0xy6L//Hb69e0n39mKqqaHw85/D/cEPEgxMcvCnT3Bu/ytk0ykAPKVlVLQsp7JlORWty/GUlC3p3t9j4Rh/2zvGi1MRCo0GvlBdzKcqirDpdTB5Dk5+H079AMLDYHbD8vtg9UegejO8i79bLBZjz549HD58GKUUq1atYsuWLfh8vkv7vNWMlW8V6r70pS/x61//mh/84AccOHDgTRcGLy8v58tf/jJf+tKXLs14ef78eRKJBJ/73OfYuHEjXq+Xb37zmxw+fBjgTYMdSHC7IgluYqmSGhNXm6ZpTI/GZ0LcWT/DF4KQh4B9hJpNLh65+w7MtqV5eWA2kCBydIjJiy8wVfAsMd9JyFuY1n2KE8EdPNMZZTKSwmLUcc/qcv7tzmXUFtnnu9mLxuXns4lIklO9U3TsHyPdFcSamNknZJlkxHkRStLsaF/DnWtuxmGSSWPEO7N7925u3L6dyPMvEPjqV0l2dGAoLaXwd34Hz4MfRjMamei9yFDXWYa7zjLc1UEyGgHA7vGyYtetbH7gYQwm0zy/k/lzJBTjb3rHeHk6gs9k4HOVPu4v8VJlMUE+B317Z0Jcx5OQiYG3DtZ8dKYnzvPOv3CZnp7m1Vdf5fjx42SzWZqbm9m2bRtVVVVv+7y3CnUwc5nl5z//ecxmM/F4nGQyyfT0NK2trdTV1XHHHXfw13/911RUVJDNZjl27Ngbgt1rPXaVlZXU1dVd6tF7beKU10hwuwIJbmKpkhoT11oqkeUn332e4Z4Y1qCXvD5Lc3sZa3bWUFzjmu/mzQstr5E8P03gyAFGtScIl70KSsNrv5lp++/w/AULPzk2RCaX557V5XzhpmUsK77yenlL3VudzzRNY6Q3xL5Xh7nQMYYlmMGSn/ngHDOFyJfEWbGmhp071uNwvrvLs8TScnmNaZpG7JV9BL76VeJHjqD3ein49Kcp+OQn0Fln6kjL5wkMDzLcdZa+k8foPnyAgooqbv+9P6SssXke38n8OxiM8rd9Y+ydnpmRcqPLzr0lHu7xeSg2GyEVhc4n4cT3ZsIcQO12WPMxaLsHTO/sS61YLMahQ4c4dOgQiUSC6upqtm7dSmNj47see/ZWPXJ/+Zd/SSgUoq+v79Iac9lslnPnzhGJRGhra8Pj8TA8PHzpEsmKigoAhoeH+fKXv8zDDz986XUkuF2BBDexVEmNibmwe/dutu/Yzr+88Bhn9g6xLLAeQ86Ir9pJ27ZymjeXYjQtzbFHGX+C6YOnGfY/RrD0BfLGBC79ehyVj/KTrjIeOzhAIpPjjhWlfGFXI23lSzPsvhPv9HwWjKZ5cm8fB46dwRAMUpH04Mh4yKksYZ+fyjWFPHDrVlwO6YkTb/RWNRY/ehT/V79KbM9eDMXF+P7gi7jvuw+lf+N5rffEUZ792v8kNjXF+rvvY8tDH8NoWtrrPPYnUjw5EeRnE9OcjSbRAVs8Du4r8XKXz43XaIDp/pnLKE88BtN9YHJA270zl1LWbH3Ha8cdP36c/fv3EwqFKCoqYvPmzaxatQrTu+gBfbseubcLdsFgkJdffpk/+7M/o6ysDLvdLj1u75UEN7FUSY2JuXB5nR0eO8z/9eJ/omS4kR3he8hM6nH5rNz08RYqmpfuYP58Okf4eA/DFx7DX/ALspYgllw1joLP8PTEer57YIhoKsvNrSV88QPLWFXpme8mLzjv5Xw2EIjzxJFuDnYewjMZZ1m4CkfGTVqXZMg7jFZtpX3dRm5rq8NrX7qXt4kZV6qx+NGjTPz135A4eRJzYyPFf/xH2HfseMPYtlQ8zp7//U1OvfA03rIKbvs3f0BFy9Ib//tmzseS/Hximp+NB7mYSGFQsMppY63TxhqXjbVOK/WTx9CdfBzO/gzSEXBVwsoPw6qHZmaovIJcLsfZs2fZt28f4+PjmM1m1qxZw8aNG9924e936r0EOxnj9i5JcBNLldSYmAu/WWf+hJ8v7/kyh0YP8ZDjM9Sc2ETEn2LFjgpueKABk2XpTsyhaRrJvgDDJ3/ImPohKWc/+qwTu/5BXk7ewXcOTxJOZmksdnBTazEfaClhXbUHg37uFoddqN7v+Syby9M5Os3T+/Yz1TmJb7IYc85K3BhhzD5M1pGhsNSIr9xBSZmH8pJiSu2llNpLsRgsV34Bsei9kxqbWQ/uWSb+7r+T6R/AtnkzxX/8x1hXvDFU9J8+wbNf/Z+E/ROsu/2DbHvkkxgtv11HWj5PJp1CKYXRvDTqTNM0zkQT/GIiyOFwjJORBPHczLpwLoOO1U4b7Rb4gP8Vll18EmffbpSWg+LlsOpBWPHhmbXirvAaAwMDHD58mI6ODvL5PPX19bS3t9PY2Ihef22uAnm7YPcaCW5XIMFNLFVSY2IuvFmd5fI5vnLyK3zt1NcoNZfz0cgfEDtmxuE1s+tjLVQvL5yfxi4guXiG8WPPMuT/DhHnUZSmxxy/mRO5h3jVb+Zg7xTZvIbbamRns4+bWorZ2VSMe4lO/nK1z2eZdJaX9h3l5KsD5PwGbEkHeu31D3MZXZqw2U/IOomrQcfdu3ayvn71VXt9sfC8mxrT0mmmn/gh/n/8R3LT07juvpuif/dvMdfVXdonnUyw93vf4sQzv8RZ6MPl85FOJMgkk6STMz8zqZlZepXSUVRdQ3lTK+XNrZQ3teIuLlkSM1XmNI3zsSTHI3FOhGduHbEE2dkoUZgO8mBgNx+eeJ4VwdMADJduJLX649Rv+gRcYRmQSCTCsWPHOHLkCJFIBLfbzbp166ipqaGkpASrdW7HvkpwuwIJbmKpkhoTc+Ht6uz4xHH+5vDfcNp/mo3sYMuFD5Pya7RsKWPrh5ZhsS/NEHI5TdMI956l/9y/4Dc8g6ZPY4u04jA/SK9zGy8PR9l9boJALI1ep2ivLeCR9ipuX1GK2bB0xg5e6/PZ6HSCb7/Qze6jg1gycRrtBiqNJnRBhS5qRiNPzOunbo2PD+xop7BMJpS53ryXGstFowT+5V+Y+ta30ZJJbJs24X34IRw334xudmzVYMdpDv70CbR8DqPFitFswWSxYrRYMFqsmCwW0skEoxfOMXqhi3RiZppUu8c7E+SaWqhfv4mC8oqr/ZYXrEQuz7lYksFkmqHXbqk02UAvGwZ+xd2jz9KYGGDEVY/plr+gaMUHr7isQC6X49y5cxw+fJje3t5L291uN6WlpZSUlFBaWkppaSkej+ddT27yTklwuwIJbmKpkhoTc+FKdaZpGs/0PcPfH/t7xsLj3Bf8LMUXWrE6Tdz4kWbq1/je8rlLTSo2xcCJbzEW/RFp4zj6lIuC6K2UVX2EgcJKdvcGePLkCP2BOF6bkQc3VPGR9mrqlsCyAnN1PgsnM3zv4ADffKWXiUiKlhIHO8ps6Pw9ZPuzeCNlAOi8WZavr6ZlY/mSnUH1evN+aiw7OUnwJz8l+MQTZIaH0Xu9uB+4H++DD2KqrX3Hx8nncwQGBxg538nIuU6Gz3cSGh8DoGHDJjbcfT8VLcuXRE/c2wmmM+x99Xu0HfwbGhKDjBSvo+jO/4qpdss7en4kEmFsbIzx8XHGxsYYGxsjEAjwWn6x2Ww0NzfT2tpKfX09BsPVu8RfgtsVSHATS5XUmJgL77TO0rk0j3c9zldPfRXLtJd7Bx/FMO2gZkUhWz+8DG/p9R8+3ilNyzPR/wKDPd8mpB0AwOFfS7HhfopX3Moxncb3Dg7wXMc42bzG1mWFfLS9hlvaSjAZrs/xcHN9Pktlc/z8+AiPHx7g9FCIbF4DcjQW91OZnaQ0UEZ5eBk6TY+rxsCWO5qpX1WM0i3tD9SL2dWoMS2fJ7bvVYJP/IDIiy9BLodt82a8Dz+E8+abUcZ3f5VBZMrP6Ree4cQzvyQRCVO6rIkNd99PY/sWdNdorNZiMRCN8tILX+H2s/9ESXqKybpb8N3xl1Dc8sYd87mZGSsnu2ZukTFYdjM0fAD0M6EsnU4zOTnJ2NgYvb29nD9/nnQ6jclkoqmpidbWVpYtW4bZ/P5mCpXgdgUS3MRSJTUm5sK7rbNgMshXT32VJzp/yIrRHawbuhV9zohvo54P3L+aIu/SnX3yzcTjgwye+w5jgR+T1YUwJopwptZT3HILlG7jpyeCPH5okOFggiKHmY+0V/GJzTUUu66viQ7m83yWSOc4NRTkSP80x/qnOTIwRVTrxuE+SFvCzeqxHThThcRsEfKtOTZtW8vKqnIK7aYl3zOymFz1cZQTE4R+8hOCT/yQzMgIhpISvB//GN6HHkLvdr/746WSdOx5kaO//BnToyO4fCWsv+teVuy6BZNlaa9R+PLYGF0v/B0f6fkujlyC+MqHcRQ1zAa1c+A/D7nU608wWCGbAHvxzIyVqz8CpSvecMxsNktPTw+dnZ10dXWRSCQwGAw0NDRQV1d36dLKdztGToLbFUhwE0uV1JiYC++1zgbDg3z/3Pc5NdCB61Q9LeM3kNYnGGg+RvEGI+vK1tJe2k6hVSYyAcjnU4yP/ZqRCz8mnD5GXp8ETYfTtggKlFIAAFe2SURBVBxP0Xa6Qhv52RkzL53zY9Ap7lldwe9uq7tu1oZbSOezfF6jxx/jWP80x4ZG6Jg+jHl8iuWTdfjiFcSNEU4VnKbDkaKpeBWf37yVnU1lEuIWuGtVY1ouR3TPHqa+8x3i+w+grFY8999PwSc/ccXLKHPhMKlz59A5nZibm1FKkc/nuHj0EEef+inDXR2Y7XZ2fOwzrLzptiVdY+l8nu9cOId65b/z8aGfYtYyJF1VmEtaUb5m8LXM3IqawGCBC8/Cycfh/NOQz0LpKljzUVj5INjfuHRALpdjYGDgUogLh8OXHnO5XG8YI1dSUkJBQcFbjpGT4HYFEtzEUiU1JubC1aizeCbOwbMn6XjKD0N2gtYJXq35KZNFvXxx3Rf5SMtH0F9h5rClJJtIMvbK8/gHXyLmOUPS3QMqj05nJWW6nRcHb+GpsxrxdI4tDYX87rY6djUXo1vEl/EthvNZPJXm6VcOc3HPOLZxDxldit6CUwx4zjFmD1NfWssdTRtZX7qKZZ5lGPUyOc9CMhc1luzqYurb3yH01FOQzeK46SYKP/0prBs2kJ2YJNnZQaqzk2RHJ8nOTjJDQ5eea/D5sG/bhmP7Nmw33IDB62XkfBf7fvAdBs6comHDZm599Pexud59b971ZDSV5h+6zvOkP0pAZ6HCbOS+Ei8fKvHS5niT3rFYAM78CE58D0ZPgM4ALXfBrv8Avubf2l3TNKLR6KUxcq+Nk/P7/ZfGyD388MO0tra+afskuF2BBDexVEmNiblwNetM0zT6Twd45UcXCE0kiPrG2V30YwoazPzF1r9gmXfZVXmd60UunCb8Qj/hY70kfOfJrOhl2riHTGaKLDUcCX6CX3RVMBbOUF9k5zPb6vjwukqspsUXghfb+SwwHOXAM+cZOD1NPjETmCdtQwx6Oxj0dOF3DtFc1MiOyh3cWnsrDZ6GeW6xmMsay05OMv3440x/73FywSA6h4N8NHrpcWNNNZbWNiytrVhaW8j6A8Re2Ut036vkQyHQ6bCsXIFj23bs27bQMdzPK49/G7Pdwe2/94fUrf2tz+ZLTiyb45lAmB+PTbN7OkxOgxa7hQdKvNxX7KHa+iZj1SY64cRjcORbkInB2o/Dzv8TXOVXfL1MJsPk5CTj4+M0NjbicDjedD8JblcgwU0sVVJjYi5cizrLZfOceXmYY8/0Ew+nmXaMcqLsRXbtXMfn1nwOk950VV9vsctMxAk93UeyI4Cmy5JY1kmofA9h01GyeeiKPMgzfVvoGFcUOUx8dns9H99cg8O8eBZDX6znMy2vMTkYYeDsFJ3HxgkNRVEo0roMY+4BLhYcoLfgNFWF5dxaeyu31twqX1DMk/mosXwySejJJ0meOYu5sRFLWyvm5mb0b/GhX8vlSJ45Q3TvK8T27iVx+jTk85gbG+GB+9hz5giBoQHW3HYXOz72mSWzqPeV+NNZnpyY5qfjM4t+AzTazGzzOtnudbDF48BjvOx8GAvA3r+FQ1+fWSdu8+/B1j8Eq+d9t0WC2xVIcBNLldSYmAvXss5ymTznDo1x9NlewuMpIqYphuvP8KkP3cuGqrXX5DUXs9RAmGTXFJnhKOmhCKnsBOHyVwhV7iVtmeTi9AqeHfoIR8ecuK1GfmdrHZ/eUrsoFvW+Xs5nqUSWrhMTvPLKELG+KPYc5Mgz4RnifMGr9BacoryohFtqbuG22tto9DbOd5OXjMVYY7lgkMiLLzH1rW+ROn8eVVxM76Y1dAxcpKCiiju/8EeU1MsXAZfrT6T45WSIvdMRDgRjJPJ5dMBKp5XtXifbvA7a3Q5set3MTJQv/T9w6omZ0Lb9j2HjZ8H41oE4lsthUjqMb3FpugS3K5DgJpYqqTExF+aizrS8Rv+ZALufOk1sQCOlj6O1TfPxR+6kpFAmL3kzmqaRC6ZID0VJD4eY8u/Hb3yKSNER+oLLeG74ExwY8eAwG/jkDTX87rY6Ch3vb5rra+l6PJ/lcnle2j/Mwb2DqKEE7pwij0bAM8I57356Ck5SXVrOB+s/yJ31d1JkLbryQcV7tphrTNM0Yq/sI/DNbxDff4BAkZdTtaWk8jna73uIpk1bKKyqRidjhd8gnc9zLBxn73SEfdNRjobjZDQNvYI2u5W1LhvrXDZuSPRS/epfobqfB3cVrP80NOwiXbKKjniGE5E4J8JxTkTinI8l+eGaBrZ6nW/6mhLcrkCCm1iqpMbEXJjrOuu7MM7PfrwXfZ+HlDFO7IYL3L5rGxtLN6JT1+caZldLPpXDv38//eNfJVy0n8FwDS8Of5q9wwWYDTo+2l7D53bUUeZeeFOLX+/ns1gqw1N7Bjj+6jC28TSF+ZlaDlunGHR1MubqoaLJw50rbmVX1S4sBrkE7mq7XmoscfYsU9/8V/zPPcuZ8kLG3DNrZJptdsqbWqhoWU5FSxulDU0YTHLZ+eViuRwHgzEOhWIcC8c4Ho4TyeUBcOp1fDx1ht85/zWqJo8DEDI42OtZx17vek752vEWN7HGbefBkgLqbG/+RZgEtyuQ4CaWKqkxMRfmq86Odpzhlcd6MAQcnPMdomf5fu5quZ17l91LuePKA8mXsnw6h//AQQZGvkbI9wpj0XJeHP4Mu4eK0SnF/WsrePTGBhp8bz7OZj4spfPZSDDBT3f3ceHEBIZAmvKswqzNBLmgZYJxVx+mCjO3bN7IB1ZsxqBfPGMVF7LrrcbSQ8NMfefbDP/wh4QrSkju2Mr4+CiBoQEA9AYDJfWN1K5eR+v2XXhKSue5xQtPXtPojqc4Fo5xLBzneDhORyxBRTbEw4kz7AoepWX8ALbo8MwTXJVQvxNu+HdQ0vamx5TgdgUS3MRSJTUm5sJ81lkul+fgU90cf3qQtCXBs7XfYthznk1lm7h/2f3cUnOLTLn+NvLpHIGDR+gf/iqhor1MJr280H8vL4+sJJPTcUuriy98YBWrKj3z3dQlez7L5PKcGw1z/NQE/Z0BEmN+CmNGzPmZnpK4MYIqTtPYXMbq5c2U1XkwL4IxiwvR9Vpj8WPHGf7DPyQXClH653+O+ZYPMHK+k+GuDoY6zzDafR40jYqW5bTtuInmG7Zhttnnu9kLViqfx6gUutfWzNM0mOqBnt0zt9498PEfQ+Wbz+wpwe0KJLiJpUpqTMyFhVBnE/1hnv/XDqbH4rB8ml8Vf4uBZB9F1iIebn6YB5selIW834aWyRE4eIyRgZ8QM3QwYR3j2ZFNvDi4nUTWxuqSCT7VDjev2ozL+eZrE11rC6HOFopYMsu+owM8vf8wmckgJSk33mTxpcctRTqql/moXVFEzYpCTBbpkXsnrucaywYCDP/7PyJ+8CCeBx+k5D/+B3TmmUv5wv5JOve+RMeeF5kaGcJgNNGwYRNtN95E7ap16PQyLu5dyecABbIA93sjwU0sVVJjYi4slDrLpnMceLKHky8M4iqyUHxnjp/Fvscrw69g0pm4s/5OPt76cZoLfntBVfG6bChF8lyAYO8pRgMn+Hkqzy+mGghlHJTbR2mvCHHX+k3cuPwGTIa5+0C3UOpsoRmajvPVvZ384vRL+HTjVOQUvlgFZdF6zBk7yqBR0eqhZUMFtauKMFslxL2V673GtGyWyX/4nwS+9jUsbW1U/MP/wFRZ+frjmsb4xQuc3fMiXa/uIRkJY3N72PyhR1hzy52otwgi4t2R4HYFEtzEUiU1JubCQquzkQvTvPDtTsL+JJUtXorWG3hJ9yRP9v2cRDZBe2k7H2/9ODsqd6CXGdbelpbTSA9FCHX4+dHpizwdH+dsykVO02M1pNhcbeb2tSvY2VxCievaTpax0OpsoZmOpfnO/n6+deAcEXUKX8l5vIkk1YFm6gOrsWc8aLo8rnoDazfX07i2DItdLqm83FKpsciLLzLy5T8FnY6Kv/5vOG688bf2yWUz9B4/yvGnn2TgzCnKm1q59dEvUlhZNQ8tvr5IcLsCCW5iqZIaE3NhIdZZOpnl5AuDdOwbITqVwuo0UtdeQE/ZMb4/9h3GYmPUumr50vovsatqF+q1sQribWWDScaPDPDr88+xNz3Fyel6gikPAG0lDm5fVc7dq8qovwaTmizEOluIEukcPzw6yGMHBugLRMgYBjHYLlChoiyLl9AwtRJnqpCcypEqTXHTrStZ016FXi+9KUupxtIDAwx98Q9IdXXhvv9+nLfcjH3TJnT2N45t0zSNzr0v8dK3v04mmWDT/Q/Tft+H0Rsk9L9XEtyuQIKbWKqkxsRcWMh1ls9rDHZMcXbvMH2nA2h5jfJmD7kWP99NfIWeSDcbSzfyJxv+hNbC+Rm7tVilJyMMnXyC/YGnORYt4OT4GrrD1QAs9zn44PpK7l5dRqXXdlVebyHX2UKlaRrBeIbRUJKxcIL+6WlOTRxnfLQb55iOZYEV2DJOkoYkliYj992zkYpaz3w3e94stRrLJ5NM/PVfE/rZz8nH4yijEdvGDdh37MCxYwemurpLX2rFQ0Fe+vbX6dr3MoWV1dz66Bcpb2qZ53ewOElwuwIJbmKpkhoTc2Gx1FksmKJz/ygdr4wQCSSxuozo1k/xrdzfM5UJcE/DPXxx3RcpthVf+WDiEk3TGO/+Nf0DX2cgNcDhsbUcHdrKxfjM33F1gZ171lZw96aq93U55WKps8Uir+X58em9PL3nFdzDdmqDbeg1AxFHhNr1Zdxz12psroW7IPu1sFRrTEuniR87RnTPXqJ7XibdfREAY2Ul9u3bMJaUoIxGlNHEYGCc/ScPEUvEWdG2mvYdN+Nub/+tnjrx1iS4XYEEN7FUSY2JubDY6kzLawx2TnH06X5GLgSxF5gIrujmu9n/hV6v4zMrPsOnl38aq2HhLUK90MXjfYwM/pix0Z8wFM1weKSdo8M30Dd7OWWh2UBTuYumUifLSpw0FjtoKnFSYL/yIsCLrc4Wk0gqxj/ve5LOw91UTVRRHKsmT55RTz+Bin709RG8bhsukwuHyYHL5GJdyTraCtquq8uMpcZmZIaHie7dS/TlPcQOHEBLJN7weFanOFdWSH+hC3M2R3k4Tk15NdU7duG6cQemZcuuWBdaLkc2EMBQUIAyLK0JcxZicFta/waEEEIsGkqnqF5eSFVbAYOdUxz4WQ+xPdV8sfjv6F52gH86/hV+dP5HfGHNF7i74W6MOhnL8U7ZbLUsa/4jGpq+xHTwICtHf8zd43/FcNRJx9hmxidbGBkq5UcDQWK5/KXnFdpNrKnycPfqMm5pK8Vhlo8Rc8lptvMnN30EboLuqUG++tyTJM9rVExUUXG2jkxHhgHvOc74jtLnOUlelwOg0lHJbbW3cWvtrbQWtF5XIW4pM1ZU4H3kEbyPPIKmaZDNomUyaOn0zM9MhuZ0mpHucxx69pf0D/TSmwpi+tUPKfn+tynXm6jdsBnXjTswlpWRGRoiPTREZmiYzOAg6eEhMiOjkMmgc7txbNuGY+eN2Ldtw+D1zvfbX5Kkx+0dkG92xLUmNSbmwmKvM03T6DkxycEne5kejWEv03Oo6pfs1f2aKlcVj656lLvq78KgkzDxXmSzUSYmn2Zs7EmC0wfQyKFPeEhPbCVs3cWUr42L0yle6fYzHExgMer4QEsJH1xdzs5mHxbjzMyfi73OFqNcNs+BI6Oc3DdMujeKMQsJpdFtTjJVMch02T4mcqfIk6fKWcVttbdxW+1tNHubF2WIkxp7b1LxOL3HD3N+z0v0njlBNpvFkM/jC8UoCcfxheMY83n0Hg/GqiqMlRWYKisxFJeQ7OggumcPuUAAdDqsq1fjuPFGHLt2Ym5qWpR1dCULscdNgts7ICcIca1JjYm5cL3UWT6vceHQGIee6iXsT2Iuho7CV9ln+zW+Ii+PrnqUO+vulCUE3odMJoQ/8BLj/b9iOvIKeV0KXcaGR3cDxcvuYiC7ml93RPnlqVECsTROs4HbVpRyz+pyssNnuGnXrvl+C0tWLpen94yfwy8PEzgfRGU1kkrjoinFRXc3UxWvkrJ0opGn3F7FnfW3cUvNLYuqJ+56OZfNp2w6zcDZk1w4sI/uQ6+SjMdROh0VjS00tN9A/bp2Csor3vAcLZ8neeYM0d0vE335ZZJnzwJgKC/D+/AjeB568LrqiZPgdgUS3MRSJTUm5sL1Vme5bJ6u/aN0vjrKeG8YlEagaIDjnt1otRE+v/az3FZ7mwS49ymXSzLR8zxj539BUL+fvCkGgN3chLtoKxfC7ezuKeC5jgCRVJZCi+LRm5p5eGM1bqtcvjqfsukcAx1TdB+boOeUn1wyR04HfeY05+zdDBbvQXOdA5XHZynjzvrbuL3uNpYXLl/QIe56O5fNt3w+x1j3eS4ePUTPscP4B/oA8JaVU7+unfp17VS0tKH/jTFumYkJYnv2EP7Vr4i9uh9lseC+5x4KPvVJzA0N8/BOri4JblcgwU0sVVJjYi5cz3U2PRbj3MExzh0cIzqVIqtP011wjGjtCB+84QPc2XQHFsO1XXh6Kcj4I0wceBn/2F7i7g4S3m40XRqFHrN9DV3hD/DEsVLOTRuwmfR8aF0ln95aS8M1WC9OvDu5XJ6Rc0Eunpik58QkiXAadDDt0DhpvEh/0askvMdB5fGYirmz7lY2lq3HrDdj0psw680Y9UZMupnfzXozPpsPnZr7deWu53PZQhCenKDn2GEuHjvE4JmT5LJZLA4nDes30bjpBmpWrsVgeuNERcnz55n+7ncJ/fxJtHQa+7ZtFHzqU9i3bV3QXwK8HQluVyDBTSxVUmNiLiyFOtPyGiMXgnQdGOXc0VG0tCJPnojNj7PMxKrmJmrryyiqdGBzmxbtB4r5lk9kiR0eI7y/jxgdJCoukKy4QIxONC1H3PRJXhy6hV+eDpLO5bmxycdnttayo9GHTid/8/mWz2uM9YToPTFJ3+kAwfE4AEm7osM0yEXvIfy+fShd9m2PU+2s5sGmB7l32b14LXN3idxSOJctFOlkgv7TJ+g+tJ+LRw+SisUwWqzUrd1AY/sN1K/dgMn6+hqQ2akpgj/4AVPf+x65ST+mhga8Dz+M8wM3YayoeJtXWngkuF2BBDexVEmNibmw1Oosk84xcDbAqc5znO8eQAuYcaYKLj1ucRgpa3DT/sF6iiqlR+i90HIaiQ4/0VdGSPeHyTlijDT/nEThblAa9oJPsm/8Lh4/PMlkJEW9z85H26u5f20FhY6ltfbYQhYcj9N7yk/fKT+jF4NoeciZFKPmOP5skrghQ9aUpaBIR0mJnooKPVZPmudGnuHYxDFMOhO31t7KQ80Psca35pp/IbLUzmULRS6bZfDsKS4cepXuwweIh4LoDQYqWpZjslpRSgcKlNKhNI3s2Bjp3l6M/gAloRglldU4d92Ec9dOLKtWoXRz31v7bkhwuwIJbmKpkhoTc2Gp19lQZIjvn/whr5w6jDXsoSG3nPLJZrSUjobNhWy/rwW7W8LEe5UejBDdP0L05Dg5wxRTzb8gWLIHnc5MafmnORu+j8cOj3N8IIhRr7i5tYSHNlaxo9GHXnrhFoxkLMPA2QB9p/z4h6LEwmnS8TfveUuZFfmiPFMF5zlmeJYRcw8N3noean6Iu+vvxmlyXpM2LvVz2UKQz+cYOd9F96FXGew4Qz6XA01D0zS0fB4NQMuTz+eJ+CfJ53JYUJQEQpRORyiy2HHNzkrp2LEDnXnhnXsluF2BBDexVEmNibkgdTYjnonz5MUneazzMUYDE6wfvo3lY9vJ67KMNJ7CuDZKjbeKWlctG0o3UGApuPJBxSUvv7Cb9rKVJE77CfWeYbLqR0TKDqHPO6j0fJJY4T384myGnxwfZiqWpsxt4cPrK3loQxVVBbYrv4CYc7lsnkQkQzycon84wtmeafqGwqQnk7jjGg5tJnhnVI5J5zCjzk4mXYPUtpRyV9Ot7Kjcgc149f7dyrlscUnFY/QcPcSFQ/vpPX6EbCaNWaenOBilxB+kxGzD9+lP4XnkEfSOhXP1gwS3K5DgJpYqqTExF6TO3kjTNIYiQ/SGe+npH2Z6twHTYCExS5BXq37GxcLj2E12Pr/q83y89eOY9KYrH1S8oc60bJ7k+WkCnQcZyn+dWOEpACxU4y7axdnoVn7ZaWdvdwBNg63LCvnYphpuaSvBqF/Yl1GJGfFUllPnA3Sd8TPZGyY3mcSeyKNDkdGlGXJ3MVjYSflyFzc37+TGyhtxmN7fh3M5ly1emWSS3pNHuXDwVXqOHiKdTODSGWg730+R3oT3ox+h4JOfxFAw/1+YSXC7AgluYqmSGhNzQersyoa6pnjlR90EhqI4qwycbnqep+M/pcpZxR9t+CNuqrpJJjS5greqMy2bZ+r0ccYvPE2IQyS859D0GXTKQta0kwPjN/Krcx5GQxl8TjMPb6jikfYqKr3SC7fYpBMZDh4e49C+IXJDYew5I3nyjDt7GSjspKjVxK4VW9lVtes9hTg5l10fspkMF48cYM9j/0p4coJai5OGo6exGIx4HnyQws98GmN5+by1T4LbFUhwE0uV1JiYC1Jn70w+r9G1f5SDP+8hHk5TsFrPTwu+SmfyNJvKNvHljV+m0ds4381csN5JnWUm4kQO9jLZs5eo6wTx0jOkzaPkNcWF6M3sGd7JoUEnGrCzycfHNtWwq6VYxsItQulsjudeGeTgviF0Y2F8mZllOaaso/QUnYC6HO2NN3BL7S6qvQWYDFfuaZVz2fUlk0py8KdPcPjJn2A0GlnpKMD38qsowP3BD1L0b38PU1XVnLdrIQY3w5vtLIQQQixVOp2ibWs5y9YXc/TXfZx4fpCbjY9y+8Zp/nXyv/PhX3yYB5se5AtrvoDH4pnv5i5KxmIbBR9cjifdQuLEJNH9I8SCvcRKTuKsOklzy3/igRo3r47dzJ6BTbx0bpIyt4V711RwS1sJa6s8sqzAImEy6LlrZy137axlOpbmZ/v6OfLqMK4pNxsG74BBGD3Wx58V/Be6LBGy+VZ8ujUs8xWwotzNigo3y8tdFLtkHcbrldFsYdsjn6R1+y5e/OZXOHLmFCV33Mhak4vwL39N6Kmn8D74IEW/928w+Hzz3dx5JT1u74B8syOuNakxMRekzt6b4HicV350gf7TAVzFZkbXnOB70a9jM9rYVbWLDSUb2Fi6kQpHhVxGyXurM03TSA9ESJzxk+oOkpwcJ+o7SbTsBGHPGU4EGnl5eAedgWXkNB2FdiM3t5ZyS1sJ2xqLsBj11+bNiGsmnc0zMBSm69AY/SeGYUqhkWfY1c3FopMMO4IEsnryGS9axovTUExTYTVrymoxhib4N/ftxG6W/ofrjaZpdL26h5e/8y/EQkFWbt1J9cgE2i9+hTIaKfjkJyn83d9B73Jd87YsxB43CW7vgHzYEdea1JiYC1Jn70/faT+v/PACoYkEvlYrJxqe5pXoS0ynpgEos5exsXTjkg9yV6POcpE0qYtBkt1BEt0TRIzHiBQfY8LbxclQFScmV3PGv4J41ojFqGN7o49b2kq4sclHifTMLErTYzHOHRrjzIEBUlMzn00TljCj9h7GHL2MO/vw24fI6bLkMy5INLPSu42Pr7qZm1srJLxfZ1LxGPue+N+cePqXaFoeX3kVFbEk3v2HsdscFH3us3g/9jF0Vus1a4MEtyuQ4CaWKqkxMRekzt6/XCbPyRcHOfKrPnK5PJUtXmx1GqMFFziWPMCR8SOXglylo5J7lt3D/cvup9ReOs8tnztXu840TSPrT8z0xF0MMB04RNh1mGDRCc4mCzgxsZKTk+sIJGcmuWgpdbK9sYjtjT7a6wrkA/0io2ka/sEoIxeCjPWGGOsJEZ1KzTyo16AwyYChlxFjDxGTn5ghTjRfTEPxWj6+9lY+0FwlM5JeR6LTU5zfv5fOfS8z1n0egCK9iZL+YSoNVip+7/fwfOgBlNF41V9bgtsVSHATS5XUmJgLUmdXTyyY4vizA/Sd8ROaSADgLLRQ3VaAsSZNv7ODl8Zf4MDoARSKLRVb+FDjh9hZuROj/up/wFhIrnWdaXmN7EScZPc0waFjBJK7CXsP0wOcnVzBOf9mOsNFZPJgMujYVFfA9sYibmwqpqnEsSR7QRe7WCjFeG+Y8d4QYz1hxnqD5N9kTfCEIUbMkCTn1GFp87CyrYV6n4O6Ijs2k1xWudhNj41wbt8eOve9zNTwIApwxZMYjCYs1dWYy8oxGI3oL91MlNYvo3HTVsy2dz877ZIKbkqpbwJ3AxOapq14J8+R4CaWKqkxMRekzq6N0GSCwY4A/WenGD43TSaVQ6dTlDV6KNto4bDlBX7a+1Mm4hMUWAr4YP0HeaDxAeo99fPd9GtirutMy2tkxuNMdx9hJPg405bdJIH+/pu4MLGdE+lCepIZAGoKbdzaVsKty0tZV+2VWSoXqZdeeokb2rcRC6aIBVOEgwnOD/Zytq+PaChKSbgKc87GqKOP44Vn6TZmcOjqqXO00lhUxtoqL7taivE5zfP9VsR7oGkak/29dL7yMqPHj5AcGCCbSIDVgiooQDMZyWUyZNIpUrEYBqOJhg2baN2+i9rV69Ab3lmIX2rBbQcQBb4jwU2Ityc1JuaC1Nm1l8vmGbsYYqBjiu6j44T9SexuE63by4gtG+YXoz9l9+BuslqWzWWb+f21v88q36r5bvZVNd91lkoGGOp+jJGJx0kzgTFRTPbiHZwd28A+vZEj2TRZDQrtJm5pK+G25aXc0FAol1QuIm9XY3ktT/dkD6++0EXwiMIYsxIy+zlV/hLnfIfIanYysVqysWU0u9dxe3MzN7UW01bmkt7YRUrL54k8/TST/+MfSPf3Y129Gt+XvoRtUztj3efp2PsiXa/uJRkJY3W5admyg9btOyltaHrbf+dLKrjNvmgt8JQENyHentSYmAtSZ3Mrn9cYOBvg9O4hBs5OodMrGtYVU73FwSuZ5/lu53eYSk5xU9VNfGHtF66bteEWSp3l81km/c8xOPhtQqHDKEw4E6uhby2nR1awL2dgv8oR1zRsBh1blxWxeVkRm+sLaC11yXIDC9g7rbF8Lk/PCT/Hnutjsi8KlhzT9T28Yvs1w4aLoCCf8pGNNeCijZ01m7mjrZ4NtQW4LNf3Jc3XIy2bJfjTn+L/x38iOzaG7YbN2DdtIp9KkUsmGfZP0Ds1zlA0RB4Np87ABz7xuzTc+cE3PZ4Etzff5/PA5wFKSkrWf//7379m7XmvotEoDodjvpshrmNSY2IuSJ3Nn1RYY6pbI9gL+QxYvOCsz3LCvYfnks+Q0lJssG/gTvedFBmL5ru578tCrDNN60fT9qNxDAiApjAkmzCPr6evbx3703aOkGWYmc9EdgM0FehpKdDTUqCjyqlDJ70xC8a7rTFN00j4wd+lERme2abMORKeaYbs3Zy1HWHc3kNO5cknK8jFluHON9JoqafRY6bBo6fCoaQGFotMBuuevdiffhp9JIKmFBiNaEYjmsFA2mRk3Glh1GKkZtdt6FeuftPDzOe5bNeuXQszuF1OetzEUiU1JuaC1Nn8SyeznD80zundQ0yNxNDpFeWtLnp9J3k8+XXSuiQfbvwwn1/1eXy2xbnQ7EKuM03TiETPMjn5LJOTzxKLXQDAbmzBGV1H6HwdHWPlnNR0nDBoDGZnZsBwWQysrvKwutLDqko3a6o8siD0PHo/NRb2Jxjqmma0O8joxRChyZnJhZQB8oVx+qzn6TWcYdo6RtA8RSJVRi6+DFO6hVUlrayrKmR9jZd11V7cNumVW8i0XA7yeTAY3tNlsAuxx02m2BFCCCHmiMliYMWOCpZvL8c/GOX8oTEuHB7HeKaW3zH/FbGKMV6a+hk/v3A3dzbcwb3L7mWNb42MvblKlFK4nCtwOVfQUP/vicd7mZx8lonJ5xjLfB9W5qlbqWdFvpHf9TcSGWjkXLCO08pI13iUr3QHyM1+4V3qsrCq0s3qKg9rqzysr/ViNsg4uYXOVWSlbZuVtm3lAMTDacYuhhi5GGTsYgj9gJ263JpL+yfNUQLmEYLWYUKTZ3l2UvHYSY1o3km5vZK1ZU1sq525vLKm0Cb/rS4gSq8H/fX136QENyGEEGKOKaXwVTvxVTu54YFljFwIcuHQGBeP67g9/nlyljQXeo7y5SN/gbEiy72N93BPwz1Laj24uWCz1VFT8yg1NY+SzUYJhY4RDB4iGDzClP4ZtOJfUIeiNVmFcboc4hWMWdsYcNZxPm7n9HCUZzvGZ45l0rN1WRG7movZ2eyj3HPtFgYWV4/NZaJ+rY/6tTM93LlsntBkguB4nOmxGMGxOJOjPqbH4uRTr4eyuDHClG0E/9RzfK9nnP9hjBM16aj1NPKhtp08tPIGTAbpkRNX1zULbkqpx4GdQJFSagj4c03TvnGtXk8IIYRYjHQ6RWWzl8pmLzseaab/bIDzh8YxnbbQMnoD6Z44x04f5keFj1LbVMK9jfdyU/VNWA0SDK4mg8FBYeEOCgt3AJDLpQiHTxIMHiIUOkrU0U0qcxC7+jGtQKsTHiwtRrO20hNZyYnxSg4O5HluNsg1lzjZ2eJjV3Mx62u8sij0IqE36Cgos1NQZgdev1xZ0zQSkQxTozEmB8MM9U8yOeSicqIJcjOBLq9yTNoHeaH3F/zr3r/H5HNzW8NW7li2nUZvIzolNSDen2sW3DRN+8i1OrYQQghxPdIbddSv8VG/xkcmlaPvtJ/uoxNYTttZOXYjie4ITxYc5Csl32LTqlU80PQAbYVtcnnWNaDXm/F62/F62y9ty+WSxKa7me44SXjgLEkGSTuHqHUcoao8xt1lMBor5XRgOWcDa/nG3kq++nIPNpPGlnovO1squbHJR1XBu18MWMwvpRQ2lwmby0Rls5e11AAzM1cGJxIEhqP4B6P0dTooHqxhw5AiqU/Qf6aT/+D5GyYLhlhV28r2yhu4ofwGqpxV8/yOxGIkl0oKIYQQC5DRrKdxQwmNG0pIJ7P0nfJz4eg4tjNOVo3uZLJ7kP9U+jfol8W5r/le7q6/G7fZPd/Nvq7p9RZcRStw7ViBpmmkekLE9o8QPxQgpwuTto9TWTbNurJpMk3HmMo/w7ERM6cnGzje18LzXUEAqr1wY3MZN7VUsqm+AJtJPo4tVjr96z10jRtKuOH+BpKxDIOdU5w7MYnpjI1lgXVwEaZOj3PANsjz5tOkzVmsjgLKfXWsrl1JU1UZZV4rLst7m0hDLA1yphBCCCEWOJPFQFN7KU3tpaQSWS4cHuf48xZ83VWkBmM80/Ei/6v0K2xftoUHGh+gvbRdLsu6xpRSWBo8WBo8FGRypAcjpHpCpPrCpPeF0TJ5ioDWYgv5hgCxNZ2cSx1i/2CW0/56fnAozXcPjGLU5dnZZOOjm1ewo6kYvawft+hZ7MZLX7pomoZ/KMrhAyNkTpmwRnwYpzUM2uuTZgwyTB8DRIxJJowZolYHmteGtcSCz22l2GWm2Gmh3mdnRbkbk0H+216qJLgJIYQQi4jZOjsz5bZy+s8GOPXiIObOD9I+fCcXBo/wJx3/AWuRnttqb+P2uttpK5BLKa81ZdRjrvdgrvcAoGXzpIejpHpDpHpCpI+7sSU3sJYNrLVqZBtGCa08w+H4JAdGrey/uI7nuo5QZM/wwJpiPrZlNTWF9vl9U+KqUErhq3JyZ1Uzdz7YDMyMl0vFs/gnIhy+0EnnwAUm/X5UWEdZtBpnwACBNLmLSQLGMY4oHaN6HZP6PEmToq3aw8ZaLxtqC2aWJbDKJChLhQQ3IYQQYhFSOkXtyiJqVxYRGI5y8sVBDAcNNI1uIlI6ygtjP+VbZ75FlauK22tv5/a622n0NEqImwPKoMNc48Jc44KdVWh5jaw/QXogQnowTHrAgeFsObdrcIshTnjZGXYbRnl2rJiv79PztX27WVOe5JH2Ru5dtxyr6fqa0nypU0phsRuprCugsm4r97MVgHgmzomJExzpOcHF8yMkRsAXqWJVtJr1KdOl56eCEaZPh/iJ6udfdWD1mKmocrJ6dTFbW4spcpjn662Ja0yCmxBCCLHIFVY4uOkTrWy+t4Gze4c5vdvIXWP/FmNJlgs1B/nm6X/l66e/ToO7gdvqbuOehnuocFTMd7OXDKVTGIttGItt2DeUAJBP5UgPRUj3h7H1lPPAxTAfVNP0lZ/g18YUL0008Kc/G+TPf9HD8jIjm5fVs7G2kLXVHjw20xVeUSxGNqONLRVb2FKxBbZDIpvg9ORpDo8eoaO7m+nROIaYFWeyEGeqgLJUIY2pAvTjeRgP0XdkmpdNpwl7rVStKGJTq4/N9QVSL9cRCW5CCCHEdcLmMrHxrjrW3lJN14ExTjw/QO2hrfxhwS5YFWCP4Rd85cRX+MqJr7CjcgcPNz/M1oqtMh5uHujM+ktj5Lhp9vLKgQgFPStpuxjkUdXDgdKT7FYpzodL+Ofdef6JHgDqDAZW2cyscdpor3TTsKoEc40LJWOfritWg5X2snbay9ph3cwllsFUkP5wP33hPvpCffQGDzA66Sc2maFsqpH6qVU0jFvIj4/z8r4uvmFOkfMVs6qpgppCG+UeKxWzN4/NKD3wi4wENyGEEOI6YzDpWbGjgrZt5fSd9HP8uX7GdjvZYv8kH7vhi3T69vOjscd5eehlKhwVPNT8EPcvux+vxTvfTV+ylEGHud6Nud6N6+YaitIrKO/fyd3DIQLp3fTl/5nOaJae6eX0+9fzYsTLz8MxGJ6k/mAP23Qmbqr2sm51KbbmAgwFlvl+S+IqU0rhtXjxWrysKV7zhsey+SzdwW5OTpyi8/whQl15vKPV7AyVQwgmh0/ykmOEi+YYY5qNfLoUqyqi3DMT5moLbTSXOmkpddJU4sRpkXFzC5EENyGEEOI6pdMp6tf6qF/rY7Q7yPHnBuh6wY/SGnm04r+h1YZ5JfNr/u7I3/GPx/+R22pv46Hmh1jtWy3fxM8znUmPpdGLpdGLi09Tq32K1dOv0t//Vaam/wylc6I5PsP5qRvYfTbJY+MRvtM3SkHfGFsxcKPLzrbWYgo2lmKqdM732xHXmEFnoKWghZaCFmgB7oFQKsSx86fpPDqM/YKR9sm1bEIRMU3T7z3NYMHTBF1JLmSLOXbRRarTjJazoOWtFNnc1BcW0ezzsaKslPXVxdQW2uS8MM8kuAkhhBBLQNkyD2XLPIT9CXpOTNJzYpKxV/Us1+5mvedeQmVDvBz5JZ+8+CnKnWXcVnsbt9XeRmtBq3xYWwCUUhQUbKWgYCvh8Gn6B77GxMT/osnwD7Sus6EZl9MxvZEjg9W8MGTlF+EM5oNBVh+8yAavnW2bKtmwtRqTUSY6WSrcZje7Vm5j18qZ+/FwmnMnhuk6bsR5YTsrxneQM6QZ8p5jwNFF2BIgYp4iap4irs9wBjjjhx/7IXeoAkNyFcvd27ihupV11V5WVblxSc/cnJLgJoQQQiwhriIra26uZs3N1SQiafpO++k54SfTqXFr5rMok0bcFmT46CB/Z34Mg1ujtbaBrS3trKpvxSiLRc87l2slK1f8TxKJAaanDxKNnSMa7WJl7vu0NE3xyDI956aXcTqwkS5/I/80neOfnu7A8swZ1haZ2bqqhi3NxayscGPUy7i4pcLmMrF2Rx1rd9SRTecY6pqm95Qf5ykHNZMr37Cv3gZ6Vx7NkSZsCtOlneGC6TAdPMPJ7mKyx1eQi6yk3lPP+uoCbmgoZEtDET6nzGh5LcnZVwghhFiirE4TrVvKad1STiaVY7BjiqGuKUL+IkomSwlPJGFUQRcceHqSA0ySdcbJVgWhJoq+LIXRZMCkM2HUGTHqjaSSKbbnt6PXSc/OtWa1VmO1Vl+6r2ka6bSfaOwcrdFz3Bw9Ryz+M8amx+jwF3NuqpGuqWXsfyEDL3Rj1OUodmiUeWyUewso89goc1kodVspdc8s+Cw9Ktcng0lP7aoialcVoeU14uE04UCSSCAx+zNJZGrmZz5gY222mLXcBHqNqCPAgPk8fvshwsaXeXqgkB+eqSeXqKal1MO2ZUVsXVZEe10BdrNEjatJ/ppCCCGEwGjWXxoP95rXPtANjYxz6PxxzvX3wriV4s5a9B3lpPVJLro76fceZcDbSdIYBeDbP/w2O6t2sqtqF5vLNmMxyEQZc0Ephdnsw2z2UViw7Q2P3ZaeIp7oJTzQQf+5/RybTNGVNRPImZgOe+if9DCd8pDNvx649TpFe20BN7eVcHNrsSwKfp1SOoXdY8buMVPW4P6tx/N5jeB4HP9ghMmBCJODBXgHSshM5GYeJ8eUbYyAo5NQMsNzx418+2AxWq6YddUFbKzz0lzqoqXUSV2RXXp53wcJbkIIIYR4U699oGv2VNPc9nrPTiaVY6hrir7TAbynXTRcXAsKCqptjNsuMNHYzbN9z/KTCz/BarCypXwLu6p2cWPljXgsnvl7Q0uYyVSAyVSAZ+V6qlfCDVNJ4sfGCXdfJKIdJ16yj3jhBfzGKaZTbqZThQwlNnJiooX/+6kA//dTHTQWOy6FuDVVXvQ6Gfu4FOh0ioIyOwVldpraS4GZ3t1IIMnkYIShXj+93ToKhovRTRhpB3IqR8g2QWBohFcH4Huam+m8HaNB0eBz0Dw7e2VLqZPmUicVHquMpX0HJLgJIYQQ4l0xmvXUrfZRt9qHpmn4B6P0nfbTd8qPsbOCis4K/rDqLoyNSbo8B3nB/zQvDLyATulYW7yWXVW72Fm1kxpXzXy/lSXLUGDBdXMNrptryEW2kTw3RbJriljPCHHbORIF50iUvsTd1f/CZLyQM1NbOTO9ka/tifKV3RcptJtYVemmweegodhBg89Bvc9Ood0kH8CXAKUUriIrriIrDWuLuZE2NE0jOp2io6uXjq6LpAb0VPlLaczO9NQmTFFCnhBTySm6ul38/LgeZkvFaTHQWuqitcxJS5mL1jIXzSVOrCa55PpyEtyEEEII8Z4ppfBVO/FVO9l4Vx3P/vIlfKYGLh6bYPTFLG7W8/mqG3G2wMXC4+wOPcvfHvlb/vbI31Lnrrt0SeWqolUyLm6e6J0m7BtKsW8opSDbQqpvA8muKVI9IRKBIUoKTlLnO8FNbc8Qa9Fx1r+KzultDEyW8epFE6ns68dyW400+OwsK3awusrD+hovjcVO6Z1bApRSOAssbNrSyqYtrQBkc1mOXzjLiRPnCV2M4Rp3Uzrhpg1ImWKkfVFSDgiqHOOxUZ49keV7R/Rk81bIW6ktdNPgs1NXZKeuyEFdkZ16n51ip3lJfkEgwU0IIYQQV43Jrli7s5q1t1QTmUpy8dgE3Ucn6H0ujI5G7nIt56OVRoKuMc5GjvDEiR/xr2f+Fa/Zy9aKrWws3cjGko1UOiuX5Aez+aYMOizLPFiWeQDQsqvJjO4kPRQhOTTFdOgg5YaDbKn7Nhmrn7ymmEoUMBVbzVSmjclcDSNxPc93xHjiyBAADrOBtdUe1lZ7WV/jZU2VB7dVJj1ZCgx6AxtbVrOxZTUAmVyG4xfOcOLkBaYvxjCOuyga9lIELAO2zj4vbgwTNU0RneojFE/yap+eH2U8TGeKQemxmfTUFdlp8DlYXu5iRYWb5eUuPDbTfL3VOSHBTQghhBDXhLPAcmnpgchUkv7TfsZ7w4z3hUl2OmnQdtHALgwejZB7jM7RI/yl+/8ho09RbCtmY+lGNpRsYEPJBmpcNRLk5oEy6DBVOTFVOXFQThEryKc+TWY4SnS4n7D/BOHkaeL68yR9B8gb4zNPXGYilGyhL76SnlgtXYEE+7r95DVQCppLnNzY5GNHk48NtV7MBultXQqMeiPtLWtpb1kLQF7LE4qHGZ8I4J8MM+2PEplKYA4asYeKKAwWo5uysHb2msqMLkXUGSJpyBOOJ+g7F+XpUxfJ6PJAnlK3iaZSG8tKbCwrtrKusoqmopLr5twhwU0IIYQQ15yzwMKKGytZcePM/XQiy8RAhIm+mSA33mvB3l/GJtM9GJvjdLuPsH/kJX7Z80sAfFYf2yu3c1vNbbSXtWPQyUeY+aIz6zHXuzHXr6KQVQDk0znSo1GiQ+cIBo4TTXTiyI9QbN3LWs9PyNcmSGTN9IZquBis43xwOd94pZqv7unBalTcUF/EjiYfNzYXU1tou24+aIu3p1M6vHYP3joP1L35PplUjt7eEU6e62KwdwrG8xSMeynL2WgGbsNM2OwnYBsjkBoh4B/hmfgIPxz1o53SIOfASjnFlioaPPWsKm5ma00bzUWLr1dfznpCCCGEmHMmq4HKZi+VzV5gZpa6ib4IZ/YMceHIBJWnt/P79XdRstHMcHEnR/yHeabvGX5y4Sd4zV5urrmZ22tvZ33JehkbtwDoTHosNW4sNe0U0Q5APpklPRgh1R8iPjBKbPIiDYZxdlgnSVW/yvTy/82ZcDFnAy2cGVzBi+cm4RcdVHqM3NBQwroaL2urPTJGbokzmvU0tVTR1FJ1aVsgEeBg9zFG+gJoATOFU3a8k23UjawEbaZWNING2pwirosT04eI66dJGQPsNTzP84afk9JnuH3jA3x+5x3z9dbeNQluQgghhJh3SilK6lyU1LWx9cONdO0f5cyeYU7+IIzFXsb9Wx7lS1v/lA7tBM/0P81TPU/xw/M/pMhaxC01t3BH3R2s8a1ZdN+gX890FgOWRi+WRi9uatHym8lOxEn1h8kMR0n3x2gMdXOb4yzxhl/RZ53gZLiSs4FWfn2qgR8etQFgN+lYW13A2moP66q9xNLaPL8zMd8KrYXcufIWWPnG7dl0jqnRGP6hKIHhKPFQmmQsQyqeJRnLkAimySbzl/av2lAwxy1/fyS4CSGEEGJBsdiNrLm5mtU3VTF0bpozLw9z4oVBjj83gN1j4c7lv8PvtP4Bvc4zPDcy0wv3eNfjLPMs42OtH+Ou+ruwGqzz/TbEb1A6hbHUjrH09YW8NW01udDdZMbitIxF2ZY/T0h/hHDZT+i1THAh7uNisJbesUZe7S4hPzvW6a+PvciqSjerqj2srPCwosKF0yITnix1BpOe4hoXxTWut9wnn8uTSmRJxbLY3ItrMhMJbkIIIYRYkJROUdVaQFVrAbFQiv4zAQbOBLhwdIKOfaPodGZubPwEj7T8W/pdHfxs9Mf811f+ir8/+j/4UNMDPNL8CGWOsvl+G+JtKKUweCwYPBasLQW4qKacm9GyedZMxAgPn2Yq8CqhzHME9OfpifvoCdUyMNXEwXNVPHXm9RBYbTKw3GFlRbGDNStLWLW8WMKc+C06vQ6rw4TVsbhCG0hwE0IIIcQiYHebadtaTtvWcnK5PGPdIfrPBug/E+DIzwcBJ1v59KXpxLN70zymO4zBrMNld1BU6KZ+bTENa31YnYvvA9tSoww6zOVOfOVb8LEFgFwuQ2jsBGeP/RBb4wki2e8QTENfuIrB6WYGpps4FCrm11MR6BpF/RBqbSZWVLhZ01TEykoPy8td2M3y8VcsTlK5QgghhFhU9HodFc1eKpq9bHlgGZGpJKPdQVLxLJl0jmwqx3Q0zLmJ8wxMDaFlFCX91Qx2TvPy410UL3PQ1l5J/VrfovzWfanS640UVGwkdyHG+h070bQ80dh5gsHDBIOHCQW/TSo9TijlZCC8jOHAKvr81bx6Mc4vLkwCoIDGIjtrS1ysLXawxmunymKCTB4tk0PLapgqHJiqnCiD7g2vn8trZPN5WbpAzBsJbkIIIYRY1JwFFpztpb+1/TbWkMgmeKrnKZ7rfYb+/nEqxltYNriOiQsxXvpeJ+bqLE0bSlm/sRmHR8bFLSZK6XA6WnA6Wqiq/ASappFMDhIMHqUtfJxQ6DDR6HeBPMGUi+GJ1QxOtnExVsJTnR5+cHbmY7BLl6HFFKXVFKPRkCKV8jCd8TJtc+O36JhAYzyRZjySQq9T3NpWwofWVbK9sQiDXvf2jRTiKpLgJoQQQojrltVg5cGmB3mw6UGy+Sznps9xbOw4Z8/vIdqpKB9rJf1jE2d+vJ+EPQSlcby1ZupaSllR34TP5pOZKhcJpRRWazVWazVlZfcDkM3GCIdPEgofp6HsGKHg98nmQ+Q1xWishO5gHRdnb4fClW84njE7RWEyQqE+TbM+z43FVlKmQl48N8FTp0Ypcpi5d005D6yrYHm5ez7eslhiJLgJIYQQYkkw6AwsL1zO8sLlsBy0+zT6w/0cPH2SoXPTpIYU1oFCkhdtdL6Q5qhxPwH3AFpJHHeJFV+xh+rycmqLqqh2VcvMlYuAwWCnoGALBQVbLm3TNA1Ny83espdugWiSrtEgFp0fl2EYg9ZDPHKReKSXZG4Y1Mw08rc1Gugc3sL+sU18e1+Cb7zSS5PXzIfWVXPrmnJqi+wS9sU1IcFNCCGEEEuSUopady2122ph28w2La/ROzBC55k+RroTmIca0J+1wFlIA93AWf0FIuaDZGxxdM481gI91hIdnnILhV4PBZaCN9yMepnZcCFRSqGUgZmPweZL28sKoKyg4k2fk89nSCaHCPs7CY+fokjfwbqKbzGdi3FobB37R9v5qxdS/NULF3AbcqwudLK+voT1rT5WV3tkdktxVUhwE0IIIYSYpXSK+toK6mtf/wAfD6cJ+xNMTgQZGh3HP5nDEvCSDnlQgyYMvTMTnMSAMdM0AfsRArYR/PZhAvYhnIUW1pasZV3JOtYXr6fOXSc9MouMTmfEZqvDVl1HafWdl7ZnMtNsnTrD74ye4NzwCxyajHIhXMKFUC179sdhfy8KaHCYWVPpobHCRW2Zi9oiO9UFNqwmmehEvHMS3IQQQggh3obNZcLmMlFa72YlNb/1eDycxj8UYbg/wFi/g+mRQhIjK0CbCWc5Y4aAfYhnrSd4zPELUt4QjTU1rCtZx7qSdbQVtmHQyUeyxcho9FJUsp2iku00rIE7tDzh8Ckmhp6jf/RJzk5l6QnV0jvVyDMXqvlRl/kNz/cZdFTazNS4LNQV2WltKqKtzkuFxyrhXvwWOUsIIYQQQrwPNpeJ6rZCqtsKL23LpnNMjcaYHIjgH4wy0V9A6XA9+VENgMyxFOdt/eyz/4C4e5q6unI2t65le8023GaZ6GKxUkqH270Gt3sNjcv/hG2pMQL+l5gcf5Hp0NeJpBWT8SLG4z4mE0VMxIuYjPvYPVHMz4accGIIALteo9Fro626kNYqN82lLppLnbitcsnlUibBTQghhBDiKjOY9BTXuCiucV3alsvlmRqZCXMT/RFG+zxMDzeijSrogp6ncxy3PIVWkKS4ys2qpiZWtTbh8Frm8Z2I98NiLqWi4iNUVHwETcuTzYZIpSZJpydJp/2k035SqUlSiUMEpsc4H4gyEHEzHC1nMFLOz05V8L1jr0+C47MpGksdtJYV0lTqpLHESWOxQ8bQLRES3IQQQggh5oBer8NX5cRX5aRt68y2XC5PcDyOfyjCue4+BvripCYd5IadHD/g5xiTREpHMayMUNVWQL2njjp3HUXWIrmUbpFRSofR6MVo9AJNb7rPDk0jlR4nGuokNHqKkP85hiJjXEzCcKyEkWgpw/4yjvSVks6/vnh8iSPLijIDG2td3NBQzoqqGvR6+Zh/vZF/o0IIIYQQ80Sv11FY7qCw3EFze9ml7UP+EfacPkTf2UmsF8owPVdOz95JflHyXbqKD2Ky6qlz11HtqqbKWUWVs4pKRyVVzioJdYuYUgqLuRRLcSlFxbsAWAfkMilioxeJjl0kNt1DLLqPgXiI3gwMZC0MxYs4PljPCxeA58LYDMdocg+x3B1ghSdJm8eK19GGy7sSe1E9Bq8FZZDFwxcbCW5CCCGEEAtMZVE5H911H+yCXDbPxWMTHHuxD3efjy3D95Gqn6DHeJRjiWP8qudXaGiXnmvRW6h0VlLprKTGWUONu4ZaVy21rloJdYuU3mjGVd2Gq7rt0rbVmkYunCYzEiUxOk4qMUpfdJxjwRgnI4oz0VJOBGZ69gwqS4FlGq/leQpNEUoUlCkLlUYfdfYaKoqq8JY4MPlsGIqs6GwGqZMFSIKbEEIIIcQCpjfoaGovpam9lMmBCKdfHuL8IT2t5+9kc/GHcBZa0LmypG1xIuYp/IYRhlUffeFu9o/sJ5VLXTqWzWCjxjUb5Ny1NHubaS5opsJRIR/UFxmlFAa3GYPbjLW1EGijDLjhsn0mIykO901xciBA//g4Q1Nuzofy7E+a0Hitxy0OnEORx65P49CncepzuAwKl0mPx2rB67LjKXLj8bjw2Bw4rSZcFgNOixHn7E+7SS81dI1JcBNCCCGEWCR81U5u+kQrWx5YRtf+UcZ6QkQCScKDSZLRHODGiptltNJs0GFzmzA6FHlrioQpStgwxWR8lJHhfo7kf0nc8DhJQwybxUJTQRPN3mZaClpoLmimzl2H1WC9YpvEwuVzmrlzZRl3riwDVlzans3lGQ1G6B47R+9YL+OhINORJKF4lnBKI5LRMZWxMBi3EQ3pSAzp0UgDk2/5WjrFpRDntBgvBbsCu5Eyt5UKj5Uyj4Vyj5Vyt1XWsHsPJLgJIYQQQiwyFruRNTdXv2FbJpWbCXGBBNGpJOFAklgoRTyUJhbSQUiHOW6jkkoq2Uj7Zc/VDDnSxgRRfZCD+hF2Gy+QMEbI2hIYnGD1GHB5bRQVuvHZfRTbiimyFuGz+SiyFmHWv3F9MrGwGfQ6qgrdVBW2s2t5+5vuk8slSKcnScbGiI+PExwbY8o/TTAcIZpNElE5YipP1JAlrBLEM1aSWQeZfDkZzUcq6WEobuHkUIbJSOq3ju+xGSl3W6nz2WkucdJc6qS5xElVgQ29Tnru3owENyGEEEKI64DRrKeg3E5Buf0t98lmcsRDaeLhNPFQmmQsQyKaJhnNkIzO/B4KxYiGk2SDGmTfOIFFnhyDpjCdpn4C9lcZd/Yx5uhFc6UuhbgiaxGl9lLWl6xnfcl67Ma3bo9YuPR6K1ZrNVZrNd4iqFj++mO5UIr0YITUQITMSJRUdJKI7hRx51niBXtJO0YA0GWsWOI1oBUS0coIaqVMa4VMaW6mcmbGYzlOD03zy1Ojl45tMepoLHbSVOKkpdTJmmoPKyvcWIzSQyfBTQghhBBiiTAY9biKrLiKrnwJpKZppOJZotMpotNJotMpIlMJpvwRgoEY4ZE6lo9vAyBvzpAoDBBwDzFku8ALxpf45plvYlAGVhStYFPZJjaVbWK1bzUmvekKrywWOr3bjNVtxrqi6LKtN5FPZcmF0ySmRpmePkAofpi4vYdsvg+j7gSFhhiFv3mwesjGS5gMtTAaqWMoUsbgtIfdY0F+fGym502voMVjYnWZmTV1NtbUmSlx5meXWHBjMHgwGBwodX3PlCnBTQghhBBC/BalFBa7EYvdSFGl47cez+c1pkdjjPWEZm9u7J2lVLOBreojmAoUSWeQQf9Fnu86xBPWn5G0R1hbtoYVRSvwmr24zW68Fi8eswe32Y3H7MFhdMgkF4uUzmxA5zNg9DXgogH42BsezyaTJCfHSAZGSUyPkYpMkNJGSelHcBeMUFV8knX64KX9wykHPaFaLobquBis5Udd1XyvY+ayXI85SJVzGI85hNscxm2K4jWnKbDkKbIpfHYTXk817sL1eDzrsFgqF31dSXATQgghhBDvmk6nKKxwUFjhYPn2CgCS0QxjvSHGe8NMjcaYGrGi63dTra0DQNPlidqm6Lb0MuI6xajrIiHLJFz2edqgM1BuL6fWXUuda2bB8dduXot3Pt6quEoMFguOqlocVbVvuU82GyGe6CcR7yeZGmE9ehQGtARkojF6RhOcHjNwNmChL9LI0LQilDOQ57dDmdsUpsLZTaVjD9W2II12K63eKoq9q3H51mItLUItokswJbgJIYQQQoirwuIwUruyiNqVr19Cl83kmB6LMzUSY2okRmDER3FfGU09GwEwOhW2KlDlcdIlQULWSYZjw/SGejk4cpBcRsOctWHOWinQ+SjIFXI4fJZlxXW0lbVQU1SJ2WpEyYQW1wWDwYnLuQKXc8WbPt4A3PIb23J5jUAkyYQ/zkQgzvh0kolggov+COem3eyeaiKtzVxGqchTbBuh0nGUf7d6OTd94L5r+n6uJgluQgghhBDimjEY9fiqnPiqnJe2aZpGcDzO8PkgI+enGb4QJN5hBay4nNUUWjbREs+SSmTQ8m9y0NMwAozQB/TNbDPlMFr0ONxWSmvcFFe78VU7KaywY1hEvSri3dPrFMVuK8VuKzT81ig6cnmNvkCMc2MRzvaPcXZQxwW/B2tJyzy09r2T4CaEEEIIIeaUUgpvqR1vqZ0VOyrQNI3QRIKRC0FGu4PkchpmmwGz1YDJZsBiM2KyGjDbDJw+e5K2thUM+Ifp8w8wEhhjMjRFLJrAlLPgCHkZ21+J+RUbAJrKk3HH0PnSWEsVpdUeWpfVU19Sg14ngW4p0OsUDT4HDT7H7Jp2a+e7Se+JBDchhBBCCDGvlFJ4Smx4Smy0bSt/230vjitq23zU4mMHay5tj2VidAQ6uBi8SCDRz9RkhMQYaJMmjFNOXH3FGC44GQQG6SNhPE3KFcZYlKegzE51TSlN9TXozBrRXJRIOkI0HSWcDhPNzNzX0Kh0VFLlrKLaVU2hpXDRT3ghFg8JbkIIIYQQYtGzG+1sLN3IxtKNb/p4Pp9nMjDN+e5++vpGyYwmyU+aMXU7SZ0zc4E0F7gAQFZlyOrSZPVpsro0GX2erM5EWp/grPkkEfOLRMzTpG0x3EU2SguLqHJV4TA5yOazr9+013/Pa3kqHBU0eBpo8DRQ6aiUHj/xrkhwE0IIIYQQ1z2dTkeJr5ASXyHbb3h9u6ZpDI9O0Nndw8iIH13agFEzo8/Z0OeM6LJ6yOkgo0jGMoSnEmTG3zjwLqfLEjFNEdInABPqtX/UzE8dCh3Qow9z2niIuOl50qY4Do+FokIPlcWlVJaU4XE6cZqcOEwOnCYndqMdi94ivXoCkOAmhBBCCCGWMKUUleUlVJaXvOPnpBNZIlNJIoEk4UCSSCBBOFBKJpWbCWtKXVri4LXIpWkQiyaJTCdITecg93oYywC9QE5FSRrGSRpjJAxRksYoKWOcvDmDyaGjqMBDRXEJ9eXVtFY0Ueopvmp/B7HwSXATQgghhBDiXTBZDZfWsHsvNE0jFc8SD6WJh1NMTUUYm5wkFkmRiBpJRh1kYj5yCY18VIdKvf6RPQl0kKaDM2T0KfKWNAaHwmI1YLGasdutOO12XA4HFqsRo1mPyWrA4jBidZiwOmYWVdcbdVfpryHmigQ3IYQQQggh5pBSCot9JkAVlNuppIBV1Lzl/vlcnkQ0QzycZsI/Rf/YECOTE8SmwsTCKXJRMETNmHIWjDnzzC1vfts2ZPUpUqYEKUOMpDlKwhohbY+StsfI2RPknSkMZh0mvQmz3ozVYMWsN7/hd4vBgtVgxWly4jK5Zm7mmZ9OkxODTqLG1SR/TSGEEEIIIRYwnV6H3W3G7jbjq3Ky/DdCXl7LM5WcYiI+8fotepHJcIBAOEgsnsCacWDNOjBnbZjSNkwZK8a0BUfKiivuQTdqRpd9YzRImxIkbWEy+hQ5sqTIEiNDlgw5UmgqSF7lSBuSpPQJ0oYEKX189mcCvUVht1kosBdQ5CjA5yii2OGjxFVCmb2UEnuJzMz5LkhwE0IIIYQQYhHTKR1F1iKKrEW0Fba9p2NomkYymiHkTxDxJwkHEoT9M+P3Mqk8+byGltfI5zTyeY18Lk8ulyeXyZEO58iltHf0OsHZW4caIa8GyBrSaKYcRosOq92E02mnwOXG5XRgsRmxe8zYPWYcsz+N5vc+E6emacSzcQKJAP6EnwZPA26z+z0fb65JcBNCCCGEEGKJU0phdZqwOk2U1r37MJPP5Uknc6TiWdKJLKl4hlQiSyaZI5fNk8tq5LI5IskYkUSESDJGNJEgHIsRiyYJJbLo/UZM41ZGskHMORs67bdDmmbKgj2LzpFHZ9NAnwODRl6fA30eTZ8nr8+h6XMk9FGmdX4m1Sjj2jATmTES2cSlY/3zzf/M1oqt7+vvNpckuAkhhBBCCCHeF51eh8Wuw2I3vqfna5pGIBmgO9hN93Q33dPHGZwaJhdTqJgRfdyMPmHBlLBjTtmxT7mxTNjR540Y8kb0eRsGbea1X5t2xTF7q3rtNYw5dLY8JocOq8tIWbzu/b7tOSXBTQghhBBCCDGvlFKXLvfcXLb5bffVNI1sPksmn0EphV7pZ5ZhyCvyOchnNLKZHMlYlng4RTycnp3Bc/YWShGfTmPV2efo3V0dEtyEEEIIIYQQi4ZSCqPeiFH/G717OmbSjRnAiMMLM31u1wdZwEEIIYQQQgghFjgJbkIIIYQQQgixwElwE0IIIYQQQogFToKbEEIIIYQQQixwEtyEEEIIIYQQYoGT4CaEEEIIIYQQC5wENyGEEEIIIYRY4CS4CSGEEEIIIcQCJ8FNCCGEEEIIIRY4CW5CCCGEEEIIscBJcBNCCCGEEEKIBU6CmxBCCCGEEEIscBLchBBCCCGEEGKBk+AmhBBCCCGEEAucBDchhBBCCCGEWOAkuAkhhBBCCCHEAifBTQghhBBCCCEWOAluQgghhBBCCLHASXATQgghhBBCiAXumgY3pdTtSqlzSqlupdSfXsvXEkIIIYQQQojr1TULbkopPfCPwB1AG/ARpVTbtXo9IYQQQgghhLheXcset3agW9O0Hk3T0sD3gXuv4esJIYQQQgghxHVJaZp2bQ6s1IeB2zVN++zs/U8AmzRN+8Jv7Pd54PMAJSUl67///e9fk/a8H9FoFIfDMd/NENcxqTExF6TOxFyQOhPXmtSYmAvzWWe7du06qmnaht/cbpiPxlxO07SvAV8DUEpN7tq1q3+em/RmigD/fDdCXNekxsRckDoTc0HqTFxrUmNiLsxnndW82cZrGdyGgarL7lfObntLmqb5rmF73jOl1JE3S71CXC1SY2IuSJ2JuSB1Jq41qTExFxZinV3LMW6HgUalVJ1SygQ8Ajx5DV9PCCGEEEIIIa5L16zHTdO0rFLqC8AzgB74pqZpZ6/V6wkhhBBCCCHE9eqajnHTNO1XwK+u5WvMka/NdwPEdU9qTMwFqTMxF6TOxLUmNSbmwoKrs2s2q6QQQgghhBBCiKvjWo5xE0IIIYQQQghxFUhwE0IIIYQQQogFToLb21BK3a6UOqeU6lZK/el8t0dcH5RSVUqpl5RSHUqps0qpP5jdXqCUek4pdWH2p3e+2yoWN6WUXil1XCn11Oz9OqXUwdlz2g9mZ/wV4j1TSnmUUj9SSnUppTqVUjfIuUxcbUqpL83+//KMUupxpZRFzmfi/VJKfVMpNaGUOnPZtjc9f6kZ/zBbb6eUUuvmo80S3N6CUkoP/CNwB9AGfEQp1Ta/rRLXiSzwR5qmtQGbgX83W1t/CrygaVoj8MLsfSHejz8AOi+7/9+Av9M0bRkwDfzuvLRKXE/+B/C0pmktwGpm6k3OZeKqUUpVAF8ENmiatoKZmcofQc5n4v37FnD7b2x7q/PXHUDj7O3zwFfmqI1vIMHtrbUD3Zqm9Wialga+D9w7z20S1wFN00Y1TTs2+3uEmQ86FczU17dnd/s2cN+8NFBcF5RSlcBdwL/M3lfATcCPZneRGhPvi1LKDewAvgGgaVpa07Qgci4TV58BsCqlDIANGEXOZ+J90jRtDzD1G5vf6vx1L/AdbcYBwKOUKpuThl5GgttbqwAGL7s/NLtNiKtGKVULrAUOAiWapo3OPjQGlMxXu8R14e+B/wPIz94vBIKapmVn78s5TbxfdcAk8K+zl+T+i1LKjpzLxFWkadow8LfAADOBLQQcRc5n4tp4q/PXgsgFEtyEmCdKKQfwY+APNU0LX/6YNrNOh6zVId4TpdTdwISmaUfnuy3iumYA1gFf0TRtLRDjNy6LlHOZeL9mxxjdy8wXBeWAnd++vE2Iq24hnr8kuL21YaDqsvuVs9uEeN+UUkZmQttjmqb9ZHbz+Gvd7rM/J+arfWLR2wrco5TqY+Yy75uYGYvkmb3UCOScJt6/IWBI07SDs/d/xEyQk3OZuJpuBno1TZvUNC0D/ISZc5ycz8S18FbnrwWRCyS4vbXDQOPsrEUmZgbCPjnPbRLXgdmxRt8AOjVN+++XPfQk8KnZ3z8F/Hyu2yauD5qm/Z+aplVqmlbLzLnrRU3TPga8BHx4djepMfG+aJo2BgwqpZpnN30A6EDOZeLqGgA2K6Vss///fK3O5HwmroW3On89CXxydnbJzUDosksq54ya6QUUb0YpdScz40T0wDc1Tfuv89sicT1QSm0D9gKneX380f/FzDi3J4BqoB94SNO03xw0K8S7opTaCfyxpml3K6XqmemBKwCOAx/XNC01j80Ti5xSag0zE+CYgB7gM8x8KSznMnHVKKX+AniYmVmZjwOfZWZ8kZzPxHumlHoc2AkUAePAnwM/403OX7NfGvwvZi7TjQOf0TTtyJy3WYKbEEIIIYQQQixscqmkEEIIIYQQQixwEtyEEEIIIYQQYoGT4CaEEEIIIYQQC5wENyGEEEIIIYRY4CS4CSGEEEIIIcQCJ8FNCCHENaGU0pRS/99l9/9YKfWfr9Kxv6WU+vCV93zfr/OgUqpTKfXSb2yvVUollFInLrt98iq+7k6l1FNX63hCCCEWP8OVdxFCCCHekxTwgFLqrzRN8893Y16jlDJompZ9h7v/LvA5TdNeeZPHLmqatubqtUwIIYR4a9LjJoQQ4lrJAl8DvvSbD/xmj5lSKjr7c6dS6mWl1M+VUj1Kqf9XKfUxpdQhpdRppVTDZYe5WSl1RCl1Xil19+zz9Uqpv1FKHVZKnVJKPXrZcfcqpZ4EOt6kPR+ZPf4ZpdR/m932Z8A24BtKqb95p29aKRVVSv2dUuqsUuoFpZRvdvsapdSB2Xb9VCnlnd2+TCn1vFLqpFLq2GXv0aGU+pFSqksp9djsArDM/k06Zo/zt++0XUIIIRY3CW5CCCGupX8EPqaUcr+L56wG/g3QCnwCaNI0rR34F+D3L9uvFmgH7gL+WSllYaaHLKRp2kZgI/A5pVTd7P7rgD/QNK3p8hdTSpUD/w24CVgDbFRK3adp2n8BjgAf0zTtT96knQ2/cank9tntduCIpmnLgZeBP5/d/h3gy5qmrQJOX7b9MeAfNU1bDWwBRme3rwX+EGgD6oGtSqlC4H5g+exx/vLt/5RCCCGuFxLchBBCXDOapoWZCSxffBdPO6xp2qimaSngIvDs7PbTzIS11zyhaVpe07QLQA/QAtwKfFIpdQI4CBQCjbP7H9I0rfdNXm8jsFvTtMnZSygfA3a8g3Ze1DRtzWW3vbPb88APZn//38C22eDq0TTt5dnt3wZ2KKWcQIWmaT8F0DQtqWla/LL2DmmalgdOzL73EJBkphfwAeC1fYUQQlznJLgJIYS41v6emZ4w+2Xbssz+P0gppQNMlz2Wuuz3/GX387xxbLb2G6+jAQr4/cvCVJ2maa8Fv9j7eRPvw2+28526/O+QA14bm9cO/Ai4G3j6fbZNCCHEIiHBTQghxDWladoU8AQz4e01fcD62d/vAYzv4dAPKqV0s2PC6oFzwDPA7ymljABKqSallP3tDgIcAm5UShUppfTAR5i5xPG90gGvjd/7KPCKpmkhYPqyyyk/AbysaVoEGFJK3TfbXrNSyvZWB1ZKOQC3pmm/Ymbs4Or30U4hhBCLiMwqKYQQYi78f8AXLrv/deDnSqmTzPQavZfesAFmQpcL+DeapiWVUv/CzCWFx2Yn85gE7nu7g2iaNqqU+lPgJWZ67H6padrP38HrN8xekvmab2qa9g/MvJd2pdR/BCaAh2cf/xQzY/FszFza+ZnZ7Z8AvqqU+i9ABnjwbV7TyczfzTLb1n//DtophBDiOqA07b1ewSGEEEKI36SUimqa5pjvdgghhLi+yKWSQgghhBBCCLHASY+bEEIIIYQQQixw0uMmhBBCCCGEEAucBDchhBBCCCGEWOAkuAkhhBBCCCHEAifBTQghhBBCCCEWOAluQgghhBBCCLHA/f/tJ7ztIuenAQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss_history_key = list(loss_history.keys())\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.title(\"Training loss vs. Number of Epochs\")\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Training Loss\")\n",
    "z\n",
    "\n",
    "for key in loss_history_key:\n",
    "    loss_list = loss_history[key]\n",
    "    labels = f'd_model: {transformer_experiment[transformer_experiment[\"experiment_id\"] == key][\"d_model\"].values[0]}, heads: {transformer_experiment[transformer_experiment[\"experiment_id\"] == key][\"heads\"].values[0]}, num_layers: {transformer_experiment[transformer_experiment[\"experiment_id\"] == key][\"num_layers\"].values[0]}'\n",
    "    plt.plot(loss_list, label = labels)\n",
    "\n",
    "    \n",
    "plt.plot(history_rnn['loss'], \n",
    "                label = 'LSTM (Baseline FLUENT 2023)', \n",
    "                linestyle='dashed', \n",
    "                color='black', \n",
    "                linewidth=2.5, \n",
    "                alpha=0.7, \n",
    "                marker='o', \n",
    "                markerfacecolor='black', \n",
    "                markersize=5\n",
    "        )\n",
    "\n",
    "plt.legend()\n",
    "torch.cuda.is_available()plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformers without reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = [512, 1024, 2048, 4096]\n",
    "heads = [8, 16, 32]\n",
    "num_layers = [5, 10]\n",
    "epochs = 100\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "with open('WORDMAP_corpus_KBFILKOM.json', 'r') as j:\n",
    "    word_map = json.load(j)\n",
    "\n",
    "transformer_experiment = pd.DataFrame(columns = ['experiment_id', 'd_model', 'heads', 'num_layers', 'train_loss'])\n",
    "loss_history = {}\n",
    "\n",
    "experiment_id = -1\n",
    "\n",
    "for d_m in d_model:\n",
    "    for h in heads:\n",
    "        for n_l in num_layers: \n",
    "            experiment_id += 1\n",
    "            print('\\nRunning for experiment {} with d_model {}, heads{}, num_layers{}\\n'.format(experiment_id, d_m, h, n_l))\n",
    "            name = \"experiment_2724_noreg_\" + str(experiment_id)\n",
    "\n",
    "            run = neptune_init(name)\n",
    "            run['parameters'] = {\n",
    "                'd_model': d_m,\n",
    "                'heads': h,\n",
    "                'num_layers': n_l\n",
    "            }\n",
    "\n",
    "            transformer_experiment.loc[experiment_id, 'experiment_id'] = 'experiment_{}'.format(str(experiment_id))\n",
    "            transformer_experiment.loc[experiment_id, 'd_model'] = d_m\n",
    "            transformer_experiment.loc[experiment_id, 'heads'] = h\n",
    "            transformer_experiment.loc[experiment_id, 'num_layers'] = n_l\n",
    "\n",
    "            transformer = Transformer(d_model = d_m, heads = h, num_layers = n_l, word_map = word_map, max_len=95)\n",
    "            transformer = transformer.to(device)\n",
    "            adam_optimizer = torch.optim.Adam(transformer.parameters(), lr=0.001, betas=(0.9, 0.98), eps=1e-9)\n",
    "            transformer_optimizer = AdamWarmup(model_size = d_m, warmup_steps = 4000, optimizer = adam_optimizer)\n",
    "            criterion = LossWithLS(len(word_map), 0.2)\n",
    "\n",
    "            loss_list_experiment = []\n",
    "            for epoch in range(epochs):\n",
    "                loss_train = train(train_loader, transformer, criterion, epoch)\n",
    "\n",
    "                state = {'epoch': epoch, 'transformer': transformer, 'transformer_optimizer': transformer_optimizer}\n",
    "                torch.save(state, 'checkpoint_experiment_' + str(epoch) + 'id_'+ str(experiment_id) +'.pth.tar')\n",
    "\n",
    "                loss_list_experiment.append(loss_train)\n",
    "\n",
    "                run['train/loss'].append(loss_train)\n",
    "\n",
    "            transformer_experiment.loc[experiment_id, 'train_loss'] = loss_train\n",
    "            loss_history['experiment_{}'.format(str(experiment_id))] = loss_list_experiment\n",
    "            \n",
    "            run.stop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andyalyfsyah/.conda/envs/myenv/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.Size([100, 90, 2048])\n",
      "tensor([[[  -4.5191,   50.5624,    0.0000,  ...,    5.9596,   -8.0914,\n",
      "             7.4170],\n",
      "         [  21.1835,  -32.8019,    2.5135,  ...,  -12.0732,    0.6595,\n",
      "             0.0000],\n",
      "         [   9.1062,   -6.3892,   69.0442,  ...,  -54.4731,  -90.4005,\n",
      "            48.6294],\n",
      "         ...,\n",
      "         [ -68.7001,  -13.0567,   -3.5143,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         [ -67.7476,  -12.0546,   -3.9737,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         [ -66.8313,  -11.7860,   -3.4453,  ...,   79.5327,   67.9524,\n",
      "           -78.4697]],\n",
      "\n",
      "        [[ -60.7689,   -5.1273,   71.5492,  ...,   -9.0693, -115.8350,\n",
      "           -40.0406],\n",
      "         [ -36.5924,   81.6685,  -72.3661,  ...,  114.3140,  -25.8074,\n",
      "             6.2455],\n",
      "         [ -70.5471,   14.0965,  -23.4235,  ...,    7.0582,  -30.7245,\n",
      "            79.4537],\n",
      "         ...,\n",
      "         [  -0.0000,  -13.0567,   -3.5143,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         [ -67.7476,  -12.0546,   -3.9737,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         [ -66.8313,  -11.7860,   -3.4453,  ...,   79.5327,    0.0000,\n",
      "           -78.4697]],\n",
      "\n",
      "        [[  86.3852,    0.0000,    6.1185,  ...,   77.6506,   -0.0000,\n",
      "           -41.2876],\n",
      "         [ -13.4383,   34.8706,   15.1649,  ...,   50.2014,  -11.3914,\n",
      "            41.3254],\n",
      "         [ -42.3586,   80.4666,  104.6697,  ...,   36.6179,   59.3807,\n",
      "            10.7103],\n",
      "         ...,\n",
      "         [ -68.7001,  -13.0567,   -3.5143,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         [ -67.7476,  -12.0546,   -3.9737,  ...,   79.5327,    0.0000,\n",
      "           -78.4697],\n",
      "         [ -66.8313,  -11.7860,   -3.4453,  ...,   79.5327,   67.9524,\n",
      "           -78.4697]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -60.7689,   -5.1273,   71.5492,  ...,   -9.0693, -115.8350,\n",
      "           -40.0406],\n",
      "         [ -36.5924,   81.6685,  -72.3661,  ...,  114.3140,   -0.0000,\n",
      "             6.2455],\n",
      "         [   5.6516,  -26.9206,  -55.3294,  ...,    0.2853,    1.4260,\n",
      "           -48.5408],\n",
      "         ...,\n",
      "         [ -68.7001,  -13.0567,   -3.5143,  ...,   79.5327,    0.0000,\n",
      "           -78.4697],\n",
      "         [ -67.7476,  -12.0546,   -0.0000,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         [ -66.8313,  -11.7860,   -3.4453,  ...,   79.5327,   67.9524,\n",
      "           -78.4697]],\n",
      "\n",
      "        [[ -64.7824,    5.7053,   13.4799,  ...,  -89.4086,   15.9771,\n",
      "           120.2854],\n",
      "         [  32.1104,  -11.5790,   -9.0661,  ...,  -24.0485,  -38.4529,\n",
      "            39.7281],\n",
      "         [ 114.1511,   58.1542,   96.3612,  ...,   48.0482,   10.1813,\n",
      "             0.0000],\n",
      "         ...,\n",
      "         [ -68.7001,  -13.0567,   -3.5143,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         [  -0.0000,  -12.0546,   -3.9737,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         [ -66.8313,   -0.0000,   -3.4453,  ...,   79.5327,   67.9524,\n",
      "           -78.4697]],\n",
      "\n",
      "        [[  86.3852,    0.0000,    6.1185,  ...,   77.6506,  -21.4817,\n",
      "           -41.2876],\n",
      "         [ -13.4383,   34.8706,   15.1649,  ...,   50.2014,  -11.3914,\n",
      "            41.3254],\n",
      "         [-115.6408,  -76.6615,  -31.9216,  ...,   43.5892,   72.0255,\n",
      "            65.1974],\n",
      "         ...,\n",
      "         [ -68.7001,  -13.0567,   -3.5143,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         [ -67.7476,  -12.0546,   -3.9737,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         [ -66.8313,  -11.7860,   -3.4453,  ...,   79.5327,   67.9524,\n",
      "           -78.4697]]], device='cuda:0', grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 90, 2048])\n",
      "tensor([[[ 0.6290,  2.4933,  1.2798,  ...,  2.5323,  0.1885,  2.3423],\n",
      "         [ 1.9088,  0.6183,  2.4596,  ...,  1.2660,  0.0213,  2.0408],\n",
      "         [ 0.0000, -0.0620,  3.7310,  ...,  0.5749, -1.4656,  2.7865],\n",
      "         ...,\n",
      "         [-1.4060,  0.3380,  0.9184,  ...,  4.3798,  1.5140,  1.0163],\n",
      "         [-0.5189,  1.1619, -0.1474,  ...,  3.5697,  1.4960,  0.2278],\n",
      "         [ 0.6782,  0.9326,  0.2382,  ...,  4.5895,  0.0000, -0.0398]],\n",
      "\n",
      "        [[-0.0000,  0.0000,  2.5057,  ...,  1.5767, -2.4499,  0.9081],\n",
      "         [ 0.0000,  3.3456,  0.5653,  ...,  4.1484, -0.2864,  1.8400],\n",
      "         [ 0.4658,  0.8573,  2.0922,  ...,  1.6520, -0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.4356, -0.2314, -0.2775,  ...,  3.8182,  1.8612, -0.0663],\n",
      "         [-0.2186,  0.0000, -0.1332,  ...,  4.4441,  1.2523,  0.2597],\n",
      "         [ 0.5020,  1.0936,  0.4702,  ...,  4.2466, -0.0686, -0.1295]],\n",
      "\n",
      "        [[ 2.5325,  1.5002,  0.8511,  ...,  3.5858,  0.2765,  0.5870],\n",
      "         [ 1.4503,  2.1735,  1.3441,  ...,  3.6636,  0.9997,  3.1572],\n",
      "         [ 0.6893,  1.5710,  3.7434,  ...,  3.9286,  2.0064,  1.7727],\n",
      "         ...,\n",
      "         [-0.8794,  0.0000,  0.4241,  ...,  3.8602,  1.5948,  0.1774],\n",
      "         [ 0.3715,  1.4470, -0.4228,  ...,  4.4795, -0.1688,  0.3695],\n",
      "         [ 1.4002,  1.5898,  0.4113,  ...,  3.9677,  1.1878,  0.5917]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.1151,  1.1751,  3.5954,  ...,  0.0000, -2.5821,  0.9503],\n",
      "         [ 1.6245,  3.3616,  1.0841,  ...,  4.7177,  0.1514,  2.2577],\n",
      "         [ 2.3384,  0.5066,  1.7236,  ...,  2.4273,  0.2858,  2.0538],\n",
      "         ...,\n",
      "         [-2.2867,  0.0000,  1.2356,  ...,  0.0000,  0.1078,  0.0562],\n",
      "         [-1.1799,  0.8976,  1.2638,  ...,  3.1394,  1.3648,  0.2161],\n",
      "         [ 0.1812,  1.6568,  1.3649,  ...,  3.8688,  1.3849,  0.5365]],\n",
      "\n",
      "        [[-0.1094,  1.6680,  1.0478,  ...,  0.7403,  0.0000,  0.0000],\n",
      "         [ 2.9209,  0.7156,  2.0411,  ...,  1.6294, -0.4336,  3.1134],\n",
      "         [ 4.8763,  1.3395,  4.5146,  ...,  3.2747,  0.7776,  2.0573],\n",
      "         ...,\n",
      "         [-1.0348, -0.0328,  0.0000,  ...,  3.9686,  2.4999,  0.1134],\n",
      "         [ 0.0000,  1.0322,  0.6127,  ...,  3.4730,  2.6846, -0.1827],\n",
      "         [ 0.7243,  1.3730,  0.2399,  ...,  3.3490,  2.2292, -0.3771]],\n",
      "\n",
      "        [[ 2.3926,  2.1479,  0.0000,  ...,  3.8223,  0.5609,  0.0000],\n",
      "         [ 1.1081,  1.2015,  1.8829,  ...,  2.8690,  0.2368,  2.5908],\n",
      "         [-0.6526, -1.5938,  2.4352,  ...,  3.8009,  0.9441,  0.0000],\n",
      "         ...,\n",
      "         [-0.3872,  0.3306,  1.3978,  ...,  4.2136,  1.7615,  0.1592],\n",
      "         [-0.0345,  0.0000,  0.1040,  ...,  3.4295,  1.6072,  0.1809],\n",
      "         [ 1.0438,  1.0367,  0.0000,  ...,  0.0000,  0.0000,  0.0134]]],\n",
      "       device='cuda:0', grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 90, 2048])\n",
      "tensor([[[ 0.9119,  1.6483,  1.4004,  ...,  3.1490,  0.6308,  3.2488],\n",
      "         [ 0.0000,  0.0278,  3.4716,  ...,  2.6343, -0.1903,  0.0000],\n",
      "         [ 1.3450, -1.3753,  4.0828,  ...,  2.1119, -0.4965,  3.7058],\n",
      "         ...,\n",
      "         [-1.5574, -0.7657,  0.0000,  ...,  0.0000,  1.0961,  2.2809],\n",
      "         [-0.0000,  0.5709, -0.8251,  ...,  4.4309,  1.3614,  2.0634],\n",
      "         [ 1.6357,  0.7168, -0.1431,  ...,  5.1315, -0.4459,  1.6222]],\n",
      "\n",
      "        [[ 0.3964,  0.0000,  2.4385,  ...,  2.9102, -1.4740,  0.0000],\n",
      "         [ 0.0000,  0.0000,  1.5554,  ...,  4.1638, -0.0676,  2.8956],\n",
      "         [ 1.8337, -0.0000,  2.7473,  ...,  2.6034,  0.0794,  1.8560],\n",
      "         ...,\n",
      "         [-0.0930, -1.5256,  0.2812,  ...,  4.1124,  1.6849,  1.5192],\n",
      "         [ 0.7373, -0.0000, -0.2904,  ...,  4.6012,  1.2199,  1.7831],\n",
      "         [ 1.9231,  0.5533,  0.7151,  ...,  4.2304,  0.0000,  1.3873]],\n",
      "\n",
      "        [[ 0.0000,  0.9692,  1.3083,  ...,  0.0000,  0.0000,  2.0496],\n",
      "         [ 2.3217,  0.0000,  2.4302,  ...,  4.2232,  0.0000,  3.8703],\n",
      "         [ 2.0761, -0.7983,  4.1681,  ...,  4.4488,  1.9180,  2.7785],\n",
      "         ...,\n",
      "         [-0.7252, -1.4282,  0.6638,  ...,  0.0000,  1.5881,  1.8615],\n",
      "         [ 0.9736,  0.4737, -0.9143,  ...,  5.0020,  0.0000,  1.8258],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  4.3669,  1.0534,  2.0230]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.6259,  0.4265,  2.9943,  ...,  1.4720, -1.6630,  2.8472],\n",
      "         [ 2.5065,  0.0000,  2.2597,  ...,  4.9593,  0.0000,  3.4850],\n",
      "         [ 3.1330, -1.4150,  3.0354,  ...,  3.2177,  0.3573,  3.8463],\n",
      "         ...,\n",
      "         [-2.0584, -1.2315,  0.7927,  ...,  1.7730,  0.4252,  2.1097],\n",
      "         [-0.5020, -0.1124,  0.6545,  ...,  3.6258,  0.3896,  2.3316],\n",
      "         [ 1.2966,  1.2182,  0.0000,  ...,  4.0948,  1.2172,  2.2488]],\n",
      "\n",
      "        [[ 0.0824,  0.6961,  0.8470,  ...,  1.9830,  0.4168,  2.0696],\n",
      "         [ 3.4511, -0.4416,  2.3306,  ...,  0.0000,  0.0000,  3.9957],\n",
      "         [ 4.8058, -1.3045,  4.4983,  ...,  3.5491,  0.6997,  3.2901],\n",
      "         ...,\n",
      "         [-0.9476, -1.9865,  0.2442,  ...,  4.3378,  2.2326,  1.7430],\n",
      "         [ 0.4555, -0.0729,  0.3998,  ...,  4.2177,  2.6838,  1.6669],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  3.9643,  1.9313,  1.5113]],\n",
      "\n",
      "        [[ 1.5786,  1.1613,  0.1543,  ...,  4.1958,  0.2765,  1.7262],\n",
      "         [ 1.7795,  0.0794,  2.4081,  ...,  3.5796,  0.9683,  2.9849],\n",
      "         [ 0.6917, -2.8499,  3.1365,  ...,  4.5078,  0.8903,  1.6951],\n",
      "         ...,\n",
      "         [-0.7508, -1.0640,  0.9037,  ...,  4.7244,  1.5455,  1.5011],\n",
      "         [ 0.3255, -0.5569, -0.0000,  ...,  3.8680,  1.3838,  1.9305],\n",
      "         [ 1.5945,  0.5996,  0.1759,  ...,  1.5829,  0.2693,  1.5714]]],\n",
      "       device='cuda:0', grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 90, 2048])\n",
      "tensor([[[ 0.1786, -0.0407,  0.6005,  ...,  3.4857,  0.0000,  3.4696],\n",
      "         [ 0.7798, -1.0657,  2.8537,  ...,  3.2422,  0.2874,  1.6023],\n",
      "         [ 0.0000, -2.8214,  2.9468,  ...,  2.8024, -0.7900,  3.7378],\n",
      "         ...,\n",
      "         [-1.9012, -2.2696, -0.6301,  ...,  2.0007,  0.8615,  2.9206],\n",
      "         [-0.0654, -0.6368, -1.6802,  ...,  4.2754,  1.0465,  2.8994],\n",
      "         [ 1.5077, -0.1899, -0.6840,  ...,  4.3556,  0.3849,  2.5589]],\n",
      "\n",
      "        [[-0.0000, -1.1180,  1.2917,  ...,  3.4569, -1.1904,  1.8644],\n",
      "         [ 0.9274, -1.3331,  1.4744,  ...,  0.0000, -0.5571,  3.1563],\n",
      "         [ 1.7692, -2.2390,  2.3047,  ...,  3.1639,  0.0000,  2.5943],\n",
      "         ...,\n",
      "         [-0.8632, -3.1830, -0.0000,  ...,  3.7384,  1.5822,  2.6184],\n",
      "         [ 0.1748, -0.8777, -1.2386,  ...,  4.0793,  1.1435,  2.7947],\n",
      "         [ 1.6470, -0.2520, -0.2449,  ...,  0.0000,  1.0083,  2.5341]],\n",
      "\n",
      "        [[-0.0000, -0.3682,  0.7037,  ...,  1.7428,  0.2402,  2.8634],\n",
      "         [ 2.1731, -0.9505,  2.3585,  ...,  3.9638,  0.2317,  3.5602],\n",
      "         [ 1.4992, -2.8782,  3.1282,  ...,  3.9888,  0.7342,  3.1296],\n",
      "         ...,\n",
      "         [-1.3228, -2.5902, -0.1881,  ...,  2.0396,  1.5419,  0.0000],\n",
      "         [ 0.3232, -0.8759, -1.7362,  ...,  4.4207, -0.0000,  2.8166],\n",
      "         [ 0.7561, -0.7948, -0.4057,  ...,  0.0000,  1.2560,  2.4263]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0234, -0.0000,  1.5403,  ...,  2.3441, -0.5854,  3.4512],\n",
      "         [ 2.1372, -0.7661,  1.9586,  ...,  0.0000,  0.2530,  3.9486],\n",
      "         [ 0.0000, -2.8385,  2.5166,  ...,  0.0000, -0.0513,  3.9506],\n",
      "         ...,\n",
      "         [-2.3094, -0.0000, -0.1477,  ...,  2.4236,  0.5389,  0.0000],\n",
      "         [-0.4155, -1.1496, -0.7313,  ...,  3.4250,  0.7962,  3.1651],\n",
      "         [ 1.3480,  0.0000, -0.5137,  ...,  3.9343,  0.9673,  3.5120]],\n",
      "\n",
      "        [[-0.0000, -0.8614,  0.0000,  ...,  2.9146,  0.9043,  3.0567],\n",
      "         [ 2.3836, -1.6718,  2.2566,  ...,  2.1047,  0.5055,  3.5882],\n",
      "         [ 3.4594, -2.8651,  3.5950,  ...,  0.0000,  0.7863,  3.2465],\n",
      "         ...,\n",
      "         [-1.4503, -3.3433, -0.3293,  ...,  4.0446,  1.5842,  2.9127],\n",
      "         [-0.2058, -1.5773, -0.5404,  ...,  3.9420,  0.0000,  3.1283],\n",
      "         [ 0.6282, -1.2314, -0.2447,  ...,  3.9392,  1.4232,  2.4510]],\n",
      "\n",
      "        [[ 0.5511, -0.0980,  0.3774,  ...,  3.9688,  0.0000,  2.5097],\n",
      "         [ 1.5017, -0.9619,  2.2913,  ...,  3.5668,  0.7393,  3.1906],\n",
      "         [ 1.0922, -0.0000,  0.0000,  ...,  3.9345,  0.8358,  2.3977],\n",
      "         ...,\n",
      "         [-1.4204, -2.5590, -0.0122,  ...,  4.2704,  0.9727,  2.2082],\n",
      "         [ 0.1327, -1.4133, -0.8589,  ...,  3.8054,  0.0000,  2.6411],\n",
      "         [ 1.3936, -0.4388, -0.1591,  ...,  2.6134,  0.0000,  2.5613]]],\n",
      "       device='cuda:0', grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 90, 2048])\n",
      "tensor([[[-1.0208, -0.7633, -0.7114,  ...,  3.4740,  0.6778,  3.3177],\n",
      "         [ 0.1325, -1.5889,  1.2576,  ...,  0.0000,  0.4794,  2.8108],\n",
      "         [ 0.0000, -3.2044,  1.2962,  ...,  3.2869,  0.0291,  3.5360],\n",
      "         ...,\n",
      "         [-3.1626, -2.9010, -1.9791,  ...,  3.1294,  0.6313,  3.2404],\n",
      "         [-1.1142, -1.1849, -2.9812,  ...,  4.0447,  1.0010,  3.1067],\n",
      "         [ 0.5430, -0.5102, -1.9036,  ...,  4.1549,  0.7714,  3.0710]],\n",
      "\n",
      "        [[-0.9682, -1.2422, -0.3444,  ...,  3.7260, -0.1978,  2.9571],\n",
      "         [ 0.7578, -1.4743,  0.4507,  ...,  0.0000, -0.1282,  3.4506],\n",
      "         [ 0.4025, -0.0000,  0.8702,  ...,  0.0000,  0.0000,  3.0849],\n",
      "         ...,\n",
      "         [-2.4027, -0.0000, -1.4215,  ...,  0.0000,  0.9339,  3.1920],\n",
      "         [-0.6388, -1.0711, -0.0000,  ...,  3.7831,  1.0854,  3.2146],\n",
      "         [ 0.0000, -0.5654, -1.9925,  ...,  1.7686,  0.7862,  3.0363]],\n",
      "\n",
      "        [[-1.3300, -0.5467, -0.4322,  ...,  2.6888,  0.1773,  3.1414],\n",
      "         [ 1.0796, -0.0000,  1.4273,  ...,  3.6518,  0.7128,  3.3016],\n",
      "         [ 0.6188, -3.2480,  1.8471,  ...,  3.7336,  0.6844,  3.1985],\n",
      "         ...,\n",
      "         [-2.5950, -2.6339, -0.0000,  ...,  0.0000,  0.5880,  0.0000],\n",
      "         [-0.8722, -1.0181, -2.8061,  ...,  4.0259,  0.2945,  0.0000],\n",
      "         [ 0.0719, -0.9719, -1.4896,  ...,  2.0043,  0.8534,  2.9442]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.0287, -0.0000, -0.6212,  ...,  2.9276, -0.0207,  3.9569],\n",
      "         [ 0.8419, -1.1502,  0.9799,  ...,  2.0034,  0.8275,  3.9490],\n",
      "         [-0.0000, -0.0000,  1.1831,  ...,  1.7449,  0.1601,  3.3502],\n",
      "         ...,\n",
      "         [-3.1630, -1.5736, -1.2260,  ...,  2.7752,  0.6026,  1.8264],\n",
      "         [-1.4589, -1.2912, -0.0000,  ...,  3.6253,  0.8268,  0.0000],\n",
      "         [ 0.0000, -0.1265, -1.5658,  ...,  3.9020,  1.1707,  3.2028]],\n",
      "\n",
      "        [[-0.7710, -0.9048, -0.8770,  ...,  3.3116,  0.1049,  3.6510],\n",
      "         [ 1.5033, -1.9124,  1.0456,  ...,  3.0532,  0.5213,  3.6460],\n",
      "         [ 1.8497, -3.6893,  1.4455,  ...,  1.9473,  0.4332,  3.5443],\n",
      "         ...,\n",
      "         [-2.8166, -3.4450, -1.6209,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [-1.2439, -1.3836, -0.0000,  ...,  4.0152,  0.6158,  0.0000],\n",
      "         [ 0.1895, -1.0252, -1.4373,  ...,  3.9638,  0.8223,  3.3387]],\n",
      "\n",
      "        [[-0.4386, -0.5812, -0.7702,  ...,  3.9713,  0.3276,  2.8474],\n",
      "         [ 0.2006, -1.2806,  1.0352,  ...,  3.2964,  0.6530,  0.0000],\n",
      "         [ 0.4620, -1.9181,  0.4780,  ...,  3.8084,  0.6839,  0.0000],\n",
      "         ...,\n",
      "         [-2.6431, -2.6983, -1.3147,  ...,  0.0000,  0.8688,  2.6832],\n",
      "         [-0.8591, -1.1610, -2.1664,  ...,  3.4594,  0.3161,  3.2450],\n",
      "         [ 0.3195, -0.4684, -1.7411,  ...,  3.0331,  0.4740,  2.7528]]],\n",
      "       device='cuda:0', grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 91, 2048])\n",
      "tensor([[[-1.2303e+02,  7.2536e+01,  5.5620e+01,  ..., -2.7637e+01,\n",
      "           9.8614e-03,  9.5118e+01],\n",
      "         [ 0.0000e+00,  2.2842e+01, -3.2537e+01,  ...,  7.0587e+00,\n",
      "           3.0977e+01, -3.9303e+00],\n",
      "         [-7.0547e+01,  0.0000e+00, -2.3424e+01,  ...,  7.0582e+00,\n",
      "          -3.0725e+01,  7.9454e+01],\n",
      "         ...,\n",
      "         [-6.7748e+01, -1.2055e+01, -3.9737e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -0.0000e+00],\n",
      "         [-6.6831e+01, -1.1786e+01, -3.4453e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6794e+01, -1.2494e+01, -2.3993e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01]],\n",
      "\n",
      "        [[-1.2303e+02,  7.2536e+01,  5.5620e+01,  ..., -2.7637e+01,\n",
      "           9.8614e-03,  9.5118e+01],\n",
      "         [-3.5841e+00,  5.0060e+01,  1.0187e+02,  ...,  5.9596e+00,\n",
      "          -8.0914e+00,  0.0000e+00],\n",
      "         [ 2.1259e+01, -3.3855e+01,  2.6155e+00,  ..., -1.2073e+01,\n",
      "           6.5951e-01,  6.7868e+01],\n",
      "         ...,\n",
      "         [-6.7748e+01, -1.2055e+01, -3.9737e+00,  ...,  7.9533e+01,\n",
      "           0.0000e+00, -7.8470e+01],\n",
      "         [-6.6831e+01, -1.1786e+01, -3.4453e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6794e+01, -0.0000e+00, -0.0000e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01]],\n",
      "\n",
      "        [[-1.2303e+02,  7.2536e+01,  5.5620e+01,  ..., -0.0000e+00,\n",
      "           9.8614e-03,  9.5118e+01],\n",
      "         [-4.2434e+01,  8.1519e+01,  1.0457e+02,  ...,  3.6618e+01,\n",
      "           5.9381e+01,  1.0710e+01],\n",
      "         [ 5.8031e+01,  4.9025e+01,  5.3900e+01,  ..., -3.7644e+01,\n",
      "           1.1883e+02,  1.5150e+02],\n",
      "         ...,\n",
      "         [-6.7748e+01, -1.2055e+01, -3.9737e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6831e+01, -1.1786e+01, -3.4453e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-0.0000e+00, -1.2494e+01, -2.3993e+00,  ...,  0.0000e+00,\n",
      "           6.7952e+01, -7.8470e+01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.2303e+02,  7.2536e+01,  5.5620e+01,  ..., -2.7637e+01,\n",
      "           9.8614e-03,  9.5118e+01],\n",
      "         [-3.5841e+00,  5.0060e+01,  1.0187e+02,  ...,  5.9596e+00,\n",
      "          -8.0914e+00,  7.4170e+00],\n",
      "         [ 2.1259e+01, -3.3855e+01,  2.6155e+00,  ..., -1.2073e+01,\n",
      "           6.5951e-01,  6.7868e+01],\n",
      "         ...,\n",
      "         [-6.7748e+01, -1.2055e+01, -3.9737e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6831e+01, -1.1786e+01, -3.4453e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6794e+01, -1.2494e+01, -2.3993e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01]],\n",
      "\n",
      "        [[-1.2303e+02,  7.2536e+01,  5.5620e+01,  ..., -2.7637e+01,\n",
      "           0.0000e+00,  9.5118e+01],\n",
      "         [-1.2189e+02,  3.4296e+01,  8.2960e+01,  ..., -5.0501e+01,\n",
      "          -0.0000e+00, -2.4845e+01],\n",
      "         [-0.0000e+00, -3.7859e+01, -0.0000e+00,  ...,  3.0751e+01,\n",
      "          -7.2558e+01,  3.3138e+01],\n",
      "         ...,\n",
      "         [-0.0000e+00, -1.2055e+01, -3.9737e+00,  ...,  7.9533e+01,\n",
      "           0.0000e+00, -7.8470e+01],\n",
      "         [-6.6831e+01, -1.1786e+01, -3.4453e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-0.0000e+00, -1.2494e+01, -2.3993e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -0.0000e+00]],\n",
      "\n",
      "        [[-1.2303e+02,  7.2536e+01,  5.5620e+01,  ..., -2.7637e+01,\n",
      "           9.8614e-03,  9.5118e+01],\n",
      "         [ 8.3301e+01, -4.8273e+01,  1.9783e+01,  ..., -0.0000e+00,\n",
      "           4.7483e+01,  1.6129e+01],\n",
      "         [-1.1564e+02, -7.6661e+01, -0.0000e+00,  ...,  4.3589e+01,\n",
      "           7.2025e+01,  6.5197e+01],\n",
      "         ...,\n",
      "         [-6.7748e+01, -1.2055e+01, -3.9737e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6831e+01, -1.1786e+01, -3.4453e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6794e+01, -1.2494e+01, -2.3993e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01]]], device='cuda:0',\n",
      "       grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 91, 2048])\n",
      "tensor([[[-2.5289,  3.2575,  2.1019,  ...,  1.3337, -0.0104,  0.0000],\n",
      "         [ 1.4768,  1.2755,  0.0000,  ...,  2.3792, -0.0198,  0.9228],\n",
      "         [-0.6095,  0.2566,  1.8050,  ...,  2.5838, -0.4577,  2.7215],\n",
      "         ...,\n",
      "         [-0.2907,  1.3843,  0.1818,  ...,  4.1236,  0.8964,  1.3837],\n",
      "         [ 0.2755,  1.6755,  0.6726,  ...,  0.0000,  1.0176, -0.4445],\n",
      "         [-1.0129,  0.0000,  0.0000,  ...,  3.7543,  1.0904, -0.2128]],\n",
      "\n",
      "        [[-1.5681,  3.3547,  2.5097,  ...,  0.6913, -0.4189,  3.3948],\n",
      "         [ 2.3956,  1.9539,  3.6184,  ...,  2.3329, -0.1168,  1.2077],\n",
      "         [ 2.6630, -0.2085,  2.5853,  ...,  1.1520, -0.0226,  2.1392],\n",
      "         ...,\n",
      "         [-0.2378,  0.4473, -0.0206,  ...,  3.8941, -0.3786,  0.5883],\n",
      "         [ 0.4127,  1.4257,  0.0000,  ...,  3.4836,  1.5106,  0.0802],\n",
      "         [ 0.3729,  0.9358,  2.0758,  ...,  3.3418,  1.3219,  0.0193]],\n",
      "\n",
      "        [[-2.0991,  3.9105,  1.7694,  ...,  1.2656, -0.0447,  2.8594],\n",
      "         [ 0.5027,  3.3447,  4.3119,  ...,  0.0000,  1.1763,  1.8531],\n",
      "         [ 0.0000,  0.9637,  3.3965,  ...,  0.0000,  2.1465,  4.7370],\n",
      "         ...,\n",
      "         [-1.2044,  1.3067, -1.1570,  ...,  4.0777,  1.0582,  0.5975],\n",
      "         [-0.5071,  1.7508, -0.4512,  ...,  3.5031,  1.7627,  0.1776],\n",
      "         [ 0.0000,  0.9359,  0.7657,  ...,  2.0957,  0.7278,  0.2100]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.5712,  3.6395,  1.9175,  ...,  0.6903, -0.1074,  2.9788],\n",
      "         [ 1.1383,  2.3820,  4.4725,  ...,  2.0398,  0.3946,  1.1876],\n",
      "         [ 1.8172, -0.4878,  2.0722,  ...,  0.0000,  0.3296,  3.0644],\n",
      "         ...,\n",
      "         [-0.3312,  1.3372,  0.0532,  ...,  0.0000,  1.6065,  0.6382],\n",
      "         [ 0.1875,  0.0000,  0.2155,  ...,  3.8148,  1.6211,  0.0000],\n",
      "         [ 0.5640,  1.2241,  1.0825,  ...,  3.7644,  1.3085,  0.3444]],\n",
      "\n",
      "        [[-2.6419,  0.0000,  2.2640,  ...,  1.1773, -0.0599,  2.7158],\n",
      "         [-0.0000,  1.8863,  3.1650,  ...,  1.1057,  0.0000,  1.0178],\n",
      "         [ 1.6623, -0.9799,  2.1640,  ...,  2.6341, -1.3148,  0.0000],\n",
      "         ...,\n",
      "         [-0.0933,  1.6702, -0.0000,  ...,  3.4269, -0.0000, -0.3422],\n",
      "         [-0.7484,  2.1661,  0.4503,  ...,  3.8648,  0.6650,  0.2038],\n",
      "         [ 0.9942,  0.6993,  0.8046,  ...,  4.0906,  0.5271,  1.1017]],\n",
      "\n",
      "        [[-2.3076,  3.4622,  2.1754,  ...,  1.0069,  0.1194,  3.6473],\n",
      "         [ 3.3446,  0.0626,  2.3358,  ...,  1.6092,  1.3151,  1.4891],\n",
      "         [-0.0000, -1.2281,  2.5928,  ...,  2.4944,  1.6589,  2.7783],\n",
      "         ...,\n",
      "         [-0.7579,  0.0000,  0.3124,  ...,  0.0000,  1.0740,  0.3837],\n",
      "         [ 0.3160,  1.4632,  0.4691,  ...,  3.6871,  1.0784,  0.7038],\n",
      "         [-0.3144,  0.0000,  0.6206,  ...,  3.8133,  1.2214,  0.3774]]],\n",
      "       device='cuda:0', grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 91, 2048])\n",
      "tensor([[[-1.5752e+00,  2.6781e+00,  2.1913e+00,  ...,  1.8358e+00,\n",
      "          -3.2965e-01,  3.3773e-01],\n",
      "         [ 2.3457e+00,  1.0596e+00,  1.8417e+00,  ...,  2.7008e+00,\n",
      "          -5.1233e-01,  0.0000e+00],\n",
      "         [ 3.3550e-01, -4.9403e-01,  3.2313e+00,  ...,  2.3846e+00,\n",
      "          -7.2159e-01,  1.7502e+00],\n",
      "         ...,\n",
      "         [-8.9813e-02,  1.0674e+00, -1.9506e-01,  ...,  3.5300e+00,\n",
      "           3.0797e-01,  1.3963e+00],\n",
      "         [ 1.3989e+00,  0.0000e+00,  0.0000e+00,  ...,  1.1593e+00,\n",
      "           1.1731e-01,  7.1428e-01],\n",
      "         [ 6.4283e-01, -0.0000e+00,  2.0768e+00,  ...,  3.2136e+00,\n",
      "           3.5358e-03,  8.1240e-01]],\n",
      "\n",
      "        [[-4.8117e-01,  2.7776e+00,  2.6086e+00,  ...,  1.3589e+00,\n",
      "          -7.2591e-01,  2.4299e+00],\n",
      "         [ 0.0000e+00,  1.3238e+00,  4.3887e+00,  ...,  2.5637e+00,\n",
      "          -2.4220e-01,  1.6380e+00],\n",
      "         [ 3.4577e+00, -1.6064e+00,  4.2390e+00,  ...,  2.1205e+00,\n",
      "          -4.4866e-01,  1.9323e+00],\n",
      "         ...,\n",
      "         [ 5.4722e-02,  7.5717e-01,  1.0160e-01,  ...,  3.6493e+00,\n",
      "          -0.0000e+00,  1.1614e+00],\n",
      "         [ 1.6695e+00,  1.1977e+00,  4.7664e-01,  ...,  3.3189e+00,\n",
      "           6.5474e-01,  8.5057e-01],\n",
      "         [ 1.4326e+00,  4.0011e-01,  0.0000e+00,  ...,  3.3265e+00,\n",
      "           0.0000e+00,  1.0923e+00]],\n",
      "\n",
      "        [[-7.2808e-01,  3.0764e+00,  2.2024e+00,  ...,  2.0267e+00,\n",
      "          -1.4020e-01,  2.3232e+00],\n",
      "         [ 7.5146e-01,  2.0137e+00,  0.0000e+00,  ...,  1.5916e+00,\n",
      "           6.5856e-01,  1.6048e+00],\n",
      "         [ 6.6928e-01,  2.3427e-01,  4.5335e+00,  ...,  1.2329e+00,\n",
      "           7.3691e-01,  3.2010e+00],\n",
      "         ...,\n",
      "         [-6.5344e-01,  1.3830e+00, -0.0000e+00,  ...,  3.1905e+00,\n",
      "           1.4930e-01,  0.0000e+00],\n",
      "         [ 7.1258e-01,  1.8316e+00,  4.1710e-02,  ...,  3.5743e+00,\n",
      "           6.1719e-01,  1.0057e+00],\n",
      "         [ 5.2759e-01, -2.9327e-01,  2.0848e+00,  ...,  2.6845e+00,\n",
      "           1.8580e-01,  1.1230e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.4919e+00,  2.4752e+00,  2.0930e+00,  ...,  1.2348e+00,\n",
      "          -4.9606e-01,  2.7620e+00],\n",
      "         [ 2.0431e+00,  1.7609e+00,  4.7758e+00,  ...,  0.0000e+00,\n",
      "           3.0483e-02,  1.1503e+00],\n",
      "         [ 2.4249e+00, -0.0000e+00,  0.0000e+00,  ...,  1.2542e+00,\n",
      "           0.0000e+00,  2.4271e+00],\n",
      "         ...,\n",
      "         [-0.0000e+00,  1.1825e+00,  9.6118e-02,  ...,  8.4316e-01,\n",
      "           0.0000e+00,  1.2825e+00],\n",
      "         [ 1.2548e+00,  1.6940e-01,  7.6274e-01,  ...,  3.4484e+00,\n",
      "           8.8604e-01,  5.4957e-01],\n",
      "         [ 1.5210e+00,  6.9323e-01,  2.3296e+00,  ...,  0.0000e+00,\n",
      "           4.5281e-01,  1.4038e+00]],\n",
      "\n",
      "        [[-1.4272e+00,  3.9753e-01,  0.0000e+00,  ...,  1.7579e+00,\n",
      "          -2.5413e-01,  2.5334e+00],\n",
      "         [ 5.6777e-01,  0.0000e+00,  3.8750e+00,  ...,  1.6893e+00,\n",
      "          -9.4848e-02,  1.4522e+00],\n",
      "         [ 1.5504e+00, -0.0000e+00,  0.0000e+00,  ...,  2.5777e+00,\n",
      "          -1.3773e+00,  4.4541e-01],\n",
      "         ...,\n",
      "         [-0.0000e+00,  1.1814e+00, -4.4659e-02,  ...,  3.3259e+00,\n",
      "          -2.9780e-01,  3.8443e-01],\n",
      "         [-0.0000e+00,  1.9275e+00,  8.7569e-01,  ...,  3.7137e+00,\n",
      "          -1.5387e-01,  9.7194e-01],\n",
      "         [ 9.5925e-01,  1.3290e-01,  1.5851e+00,  ...,  3.5801e+00,\n",
      "          -5.1979e-01,  1.0670e+00]],\n",
      "\n",
      "        [[-1.6423e+00,  3.1153e+00,  2.3537e+00,  ...,  1.4547e+00,\n",
      "          -7.2508e-01,  3.2737e+00],\n",
      "         [ 3.2999e+00,  4.7785e-02,  3.7289e+00,  ...,  2.0712e+00,\n",
      "           6.7716e-01,  1.3308e+00],\n",
      "         [ 9.6907e-01, -1.6602e+00,  3.9970e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  1.9940e+00],\n",
      "         ...,\n",
      "         [-5.8924e-01,  4.8360e-01,  2.7237e-01,  ...,  1.0419e+00,\n",
      "           1.7094e-01,  1.2500e+00],\n",
      "         [ 1.6195e+00,  1.4463e+00,  8.6552e-01,  ...,  3.2716e+00,\n",
      "           6.1950e-01,  1.6170e+00],\n",
      "         [ 1.0092e+00, -2.5279e-01,  1.9659e+00,  ...,  0.0000e+00,\n",
      "           4.0003e-01,  9.2101e-01]]], device='cuda:0',\n",
      "       grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 91, 2048])\n",
      "tensor([[[-1.7156e+00,  1.1745e+00,  1.0391e+00,  ...,  2.0146e+00,\n",
      "          -1.9883e-01,  1.1330e+00],\n",
      "         [ 1.5295e+00, -7.4338e-02,  2.6538e+00,  ...,  2.4849e+00,\n",
      "          -6.6281e-01,  1.0919e+00],\n",
      "         [ 5.6586e-01, -1.5667e+00,  0.0000e+00,  ...,  1.9663e+00,\n",
      "          -4.5545e-01,  1.9038e+00],\n",
      "         ...,\n",
      "         [-9.0397e-01,  5.9194e-01, -7.7352e-01,  ...,  0.0000e+00,\n",
      "          -3.3216e-03,  1.8096e+00],\n",
      "         [ 8.5424e-01, -1.7337e-01, -4.8768e-01,  ...,  1.2804e+00,\n",
      "           1.1782e-01,  1.8208e+00],\n",
      "         [ 0.0000e+00, -4.2345e-01,  1.9029e+00,  ...,  2.4945e+00,\n",
      "          -4.0387e-01,  0.0000e+00]],\n",
      "\n",
      "        [[-3.6745e-01,  0.0000e+00,  2.1273e+00,  ...,  2.3179e+00,\n",
      "          -9.2602e-01,  2.3740e+00],\n",
      "         [ 5.2099e-01,  3.6466e-01,  4.0038e+00,  ...,  2.6348e+00,\n",
      "          -4.8277e-01,  1.7175e+00],\n",
      "         [ 0.0000e+00, -2.0697e+00,  3.0386e+00,  ...,  2.3115e+00,\n",
      "          -5.2803e-01,  2.1494e+00],\n",
      "         ...,\n",
      "         [-5.0100e-01,  0.0000e+00, -1.1775e-01,  ...,  2.3952e+00,\n",
      "          -3.5000e-01,  1.9445e+00],\n",
      "         [ 1.2717e+00,  8.2243e-01,  8.8030e-02,  ...,  2.4507e+00,\n",
      "           3.2144e-02,  1.7530e+00],\n",
      "         [ 0.0000e+00, -4.0201e-01,  1.0765e+00,  ...,  2.4844e+00,\n",
      "          -2.4731e-01,  1.3641e+00]],\n",
      "\n",
      "        [[-1.1486e+00,  1.9833e+00,  1.2713e+00,  ...,  2.0707e+00,\n",
      "          -2.2955e-01,  2.1380e+00],\n",
      "         [ 7.1493e-02,  7.0753e-01,  1.7753e+00,  ...,  2.0472e+00,\n",
      "           3.4658e-02,  1.6895e+00],\n",
      "         [ 5.0630e-01, -1.7810e+00,  0.0000e+00,  ...,  1.5698e+00,\n",
      "          -2.9721e-01,  2.6477e+00],\n",
      "         ...,\n",
      "         [-1.0973e+00,  2.7237e-01, -6.0503e-01,  ...,  2.6742e+00,\n",
      "          -1.1587e-01,  1.2964e+00],\n",
      "         [ 8.4363e-01,  1.5405e+00,  9.3482e-02,  ...,  3.0607e+00,\n",
      "          -2.7774e-02,  1.7133e+00],\n",
      "         [ 0.0000e+00, -3.9611e-01,  2.0644e+00,  ...,  2.5982e+00,\n",
      "          -2.3291e-01,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.2820e+00,  2.0664e+00,  1.5576e+00,  ...,  1.4562e+00,\n",
      "          -5.8410e-01,  3.0816e+00],\n",
      "         [ 1.4453e+00,  3.2099e-01,  3.7002e+00,  ...,  1.0001e+00,\n",
      "          -3.0309e-01,  1.4441e+00],\n",
      "         [ 1.5854e+00, -9.4807e-01,  1.6743e+00,  ...,  1.9535e+00,\n",
      "          -3.0976e-01,  2.2708e+00],\n",
      "         ...,\n",
      "         [-8.1267e-01,  4.6319e-01, -7.5054e-01,  ...,  1.4063e+00,\n",
      "          -2.7475e-01,  1.5649e+00],\n",
      "         [ 3.1495e-01,  0.0000e+00,  2.8743e-01,  ...,  2.7219e+00,\n",
      "           7.5627e-02,  1.3975e+00],\n",
      "         [ 1.1385e+00,  8.1408e-02,  1.8900e+00,  ...,  7.1862e-01,\n",
      "          -2.3226e-01,  1.6133e+00]],\n",
      "\n",
      "        [[-1.0554e+00,  8.1156e-02,  9.9830e-01,  ...,  2.3305e+00,\n",
      "          -5.5411e-01,  1.5323e+00],\n",
      "         [ 3.8263e-01, -1.7911e-01,  3.2214e+00,  ...,  2.3411e+00,\n",
      "          -3.5803e-01,  1.5310e+00],\n",
      "         [ 4.0760e-01, -1.0658e+00,  1.5124e+00,  ...,  2.3182e+00,\n",
      "          -8.4288e-01,  1.3247e+00],\n",
      "         ...,\n",
      "         [-0.0000e+00,  3.9712e-01, -4.3745e-01,  ...,  2.8296e+00,\n",
      "          -5.8380e-01,  9.9725e-01],\n",
      "         [ 1.2488e-01,  1.2734e+00,  4.1406e-01,  ...,  3.0441e+00,\n",
      "          -0.0000e+00,  1.1816e+00],\n",
      "         [ 4.9945e-01, -2.0258e-01,  2.0223e+00,  ...,  2.8902e+00,\n",
      "          -6.3544e-01,  1.8220e+00]],\n",
      "\n",
      "        [[-1.4247e+00,  1.8066e+00,  1.3465e+00,  ...,  1.4800e+00,\n",
      "          -5.7517e-01,  2.3442e+00],\n",
      "         [ 1.7705e+00,  7.7670e-02,  3.7350e+00,  ...,  1.6446e+00,\n",
      "          -1.2217e-01,  1.5563e+00],\n",
      "         [ 1.1026e+00, -2.0897e+00,  3.7352e+00,  ...,  1.3478e+00,\n",
      "          -7.4789e-02,  1.6253e+00],\n",
      "         ...,\n",
      "         [-8.0501e-01,  5.2209e-01, -2.4703e-01,  ...,  1.9319e+00,\n",
      "          -0.0000e+00,  0.0000e+00],\n",
      "         [ 9.9563e-01,  1.2551e+00,  4.8810e-01,  ...,  0.0000e+00,\n",
      "           2.5916e-01,  2.0153e+00],\n",
      "         [ 1.1510e+00, -2.2834e-01,  2.1024e+00,  ...,  1.4217e+00,\n",
      "          -1.8528e-01,  1.4482e+00]]], device='cuda:0',\n",
      "       grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 91, 2048])\n",
      "tensor([[[-1.7093e+00,  5.2684e-01,  3.2534e-01,  ...,  1.9148e+00,\n",
      "          -2.7493e-01,  1.4981e+00],\n",
      "         [ 7.9199e-02,  2.4555e-01,  1.6140e+00,  ...,  2.2870e+00,\n",
      "          -7.3472e-01,  0.0000e+00],\n",
      "         [-1.4759e-01, -1.3500e+00,  9.7292e-01,  ...,  1.7294e+00,\n",
      "          -1.6265e-01,  2.0595e+00],\n",
      "         ...,\n",
      "         [-1.6006e+00,  1.0201e+00, -1.7570e+00,  ...,  9.6909e-01,\n",
      "          -4.0733e-01,  2.0220e+00],\n",
      "         [-3.6978e-02,  4.8237e-01, -1.3252e+00,  ...,  1.8280e+00,\n",
      "          -0.0000e+00,  2.2545e+00],\n",
      "         [ 1.0485e-01, -5.7526e-01,  8.0513e-01,  ...,  2.3555e+00,\n",
      "          -4.5019e-01,  0.0000e+00]],\n",
      "\n",
      "        [[-1.1476e+00,  6.1305e-01,  1.1176e+00,  ...,  2.7017e+00,\n",
      "          -1.0500e+00,  2.7093e+00],\n",
      "         [ 4.7231e-03,  3.4047e-01,  2.1312e+00,  ...,  2.3354e+00,\n",
      "          -6.8549e-01,  1.7236e+00],\n",
      "         [-2.0533e-01, -1.6830e+00,  2.5079e+00,  ...,  2.1412e+00,\n",
      "          -4.6360e-01,  1.7955e+00],\n",
      "         ...,\n",
      "         [-1.3032e+00,  5.8858e-01, -1.4903e+00,  ...,  1.8556e+00,\n",
      "          -6.2281e-01,  1.8137e+00],\n",
      "         [ 5.2616e-01,  1.2263e+00, -9.9823e-01,  ...,  1.8079e+00,\n",
      "          -3.3896e-01,  2.1835e+00],\n",
      "         [-3.2440e-01, -4.8265e-01,  0.0000e+00,  ...,  1.7657e+00,\n",
      "          -3.8131e-01,  1.6473e+00]],\n",
      "\n",
      "        [[-1.7490e+00,  1.5978e+00,  2.5592e-01,  ...,  2.1707e+00,\n",
      "          -8.9093e-01,  1.6716e+00],\n",
      "         [-4.0018e-01,  8.8401e-01,  1.9239e+00,  ...,  1.8780e+00,\n",
      "          -4.3128e-01,  1.6134e+00],\n",
      "         [-4.7248e-01, -1.7703e+00,  7.1822e-01,  ...,  1.5890e+00,\n",
      "          -5.3190e-01,  2.1718e+00],\n",
      "         ...,\n",
      "         [-2.0625e+00,  8.3449e-01, -1.8061e+00,  ...,  2.7781e+00,\n",
      "          -2.6871e-01,  2.2256e+00],\n",
      "         [ 1.6187e-01,  1.4156e+00, -9.5049e-01,  ...,  2.3618e+00,\n",
      "          -4.2406e-01,  2.0140e+00],\n",
      "         [-6.3956e-01, -3.4917e-01,  1.0949e+00,  ...,  0.0000e+00,\n",
      "          -4.5955e-01,  1.2449e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.9117e+00,  1.8700e+00, -2.2183e-01,  ...,  1.2902e+00,\n",
      "          -4.5320e-01,  2.6249e+00],\n",
      "         [ 2.0306e-01,  0.0000e+00,  0.0000e+00,  ...,  1.6860e+00,\n",
      "          -3.0002e-01,  1.3248e+00],\n",
      "         [ 2.5663e-01, -1.4628e+00,  1.2744e+00,  ...,  1.8099e+00,\n",
      "          -5.0776e-01,  1.9352e+00],\n",
      "         ...,\n",
      "         [-1.9999e+00,  9.0948e-01, -1.8503e+00,  ...,  1.1850e+00,\n",
      "          -5.9655e-01,  1.8758e+00],\n",
      "         [-0.0000e+00,  6.3041e-01, -9.5766e-01,  ...,  1.7382e+00,\n",
      "          -2.2230e-01,  1.9425e+00],\n",
      "         [ 7.4959e-02,  6.8083e-02,  9.8053e-01,  ...,  1.5617e+00,\n",
      "          -3.2670e-01,  0.0000e+00]],\n",
      "\n",
      "        [[-1.2691e+00,  5.1812e-01,  3.5295e-01,  ...,  0.0000e+00,\n",
      "          -5.4439e-01,  1.8428e+00],\n",
      "         [-2.1845e-01,  4.1951e-01,  2.3263e+00,  ...,  2.2661e+00,\n",
      "          -4.6971e-01,  1.8800e+00],\n",
      "         [-6.1465e-01, -9.8697e-01,  1.4703e+00,  ...,  2.6081e+00,\n",
      "          -7.6981e-01,  1.6129e+00],\n",
      "         ...,\n",
      "         [-1.9500e+00,  4.4221e-01, -1.2955e+00,  ...,  2.1117e+00,\n",
      "          -7.6155e-01,  1.5268e+00],\n",
      "         [-8.8793e-01,  1.3852e+00, -7.2559e-01,  ...,  2.4522e+00,\n",
      "          -4.4285e-01,  1.9492e+00],\n",
      "         [-4.3566e-01,  1.7749e-03,  4.3883e-01,  ...,  2.4046e+00,\n",
      "          -6.8589e-01,  1.8666e+00]],\n",
      "\n",
      "        [[-2.0381e+00,  2.2432e+00,  2.6958e-01,  ...,  1.7365e+00,\n",
      "          -4.9976e-01,  2.1669e+00],\n",
      "         [ 1.2002e-02,  1.3700e-01,  1.5283e+00,  ...,  1.5848e+00,\n",
      "          -1.6672e-01,  1.8442e+00],\n",
      "         [ 3.1869e-02, -2.1090e+00,  0.0000e+00,  ...,  1.9006e+00,\n",
      "          -3.3941e-01,  1.9496e+00],\n",
      "         ...,\n",
      "         [-1.9207e+00,  7.6876e-01, -1.7306e+00,  ...,  0.0000e+00,\n",
      "          -2.5168e-01,  1.2381e+00],\n",
      "         [-1.5031e-01,  0.0000e+00, -8.0024e-01,  ...,  1.1212e+00,\n",
      "           0.0000e+00,  2.0660e+00],\n",
      "         [-2.6463e-01, -0.0000e+00,  1.0260e+00,  ...,  2.3990e+00,\n",
      "          -3.8905e-01,  2.0154e+00]]], device='cuda:0',\n",
      "       grad_fn=<NativeDropoutBackward0>)\n",
      "Epoch [0][0/12]\tLoss: 5.356\n",
      "\n",
      "torch.Size([100, 90, 2048])\n",
      "tensor([[[ 0.0000e+00,  4.9876e+01,  6.1185e+00,  ...,  7.7651e+01,\n",
      "          -2.1482e+01, -4.1288e+01],\n",
      "         [-1.3438e+01,  3.4871e+01,  1.5165e+01,  ...,  5.0201e+01,\n",
      "          -1.1391e+01,  4.1325e+01],\n",
      "         [-6.3923e+01, -2.3716e+01, -2.4289e+01,  ..., -5.8915e+01,\n",
      "          -1.8130e+01, -7.8652e+00],\n",
      "         ...,\n",
      "         [-6.8700e+01, -1.3057e+01, -3.5143e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.7748e+01, -1.2055e+01, -3.9737e+00,  ...,  0.0000e+00,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6831e+01, -1.1786e+01, -3.4453e+00,  ...,  7.9533e+01,\n",
      "           0.0000e+00, -0.0000e+00]],\n",
      "\n",
      "        [[-0.0000e+00, -7.2854e+01, -3.8650e+00,  ...,  6.4503e+01,\n",
      "          -4.0917e+00,  9.5946e+00],\n",
      "         [ 2.7431e+01, -2.5088e+01,  6.7927e+00,  ...,  3.7858e+00,\n",
      "           0.0000e+00, -1.3654e+00],\n",
      "         [ 9.9273e+01, -1.9218e+01, -7.3559e+01,  ..., -6.6725e+01,\n",
      "           6.9020e+01, -1.1120e+01],\n",
      "         ...,\n",
      "         [-0.0000e+00, -1.3057e+01, -3.5143e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.7748e+01, -1.2055e+01, -3.9737e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6831e+01, -1.1786e+01, -3.4453e+00,  ...,  0.0000e+00,\n",
      "           6.7952e+01, -7.8470e+01]],\n",
      "\n",
      "        [[-8.8967e+01,  2.6819e+01, -1.9535e+00,  ..., -3.4630e+01,\n",
      "          -2.4466e+01, -5.4679e+01],\n",
      "         [-1.5188e+02, -1.4156e+00, -4.9651e+01,  ..., -0.0000e+00,\n",
      "           1.9726e+01,  1.2007e+01],\n",
      "         [ 2.5140e+01,  8.9977e-02, -5.1773e-01,  ..., -3.1622e+01,\n",
      "           4.5982e+00,  6.2781e+01],\n",
      "         ...,\n",
      "         [-6.8700e+01, -1.3057e+01, -3.5143e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.7748e+01, -0.0000e+00, -3.9737e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6831e+01, -1.1786e+01, -3.4453e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 2.8286e+01,  2.3344e+01, -0.0000e+00,  ...,  7.0587e+00,\n",
      "           3.0977e+01, -0.0000e+00],\n",
      "         [ 2.8580e+01,  7.2780e-01,  1.3657e+01,  ..., -1.0675e+01,\n",
      "           2.9419e+01,  1.5804e+01],\n",
      "         [-9.7456e+00,  1.2121e+01,  1.3451e+02,  ...,  2.6554e+01,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [-6.8700e+01, -0.0000e+00, -3.5143e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-0.0000e+00, -1.2055e+01, -3.9737e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6831e+01, -1.1786e+01, -3.4453e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01]],\n",
      "\n",
      "        [[-2.7334e+01,  0.0000e+00,  1.0155e+02,  ..., -1.6195e+01,\n",
      "          -8.3145e+00,  3.1100e+01],\n",
      "         [-1.0722e+02,  2.6405e+01, -5.9223e+00,  ...,  3.6799e+01,\n",
      "           7.5500e+00, -9.8760e-01],\n",
      "         [-2.5277e+01, -8.0109e+01, -3.0028e+01,  ...,  8.4847e+00,\n",
      "           2.5155e+01, -1.4256e+02],\n",
      "         ...,\n",
      "         [-6.8700e+01, -1.3057e+01, -3.5143e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.7748e+01, -1.2055e+01, -3.9737e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6831e+01, -0.0000e+00, -3.4453e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01]],\n",
      "\n",
      "        [[ 4.9798e+01,  0.0000e+00,  2.2904e+01,  ...,  0.0000e+00,\n",
      "           1.9195e+01,  5.7498e+01],\n",
      "         [ 0.0000e+00,  3.9191e+01, -6.8040e+01,  ..., -1.0968e+01,\n",
      "           0.0000e+00,  3.2152e+01],\n",
      "         [-0.0000e+00,  2.7143e+00, -6.9537e+01,  ..., -1.0627e+02,\n",
      "           2.0256e+01,  2.9004e+01],\n",
      "         ...,\n",
      "         [-6.8700e+01, -0.0000e+00, -3.5143e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.7748e+01, -1.2055e+01, -0.0000e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6831e+01, -0.0000e+00, -0.0000e+00,  ...,  7.9533e+01,\n",
      "           0.0000e+00, -7.8470e+01]]], device='cuda:0',\n",
      "       grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 90, 2048])\n",
      "tensor([[[ 6.2688e-01,  2.8714e+00,  1.1592e+00,  ...,  2.6375e+00,\n",
      "          -2.0207e-01,  8.9062e-01],\n",
      "         [ 1.5466e+00,  1.9315e+00,  1.8811e+00,  ...,  2.9182e+00,\n",
      "           1.2507e+00,  2.8729e+00],\n",
      "         [ 6.2606e-01,  4.4474e-01,  2.4238e+00,  ...,  8.4756e-01,\n",
      "          -4.3878e-01,  1.7659e+00],\n",
      "         ...,\n",
      "         [-1.2564e+00, -5.4678e-01,  3.9205e-01,  ...,  4.2412e+00,\n",
      "           1.8380e+00,  7.7872e-01],\n",
      "         [-5.5960e-01,  4.1190e-01,  2.8733e-02,  ...,  2.8043e+00,\n",
      "           1.4786e+00,  4.1417e-01],\n",
      "         [ 1.0952e+00,  9.8005e-01,  7.5114e-01,  ...,  4.4982e+00,\n",
      "          -3.9646e-02,  1.8590e+00]],\n",
      "\n",
      "        [[ 1.0246e+00,  1.9281e-02,  1.1045e+00,  ...,  3.7783e+00,\n",
      "           3.2515e-02,  2.9588e+00],\n",
      "         [ 0.0000e+00,  6.7308e-01,  2.1648e+00,  ...,  2.5848e+00,\n",
      "           2.4397e-01,  2.2741e+00],\n",
      "         [ 4.3170e+00,  1.4827e-01,  1.7712e-01,  ...,  3.7390e-01,\n",
      "           1.9704e+00,  1.7869e+00],\n",
      "         ...,\n",
      "         [-3.0560e-02, -2.9208e-01,  1.3969e+00,  ...,  3.7013e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 5.0056e-01,  8.1710e-01,  5.8608e-01,  ...,  0.0000e+00,\n",
      "           1.4920e+00,  0.0000e+00],\n",
      "         [ 9.9081e-01,  7.6498e-01,  1.1126e+00,  ...,  1.9540e+00,\n",
      "           1.6388e+00,  6.8387e-01]],\n",
      "\n",
      "        [[-5.2756e-01,  2.0202e+00,  1.2800e+00,  ...,  8.4241e-01,\n",
      "          -0.0000e+00,  0.0000e+00],\n",
      "         [-4.2843e-01,  1.4025e+00,  1.6351e+00,  ...,  2.3796e+00,\n",
      "           6.2179e-01,  2.1018e+00],\n",
      "         [ 2.5921e+00,  0.0000e+00,  2.0958e+00,  ...,  6.0940e-01,\n",
      "           7.6287e-01,  3.6019e+00],\n",
      "         ...,\n",
      "         [-8.1212e-01, -6.7895e-01,  5.8305e-01,  ...,  3.3047e+00,\n",
      "           1.6033e+00,  4.5329e-01],\n",
      "         [ 1.2472e-01,  0.0000e+00,  3.3529e-01,  ...,  3.6686e+00,\n",
      "           1.1435e+00,  3.8817e-01],\n",
      "         [ 8.8728e-01,  8.3120e-01,  9.8812e-01,  ...,  3.0785e+00,\n",
      "           1.7930e+00,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 7.1007e-01,  1.4853e+00,  0.0000e+00,  ...,  1.7209e+00,\n",
      "           8.6124e-01,  1.4052e+00],\n",
      "         [ 0.0000e+00,  9.3924e-01,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           1.4923e+00,  1.7042e+00],\n",
      "         [ 1.2505e+00,  7.2002e-01,  0.0000e+00,  ...,  2.8567e+00,\n",
      "           4.7218e-01,  1.8685e+00],\n",
      "         ...,\n",
      "         [-1.3946e+00, -6.9712e-01,  7.2711e-01,  ...,  4.2573e+00,\n",
      "           1.5531e+00, -5.3020e-01],\n",
      "         [ 1.6342e+00,  5.1913e-01,  2.8497e-01,  ...,  4.3764e+00,\n",
      "           0.0000e+00,  1.0532e-01],\n",
      "         [ 7.2383e-01,  5.1797e-01,  1.1479e-01,  ...,  3.8672e+00,\n",
      "           1.5156e+00, -5.5736e-02]],\n",
      "\n",
      "        [[ 9.9269e-01,  1.8993e+00,  0.0000e+00,  ...,  2.2249e+00,\n",
      "           2.6245e-03,  3.4475e+00],\n",
      "         [-5.5681e-01,  1.0594e+00,  0.0000e+00,  ...,  3.0415e+00,\n",
      "          -1.8636e-01,  1.4696e+00],\n",
      "         [ 0.0000e+00, -1.3498e+00,  1.2644e+00,  ...,  3.1749e+00,\n",
      "           1.0759e+00, -1.1762e+00],\n",
      "         ...,\n",
      "         [-0.0000e+00, -4.4765e-01,  5.1404e-01,  ...,  3.6370e+00,\n",
      "           1.8252e+00,  1.2961e+00],\n",
      "         [-4.4578e-01,  5.0067e-01,  7.1692e-01,  ...,  3.5122e+00,\n",
      "           1.5480e+00,  4.9570e-02],\n",
      "         [ 1.1641e+00,  1.5284e+00,  6.9372e-01,  ...,  4.0403e+00,\n",
      "           1.0424e+00,  4.8417e-01]],\n",
      "\n",
      "        [[ 1.8531e+00,  1.2303e+00,  2.5078e+00,  ...,  1.7708e+00,\n",
      "           8.9153e-01,  2.8674e+00],\n",
      "         [ 2.3198e+00,  1.4398e+00,  6.9066e-01,  ...,  1.7146e+00,\n",
      "           5.6442e-02,  2.7061e+00],\n",
      "         [ 1.5296e+00,  5.4943e-01,  1.1726e+00,  ...,  2.6894e-02,\n",
      "           9.2936e-01,  2.8794e+00],\n",
      "         ...,\n",
      "         [-8.5505e-01, -6.3615e-01,  0.0000e+00,  ...,  4.0494e+00,\n",
      "           1.7084e+00,  1.7576e-01],\n",
      "         [ 4.3054e-01,  0.0000e+00, -1.5580e-01,  ...,  4.0018e+00,\n",
      "           1.9131e+00,  3.0370e-01],\n",
      "         [ 9.4579e-01,  1.2827e+00,  8.1511e-01,  ...,  0.0000e+00,\n",
      "          -2.7985e-01,  7.6104e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 90, 2048])\n",
      "tensor([[[ 0.0000e+00,  1.4655e+00,  1.0062e+00,  ...,  2.9726e+00,\n",
      "          -4.9692e-01,  2.2174e+00],\n",
      "         [ 1.8648e+00,  6.0318e-01,  2.5681e+00,  ...,  3.2213e+00,\n",
      "           9.8778e-01,  3.4694e+00],\n",
      "         [ 0.0000e+00, -1.2326e+00,  3.3483e+00,  ...,  0.0000e+00,\n",
      "          -0.0000e+00,  3.0202e+00],\n",
      "         ...,\n",
      "         [-1.8647e+00, -1.6366e+00,  2.6280e-01,  ...,  4.5003e+00,\n",
      "           1.6874e+00,  1.9252e+00],\n",
      "         [-2.2801e-01, -3.3185e-01, -2.4760e-01,  ...,  3.6599e+00,\n",
      "           1.0018e+00,  1.9659e+00],\n",
      "         [ 2.0621e+00,  3.9139e-01,  7.6294e-01,  ...,  4.5289e+00,\n",
      "           1.6378e-01,  2.5356e+00]],\n",
      "\n",
      "        [[ 1.1883e+00,  4.1399e-03,  1.4203e+00,  ...,  4.5342e+00,\n",
      "           1.8855e-01,  4.0867e+00],\n",
      "         [ 1.4482e+00, -2.4288e-01,  3.0219e+00,  ...,  3.0580e+00,\n",
      "           2.6777e-01,  3.0455e+00],\n",
      "         [ 4.0972e+00, -1.3970e+00,  1.8768e+00,  ...,  1.4973e+00,\n",
      "           1.7510e+00,  3.4233e+00],\n",
      "         ...,\n",
      "         [-1.1595e-01, -1.9087e+00,  6.4323e-01,  ...,  4.0802e+00,\n",
      "           7.2652e-01,  2.1551e+00],\n",
      "         [ 8.8199e-01,  2.8720e-01, -2.4658e-01,  ...,  0.0000e+00,\n",
      "           1.6910e+00,  2.1119e+00],\n",
      "         [ 1.9944e+00,  1.4973e-01,  1.1557e+00,  ...,  0.0000e+00,\n",
      "           1.9191e+00,  2.7686e+00]],\n",
      "\n",
      "        [[-9.5346e-02,  1.0064e+00,  1.4994e+00,  ...,  2.1227e+00,\n",
      "           3.7673e-01,  1.6180e+00],\n",
      "         [ 0.0000e+00,  5.7865e-01,  2.3543e+00,  ...,  3.3552e+00,\n",
      "           0.0000e+00,  3.2450e+00],\n",
      "         [ 3.2011e+00, -1.7449e+00,  2.7204e+00,  ...,  1.7847e+00,\n",
      "           6.4457e-01,  4.1451e+00],\n",
      "         ...,\n",
      "         [-8.5454e-01, -1.9601e+00,  2.5212e-01,  ...,  3.9465e+00,\n",
      "           1.6864e+00,  1.6319e+00],\n",
      "         [ 1.2315e+00, -4.4020e-01, -1.8430e-01,  ...,  3.9417e+00,\n",
      "           1.2700e+00,  0.0000e+00],\n",
      "         [ 2.2588e+00,  6.3613e-01,  8.1671e-01,  ...,  3.6847e+00,\n",
      "           0.0000e+00,  1.6915e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 8.0981e-01,  1.8832e-01,  2.6812e-01,  ...,  2.9329e+00,\n",
      "           6.0996e-01,  2.5806e+00],\n",
      "         [ 1.3186e+00, -2.8376e-01,  1.3034e+00,  ...,  2.1924e+00,\n",
      "           1.3542e+00,  2.3868e+00],\n",
      "         [ 2.6873e+00, -1.6284e+00,  1.2106e+00,  ...,  3.9115e+00,\n",
      "          -1.3949e-01,  2.8133e+00],\n",
      "         ...,\n",
      "         [-1.4024e+00, -2.2691e+00,  3.9607e-01,  ...,  4.2341e+00,\n",
      "           1.2514e+00,  1.3078e+00],\n",
      "         [ 1.1759e+00, -4.3223e-01, -0.0000e+00,  ...,  5.0251e+00,\n",
      "           1.1363e-01,  1.3025e+00],\n",
      "         [ 1.2895e+00, -2.2257e-01,  1.6875e-01,  ...,  0.0000e+00,\n",
      "           1.2379e+00,  1.4164e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  1.4415e+00,  2.6751e-01,  ...,  3.0460e+00,\n",
      "          -0.0000e+00,  4.4226e+00],\n",
      "         [ 8.5655e-01, -4.3438e-01,  1.3733e+00,  ...,  3.7007e+00,\n",
      "           9.1789e-02,  2.3008e+00],\n",
      "         [ 1.0327e+00, -0.0000e+00,  2.2574e+00,  ...,  3.5020e+00,\n",
      "           7.7662e-01,  9.8233e-01],\n",
      "         ...,\n",
      "         [-5.6225e-01, -1.8084e+00,  4.0786e-01,  ...,  4.2008e+00,\n",
      "           0.0000e+00,  3.0506e+00],\n",
      "         [ 4.1622e-01, -2.2938e-01,  5.0329e-01,  ...,  4.0779e+00,\n",
      "           1.5481e+00,  1.7100e+00],\n",
      "         [ 0.0000e+00,  3.4644e-01,  6.0817e-01,  ...,  4.2725e+00,\n",
      "           1.3326e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 1.8710e+00,  6.1651e-01,  2.4012e+00,  ...,  2.5096e+00,\n",
      "           0.0000e+00,  3.7470e+00],\n",
      "         [ 3.0273e+00, -4.7582e-01,  1.9810e+00,  ...,  0.0000e+00,\n",
      "           2.0369e-01,  3.6642e+00],\n",
      "         [ 2.3677e+00, -1.3191e+00,  2.4597e+00,  ...,  1.2272e+00,\n",
      "           8.8094e-01,  3.5585e+00],\n",
      "         ...,\n",
      "         [-0.0000e+00, -1.6362e+00, -1.2482e-01,  ...,  4.4975e+00,\n",
      "           1.2279e+00,  2.2912e+00],\n",
      "         [ 6.4095e-01, -4.0864e-01, -5.8097e-01,  ...,  4.2938e+00,\n",
      "           1.9467e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  7.0601e-01,  9.5245e-01,  ...,  1.7640e+00,\n",
      "           2.0555e-01,  1.6902e+00]]], device='cuda:0',\n",
      "       grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 90, 2048])\n",
      "tensor([[[-0.6521, -0.3110,  0.5821,  ...,  3.7067, -0.7619,  3.0186],\n",
      "         [ 1.4874, -1.1656,  2.3769,  ...,  3.5294,  0.7109,  3.8061],\n",
      "         [ 0.3773, -2.7603,  3.2112,  ...,  2.0098,  0.2761,  3.5677],\n",
      "         ...,\n",
      "         [-2.4880, -2.8419, -0.0227,  ...,  4.2949,  1.2946,  2.3784],\n",
      "         [-0.6902, -1.1270, -0.9045,  ...,  3.9798,  0.4842,  2.8995],\n",
      "         [ 1.7484, -0.4346,  0.2425,  ...,  4.2666,  0.5168,  0.0000]],\n",
      "\n",
      "        [[ 0.1791, -0.9508,  0.8088,  ...,  4.2305,  0.3606,  0.0000],\n",
      "         [ 1.3823, -1.4561,  2.6901,  ...,  3.3348,  0.0000,  3.4508],\n",
      "         [ 2.5055, -3.2744,  0.0000,  ...,  2.4397,  1.4584,  3.9230],\n",
      "         ...,\n",
      "         [-1.5277, -2.9340, -0.0299,  ...,  4.1104,  0.9472,  2.6701],\n",
      "         [ 0.0262, -0.0000, -0.4943,  ...,  0.0000,  1.4611,  3.3372],\n",
      "         [ 1.5883, -0.5916,  0.5630,  ...,  2.0758,  1.5355,  3.2307]],\n",
      "\n",
      "        [[-0.1482, -0.3035,  0.9037,  ...,  2.7833,  0.4653,  2.4937],\n",
      "         [ 0.9371, -1.0302,  0.0000,  ...,  3.3926,  0.1713,  3.3425],\n",
      "         [ 2.5831, -2.8467,  2.4162,  ...,  2.4769,  0.7364,  3.9889],\n",
      "         ...,\n",
      "         [-1.6440, -2.6668, -0.4637,  ...,  3.8517,  0.0000,  2.3328],\n",
      "         [ 0.3721, -1.1238, -1.1344,  ...,  3.6518,  1.3139,  1.7901],\n",
      "         [ 2.0408, -0.1008, -0.2688,  ...,  3.5943,  0.5566,  2.3787]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0552, -1.1243,  0.0000,  ...,  3.4068, -0.2608,  3.1347],\n",
      "         [ 1.1508, -0.0000,  0.0000,  ...,  3.2473,  0.0000,  3.0910],\n",
      "         [ 1.8365, -3.2393,  1.5815,  ...,  4.2207,  0.1402,  3.3161],\n",
      "         ...,\n",
      "         [-2.2515, -3.1240, -0.6618,  ...,  4.2985,  0.7747,  2.5876],\n",
      "         [ 0.4646, -1.7078, -0.0000,  ...,  4.7662,  0.2776,  2.2504],\n",
      "         [ 1.5689, -0.0000, -0.0000,  ...,  2.0605,  1.0187,  2.5543]],\n",
      "\n",
      "        [[-0.0000,  0.1209,  0.2477,  ...,  3.2823,  0.3159,  4.0673],\n",
      "         [ 1.1924, -1.4264,  1.5145,  ...,  4.0890,  0.2139,  3.1311],\n",
      "         [ 1.6287, -2.2731,  1.9534,  ...,  3.8156, -0.1301,  2.3490],\n",
      "         ...,\n",
      "         [-1.6500, -2.8922, -0.3415,  ...,  4.4045, -0.3269,  0.0000],\n",
      "         [ 0.0000, -1.1916, -0.6150,  ...,  4.0015,  1.5239,  2.6050],\n",
      "         [ 1.0422, -0.9136, -0.5696,  ...,  4.0959,  0.9899,  1.9408]],\n",
      "\n",
      "        [[ 0.5735, -0.0000,  0.0000,  ...,  2.9638, -0.3887,  3.5559],\n",
      "         [ 2.1928, -1.5636,  1.6133,  ...,  1.9544,  0.1275,  3.5445],\n",
      "         [ 2.3460, -2.8617,  2.1399,  ...,  2.2623,  0.6953,  3.6179],\n",
      "         ...,\n",
      "         [-1.2364, -3.0631, -1.0045,  ...,  4.0516,  0.9264,  2.9989],\n",
      "         [ 0.1728, -1.5320, -1.5039,  ...,  3.8371,  1.1959,  2.1489],\n",
      "         [ 0.6175, -0.7784,  0.0000,  ...,  2.7916,  0.5977,  2.9126]]],\n",
      "       device='cuda:0', grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 90, 2048])\n",
      "tensor([[[-1.7349e+00, -7.7203e-01, -6.5824e-01,  ...,  3.8352e+00,\n",
      "          -1.2111e-01,  0.0000e+00],\n",
      "         [ 4.2525e-01, -1.6532e+00,  1.3104e+00,  ...,  3.4689e+00,\n",
      "           7.7463e-01,  3.9064e+00],\n",
      "         [-1.2833e-01, -3.2676e+00,  1.9681e+00,  ...,  2.6356e+00,\n",
      "           0.0000e+00,  3.7666e+00],\n",
      "         ...,\n",
      "         [-3.1530e+00, -3.1590e+00, -1.3476e+00,  ...,  4.0279e+00,\n",
      "           1.1434e+00,  3.0304e+00],\n",
      "         [-1.4508e+00, -9.2688e-01, -2.1788e+00,  ...,  0.0000e+00,\n",
      "           7.4633e-01,  3.5031e+00],\n",
      "         [ 6.9091e-01, -5.9492e-01, -1.2721e+00,  ...,  3.7448e+00,\n",
      "           5.4290e-01,  0.0000e+00]],\n",
      "\n",
      "        [[-1.0702e+00, -1.0563e+00, -0.0000e+00,  ...,  3.8209e+00,\n",
      "          -2.3988e-01,  2.0979e+00],\n",
      "         [ 2.8911e-01, -1.6277e+00,  1.4508e+00,  ...,  3.3405e+00,\n",
      "           1.7737e-01,  3.7241e+00],\n",
      "         [ 1.2093e+00, -3.4363e+00,  5.1663e-01,  ...,  3.0881e+00,\n",
      "           1.1041e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [-2.7732e+00, -3.4424e+00, -1.2994e+00,  ...,  3.9280e+00,\n",
      "           1.0293e+00,  3.2267e+00],\n",
      "         [-1.4069e+00, -6.3798e-01, -1.7551e+00,  ...,  1.6713e+00,\n",
      "           1.0368e+00,  3.7578e+00],\n",
      "         [ 3.1035e-01, -5.9172e-01, -7.4204e-01,  ...,  2.6547e+00,\n",
      "           1.0887e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-1.1304e+00, -6.1498e-01, -8.0487e-01,  ...,  0.0000e+00,\n",
      "          -7.5920e-02,  2.8798e+00],\n",
      "         [ 5.8614e-01, -1.2953e+00,  0.0000e+00,  ...,  3.3928e+00,\n",
      "          -2.4899e-01,  3.6156e+00],\n",
      "         [ 1.3648e+00, -0.0000e+00,  1.3015e+00,  ...,  2.8974e+00,\n",
      "           5.2638e-01,  3.4490e+00],\n",
      "         ...,\n",
      "         [-2.6059e+00, -2.4952e+00, -1.5456e+00,  ...,  3.7117e+00,\n",
      "           0.0000e+00,  2.8924e+00],\n",
      "         [-6.0826e-01, -1.0593e+00, -2.5433e+00,  ...,  3.2714e+00,\n",
      "           1.1321e+00,  2.3686e+00],\n",
      "         [ 8.8013e-01, -3.6702e-01, -1.5891e+00,  ...,  3.5370e+00,\n",
      "           0.0000e+00,  3.0676e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-8.8598e-01, -1.4588e+00, -0.0000e+00,  ...,  3.8053e+00,\n",
      "           1.1762e-01,  3.0826e+00],\n",
      "         [ 2.3822e-01, -1.0084e+00,  8.8605e-02,  ...,  3.5500e+00,\n",
      "           7.4130e-01,  3.4963e+00],\n",
      "         [ 7.6779e-01, -3.5138e+00,  0.0000e+00,  ...,  4.0112e+00,\n",
      "           4.5644e-01,  3.5688e+00],\n",
      "         ...,\n",
      "         [-3.2928e+00, -3.3282e+00, -1.8436e+00,  ...,  3.7497e+00,\n",
      "          -1.7883e-02,  3.1088e+00],\n",
      "         [-7.3392e-01, -1.7408e+00, -1.7794e+00,  ...,  4.1858e+00,\n",
      "          -1.7729e-01,  0.0000e+00],\n",
      "         [ 0.0000e+00, -7.7905e-01, -1.1008e+00,  ...,  2.7999e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-7.9636e-01, -4.0395e-01, -1.0999e+00,  ...,  3.4982e+00,\n",
      "           4.9426e-01,  3.9266e+00],\n",
      "         [ 4.8336e-01, -1.4220e+00,  7.5694e-01,  ...,  0.0000e+00,\n",
      "           4.5458e-01,  3.3137e+00],\n",
      "         [ 1.0584e+00, -3.0191e+00,  8.5118e-01,  ...,  3.8680e+00,\n",
      "           1.5357e-01,  3.1215e+00],\n",
      "         ...,\n",
      "         [-2.7296e+00, -3.2241e+00, -1.6714e+00,  ...,  3.9865e+00,\n",
      "           3.2756e-01,  1.9699e+00],\n",
      "         [-8.8858e-01, -1.1884e+00, -2.0594e+00,  ...,  3.7016e+00,\n",
      "           9.8774e-01,  3.0172e+00],\n",
      "         [ 3.6240e-01, -9.0153e-01, -1.8071e+00,  ...,  3.6810e+00,\n",
      "           5.7138e-01,  3.0245e+00]],\n",
      "\n",
      "        [[-1.0507e+00, -7.9690e-01, -8.4774e-01,  ...,  3.1535e+00,\n",
      "           3.6174e-03,  3.2670e+00],\n",
      "         [ 9.6852e-01, -1.8924e+00,  3.4799e-01,  ...,  2.8368e+00,\n",
      "           9.2529e-02,  3.6560e+00],\n",
      "         [ 9.4424e-01, -3.5343e+00,  1.0783e+00,  ...,  2.9291e+00,\n",
      "           4.9357e-01,  3.6784e+00],\n",
      "         ...,\n",
      "         [-2.8289e+00, -3.3336e+00, -0.0000e+00,  ...,  3.6059e+00,\n",
      "           5.3448e-01,  3.0602e+00],\n",
      "         [-1.1903e+00, -1.6250e+00, -2.7065e+00,  ...,  3.7510e+00,\n",
      "           4.4999e-01,  2.6346e+00],\n",
      "         [ 7.3332e-02, -7.0946e-01, -1.5366e+00,  ...,  2.8887e+00,\n",
      "           6.7706e-01,  3.1861e+00]]], device='cuda:0',\n",
      "       grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 91, 2048])\n",
      "tensor([[[-1.2303e+02,  7.2536e+01,  5.5620e+01,  ..., -2.7637e+01,\n",
      "           9.8658e-03,  9.5118e+01],\n",
      "         [-6.3998e+01, -2.2663e+01, -2.4391e+01,  ..., -5.8915e+01,\n",
      "          -1.8130e+01, -7.8652e+00],\n",
      "         [ 2.2239e+01,  1.9157e+01, -1.0094e+02,  ..., -9.4963e+01,\n",
      "          -0.0000e+00, -6.7602e+01],\n",
      "         ...,\n",
      "         [-6.7748e+01, -1.2055e+01, -3.9737e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6831e+01, -1.1786e+01, -3.4453e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6794e+01, -1.2494e+01, -2.3993e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -0.0000e+00]],\n",
      "\n",
      "        [[-1.2303e+02,  7.2536e+01,  0.0000e+00,  ..., -2.7637e+01,\n",
      "           0.0000e+00,  9.5118e+01],\n",
      "         [-1.5152e+01, -7.3357e+01, -2.9408e+00,  ...,  6.4503e+01,\n",
      "          -4.0917e+00,  9.5946e+00],\n",
      "         [ 2.7506e+01, -2.6141e+01,  6.8948e+00,  ...,  3.7858e+00,\n",
      "           1.0644e+02, -1.3654e+00],\n",
      "         ...,\n",
      "         [-0.0000e+00, -1.2055e+01, -3.9737e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6831e+01, -0.0000e+00, -3.4453e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6794e+01, -1.2494e+01, -2.3993e+00,  ...,  7.9533e+01,\n",
      "           0.0000e+00, -7.8470e+01]],\n",
      "\n",
      "        [[-1.2303e+02,  7.2536e+01,  5.5620e+01,  ..., -2.7637e+01,\n",
      "           9.8658e-03,  9.5118e+01],\n",
      "         [ 4.8138e+00, -2.6053e+01,  2.4412e+01,  ..., -1.9298e+00,\n",
      "           1.0275e+01,  5.7904e+01],\n",
      "         [-9.3572e+00,  2.2299e+01,  1.5392e+01,  ..., -1.1782e+01,\n",
      "           5.5856e+01, -1.8804e+01],\n",
      "         ...,\n",
      "         [-6.7748e+01, -1.2055e+01, -3.9737e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6831e+01, -1.1786e+01, -3.4453e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-0.0000e+00, -1.2494e+01, -2.3993e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.2303e+02,  7.2536e+01,  5.5620e+01,  ..., -2.7637e+01,\n",
      "           9.8658e-03,  9.5118e+01],\n",
      "         [ 2.3727e+01, -4.9275e+01,  8.3918e+01,  ...,  0.0000e+00,\n",
      "          -4.5095e+01,  7.2740e+00],\n",
      "         [-7.0547e+01,  1.4097e+01, -2.3424e+01,  ...,  7.0582e+00,\n",
      "          -3.0725e+01,  0.0000e+00],\n",
      "         ...,\n",
      "         [-6.7748e+01, -1.2055e+01, -3.9737e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6831e+01, -1.1786e+01, -0.0000e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6794e+01, -1.2494e+01, -2.3993e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01]],\n",
      "\n",
      "        [[-1.2303e+02,  7.2536e+01,  5.5620e+01,  ..., -2.7637e+01,\n",
      "           9.8658e-03,  9.5118e+01],\n",
      "         [-2.6399e+01,  9.0901e+01,  1.0247e+02,  ..., -1.6195e+01,\n",
      "          -8.3145e+00,  3.1100e+01],\n",
      "         [-1.0714e+02,  2.5352e+01, -5.8202e+00,  ...,  0.0000e+00,\n",
      "           7.5500e+00, -9.8760e-01],\n",
      "         ...,\n",
      "         [-6.7748e+01, -1.2055e+01, -3.9737e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6831e+01, -0.0000e+00, -3.4453e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -0.0000e+00],\n",
      "         [-6.6794e+01, -1.2494e+01, -2.3993e+00,  ...,  7.9533e+01,\n",
      "           0.0000e+00, -7.8470e+01]],\n",
      "\n",
      "        [[-1.2303e+02,  7.2536e+01,  5.5620e+01,  ..., -2.7637e+01,\n",
      "           0.0000e+00,  9.5118e+01],\n",
      "         [ 5.0733e+01,  1.1241e+00,  2.3828e+01,  ...,  1.6688e+01,\n",
      "           0.0000e+00,  5.7498e+01],\n",
      "         [ 3.1734e+01,  3.8139e+01, -6.7938e+01,  ..., -0.0000e+00,\n",
      "           2.7818e+00,  3.2152e+01],\n",
      "         ...,\n",
      "         [-6.7748e+01, -1.2055e+01, -3.9737e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00, -7.8470e+01],\n",
      "         [-6.6831e+01, -1.1786e+01, -3.4453e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6794e+01, -1.2494e+01, -2.3993e+00,  ...,  7.9533e+01,\n",
      "           0.0000e+00, -7.8470e+01]]], device='cuda:0',\n",
      "       grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 91, 2048])\n",
      "tensor([[[-2.0678,  3.8241,  2.2127,  ...,  0.8402, -0.4042,  2.9275],\n",
      "         [ 0.0082,  0.8741,  2.4717,  ...,  0.4220, -0.5944,  1.3307],\n",
      "         [ 1.5593,  0.7825,  0.0000,  ..., -0.4841,  0.0900,  0.4771],\n",
      "         ...,\n",
      "         [-1.8219,  0.8229,  0.0679,  ...,  3.7905,  1.9418,  0.3350],\n",
      "         [-0.0000,  2.0751,  0.4663,  ...,  3.7447,  1.8793,  0.2932],\n",
      "         [-0.3991,  1.1420,  2.0294,  ...,  3.6672,  1.7161,  0.9807]],\n",
      "\n",
      "        [[-2.1578,  3.8105,  1.0314,  ...,  0.7579, -0.2911,  2.9349],\n",
      "         [ 1.6653,  0.3607,  1.9784,  ...,  2.9970, -0.2981,  1.1389],\n",
      "         [ 2.3262,  1.0915,  2.1206,  ...,  1.4257,  2.3151,  1.4441],\n",
      "         ...,\n",
      "         [ 0.7897,  0.9507,  0.4856,  ...,  3.9443,  0.0000, -0.1009],\n",
      "         [ 0.0000,  1.5038, -0.4347,  ...,  3.6677,  0.8141,  0.2289],\n",
      "         [ 0.3541,  0.8976,  0.9854,  ...,  3.5867,  0.0325,  0.1124]],\n",
      "\n",
      "        [[-0.0000,  3.4394,  2.3931,  ...,  1.4321, -0.7725,  3.3870],\n",
      "         [ 1.9113,  0.9646,  2.4091,  ...,  1.7034, -0.0183,  2.6887],\n",
      "         [ 1.5945,  0.8890,  2.1288,  ...,  1.7688,  1.5149,  0.8007],\n",
      "         ...,\n",
      "         [-0.6869,  0.9987, -0.5304,  ...,  0.0000,  1.5838, -0.0665],\n",
      "         [ 0.6574,  0.8469, -0.0000,  ...,  3.5323,  1.4841,  0.1959],\n",
      "         [ 0.0000,  0.1665,  1.7418,  ...,  3.1789,  0.0000,  0.2257]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.9480,  2.9240,  1.7565,  ...,  1.5957, -0.0269,  2.5719],\n",
      "         [ 1.2491,  0.2470,  4.2585,  ...,  2.2605, -1.2843,  1.8308],\n",
      "         [-0.1400,  0.7246,  2.1528,  ...,  2.0135, -0.8847,  1.7878],\n",
      "         ...,\n",
      "         [-1.2829,  1.1605, -0.4636,  ...,  3.7713,  0.5351, -1.2721],\n",
      "         [ 0.4900,  0.7865,  0.1071,  ...,  3.9784,  0.8434, -0.4473],\n",
      "         [-0.2484,  0.6409,  0.6634,  ...,  0.0000,  0.5769, -1.0225]],\n",
      "\n",
      "        [[-2.2005,  3.4055,  2.0868,  ...,  0.0000,  0.0709,  3.0951],\n",
      "         [ 0.0000,  2.8536,  4.1439,  ...,  1.8393, -0.1013,  1.9667],\n",
      "         [-0.0537,  1.0492,  2.5175,  ...,  1.7987,  0.5897,  2.3928],\n",
      "         ...,\n",
      "         [-0.0000,  1.0549,  0.2015,  ...,  3.7029,  1.3318,  0.3029],\n",
      "         [ 0.7720,  1.5345,  0.0000,  ...,  4.1227,  1.6118,  1.5833],\n",
      "         [ 0.2982,  0.8435,  1.8137,  ...,  3.8430,  0.1091,  0.5987]],\n",
      "\n",
      "        [[-2.4197,  3.0681,  2.0695,  ...,  0.9201, -0.5232,  2.4744],\n",
      "         [ 2.7295,  1.7390,  2.9198,  ...,  1.3858, -0.4878,  3.5092],\n",
      "         [ 2.3415,  1.5383,  1.2786,  ...,  0.0000,  0.0270,  2.3705],\n",
      "         ...,\n",
      "         [-0.0000,  2.1767, -0.0825,  ...,  1.6596,  0.0648, -0.1009],\n",
      "         [-0.1630,  2.4870,  0.0000,  ...,  0.0000,  0.0000, -0.1979],\n",
      "         [ 0.3066,  1.9914,  0.5555,  ...,  3.4419,  0.4540, -0.4549]]],\n",
      "       device='cuda:0', grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 91, 2048])\n",
      "tensor([[[-2.7279e-01,  2.8697e+00,  2.7623e+00,  ...,  2.0539e+00,\n",
      "          -5.4264e-01,  2.3035e+00],\n",
      "         [ 1.4538e+00,  6.4621e-01,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          -3.9784e-01,  1.8399e+00],\n",
      "         [ 0.0000e+00, -4.9229e-01,  2.5046e+00,  ...,  1.1582e-01,\n",
      "          -2.8672e-01,  0.0000e+00],\n",
      "         ...,\n",
      "         [-1.1370e+00,  6.5481e-01,  6.1356e-01,  ...,  2.9204e+00,\n",
      "           9.5206e-01,  7.2453e-01],\n",
      "         [ 1.3265e+00,  1.6748e+00,  1.2423e+00,  ...,  3.1213e+00,\n",
      "           5.2482e-01,  1.1292e+00],\n",
      "         [ 1.3980e+00,  4.0180e-01,  2.8461e+00,  ...,  3.3843e+00,\n",
      "           7.1615e-01,  1.0622e+00]],\n",
      "\n",
      "        [[-4.1236e-01,  2.5212e+00,  0.0000e+00,  ...,  1.6531e+00,\n",
      "          -8.2430e-01,  2.2590e+00],\n",
      "         [ 0.0000e+00,  5.4125e-01,  3.0141e+00,  ...,  2.7050e+00,\n",
      "          -5.4868e-01,  1.2909e+00],\n",
      "         [ 2.4359e+00, -3.1486e-01,  3.6320e+00,  ...,  1.6514e+00,\n",
      "           1.1238e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 1.3091e+00,  1.0064e+00, -6.1234e-03,  ...,  3.5685e+00,\n",
      "          -3.5398e-01,  8.6157e-01],\n",
      "         [ 0.0000e+00,  0.0000e+00,  3.2929e-01,  ...,  3.2337e+00,\n",
      "          -2.9985e-01,  7.0632e-01],\n",
      "         [ 1.7587e+00,  1.2438e-01,  2.3933e+00,  ...,  3.5239e+00,\n",
      "          -5.3258e-01,  1.0112e+00]],\n",
      "\n",
      "        [[ 6.1428e-01,  1.8960e+00,  2.7056e+00,  ...,  2.0086e+00,\n",
      "          -1.5155e+00,  2.3550e+00],\n",
      "         [ 1.8002e+00,  0.0000e+00,  3.5332e+00,  ...,  2.1286e+00,\n",
      "          -6.8267e-01,  2.5286e+00],\n",
      "         [ 2.0107e+00, -2.0754e-01,  3.0413e+00,  ...,  0.0000e+00,\n",
      "          -2.1357e-03,  1.0269e+00],\n",
      "         ...,\n",
      "         [ 4.9455e-01,  3.4345e-01, -1.1522e-01,  ...,  1.2144e+00,\n",
      "           2.6009e-01,  1.3134e+00],\n",
      "         [ 1.3507e+00,  8.3524e-01,  7.9122e-01,  ...,  3.2264e+00,\n",
      "           7.1204e-01,  9.7549e-01],\n",
      "         [ 8.9414e-01, -3.8555e-01,  0.0000e+00,  ...,  3.2671e+00,\n",
      "          -0.0000e+00,  1.0486e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-6.9037e-01,  2.1858e+00,  2.1451e+00,  ...,  2.0280e+00,\n",
      "          -5.6372e-01,  2.1517e+00],\n",
      "         [ 1.5164e+00,  5.3859e-01,  0.0000e+00,  ...,  2.2636e+00,\n",
      "          -1.5830e+00,  1.3536e+00],\n",
      "         [ 1.5356e+00, -0.0000e+00,  0.0000e+00,  ...,  2.2511e+00,\n",
      "          -8.9098e-01,  1.2281e+00],\n",
      "         ...,\n",
      "         [-6.3677e-01,  1.0267e+00, -4.7361e-01,  ...,  3.3536e+00,\n",
      "          -4.2069e-01, -3.6822e-02],\n",
      "         [ 1.1007e+00,  1.0028e+00,  4.9663e-01,  ...,  3.5643e+00,\n",
      "          -2.5490e-01,  5.3022e-01],\n",
      "         [ 8.1398e-01,  4.1044e-01,  1.7737e+00,  ...,  0.0000e+00,\n",
      "          -5.6203e-01,  7.7413e-02]],\n",
      "\n",
      "        [[-1.1476e+00,  2.6432e+00,  2.4037e+00,  ...,  1.0009e+00,\n",
      "          -0.0000e+00,  2.2907e+00],\n",
      "         [ 1.4242e+00,  2.0711e+00,  4.4637e+00,  ...,  2.0564e+00,\n",
      "          -6.0348e-01,  2.5192e+00],\n",
      "         [ 1.7677e+00, -3.3058e-01,  4.0737e+00,  ...,  2.3785e+00,\n",
      "           2.5389e-01,  2.1786e+00],\n",
      "         ...,\n",
      "         [ 1.1687e-01,  9.4409e-01,  2.3471e-01,  ...,  3.7262e+00,\n",
      "           6.1109e-01,  1.1201e+00],\n",
      "         [ 2.0485e+00,  1.5417e+00,  6.1201e-01,  ...,  3.3993e+00,\n",
      "           7.1468e-01,  2.0410e+00],\n",
      "         [ 1.8163e+00,  5.3888e-01,  2.8527e+00,  ...,  3.4502e+00,\n",
      "          -4.2738e-01,  1.6625e+00]],\n",
      "\n",
      "        [[-1.2809e+00,  2.2646e+00,  2.5865e+00,  ...,  1.2308e+00,\n",
      "          -9.1809e-01,  1.5190e+00],\n",
      "         [ 3.3587e+00,  8.6381e-01,  4.1934e+00,  ...,  1.3941e+00,\n",
      "          -9.8866e-01,  2.9628e+00],\n",
      "         [ 2.4126e+00, -3.0091e-01,  3.1272e+00,  ...,  5.6533e-01,\n",
      "          -3.7322e-01,  2.6175e+00],\n",
      "         ...,\n",
      "         [ 4.1315e-01,  1.6678e+00,  2.9020e-02,  ...,  2.0138e+00,\n",
      "          -5.0643e-01,  8.7049e-01],\n",
      "         [ 7.7574e-01,  1.9894e+00,  6.0445e-01,  ...,  1.1084e+00,\n",
      "          -3.4396e-01,  4.3422e-01],\n",
      "         [ 0.0000e+00,  9.5171e-01,  2.0696e+00,  ...,  2.7855e+00,\n",
      "          -1.8406e-01,  4.6849e-01]]], device='cuda:0',\n",
      "       grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 91, 2048])\n",
      "tensor([[[-0.3980,  1.1035,  1.4738,  ...,  2.4153, -0.6547,  0.0000],\n",
      "         [ 1.0336, -0.0144,  0.0000,  ...,  1.4425, -0.3980,  1.7742],\n",
      "         [ 0.0000, -1.4739,  0.0000,  ...,  0.9190, -0.2008,  1.0919],\n",
      "         ...,\n",
      "         [-1.1221,  0.0000, -0.1927,  ...,  2.1729, -0.1362,  1.3750],\n",
      "         [ 1.1646,  1.1552,  0.6503,  ...,  2.4690,  0.1534,  1.8967],\n",
      "         [ 1.3209, -0.0000,  1.7541,  ...,  2.6585, -0.1208,  1.4090]],\n",
      "\n",
      "        [[-0.7207,  0.0000,  0.3583,  ...,  2.1750, -0.8860,  1.8798],\n",
      "         [ 0.4918,  0.0000,  2.6412,  ...,  2.3814, -0.9066,  1.4174],\n",
      "         [ 1.7589, -0.9744,  3.3423,  ...,  1.6448,  0.1305,  0.7819],\n",
      "         ...,\n",
      "         [-0.0287,  0.7525, -0.1902,  ...,  0.0000, -0.8343,  1.7550],\n",
      "         [ 0.4083,  0.0000,  0.2991,  ...,  2.5359, -0.6774,  1.4189],\n",
      "         [ 1.2547, -0.6372,  2.3114,  ...,  2.8216, -1.0868,  0.0000]],\n",
      "\n",
      "        [[ 0.1208,  1.7237,  1.6493,  ...,  0.0000, -0.9127,  2.2213],\n",
      "         [ 0.0000, -0.6366,  3.7445,  ...,  2.6630, -0.6226,  2.0363],\n",
      "         [ 1.3324, -1.3858,  3.4027,  ...,  0.0000, -0.4984,  1.5256],\n",
      "         ...,\n",
      "         [-0.0593, -0.0697, -0.4725,  ...,  1.5050,  0.0621,  2.0089],\n",
      "         [ 1.2657,  0.5529, -0.3719,  ...,  2.8703,  0.0250,  1.7105],\n",
      "         [ 0.9383, -0.6807,  0.9711,  ...,  2.2674, -0.1333,  1.5067]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.4803,  1.5708,  1.6217,  ...,  1.9242, -0.0000,  1.7367],\n",
      "         [ 0.5908, -0.0814,  2.2361,  ...,  2.0030, -1.3992,  1.5167],\n",
      "         [ 1.2178, -1.2217,  1.4984,  ...,  2.3032, -0.8724,  1.2034],\n",
      "         ...,\n",
      "         [-0.5409,  0.5822, -0.7910,  ...,  3.2232, -0.7659,  1.1827],\n",
      "         [ 0.7701,  0.4430,  0.3359,  ...,  2.5073, -0.6088,  1.3271],\n",
      "         [ 0.8454, -0.3444,  1.6916,  ...,  1.5644, -1.3129,  1.2030]],\n",
      "\n",
      "        [[-0.3982,  1.8647,  1.4711,  ...,  1.2458, -0.2765,  2.4702],\n",
      "         [ 1.1889,  1.1122,  3.5507,  ...,  1.9677, -0.4230,  2.3700],\n",
      "         [ 1.5241, -1.0935,  3.2190,  ...,  2.2078, -0.2563,  2.1594],\n",
      "         ...,\n",
      "         [-0.4427,  0.3966, -0.5691,  ...,  3.0457,  0.0528,  2.1404],\n",
      "         [ 1.6929,  0.2669,  0.0000,  ...,  2.7174,  0.0328,  2.2896],\n",
      "         [ 1.2428, -0.1455,  2.5233,  ...,  2.6646, -0.6625,  0.0000]],\n",
      "\n",
      "        [[-1.0099,  0.6483,  0.0000,  ...,  1.6100, -0.5066,  1.5608],\n",
      "         [ 1.9688,  0.0000,  3.5802,  ...,  1.4154, -0.9464,  2.6451],\n",
      "         [ 0.0000, -0.9730,  3.1619,  ...,  0.0000, -0.6169,  1.9419],\n",
      "         ...,\n",
      "         [-0.5920,  0.4132, -0.5522,  ...,  1.6452, -0.6561,  1.4256],\n",
      "         [ 0.5517,  1.2078,  0.3775,  ...,  1.4183, -0.6039,  0.0000],\n",
      "         [ 0.2737,  0.0161,  1.4768,  ...,  2.2456, -0.4972,  1.6686]]],\n",
      "       device='cuda:0', grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 91, 2048])\n",
      "tensor([[[-1.6392,  1.1349,  0.9676,  ...,  2.0428, -0.4848,  1.2636],\n",
      "         [ 0.1677,  0.0502,  0.9625,  ...,  1.6402, -0.0000,  1.8151],\n",
      "         [-0.1787, -1.4292,  0.9918,  ...,  1.1904, -0.5304,  1.5505],\n",
      "         ...,\n",
      "         [-1.8542,  0.8730, -0.0000,  ...,  2.0942, -0.2024,  1.8820],\n",
      "         [-0.3023,  1.1626, -0.3848,  ...,  2.0755, -0.1047,  0.0000],\n",
      "         [ 0.2993, -0.0691,  0.4589,  ...,  2.2261, -0.1255,  2.1880]],\n",
      "\n",
      "        [[-1.5532,  0.7583, -0.1466,  ...,  1.9539, -0.0000,  1.8982],\n",
      "         [ 0.0031,  0.2795,  1.8580,  ...,  2.1095, -0.0000,  0.0000],\n",
      "         [ 0.4419, -1.4586,  2.3408,  ...,  1.8557, -0.6729,  1.3418],\n",
      "         ...,\n",
      "         [-0.0000,  0.8138, -1.6810,  ...,  1.2996, -0.9210,  2.0453],\n",
      "         [-0.5377,  0.8250, -0.8918,  ...,  2.1973, -0.7808,  1.6776],\n",
      "         [ 0.0279, -0.2067,  0.0000,  ...,  2.2310, -0.9794,  1.7827]],\n",
      "\n",
      "        [[-1.4316,  0.0000,  1.2628,  ...,  1.3968, -0.9250,  2.0192],\n",
      "         [-0.3417, -0.4861,  2.2678,  ...,  2.2467, -0.4080,  1.9173],\n",
      "         [ 0.3915, -1.7772,  2.5244,  ...,  1.2142, -0.7443,  1.9424],\n",
      "         ...,\n",
      "         [-1.4965,  0.3894, -0.0000,  ...,  1.4836, -0.3020,  2.2255],\n",
      "         [ 0.0909,  1.0667, -0.0000,  ...,  2.2261, -0.1394,  2.0239],\n",
      "         [-0.2116, -0.6517,  0.4668,  ...,  1.8482, -0.4825,  2.0247]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.1845,  0.9780,  0.6155,  ...,  1.8740, -0.8449,  1.8847],\n",
      "         [-0.0675,  0.3807,  2.0771,  ...,  1.9026, -1.3130,  1.6477],\n",
      "         [ 0.2631, -1.0335,  1.5271,  ...,  2.4472, -0.5999,  1.4109],\n",
      "         ...,\n",
      "         [-1.6927,  0.9407, -1.9511,  ...,  2.6613, -0.7670,  1.8745],\n",
      "         [-0.1007,  1.1584, -0.9661,  ...,  2.7785, -0.8732,  1.6659],\n",
      "         [-0.2902, -0.7185,  0.4265,  ...,  1.8421, -1.2720,  0.0000]],\n",
      "\n",
      "        [[-1.7213,  1.4469,  0.0000,  ...,  1.5648, -0.7172,  1.7600],\n",
      "         [ 0.0000,  1.0966,  1.9714,  ...,  1.8801, -0.3347,  1.9545],\n",
      "         [ 0.0000, -1.5884,  2.3441,  ...,  1.9558, -0.4505,  1.8166],\n",
      "         ...,\n",
      "         [-1.1359,  0.7957, -0.0000,  ...,  2.3800, -0.5555,  2.2207],\n",
      "         [ 0.0110,  0.9694, -0.9280,  ...,  2.3103, -0.4238,  2.0553],\n",
      "         [-0.1464,  0.0000,  1.1692,  ...,  2.3234, -0.3685,  1.3534]],\n",
      "\n",
      "        [[-2.3713,  0.0000, -0.2026,  ...,  0.0000, -0.5783,  1.5375],\n",
      "         [ 0.2430,  0.0527,  2.0124,  ...,  1.7468, -0.7313,  2.2649],\n",
      "         [-0.7598, -1.1758,  0.0000,  ...,  0.7755, -0.6936,  0.0000],\n",
      "         ...,\n",
      "         [-0.0000,  0.0000, -1.7818,  ...,  1.3622, -0.6490,  1.8537],\n",
      "         [-0.0378,  1.2981, -0.0000,  ...,  1.6058, -0.4760,  1.2801],\n",
      "         [-0.7344, -0.1803,  0.9491,  ...,  1.4669, -0.5169,  1.9203]]],\n",
      "       device='cuda:0', grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 90, 2048])\n",
      "tensor([[[-28.4509,  34.1837,   0.0000,  ...,  -0.0000,  35.5508, -48.2909],\n",
      "         [-66.8520, -12.2570,  -1.9392,  ...,  79.5327,  67.9524, -78.4697],\n",
      "         [-66.7766, -13.3099,  -1.8372,  ...,  79.5327,  67.9524, -78.4697],\n",
      "         ...,\n",
      "         [-68.7001, -13.0567,  -3.5143,  ...,  79.5327,  67.9524, -78.4697],\n",
      "         [-67.7476, -12.0546,  -3.9737,  ...,  79.5327,  67.9524,  -0.0000],\n",
      "         [-66.8313, -11.7860,  -3.4453,  ...,  79.5327,  67.9524, -78.4697]],\n",
      "\n",
      "        [[ 31.1381,  -0.0000, -33.5525,  ...,   4.5933, -17.3141, -48.8315],\n",
      "         [ 41.2821,   0.0000, -65.5167,  ..., -27.5915,   2.0144, -30.8434],\n",
      "         [ 33.9074,  39.8560,  15.0572,  ...,  53.4344, -69.9975,   2.7138],\n",
      "         ...,\n",
      "         [-68.7001, -13.0567,  -3.5143,  ...,  79.5327,  67.9524, -78.4697],\n",
      "         [-67.7476, -12.0546,  -3.9737,  ...,  79.5327,   0.0000, -78.4697],\n",
      "         [-66.8313, -11.7860,  -3.4453,  ...,  79.5327,  67.9524, -78.4697]],\n",
      "\n",
      "        [[-52.1273,  14.3900, -14.8501,  ..., -63.3435,  34.1864,   2.2903],\n",
      "         [ -0.0000,  34.1478, -39.4401,  ...,  -0.0000,  17.4334,  45.7003],\n",
      "         [-78.4874,  74.2139, 101.8266,  ...,  17.7393,  -0.0000, -28.4843],\n",
      "         ...,\n",
      "         [-68.7001, -13.0567,  -3.5143,  ...,  79.5327,   0.0000, -78.4697],\n",
      "         [-67.7476,  -0.0000,  -3.9737,  ...,  79.5327,   0.0000, -78.4697],\n",
      "         [-66.8313, -11.7860,  -3.4453,  ...,  79.5327,  67.9524, -78.4697]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 29.7912,  31.9680,  -0.0000,  ...,  21.4908,  67.4089, 129.3063],\n",
      "         [ 32.1104, -11.5790,  -9.0661,  ..., -24.0485,  -0.0000,  39.7281],\n",
      "         [ 57.7431, -13.1728, -34.4496,  ...,   0.0000,  70.7815,   5.0613],\n",
      "         ...,\n",
      "         [ -0.0000, -13.0567,  -0.0000,  ...,   0.0000,  67.9524, -78.4697],\n",
      "         [-67.7476, -12.0546,  -3.9737,  ...,   0.0000,   0.0000, -78.4697],\n",
      "         [-66.8313, -11.7860,  -3.4453,  ...,  79.5327,  67.9524, -78.4697]],\n",
      "\n",
      "        [[-40.1333, -66.5836,   0.0000,  ...,  23.9761,  42.5033,  31.6884],\n",
      "         [ 89.0018,  38.1520, -57.4399,  ..., -56.4631,  50.8761,  -4.7778],\n",
      "         [-16.1602,  22.0741, -52.6750,  ..., -10.1589,  14.2748,   0.0000],\n",
      "         ...,\n",
      "         [-68.7001, -13.0567,  -3.5143,  ...,   0.0000,  67.9524, -78.4697],\n",
      "         [-67.7476, -12.0546,  -3.9737,  ...,  79.5327,  67.9524, -78.4697],\n",
      "         [-66.8313, -11.7860,  -0.0000,  ...,  79.5327,  67.9524, -78.4697]],\n",
      "\n",
      "        [[-64.7824,   0.0000,  13.4799,  ..., -89.4086,  15.9771, 120.2854],\n",
      "         [ 32.1104, -11.5790,  -0.0000,  ..., -24.0485, -38.4529,  39.7281],\n",
      "         [  5.7899,   0.0000,   0.0000,  ..., -34.5223, -32.4050,  39.0838],\n",
      "         ...,\n",
      "         [-68.7001, -13.0567,  -3.5143,  ...,   0.0000,  67.9524, -78.4697],\n",
      "         [-67.7476, -12.0546,  -3.9737,  ...,  79.5327,  67.9524, -78.4697],\n",
      "         [-66.8313, -11.7860,  -3.4453,  ...,   0.0000,  67.9524, -78.4697]]],\n",
      "       device='cuda:0', grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 90, 2048])\n",
      "tensor([[[-0.2747,  2.4061,  1.0001,  ...,  2.4523,  0.1530,  0.6239],\n",
      "         [-0.3439,  0.0000,  1.4795,  ...,  3.7968,  1.5779, -0.1158],\n",
      "         [-0.0909,  0.2247,  1.3682,  ...,  3.8852,  0.8945, -0.4265],\n",
      "         ...,\n",
      "         [-1.7772, -0.1111, -0.7648,  ...,  3.6386,  0.9787, -0.0424],\n",
      "         [-0.5902,  1.3319, -0.8333,  ...,  3.7834,  0.7707,  1.5720],\n",
      "         [ 0.0428,  1.2174, -0.0940,  ...,  3.7268,  0.5289, -0.0652]],\n",
      "\n",
      "        [[ 0.0000,  1.7038,  0.3444,  ...,  3.4443,  0.1596,  1.0435],\n",
      "         [ 3.0162,  1.0302,  1.1210,  ...,  0.0000,  0.4677,  0.9959],\n",
      "         [ 0.0000,  1.3394,  0.0000,  ...,  3.2439, -1.4276,  1.6149],\n",
      "         ...,\n",
      "         [-0.8107, -0.5737,  1.0446,  ...,  3.8566,  0.9967, -0.1365],\n",
      "         [ 0.1564,  0.8383,  0.1787,  ...,  4.2818, -0.0544, -0.1731],\n",
      "         [ 1.2020,  1.2801,  0.9827,  ...,  0.0000,  1.4904, -0.3009]],\n",
      "\n",
      "        [[-0.1380,  2.6066,  0.9266,  ...,  0.4554,  1.0189,  3.0551],\n",
      "         [ 2.4628,  2.5649,  0.0000,  ...,  0.0000,  0.6012,  3.2950],\n",
      "         [ 0.4286,  0.0000,  3.0295,  ...,  1.8197,  0.5977,  1.7785],\n",
      "         ...,\n",
      "         [-0.6889, -0.8189,  0.5576,  ...,  3.6565,  0.3848,  0.9203],\n",
      "         [ 0.4564,  0.7559,  0.2519,  ...,  3.1308,  0.5590,  0.7964],\n",
      "         [ 0.8128,  0.3857,  0.9275,  ...,  3.2569,  2.3714,  0.8177]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 2.3392,  2.2615,  1.3075,  ...,  0.0000,  1.7520,  4.5088],\n",
      "         [ 2.9955,  1.0394,  1.9229,  ...,  1.6665,  0.7331,  3.1645],\n",
      "         [ 3.3008,  0.4956,  1.2154,  ...,  2.1239,  2.1248,  2.7370],\n",
      "         ...,\n",
      "         [ 0.5418,  0.2130,  0.9130,  ...,  1.4330,  2.1297,  0.4651],\n",
      "         [ 0.4523,  0.8799,  0.8100,  ...,  1.8100,  0.5838,  0.0621],\n",
      "         [ 0.0000,  1.0312,  0.0000,  ...,  3.8063,  1.9259, -0.0061]],\n",
      "\n",
      "        [[ 0.4518,  0.0841,  1.6569,  ...,  2.7023,  0.3930,  3.7508],\n",
      "         [ 3.8370,  1.9860,  1.1705,  ...,  0.9522,  1.3776,  2.6100],\n",
      "         [ 1.4775,  0.0000,  0.8332,  ...,  1.5264,  0.0099,  2.8297],\n",
      "         ...,\n",
      "         [-0.9393,  0.7753, -0.4095,  ...,  2.0133,  1.6030,  0.0000],\n",
      "         [-0.9182,  0.8430, -0.8442,  ...,  4.2948,  1.2918,  1.1088],\n",
      "         [ 0.7476,  1.6315,  0.2087,  ...,  3.6087,  1.1940,  0.9025]],\n",
      "\n",
      "        [[-0.9175,  0.0000,  2.0529,  ...,  0.1491,  0.3642,  4.9690],\n",
      "         [ 3.0406,  0.7726,  0.0000,  ...,  1.3294, -0.4483,  2.8829],\n",
      "         [ 2.3865, -0.0113,  2.1227,  ...,  1.1188, -0.0613,  3.3754],\n",
      "         ...,\n",
      "         [-0.7144, -0.3108,  0.8730,  ...,  2.8148,  1.2086,  0.0000],\n",
      "         [ 0.1770,  0.6764,  0.2959,  ...,  4.0919,  1.7979,  0.1971],\n",
      "         [ 0.0000,  0.0000,  1.0482,  ...,  2.4135,  1.2575,  0.4719]]],\n",
      "       device='cuda:0', grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 90, 2048])\n",
      "tensor([[[-0.4281,  1.4524,  0.8943,  ...,  3.7426, -0.0000,  2.2037],\n",
      "         [ 0.0000, -0.4380,  2.4000,  ...,  3.7190,  0.0000,  1.5631],\n",
      "         [ 1.0789, -1.9011,  2.8338,  ...,  4.3407, -0.1194,  1.2519],\n",
      "         ...,\n",
      "         [-1.8804, -1.2538, -0.4917,  ...,  4.1260,  0.2823,  1.0865],\n",
      "         [ 0.3583,  0.7022, -1.6663,  ...,  3.9647,  0.2504,  1.9091],\n",
      "         [ 1.1437,  1.0654,  0.0456,  ...,  4.3133,  0.2853,  1.5492]],\n",
      "\n",
      "        [[ 0.2949,  0.7754,  0.6374,  ...,  4.6131,  0.9374,  2.5718],\n",
      "         [ 3.4503,  0.0943,  2.1744,  ...,  1.7773,  0.8297,  2.2865],\n",
      "         [ 1.6474, -0.7066,  1.7331,  ...,  3.7732, -0.0000,  0.0000],\n",
      "         ...,\n",
      "         [-0.8417, -2.1838,  0.8673,  ...,  4.3053,  0.9679,  1.6458],\n",
      "         [ 0.5463,  0.1979, -0.1617,  ...,  0.0000,  0.6461,  1.3769],\n",
      "         [ 2.1346,  0.4562,  0.0000,  ...,  1.9170,  1.6305,  1.5959]],\n",
      "\n",
      "        [[-0.0752,  1.9735,  1.2938,  ...,  1.9248,  1.2667,  4.3348],\n",
      "         [ 2.7273,  1.3104,  0.0000,  ...,  1.6713,  0.7501,  4.3385],\n",
      "         [ 0.0000, -1.3091,  3.5522,  ...,  2.5792,  0.5275,  3.2211],\n",
      "         ...,\n",
      "         [-0.7183, -1.7920,  0.4486,  ...,  3.9722,  0.6927,  0.0000],\n",
      "         [ 1.0012,  0.1117, -0.0103,  ...,  3.7614,  0.6818,  2.6819],\n",
      "         [ 2.0411,  0.2718,  0.9285,  ...,  3.6789,  2.1392,  3.1247]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 2.2990,  1.1099,  1.4764,  ...,  2.0172,  1.2100,  4.5844],\n",
      "         [ 4.0675, -0.1681,  3.2953,  ...,  2.9950,  0.7127,  3.6230],\n",
      "         [ 3.8036, -1.3082,  2.6371,  ...,  3.0537,  1.4113,  2.9391],\n",
      "         ...,\n",
      "         [ 0.2737, -1.6461,  1.1747,  ...,  2.7593,  1.6716,  2.2093],\n",
      "         [ 1.3453,  0.4073,  0.0695,  ...,  2.9145,  0.4204,  1.8073],\n",
      "         [ 1.7733,  0.2900,  0.0998,  ...,  4.1465,  1.6585,  1.9931]],\n",
      "\n",
      "        [[ 1.1196,  0.2436,  1.7625,  ...,  3.0724,  0.5500,  0.0000],\n",
      "         [ 0.0000,  0.0000,  2.7010,  ...,  2.1604,  1.2636,  3.9321],\n",
      "         [ 2.5099, -0.0000,  0.0000,  ...,  2.4554,  0.0000,  3.9093],\n",
      "         ...,\n",
      "         [-0.9928, -0.6589, -0.0431,  ...,  3.0293,  1.8269,  1.8852],\n",
      "         [ 0.0442,  0.0000, -0.8367,  ...,  4.5268,  1.4168,  2.0567],\n",
      "         [ 0.0000,  0.8254,  0.2882,  ...,  4.2849,  1.0536,  2.5962]],\n",
      "\n",
      "        [[-0.1619, -0.1856,  2.1464,  ...,  1.6565,  0.2751,  4.9306],\n",
      "         [ 3.4964, -0.2036,  1.6836,  ...,  2.5743, -0.0000,  3.8892],\n",
      "         [ 0.0000, -1.6453,  2.9912,  ...,  2.3202, -0.3393,  3.8719],\n",
      "         ...,\n",
      "         [-0.5790, -1.7350,  1.0338,  ...,  3.7107,  1.0334,  1.7906],\n",
      "         [ 0.6257,  0.0103,  0.1556,  ...,  4.4022,  1.5844,  1.6621],\n",
      "         [ 1.5772, -0.3296,  0.0000,  ...,  0.0000,  0.4284,  2.0171]]],\n",
      "       device='cuda:0', grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 90, 2048])\n",
      "tensor([[[-0.6953,  0.0882,  0.3432,  ...,  4.1130,  0.0000,  2.9363],\n",
      "         [ 0.8659, -0.0000,  1.8356,  ...,  4.1250,  0.2521,  1.8978],\n",
      "         [ 0.0000, -0.0000,  2.3929,  ...,  4.1943,  0.1222,  1.9864],\n",
      "         ...,\n",
      "         [-0.0000, -2.1395, -0.7816,  ...,  4.4548,  0.2762,  2.1927],\n",
      "         [-0.1833, -0.0000, -1.8391,  ...,  4.1560,  0.5937,  2.5998],\n",
      "         [ 1.1248,  0.6796, -0.4959,  ...,  4.0831, -0.0396,  2.4090]],\n",
      "\n",
      "        [[ 0.0664, -0.2878, -0.0688,  ...,  4.3506, -0.0489,  3.2455],\n",
      "         [ 2.8637, -1.0805,  1.6194,  ...,  2.6411,  0.6187,  2.6208],\n",
      "         [ 1.8543, -0.0000,  1.7270,  ...,  3.2995,  0.3994,  0.0000],\n",
      "         ...,\n",
      "         [-0.0000, -3.2034,  0.2165,  ...,  4.0366,  0.8559,  2.8628],\n",
      "         [-0.0000, -1.1402, -0.9666,  ...,  1.7156,  0.7152,  2.5462],\n",
      "         [ 0.0000, -0.4258, -0.0000,  ...,  2.5981,  1.1239,  3.0375]],\n",
      "\n",
      "        [[-0.2160,  0.5147,  0.2800,  ...,  2.9799,  1.1554,  4.3127],\n",
      "         [ 1.8229, -0.1170,  1.0387,  ...,  2.6722,  0.7119,  4.2025],\n",
      "         [ 0.5112, -2.8344,  2.7741,  ...,  2.9909,  0.9257,  3.8216],\n",
      "         ...,\n",
      "         [-1.6701, -2.7285, -0.3881,  ...,  3.8392, -0.0896,  2.2002],\n",
      "         [ 0.4097, -0.9600, -0.9403,  ...,  0.0000,  0.7624,  3.3733],\n",
      "         [ 1.5758, -0.4982,  0.1470,  ...,  3.7326,  0.7285,  0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.8832, -0.2544,  0.7579,  ...,  0.0000,  0.6973,  4.1517],\n",
      "         [ 0.0000, -1.3959,  2.3645,  ...,  3.6079,  0.6110,  3.3685],\n",
      "         [ 2.7542, -2.4015,  1.9664,  ...,  3.4180,  1.0037,  3.5846],\n",
      "         ...,\n",
      "         [-0.9018, -2.9111,  0.4962,  ...,  3.3692,  1.0560,  3.2094],\n",
      "         [ 0.9606, -0.5968, -1.1437,  ...,  0.0000,  0.5764,  2.5995],\n",
      "         [ 1.6948, -0.4780, -0.6406,  ...,  4.0769,  1.3261,  0.0000]],\n",
      "\n",
      "        [[ 0.5535, -0.5245,  1.2550,  ...,  0.0000,  0.4527,  1.8266],\n",
      "         [ 0.8696, -1.2324,  2.1734,  ...,  2.9080,  0.2859,  0.0000],\n",
      "         [ 2.2219, -2.4111,  1.2959,  ...,  2.7789, -0.3263,  4.2536],\n",
      "         ...,\n",
      "         [-1.7421, -2.1404, -0.2519,  ...,  3.4096,  1.2452,  3.1299],\n",
      "         [-0.1662, -1.2415, -1.1702,  ...,  4.1782,  1.2197,  2.9504],\n",
      "         [ 0.9452, -0.0000, -0.0866,  ...,  3.9690,  0.6716,  3.6448]],\n",
      "\n",
      "        [[-0.0000, -0.0000,  1.0276,  ...,  2.6430,  0.1687,  4.2977],\n",
      "         [ 2.5456, -1.5292,  0.0000,  ...,  2.8388,  0.3910,  0.0000],\n",
      "         [ 0.0000, -3.3771,  2.0514,  ...,  0.0000, -0.0000,  0.0000],\n",
      "         ...,\n",
      "         [-1.3577, -3.0957,  0.1253,  ...,  3.5312,  0.6868,  2.9102],\n",
      "         [ 0.2109, -0.9668, -1.0899,  ...,  3.9130,  0.8707,  2.4725],\n",
      "         [ 1.6017, -0.0000, -0.8032,  ...,  0.0000,  0.0000,  3.0343]]],\n",
      "       device='cuda:0', grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 90, 2048])\n",
      "tensor([[[-1.5331e+00, -3.1306e-02, -0.0000e+00,  ...,  3.5278e+00,\n",
      "           3.5169e-01,  0.0000e+00],\n",
      "         [-2.2193e-01, -7.9963e-01,  5.7340e-01,  ...,  3.7609e+00,\n",
      "           2.3871e-01,  2.6850e+00],\n",
      "         [ 7.7491e-02, -2.0799e+00,  1.4106e+00,  ...,  0.0000e+00,\n",
      "          -1.1228e-02,  3.0124e+00],\n",
      "         ...,\n",
      "         [-0.0000e+00, -2.4113e+00, -1.9366e+00,  ...,  0.0000e+00,\n",
      "           7.7215e-01,  2.8535e+00],\n",
      "         [-0.0000e+00, -5.5365e-01, -2.8474e+00,  ...,  3.7453e+00,\n",
      "           9.2205e-01,  2.9796e+00],\n",
      "         [-2.1820e-03,  2.2671e-01, -0.0000e+00,  ...,  3.5164e+00,\n",
      "          -2.6682e-01,  3.3395e+00]],\n",
      "\n",
      "        [[-1.2796e+00, -4.8270e-01, -9.0232e-01,  ...,  4.4142e+00,\n",
      "           5.5475e-01,  3.4841e+00],\n",
      "         [ 1.3629e+00, -1.6527e+00,  3.9194e-01,  ...,  3.1958e+00,\n",
      "           6.7079e-01,  3.3688e+00],\n",
      "         [ 6.3335e-01, -2.0137e+00,  5.5058e-01,  ...,  3.3935e+00,\n",
      "           5.0896e-01,  1.8708e+00],\n",
      "         ...,\n",
      "         [-2.2637e+00, -0.0000e+00, -1.4353e+00,  ...,  3.9753e+00,\n",
      "           1.2792e+00,  3.3148e+00],\n",
      "         [-1.2783e+00, -1.1152e+00, -2.8125e+00,  ...,  2.6229e+00,\n",
      "           0.0000e+00,  3.2711e+00],\n",
      "         [-7.2365e-01, -4.9543e-01, -1.5517e+00,  ...,  3.2137e+00,\n",
      "           9.7009e-01,  0.0000e+00]],\n",
      "\n",
      "        [[-1.0339e+00, -2.3294e-01, -9.5998e-01,  ...,  3.4758e+00,\n",
      "           9.6125e-01,  3.8603e+00],\n",
      "         [ 5.9423e-01, -8.7739e-01,  4.8283e-01,  ...,  3.2918e+00,\n",
      "           7.1941e-01,  3.9937e+00],\n",
      "         [ 1.6926e-01, -3.2114e+00,  1.4725e+00,  ...,  3.1788e+00,\n",
      "           6.9828e-01,  3.6219e+00],\n",
      "         ...,\n",
      "         [-2.7275e+00, -3.0929e+00, -0.0000e+00,  ...,  3.6317e+00,\n",
      "           2.1468e-01,  2.4842e+00],\n",
      "         [-8.9832e-01, -1.0541e+00, -2.4573e+00,  ...,  1.9098e+00,\n",
      "          -7.5213e-02,  3.4341e+00],\n",
      "         [ 0.0000e+00, -9.3297e-01, -0.0000e+00,  ...,  3.6464e+00,\n",
      "           6.1618e-01,  1.8024e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-6.6936e-01, -6.6067e-01, -4.0799e-01,  ...,  1.9725e+00,\n",
      "           3.4484e-01,  3.6846e+00],\n",
      "         [-3.2561e-01, -1.6564e+00,  9.3355e-01,  ...,  3.8742e+00,\n",
      "           5.9639e-01,  3.3649e+00],\n",
      "         [ 1.2128e+00, -2.7530e+00,  9.9252e-01,  ...,  0.0000e+00,\n",
      "           6.9993e-01,  3.3497e+00],\n",
      "         ...,\n",
      "         [-2.4018e+00, -3.1124e+00, -0.0000e+00,  ...,  3.5652e+00,\n",
      "           8.8544e-01,  3.3967e+00],\n",
      "         [-1.0434e+00, -8.5352e-01, -2.7914e+00,  ...,  1.9885e+00,\n",
      "           5.6578e-01,  0.0000e+00],\n",
      "         [ 1.7798e-01, -0.0000e+00, -1.7661e+00,  ...,  3.8341e+00,\n",
      "           8.8891e-01,  1.4941e+00]],\n",
      "\n",
      "        [[-0.0000e+00, -8.2073e-01, -0.0000e+00,  ...,  1.8422e+00,\n",
      "           0.0000e+00,  2.6485e+00],\n",
      "         [ 3.0742e-01, -1.2636e+00,  1.0668e+00,  ...,  3.3091e+00,\n",
      "           2.2353e-01,  0.0000e+00],\n",
      "         [ 0.0000e+00, -0.0000e+00,  1.0244e+00,  ...,  3.1634e+00,\n",
      "           0.0000e+00,  3.7631e+00],\n",
      "         ...,\n",
      "         [-0.0000e+00, -0.0000e+00, -1.9055e+00,  ...,  3.7029e+00,\n",
      "           0.0000e+00,  3.1763e+00],\n",
      "         [-9.0477e-01, -1.4227e+00, -2.1841e+00,  ...,  4.0059e+00,\n",
      "           9.0931e-01,  3.1490e+00],\n",
      "         [ 1.8211e-01, -5.3321e-01, -1.2769e+00,  ...,  0.0000e+00,\n",
      "           4.3648e-01,  3.4857e+00]],\n",
      "\n",
      "        [[-1.2555e+00, -7.7037e-01, -4.8363e-01,  ...,  3.3099e+00,\n",
      "          -3.7768e-01,  3.8134e+00],\n",
      "         [ 1.0887e+00, -1.8053e+00,  1.7590e-01,  ...,  3.2638e+00,\n",
      "           2.6351e-01,  1.9168e+00],\n",
      "         [-0.0000e+00, -3.7851e+00,  1.0469e+00,  ...,  2.1029e+00,\n",
      "           1.2849e-01,  1.6331e+00],\n",
      "         ...,\n",
      "         [-0.0000e+00, -3.5303e+00, -1.4340e+00,  ...,  3.4672e+00,\n",
      "           7.0936e-01,  3.2317e+00],\n",
      "         [-1.0256e+00, -1.5325e+00, -2.7470e+00,  ...,  3.6931e+00,\n",
      "           5.8447e-01,  3.0747e+00],\n",
      "         [ 3.6041e-01, -8.3372e-01, -1.6649e+00,  ...,  1.9808e+00,\n",
      "           1.3394e-01,  3.1129e+00]]], device='cuda:0',\n",
      "       grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 91, 2048])\n",
      "tensor([[[-1.2303e+02,  7.2536e+01,  5.5620e+01,  ..., -2.7637e+01,\n",
      "           9.8652e-03,  9.5118e+01],\n",
      "         [-1.5188e+02, -1.4156e+00, -0.0000e+00,  ..., -1.6306e+01,\n",
      "           1.9726e+01,  1.2007e+01],\n",
      "         [ 5.0120e+01,  3.0016e+01,  1.0835e+02,  ..., -2.9314e+00,\n",
      "           6.8697e+01, -3.2877e+01],\n",
      "         ...,\n",
      "         [-6.7748e+01, -1.2055e+01, -3.9737e+00,  ...,  0.0000e+00,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6831e+01, -1.1786e+01, -3.4453e+00,  ...,  7.9533e+01,\n",
      "           0.0000e+00, -7.8470e+01],\n",
      "         [-6.6794e+01, -1.2494e+01, -2.3993e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01]],\n",
      "\n",
      "        [[-1.2303e+02,  7.2536e+01,  5.5620e+01,  ..., -2.7637e+01,\n",
      "           9.8652e-03,  9.5118e+01],\n",
      "         [-1.5188e+02, -1.4156e+00, -4.9651e+01,  ..., -1.6306e+01,\n",
      "           1.9726e+01,  1.2007e+01],\n",
      "         [ 5.0120e+01,  0.0000e+00,  1.0835e+02,  ..., -2.9314e+00,\n",
      "           6.8697e+01, -3.2877e+01],\n",
      "         ...,\n",
      "         [-6.7748e+01, -1.2055e+01, -3.9737e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6831e+01, -1.1786e+01, -3.4453e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6794e+01, -1.2494e+01, -2.3993e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01]],\n",
      "\n",
      "        [[-1.2303e+02,  7.2536e+01,  5.5620e+01,  ..., -2.7637e+01,\n",
      "           9.8652e-03,  9.5118e+01],\n",
      "         [-1.5188e+02, -1.4156e+00, -4.9651e+01,  ..., -1.6306e+01,\n",
      "           1.9726e+01,  1.2007e+01],\n",
      "         [-1.5180e+02, -2.4685e+00, -4.9549e+01,  ..., -1.6306e+01,\n",
      "           1.9726e+01,  1.2007e+01],\n",
      "         ...,\n",
      "         [-6.7748e+01, -1.2055e+01, -3.9737e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6831e+01, -1.1786e+01, -3.4453e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6794e+01, -1.2494e+01, -2.3993e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0000e+00,  7.2536e+01,  5.5620e+01,  ..., -2.7637e+01,\n",
      "           9.8652e-03,  9.5118e+01],\n",
      "         [-1.5188e+02, -1.4156e+00, -4.9651e+01,  ..., -1.6306e+01,\n",
      "           1.9726e+01,  1.2007e+01],\n",
      "         [ 5.0120e+01,  3.0016e+01,  1.0835e+02,  ..., -2.9314e+00,\n",
      "           6.8697e+01, -3.2877e+01],\n",
      "         ...,\n",
      "         [-0.0000e+00, -1.2055e+01, -3.9737e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-0.0000e+00, -1.1786e+01, -3.4453e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-0.0000e+00, -1.2494e+01, -2.3993e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01]],\n",
      "\n",
      "        [[-1.2303e+02,  7.2536e+01,  5.5620e+01,  ..., -2.7637e+01,\n",
      "           9.8652e-03,  9.5118e+01],\n",
      "         [-4.5130e+01, -1.9802e+01,  1.5068e+01,  ..., -3.6503e+01,\n",
      "          -2.8255e+01,  1.8381e+00],\n",
      "         [ 5.0120e+01,  3.0016e+01,  1.0835e+02,  ..., -2.9314e+00,\n",
      "           6.8697e+01, -3.2877e+01],\n",
      "         ...,\n",
      "         [-6.7748e+01, -1.2055e+01, -0.0000e+00,  ...,  0.0000e+00,\n",
      "           6.7952e+01, -0.0000e+00],\n",
      "         [-6.6831e+01, -1.1786e+01, -3.4453e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6794e+01, -1.2494e+01, -2.3993e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01]],\n",
      "\n",
      "        [[-1.2303e+02,  7.2536e+01,  5.5620e+01,  ..., -2.7637e+01,\n",
      "           9.8652e-03,  9.5118e+01],\n",
      "         [-0.0000e+00, -1.4156e+00, -4.9651e+01,  ..., -1.6306e+01,\n",
      "           1.9726e+01,  1.2007e+01],\n",
      "         [-1.2181e+02,  3.3243e+01,  0.0000e+00,  ..., -5.0501e+01,\n",
      "          -0.0000e+00, -2.4845e+01],\n",
      "         ...,\n",
      "         [-6.7748e+01, -1.2055e+01, -0.0000e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -0.0000e+00],\n",
      "         [-6.6831e+01, -1.1786e+01, -3.4453e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6794e+01, -1.2494e+01, -2.3993e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01]]], device='cuda:0',\n",
      "       grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 91, 2048])\n",
      "tensor([[[-1.5284,  3.4443,  2.0418,  ...,  1.4934, -0.2842,  0.0000],\n",
      "         [-1.4629,  1.4467,  2.1793,  ...,  2.7220, -0.0297,  2.4299],\n",
      "         [ 2.7468,  0.6169,  0.0000,  ...,  2.5206,  1.0478,  1.5558],\n",
      "         ...,\n",
      "         [-0.7602,  1.5159, -0.0173,  ...,  1.9054,  0.8653,  0.4392],\n",
      "         [-0.0000,  1.5096,  0.6418,  ...,  3.8209, -0.2497,  0.4099],\n",
      "         [ 0.0000,  0.0000,  1.5072,  ...,  3.6466,  1.2423,  0.2067]],\n",
      "\n",
      "        [[-2.5258,  3.7941,  1.9652,  ...,  0.0000, -0.3946,  0.0000],\n",
      "         [-1.7169,  1.9457,  0.9149,  ...,  1.8032,  0.2256,  1.8054],\n",
      "         [ 0.0000, -0.0082,  4.2127,  ...,  0.0000,  1.4119,  1.0672],\n",
      "         ...,\n",
      "         [-0.9204,  0.0000, -0.0984,  ...,  0.0000,  0.7156,  0.4368],\n",
      "         [-0.0102,  1.6938,  0.2822,  ...,  3.4431,  1.0953,  0.2555],\n",
      "         [-0.3088,  1.1426,  1.4446,  ...,  4.2561,  0.7054,  0.2837]],\n",
      "\n",
      "        [[-2.2732,  0.0000,  2.0585,  ...,  0.9375,  0.0052,  3.4580],\n",
      "         [-0.0000,  1.8692,  0.9471,  ...,  0.0000,  0.4403,  2.4474],\n",
      "         [-2.0917,  0.0000,  1.1720,  ...,  1.8160, -0.1974,  1.8038],\n",
      "         ...,\n",
      "         [-1.0521,  0.8006, -0.5767,  ...,  3.5714,  0.9441,  0.2055],\n",
      "         [ 0.0416,  1.3295,  0.3948,  ...,  2.8776,  1.1069,  0.2260],\n",
      "         [ 0.0711,  0.0000,  1.5802,  ...,  3.6701,  1.4323,  0.0200]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.4462,  2.9069,  2.0637,  ...,  0.9046, -0.2376,  3.0213],\n",
      "         [-1.3680,  2.3147,  0.9225,  ...,  1.6524,  0.2789,  1.4685],\n",
      "         [ 2.2712,  1.5752,  4.7039,  ...,  1.7941,  1.3678,  1.1323],\n",
      "         ...,\n",
      "         [ 0.6563,  1.6442,  0.2623,  ...,  3.9810,  1.1460,  0.2910],\n",
      "         [ 1.7481,  1.8407,  0.4650,  ...,  3.7502,  1.5022, -0.1344],\n",
      "         [ 2.1037,  0.3854,  2.0826,  ...,  3.5493,  0.0000,  0.4001]],\n",
      "\n",
      "        [[-2.0345,  3.7967,  2.8819,  ...,  1.3298, -0.1041,  2.8808],\n",
      "         [ 0.5023,  1.4751,  0.0000,  ...,  1.0103, -1.8559,  1.3081],\n",
      "         [ 2.4923,  0.5020,  0.0000,  ...,  1.5819,  1.1203,  1.0902],\n",
      "         ...,\n",
      "         [-0.8657,  1.7530,  0.2235,  ...,  2.0085,  0.5394,  1.1845],\n",
      "         [ 0.1587,  1.4598,  0.6558,  ...,  3.7190,  0.4826, -0.6186],\n",
      "         [ 0.5855,  0.0000,  1.5885,  ...,  4.0387,  1.2281, -0.2006]],\n",
      "\n",
      "        [[-2.2821,  3.0655,  2.3524,  ...,  1.0155, -0.4812,  3.3246],\n",
      "         [ 0.0000,  1.9597,  1.1366,  ...,  1.5146,  0.4889,  0.0000],\n",
      "         [-1.2546,  1.2918,  2.4528,  ...,  0.6804,  0.3089,  0.8599],\n",
      "         ...,\n",
      "         [-0.9462,  0.0000, -0.4994,  ...,  3.4410,  1.1076,  0.9574],\n",
      "         [ 0.4019,  1.4309, -0.5683,  ...,  0.0000,  1.0922, -0.5323],\n",
      "         [ 0.2287,  0.4918,  1.1244,  ...,  3.0439,  1.2556,  0.0586]]],\n",
      "       device='cuda:0', grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 91, 2048])\n",
      "tensor([[[-0.7469,  2.5536,  2.4243,  ...,  2.3609, -1.0282,  0.9891],\n",
      "         [ 0.2008,  0.0000,  3.7429,  ...,  2.9566, -0.3002,  2.2910],\n",
      "         [ 3.3363, -0.7024,  2.2259,  ...,  2.7160, -0.2979,  1.8063],\n",
      "         ...,\n",
      "         [ 0.2320,  0.9484,  0.2093,  ...,  2.7948, -0.1079,  1.5838],\n",
      "         [ 1.4488,  1.5201,  1.1891,  ...,  3.7254, -0.8174,  1.8351],\n",
      "         [ 1.5058, -0.0000,  0.0000,  ...,  3.6752, -0.0763,  1.0165]],\n",
      "\n",
      "        [[-1.3934,  2.9802,  1.9513,  ...,  1.1662, -0.9805,  0.7532],\n",
      "         [-0.1182,  1.5516,  2.2820,  ...,  0.0000, -0.6129,  1.5599],\n",
      "         [ 0.0000, -0.7531,  4.0548,  ...,  0.9551,  0.1365,  1.1523],\n",
      "         ...,\n",
      "         [-0.4702, -0.0000, -0.1187,  ...,  1.5742, -0.5150,  1.3075],\n",
      "         [ 1.3303,  1.6050,  0.3179,  ...,  3.6074, -0.1072,  1.0355],\n",
      "         [ 0.7606,  0.5936,  1.7953,  ...,  4.0585, -0.1740,  1.1925]],\n",
      "\n",
      "        [[-0.8789,  1.1787,  1.6580,  ...,  0.0000, -0.3118,  2.5625],\n",
      "         [ 0.8627,  2.0699,  2.4597,  ...,  1.3907,  0.0091,  2.2037],\n",
      "         [-0.2446, -0.6348,  2.9627,  ...,  2.2178, -1.1313,  1.8923],\n",
      "         ...,\n",
      "         [-0.0000,  0.8923, -0.2767,  ...,  3.0718, -0.1083,  0.0000],\n",
      "         [ 1.1332,  1.2538,  0.8076,  ...,  2.9415, -0.2115,  0.9595],\n",
      "         [ 0.0000, -0.4577,  2.5697,  ...,  3.2079,  0.0000,  0.9323]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.4602,  2.4976,  2.5674,  ...,  1.7063, -0.6511,  2.2738],\n",
      "         [ 0.1469,  1.9808,  2.7726,  ...,  2.2360, -0.4650,  2.2194],\n",
      "         [ 3.0384,  0.1796,  4.9614,  ...,  1.9908,  0.1747,  0.0000],\n",
      "         ...,\n",
      "         [ 0.2542,  1.5314, -0.0315,  ...,  3.4220,  0.2870,  0.6651],\n",
      "         [ 2.2957,  1.7910,  0.3466,  ...,  0.0000,  0.0000,  0.7684],\n",
      "         [ 2.2551,  0.1790,  3.1723,  ...,  3.0140, -0.8537,  1.2288]],\n",
      "\n",
      "        [[-0.8393,  3.3505,  3.0701,  ...,  1.5285, -0.8451,  2.3711],\n",
      "         [ 0.0000,  0.0000,  1.9278,  ...,  0.0000, -1.2139,  1.4086],\n",
      "         [ 2.7926, -0.3168,  2.4532,  ...,  2.0948,  0.0564,  1.4011],\n",
      "         ...,\n",
      "         [ 0.0052,  1.2915,  0.5439,  ...,  2.5354, -0.2554,  1.0206],\n",
      "         [ 1.2780,  1.6981,  0.5920,  ...,  0.0000, -0.5842,  0.7101],\n",
      "         [ 1.8002, -0.0438,  2.8012,  ...,  3.3769,  0.1688,  0.6504]],\n",
      "\n",
      "        [[-1.1789,  2.5465,  2.2313,  ...,  1.1823, -0.8281,  2.7421],\n",
      "         [ 1.1948,  1.5131,  3.0668,  ...,  1.4880, -0.0000,  0.7595],\n",
      "         [ 0.1354, -0.1610,  0.0000,  ...,  1.6031, -0.5218,  1.5343],\n",
      "         ...,\n",
      "         [-0.5590, -0.1338, -0.4517,  ...,  2.8806, -0.0205,  1.6642],\n",
      "         [ 0.0000,  1.5054,  0.2752,  ...,  1.1792, -0.1464,  0.7524],\n",
      "         [ 1.2771,  0.2736,  2.0545,  ...,  2.5271, -0.1825,  0.7251]]],\n",
      "       device='cuda:0', grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 91, 2048])\n",
      "tensor([[[-5.5774e-01,  1.1553e+00,  0.0000e+00,  ...,  2.4849e+00,\n",
      "          -6.9771e-01,  1.5535e+00],\n",
      "         [ 3.0680e-01, -4.6387e-01,  3.0142e+00,  ...,  0.0000e+00,\n",
      "          -4.4019e-01,  2.2775e+00],\n",
      "         [ 2.1573e+00, -1.8777e+00,  3.3348e+00,  ...,  2.4595e+00,\n",
      "          -4.5959e-01,  1.9308e+00],\n",
      "         ...,\n",
      "         [-1.8217e-01,  5.3693e-01,  1.0369e-01,  ...,  0.0000e+00,\n",
      "          -9.6860e-01,  0.0000e+00],\n",
      "         [ 1.3633e+00,  1.1009e+00,  8.6807e-01,  ...,  3.0631e+00,\n",
      "          -1.0878e+00,  2.0290e+00],\n",
      "         [ 1.5668e+00, -1.0028e+00,  1.4415e+00,  ...,  3.2185e+00,\n",
      "          -3.6130e-01,  1.9601e+00]],\n",
      "\n",
      "        [[-0.0000e+00,  1.9254e+00,  8.5890e-01,  ...,  1.9265e+00,\n",
      "          -9.9633e-01,  2.1144e+00],\n",
      "         [ 4.8436e-01,  6.6897e-01,  2.1622e+00,  ...,  1.2384e+00,\n",
      "          -9.0428e-01,  1.7396e+00],\n",
      "         [ 4.2038e-01, -1.1650e+00,  3.5603e+00,  ...,  1.6633e+00,\n",
      "          -3.1018e-01,  1.8330e+00],\n",
      "         ...,\n",
      "         [-3.6326e-01,  1.1439e-03, -6.3984e-01,  ...,  0.0000e+00,\n",
      "          -1.0082e+00,  1.4730e+00],\n",
      "         [ 1.1564e+00,  8.2763e-01,  2.5451e-01,  ...,  2.9546e+00,\n",
      "          -7.1791e-01,  1.2542e+00],\n",
      "         [ 7.1324e-01, -1.4806e-01,  1.5827e+00,  ...,  2.8759e+00,\n",
      "          -7.5873e-01,  1.6226e+00]],\n",
      "\n",
      "        [[-4.6159e-01,  9.3094e-01,  8.4932e-01,  ...,  1.1963e+00,\n",
      "          -8.4379e-01,  2.6368e+00],\n",
      "         [ 5.8434e-01,  1.0239e+00,  2.8065e+00,  ...,  2.1700e+00,\n",
      "          -5.6220e-01,  2.1147e+00],\n",
      "         [ 2.3253e-01, -1.3438e+00,  3.0696e+00,  ...,  2.2031e+00,\n",
      "          -1.0109e+00,  1.7797e+00],\n",
      "         ...,\n",
      "         [-6.7397e-01,  9.3758e-01, -0.0000e+00,  ...,  2.7212e+00,\n",
      "          -2.9804e-01,  9.5689e-01],\n",
      "         [ 8.0864e-01,  9.9219e-01, -8.1718e-02,  ...,  3.1437e+00,\n",
      "          -7.3701e-01,  1.5940e+00],\n",
      "         [-1.1210e-01, -3.9629e-01,  2.1976e+00,  ...,  0.0000e+00,\n",
      "          -5.0269e-01,  1.5210e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 7.4188e-02,  1.5499e+00,  2.2239e+00,  ...,  2.0808e+00,\n",
      "          -9.1693e-01,  1.8953e+00],\n",
      "         [ 0.0000e+00,  1.1153e+00,  2.6799e+00,  ...,  2.2635e+00,\n",
      "          -9.2626e-01,  2.0906e+00],\n",
      "         [ 1.8262e+00, -1.0810e+00,  3.2432e+00,  ...,  1.9395e+00,\n",
      "          -3.8236e-01,  7.5977e-01],\n",
      "         ...,\n",
      "         [-5.6652e-01,  1.0419e+00, -4.3975e-01,  ...,  2.6421e+00,\n",
      "          -9.9656e-02,  1.0798e+00],\n",
      "         [ 0.0000e+00,  1.2500e+00,  2.6197e-01,  ...,  1.0274e+00,\n",
      "          -4.5387e-01,  1.4053e+00],\n",
      "         [ 1.4011e+00, -7.2013e-01,  2.1955e+00,  ...,  2.1580e+00,\n",
      "          -6.2987e-01,  1.8216e+00]],\n",
      "\n",
      "        [[-6.5524e-01,  2.5198e+00,  2.0136e+00,  ...,  1.5909e+00,\n",
      "          -1.0305e+00,  2.1311e+00],\n",
      "         [ 3.2180e-01, -0.0000e+00,  2.7969e+00,  ...,  1.0382e+00,\n",
      "          -1.4454e+00,  1.4357e+00],\n",
      "         [ 1.9008e+00, -1.9419e+00,  3.3361e+00,  ...,  0.0000e+00,\n",
      "          -3.9792e-01,  1.5229e+00],\n",
      "         ...,\n",
      "         [-5.9997e-01,  7.4796e-01, -3.4944e-01,  ...,  1.9477e+00,\n",
      "          -7.4908e-01,  1.4980e+00],\n",
      "         [ 1.2330e+00,  8.7178e-01,  5.4971e-01,  ...,  8.7512e-01,\n",
      "          -8.9705e-01,  1.4792e+00],\n",
      "         [ 1.2921e+00, -4.4830e-01,  0.0000e+00,  ...,  2.6563e+00,\n",
      "          -4.6505e-01,  1.5319e+00]],\n",
      "\n",
      "        [[-1.1252e+00,  1.1321e+00,  1.9122e+00,  ...,  1.4762e+00,\n",
      "          -0.0000e+00,  0.0000e+00],\n",
      "         [ 7.9050e-01,  0.0000e+00,  2.7869e+00,  ...,  2.1242e+00,\n",
      "          -5.4395e-01,  1.4361e+00],\n",
      "         [ 1.2538e+00, -1.1882e+00,  1.8069e+00,  ...,  1.6652e+00,\n",
      "          -5.4649e-01,  1.4909e+00],\n",
      "         ...,\n",
      "         [-5.3626e-01, -4.1074e-01, -9.7375e-01,  ...,  1.9765e+00,\n",
      "          -6.3294e-01,  1.9358e+00],\n",
      "         [ 2.8646e-01,  7.1194e-01, -5.6618e-02,  ...,  1.9664e+00,\n",
      "          -3.1445e-01,  1.2967e+00],\n",
      "         [ 7.3811e-01, -4.3242e-02,  1.9004e+00,  ...,  2.0241e+00,\n",
      "          -0.0000e+00,  1.9767e+00]]], device='cuda:0',\n",
      "       grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 91, 2048])\n",
      "tensor([[[-1.4282,  0.6016,  0.2256,  ...,  0.0000, -0.3628,  1.9653],\n",
      "         [-0.2865,  0.0000,  2.3864,  ...,  0.0000, -0.4913,  2.0664],\n",
      "         [ 0.6793, -2.1399,  2.1742,  ...,  2.7190, -0.7965,  2.6311],\n",
      "         ...,\n",
      "         [-1.3137,  0.8182, -1.5843,  ...,  1.4523, -0.4469,  1.3454],\n",
      "         [-0.0476,  1.3687, -0.2540,  ...,  2.8778, -0.7408,  1.9336],\n",
      "         [ 0.9117, -0.4525,  0.7281,  ...,  2.9396, -0.7363,  2.1549]],\n",
      "\n",
      "        [[-1.3798,  0.0000,  0.0731,  ...,  1.8601, -0.9904,  2.0226],\n",
      "         [-0.0000,  0.0000,  0.8395,  ...,  1.7876, -0.9575,  1.8559],\n",
      "         [-0.2988, -1.2378,  2.7003,  ...,  1.5853, -0.3615,  2.0679],\n",
      "         ...,\n",
      "         [-1.5766,  0.6465, -2.0857,  ...,  1.0860, -0.8610,  1.9925],\n",
      "         [-0.1587,  1.2992, -0.0000,  ...,  2.3813, -0.8355,  1.4220],\n",
      "         [-0.3407, -0.1050,  0.0000,  ...,  2.3935, -0.5883,  2.0664]],\n",
      "\n",
      "        [[-1.4249,  1.3965, -0.3271,  ...,  1.3732, -0.6125,  2.2987],\n",
      "         [-0.4737,  0.9804,  1.7547,  ...,  2.0642, -0.4731,  2.1684],\n",
      "         [-0.3552, -1.0996,  1.6510,  ...,  1.9356, -0.8668,  1.8162],\n",
      "         ...,\n",
      "         [-1.8451,  1.2162, -1.5274,  ...,  2.5942, -0.4289,  1.3438],\n",
      "         [-0.4597,  0.7228, -1.0734,  ...,  2.5092, -0.0000,  1.8483],\n",
      "         [-0.7914, -0.0565,  1.0167,  ...,  1.0793, -0.6594,  1.8972]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.4451,  1.7214,  0.0000,  ...,  2.0693, -0.5380,  2.0354],\n",
      "         [-0.7470,  0.4954,  1.5032,  ...,  0.0000, -0.6888,  2.1795],\n",
      "         [ 0.1741, -0.9481,  2.6876,  ...,  1.9545, -0.6807,  1.4494],\n",
      "         ...,\n",
      "         [-1.9287,  1.2722, -0.0000,  ...,  2.2212, -0.7784,  1.4484],\n",
      "         [-0.6685,  1.6956, -0.8213,  ...,  1.3628, -0.6927,  1.8130],\n",
      "         [ 0.1216, -0.4390,  1.1005,  ...,  1.9932, -0.0000,  2.1612]],\n",
      "\n",
      "        [[-1.3453,  1.7492,  0.2995,  ...,  1.5897, -1.0682,  1.7535],\n",
      "         [-0.5783,  0.4134,  2.0072,  ...,  1.3621, -1.2598,  1.3754],\n",
      "         [ 0.9425, -1.4341,  2.0986,  ...,  1.5258, -0.8145,  1.6755],\n",
      "         ...,\n",
      "         [-1.6808,  0.2203, -1.4561,  ...,  1.4453, -0.9079,  1.5417],\n",
      "         [-0.0000,  0.0000, -0.2987,  ...,  0.0000, -1.1677,  1.5835],\n",
      "         [-0.0000, -0.1028,  0.3702,  ...,  1.9498, -0.7810,  2.1862]],\n",
      "\n",
      "        [[-2.0483,  0.9072,  0.6222,  ...,  1.5944, -0.3292,  1.1297],\n",
      "         [-0.3123, -0.2350,  2.0493,  ...,  1.7172, -0.8629,  0.0000],\n",
      "         [-0.0000, -1.2783,  0.0000,  ...,  1.6320, -0.8514,  1.5430],\n",
      "         ...,\n",
      "         [-1.8504,  0.0181, -0.0000,  ...,  1.6552, -0.6391,  2.4175],\n",
      "         [-0.6615,  1.5239, -0.0000,  ...,  1.6256, -0.6774,  2.1824],\n",
      "         [-0.3309,  0.0000,  0.0000,  ...,  1.7276, -0.6768,  0.0000]]],\n",
      "       device='cuda:0', grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 90, 2048])\n",
      "tensor([[[ -64.7824,    5.7054,   13.4799,  ...,  -89.4086,   15.9771,\n",
      "           120.2854],\n",
      "         [  32.1103,  -11.5790,   -9.0661,  ...,  -24.0485,  -38.4529,\n",
      "            39.7281],\n",
      "         [   0.0000,  -15.7789,   58.1243,  ...,   32.0411,   99.5325,\n",
      "           -34.3810],\n",
      "         ...,\n",
      "         [ -68.7001,  -13.0567,   -3.5143,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         [ -67.7476,  -12.0546,   -3.9737,  ...,   79.5327,   67.9524,\n",
      "            -0.0000],\n",
      "         [  -0.0000,  -11.7860,   -3.4453,  ...,   79.5327,   67.9524,\n",
      "           -78.4697]],\n",
      "\n",
      "        [[  28.2858,   23.3443,  -33.4608,  ...,    0.0000,   30.9774,\n",
      "            -3.9303],\n",
      "         [   6.7287,   33.9350,    4.2491,  ...,  -11.0705,  -42.2054,\n",
      "            28.5059],\n",
      "         [  23.9633,  -49.1509,  105.5970,  ...,  -17.8846,   90.6564,\n",
      "           -11.7819],\n",
      "         ...,\n",
      "         [ -68.7001,  -13.0567,   -3.5143,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         [ -67.7476,   -0.0000,   -3.9737,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         [ -66.8313,  -11.7860,   -3.4453,  ...,   79.5327,    0.0000,\n",
      "           -78.4697]],\n",
      "\n",
      "        [[ 126.3230,   43.8873,   55.4502,  ...,  -36.1146,   15.5148,\n",
      "            79.3907],\n",
      "         [  33.0242, -106.2247,  -41.0155,  ...,   36.5917,  -37.7192,\n",
      "            20.4725],\n",
      "         [ -19.3007,    0.0000,  -30.7949,  ...,   22.1280,   95.2851,\n",
      "            91.5541],\n",
      "         ...,\n",
      "         [ -68.7001,  -13.0567,   -3.5143,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         [ -67.7476,  -12.0546,   -3.9737,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         [ -66.8313,  -11.7860,   -3.4453,  ...,    0.0000,    0.0000,\n",
      "           -78.4697]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -28.4509,   34.1837,   42.0306,  ...,  -71.1576,   35.5508,\n",
      "           -48.2909],\n",
      "         [  -0.0000,  -12.2570,   -1.9392,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         [ -66.7766,  -13.3099,   -1.8372,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         ...,\n",
      "         [  -0.0000,  -13.0567,   -3.5143,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         [ -67.7476,  -12.0546,   -3.9737,  ...,    0.0000,   67.9524,\n",
      "           -78.4697],\n",
      "         [ -66.8313,  -11.7860,   -3.4453,  ...,   79.5327,   67.9524,\n",
      "           -78.4697]],\n",
      "\n",
      "        [[ -64.7824,    5.7054,   13.4799,  ...,  -89.4086,   15.9771,\n",
      "           120.2854],\n",
      "         [   0.0000,  -11.5790,   -9.0661,  ...,  -24.0485,  -38.4529,\n",
      "            39.7281],\n",
      "         [  64.3550,  -58.8239, -105.8307,  ...,   58.8418,   -0.0000,\n",
      "           -91.7171],\n",
      "         ...,\n",
      "         [  -0.0000,   -0.0000,   -3.5143,  ...,   79.5327,    0.0000,\n",
      "           -78.4697],\n",
      "         [ -67.7476,  -12.0546,   -3.9737,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         [ -66.8313,  -11.7860,   -3.4453,  ...,   79.5327,   67.9524,\n",
      "           -78.4697]],\n",
      "\n",
      "        [[  -0.0000,  -28.7443,  -38.6392,  ...,    0.0000,   84.7064,\n",
      "          -100.9259],\n",
      "         [ -37.2389,    0.0000,  -39.4401,  ...,  -69.0961,   17.4334,\n",
      "            45.7003],\n",
      "         [ -78.4874,   74.2139,  101.8267,  ...,   17.7393,   -0.0000,\n",
      "            -0.0000],\n",
      "         ...,\n",
      "         [ -68.7001,  -13.0567,   -3.5143,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         [ -67.7476,  -12.0546,   -3.9737,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         [ -66.8313,  -11.7860,   -3.4453,  ...,   79.5327,   67.9524,\n",
      "           -78.4697]]], device='cuda:0', grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 90, 2048])\n",
      "tensor([[[-2.9875e-01,  9.0374e-01,  8.6132e-01,  ...,  9.3706e-01,\n",
      "           6.5005e-01,  4.3801e+00],\n",
      "         [ 2.9934e+00,  1.0976e+00,  1.4276e+00,  ...,  1.5700e+00,\n",
      "          -3.7364e-01,  2.9997e+00],\n",
      "         [ 1.8297e+00, -1.8579e-01,  3.8456e+00,  ...,  3.0529e+00,\n",
      "           1.8859e+00,  1.6541e+00],\n",
      "         ...,\n",
      "         [-1.6322e+00,  3.4786e-01,  1.1544e+00,  ...,  3.7153e+00,\n",
      "           2.0505e+00,  7.2931e-02],\n",
      "         [-4.4686e-01,  8.4080e-01,  3.6293e-01,  ...,  3.3387e+00,\n",
      "           0.0000e+00,  1.5222e+00],\n",
      "         [ 2.0660e+00,  1.4759e+00,  6.6862e-01,  ...,  3.6709e+00,\n",
      "           2.2243e+00, -2.4828e-01]],\n",
      "\n",
      "        [[ 2.0755e+00,  2.3196e+00,  2.8900e-02,  ...,  0.0000e+00,\n",
      "           1.0095e+00,  1.9474e+00],\n",
      "         [ 1.9842e+00,  1.9757e+00,  2.2586e+00,  ...,  0.0000e+00,\n",
      "          -4.2941e-01,  3.1396e+00],\n",
      "         [ 2.8943e+00, -8.8653e-01,  4.1523e+00,  ...,  1.8058e+00,\n",
      "           1.8399e+00,  1.8086e+00],\n",
      "         ...,\n",
      "         [-4.3840e-02, -6.0962e-01,  5.5530e-01,  ...,  3.7308e+00,\n",
      "           1.2052e+00,  3.8490e-01],\n",
      "         [-3.5350e-01,  1.8854e+00, -5.5359e-01,  ...,  4.3448e+00,\n",
      "           1.6972e+00, -4.3223e-02],\n",
      "         [ 0.0000e+00,  9.9016e-01, -4.8712e-02,  ...,  3.8496e+00,\n",
      "           1.4801e-01,  2.3078e-01]],\n",
      "\n",
      "        [[ 3.5222e+00,  2.6648e+00,  1.7524e+00,  ...,  1.3884e+00,\n",
      "          -6.2381e-04,  3.5268e+00],\n",
      "         [ 0.0000e+00, -5.2546e-01,  1.0634e+00,  ...,  3.2313e+00,\n",
      "          -1.2701e+00,  1.9143e+00],\n",
      "         [ 1.7853e+00,  1.9080e-01,  0.0000e+00,  ...,  2.7747e+00,\n",
      "           2.4205e+00,  4.4111e+00],\n",
      "         ...,\n",
      "         [-1.0409e+00, -0.0000e+00, -1.1589e-01,  ...,  4.6503e+00,\n",
      "           8.2061e-01,  4.6825e-01],\n",
      "         [ 1.2489e-01,  9.8890e-01, -9.2335e-01,  ...,  4.8707e+00,\n",
      "           1.0256e+00,  3.9233e-01],\n",
      "         [ 7.5452e-01,  8.9027e-01,  4.2182e-01,  ...,  3.0371e+00,\n",
      "          -3.8385e-01,  1.7648e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 3.7446e-01,  2.9523e+00,  1.6716e+00,  ...,  0.0000e+00,\n",
      "           4.4262e-01,  0.0000e+00],\n",
      "         [ 2.0144e+00,  1.0908e+00,  1.6188e+00,  ...,  3.8382e+00,\n",
      "           1.1017e+00, -4.0463e-01],\n",
      "         [ 6.1301e-01, -3.9955e-01,  1.6642e+00,  ...,  3.3859e+00,\n",
      "           1.3128e+00, -2.5519e-01],\n",
      "         ...,\n",
      "         [ 2.0836e-01,  2.3098e-01, -5.1592e-02,  ...,  3.9090e+00,\n",
      "           1.6594e+00, -6.9495e-02],\n",
      "         [-4.1759e-01,  1.6936e+00, -4.1308e-01,  ...,  1.8939e+00,\n",
      "           8.8859e-01,  1.7641e-01],\n",
      "         [ 1.2822e-02,  1.7095e+00, -4.0336e-01,  ...,  3.9702e+00,\n",
      "           8.6950e-01, -1.4143e-01]],\n",
      "\n",
      "        [[-6.8023e-01,  1.6560e+00,  1.8124e+00,  ...,  7.4170e-01,\n",
      "           4.3876e-01,  4.1250e+00],\n",
      "         [ 1.8708e+00,  1.0717e+00,  1.7398e+00,  ...,  1.5208e+00,\n",
      "           3.3812e-01,  2.7173e+00],\n",
      "         [ 4.3138e+00, -2.2822e+00, -0.0000e+00,  ...,  3.6156e+00,\n",
      "           3.1873e-01,  2.2323e-02],\n",
      "         ...,\n",
      "         [ 9.4760e-01,  1.5776e-01,  1.1574e+00,  ...,  3.3467e+00,\n",
      "           0.0000e+00, -4.4270e-01],\n",
      "         [ 0.0000e+00,  1.1513e+00,  7.1216e-01,  ...,  3.9391e+00,\n",
      "           1.8109e+00, -3.1559e-01],\n",
      "         [ 0.0000e+00,  1.2269e+00,  0.0000e+00,  ...,  3.3660e+00,\n",
      "           1.5459e+00, -4.6232e-01]],\n",
      "\n",
      "        [[ 1.3160e+00,  8.5813e-01, -2.8885e-01,  ...,  0.0000e+00,\n",
      "           2.0431e+00, -2.5637e-01],\n",
      "         [ 5.7644e-01,  1.2651e+00,  6.7665e-01,  ...,  1.3139e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 1.8520e-01,  2.0466e+00,  3.9938e+00,  ...,  2.0978e+00,\n",
      "           1.1197e-01,  0.0000e+00],\n",
      "         ...,\n",
      "         [-4.2887e-01, -6.9490e-01,  2.4429e-01,  ...,  3.7275e+00,\n",
      "           1.9837e+00, -6.2718e-02],\n",
      "         [-5.1144e-01,  7.5996e-01, -3.0681e-01,  ...,  0.0000e+00,\n",
      "           1.5255e+00,  0.0000e+00],\n",
      "         [ 1.2572e+00,  0.0000e+00,  8.5483e-01,  ...,  3.3185e+00,\n",
      "           1.9289e+00,  1.7716e-01]]], device='cuda:0',\n",
      "       grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 90, 2048])\n",
      "tensor([[[ 0.0197,  0.0540,  0.9034,  ...,  2.2048,  0.6492,  4.3894],\n",
      "         [ 3.4244, -0.1110,  2.5156,  ...,  2.7484, -0.1623,  3.8551],\n",
      "         [ 2.2077, -2.0404,  4.2571,  ...,  3.5802,  1.2514,  2.7610],\n",
      "         ...,\n",
      "         [-0.0000, -1.6418,  0.9158,  ...,  4.5837,  1.6180,  1.3110],\n",
      "         [ 0.0000,  0.0637, -0.0586,  ...,  4.0836,  0.2425,  2.0195],\n",
      "         [ 0.0000,  0.5738,  0.8339,  ...,  4.0131,  1.7892,  1.6190]],\n",
      "\n",
      "        [[ 1.6964,  1.2301,  0.7529,  ...,  1.8537,  0.7529,  3.1472],\n",
      "         [ 2.2779,  0.6094,  2.7696,  ...,  1.8286, -0.1754,  0.0000],\n",
      "         [ 3.7307, -2.7130,  4.1664,  ...,  2.8621,  1.1164,  2.8605],\n",
      "         ...,\n",
      "         [-0.6977, -2.2255,  0.6040,  ...,  4.2564,  0.0000,  1.7024],\n",
      "         [ 0.5062,  0.4132, -0.7880,  ...,  4.9530,  1.3100,  1.6369],\n",
      "         [ 1.5638,  0.5102,  0.3257,  ...,  4.0574, -0.2603,  2.1889]],\n",
      "\n",
      "        [[ 2.4841,  1.0904,  1.2340,  ...,  2.7546, -0.2907,  3.4753],\n",
      "         [ 1.1880, -0.8739,  2.1835,  ...,  3.7985, -0.5415,  2.6209],\n",
      "         [ 2.6126, -1.4205,  1.6603,  ...,  3.9788,  0.0000,  4.5579],\n",
      "         ...,\n",
      "         [-0.9430, -1.3561,  0.0411,  ...,  5.1915,  0.9098,  1.7286],\n",
      "         [ 0.6277,  0.2633, -1.5595,  ...,  5.2298,  1.0902,  1.9202],\n",
      "         [ 1.9728,  0.2667,  0.4403,  ...,  4.0323, -0.0772,  1.0941]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.5598,  1.7368,  1.7289,  ...,  1.1447, -0.1729,  1.6655],\n",
      "         [ 2.2784,  0.2651,  2.7160,  ...,  0.0000, -0.0000,  1.3823],\n",
      "         [ 1.2034, -1.3111,  2.4540,  ...,  3.7675,  0.8647,  1.5565],\n",
      "         ...,\n",
      "         [-0.6784, -1.2148,  0.0000,  ...,  4.1744,  1.4839,  2.0613],\n",
      "         [-0.5124,  0.9752, -0.6749,  ...,  2.9325,  0.5033,  1.5367],\n",
      "         [ 0.0000,  0.0000, -0.5446,  ...,  4.1422, -0.0375,  0.0000]],\n",
      "\n",
      "        [[ 0.2121,  1.0240,  1.4986,  ...,  2.0255,  0.4428,  4.6065],\n",
      "         [ 2.9623, -0.1926,  2.4282,  ...,  2.8240, -0.4356,  3.7553],\n",
      "         [ 4.5112, -3.4570,  1.1049,  ...,  3.9175,  0.0000,  1.5623],\n",
      "         ...,\n",
      "         [ 0.7438, -1.2795,  1.0797,  ...,  3.4594, -0.0000,  1.3513],\n",
      "         [ 0.5910,  0.0120,  0.0000,  ...,  4.0406,  1.2485,  1.3307],\n",
      "         [ 1.5466,  0.3110,  0.8519,  ...,  3.6919,  1.4893,  1.1664]],\n",
      "\n",
      "        [[ 1.2703,  0.1786,  0.2441,  ...,  1.4890,  1.8641,  1.7257],\n",
      "         [ 1.5115,  0.0973,  1.4566,  ...,  2.8784,  0.1122,  1.8715],\n",
      "         [ 0.0000,  0.0315,  3.9311,  ...,  2.5964,  0.2241,  1.6048],\n",
      "         ...,\n",
      "         [-1.0457, -2.0954, -0.1529,  ...,  0.0000,  2.0727,  1.1657],\n",
      "         [ 0.0783, -0.2669, -1.1784,  ...,  1.8448,  1.7786,  0.0000],\n",
      "         [ 1.9044, -0.6902,  0.8853,  ...,  3.7283,  1.9103,  2.1422]]],\n",
      "       device='cuda:0', grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 90, 2048])\n",
      "tensor([[[-0.4353, -0.9804,  0.8153,  ...,  2.6247,  0.5846,  4.3369],\n",
      "         [ 2.5865, -1.0918,  2.2183,  ...,  3.1625,  0.3138,  3.7374],\n",
      "         [ 1.7621, -3.5513,  3.2336,  ...,  3.4485,  0.7410,  3.1881],\n",
      "         ...,\n",
      "         [-1.0044, -0.0000,  0.3632,  ...,  4.5566,  1.4354,  2.2835],\n",
      "         [-0.1957, -0.9327, -0.6850,  ...,  3.9012,  0.5688,  2.6771],\n",
      "         [ 0.6867, -0.4076,  0.1576,  ...,  3.9719,  1.0202,  2.9997]],\n",
      "\n",
      "        [[ 0.6493, -0.3325,  0.2047,  ...,  2.5872,  0.9383,  3.5503],\n",
      "         [ 1.3779, -1.2139,  0.0000,  ...,  2.6839,  0.0241,  1.6659],\n",
      "         [ 2.7212, -4.1502,  2.9503,  ...,  3.3381,  0.9470,  3.5253],\n",
      "         ...,\n",
      "         [-1.6373, -3.5363, -0.0000,  ...,  4.0916,  0.6586,  2.3424],\n",
      "         [ 0.4385, -0.9067, -1.4696,  ...,  0.0000,  1.0353,  2.2397],\n",
      "         [ 0.8913, -0.5308, -0.4935,  ...,  4.0227,  0.3874,  2.9058]],\n",
      "\n",
      "        [[ 0.0000, -0.4876,  0.3269,  ...,  3.3272,  0.1301,  0.0000],\n",
      "         [ 1.2227, -1.5137,  2.1518,  ...,  0.0000,  0.1130,  2.7973],\n",
      "         [ 1.6526, -3.1372,  0.0000,  ...,  4.2040,  0.1320,  0.0000],\n",
      "         ...,\n",
      "         [-1.5540, -2.4863, -0.4435,  ...,  4.7586,  0.9718,  2.9263],\n",
      "         [-0.0355, -0.0000, -1.9889,  ...,  4.5836,  1.3868,  0.0000],\n",
      "         [ 1.6179, -0.4882, -0.1613,  ...,  3.9712,  0.5850,  2.3081]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.3982,  0.5626,  1.0209,  ...,  2.7097, -0.0627,  2.4181],\n",
      "         [ 1.6915, -1.2672,  2.2805,  ...,  2.2328,  0.2436,  2.5439],\n",
      "         [ 1.3650, -2.5013,  2.0894,  ...,  3.8458,  0.8119,  2.4128],\n",
      "         ...,\n",
      "         [-0.0000, -2.3854, -0.4476,  ...,  4.0492,  0.0000,  2.9690],\n",
      "         [-0.7834, -0.5875, -1.4617,  ...,  3.6612,  0.7270,  2.9500],\n",
      "         [ 0.3273, -0.7530, -0.8809,  ...,  4.2098,  0.2306,  0.0000]],\n",
      "\n",
      "        [[ 0.0604, -0.4240,  0.3109,  ...,  2.9127, -0.1494,  3.6937],\n",
      "         [ 2.5429, -1.7472,  2.2526,  ...,  3.3472, -0.0000,  3.8378],\n",
      "         [ 3.2270, -4.5358,  1.5367,  ...,  0.0000,  0.0926,  2.2812],\n",
      "         ...,\n",
      "         [-0.5693, -3.1534,  0.1037,  ...,  3.4038, -0.2106,  2.3919],\n",
      "         [-0.0559, -0.9312, -0.9765,  ...,  3.7884,  0.0000,  2.3528],\n",
      "         [ 1.4648, -0.9663,  0.1609,  ...,  3.6786,  1.1722,  2.3977]],\n",
      "\n",
      "        [[ 0.4201, -0.8082, -0.0604,  ...,  2.6899,  1.5018,  2.5973],\n",
      "         [ 1.8115, -1.0366,  1.3564,  ...,  3.5398,  0.2539,  2.6495],\n",
      "         [ 0.8500, -2.2010,  2.8579,  ...,  3.2499,  0.3024,  2.5084],\n",
      "         ...,\n",
      "         [-1.8869, -3.0795, -0.7358,  ...,  1.9162,  1.5553,  0.0000],\n",
      "         [ 0.1211, -1.3358, -1.4112,  ...,  2.7109,  1.8244,  2.0589],\n",
      "         [ 1.9031, -1.4286, -0.2047,  ...,  3.9662,  1.8516,  0.0000]]],\n",
      "       device='cuda:0', grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 90, 2048])\n",
      "tensor([[[-1.2847, -1.2151, -0.4676,  ...,  3.0386,  0.7151,  4.2737],\n",
      "         [ 1.1596, -1.2759,  1.3518,  ...,  0.0000,  0.6703,  3.8050],\n",
      "         [ 0.9274, -0.0000,  0.0000,  ...,  3.4345,  1.1088,  3.6638],\n",
      "         ...,\n",
      "         [-0.0000, -0.0000, -1.0311,  ...,  3.8191,  1.1625,  3.0129],\n",
      "         [-1.1818, -1.2454, -2.3792,  ...,  3.7766,  0.8212,  3.3721],\n",
      "         [ 0.1247, -0.6055, -1.4739,  ...,  3.5841,  0.8514,  3.5740]],\n",
      "\n",
      "        [[-0.9761, -0.7084, -0.8843,  ...,  3.1819,  0.0000,  0.0000],\n",
      "         [ 0.6327, -1.7630, -0.2981,  ...,  3.4593,  0.4391,  2.2474],\n",
      "         [ 1.5406, -0.0000,  1.9047,  ...,  3.5012,  0.9591,  3.4891],\n",
      "         ...,\n",
      "         [-2.9386, -3.4024, -1.4540,  ...,  0.0000,  0.8388,  2.7270],\n",
      "         [-0.9157, -1.3634, -2.3637,  ...,  1.9031,  0.0000,  3.0834],\n",
      "         [ 0.4243, -0.6341, -1.6570,  ...,  3.8860,  0.0000,  3.1892]],\n",
      "\n",
      "        [[-1.2188, -0.9625, -1.1259,  ...,  3.3840,  0.0000,  1.6104],\n",
      "         [ 0.6711, -1.7407,  1.1348,  ...,  2.0147,  0.5681,  3.0477],\n",
      "         [ 0.5354, -0.0000,  0.0446,  ...,  4.0113,  0.3499,  1.9115],\n",
      "         ...,\n",
      "         [-2.6589, -2.8460, -1.6710,  ...,  0.0000,  0.0000,  3.3059],\n",
      "         [-0.0000, -0.6972, -0.0000,  ...,  3.9717,  0.2332,  1.8806],\n",
      "         [ 0.5750, -0.7057, -1.5213,  ...,  3.7890,  0.6757,  0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.0605, -0.5793, -0.4853,  ...,  3.3583, -0.5110,  3.3269],\n",
      "         [ 0.6013, -1.7687,  1.0727,  ...,  0.0000,  0.5786,  2.9383],\n",
      "         [ 0.7950, -0.0000,  0.9071,  ...,  3.9648,  0.0000,  3.1515],\n",
      "         ...,\n",
      "         [-2.1960, -3.3355, -1.7683,  ...,  4.5651,  0.6410,  0.0000],\n",
      "         [-1.2162, -1.3597, -2.7527,  ...,  3.6627,  1.1328,  2.8374],\n",
      "         [ 0.1869, -0.7166, -2.3327,  ...,  3.9486,  0.0000,  2.0366]],\n",
      "\n",
      "        [[-1.1041, -0.8234, -0.0000,  ...,  3.3987,  0.1158,  3.3018],\n",
      "         [ 1.3305, -1.7320,  1.1611,  ...,  3.6607,  0.3806,  3.8292],\n",
      "         [ 1.3857, -4.6722,  0.9403,  ...,  0.0000,  0.2267,  2.9971],\n",
      "         ...,\n",
      "         [-1.8082, -3.1710, -1.7583,  ...,  0.0000,  0.2770,  2.9174],\n",
      "         [-1.0368, -1.0200, -2.4251,  ...,  0.0000,  0.5194,  2.7809],\n",
      "         [ 0.8521, -0.6094, -0.0000,  ...,  3.4435,  0.5287,  3.0621]],\n",
      "\n",
      "        [[-0.7332, -0.8838, -0.9452,  ...,  3.2518,  1.1524,  3.2457],\n",
      "         [ 0.7050, -1.4116,  0.5949,  ...,  3.7893,  0.3483,  3.2212],\n",
      "         [ 0.0000, -2.6640,  1.5042,  ...,  3.1309,  0.7174,  3.1495],\n",
      "         ...,\n",
      "         [-3.0497, -3.0696, -0.0000,  ...,  3.0289,  0.3912,  1.8391],\n",
      "         [-0.8437, -1.3228, -2.6519,  ...,  2.9542,  0.0000,  2.8006],\n",
      "         [ 0.6848, -1.2404, -1.5179,  ...,  3.6029,  1.5206,  0.0000]]],\n",
      "       device='cuda:0', grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 91, 2048])\n",
      "tensor([[[-1.2303e+02,  7.2536e+01,  5.5620e+01,  ..., -0.0000e+00,\n",
      "           9.8611e-03,  9.5118e+01],\n",
      "         [-9.8861e+00,  4.8866e+01,  4.5202e+00,  ..., -5.6521e+01,\n",
      "          -3.2143e+01,  1.4092e+01],\n",
      "         [ 1.2503e+01, -8.8972e+01,  5.0518e+01,  ...,  4.2466e+01,\n",
      "          -3.0594e+01,  2.5282e+01],\n",
      "         ...,\n",
      "         [-6.7748e+01, -1.2055e+01, -0.0000e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6831e+01, -1.1786e+01, -3.4453e+00,  ...,  7.9533e+01,\n",
      "           0.0000e+00, -7.8470e+01],\n",
      "         [-6.6794e+01, -1.2494e+01, -2.3993e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01]],\n",
      "\n",
      "        [[-1.2303e+02,  7.2536e+01,  5.5620e+01,  ..., -2.7637e+01,\n",
      "           9.8611e-03,  0.0000e+00],\n",
      "         [ 2.3727e+01, -4.9275e+01,  8.3918e+01,  ...,  5.0868e+01,\n",
      "          -4.5095e+01,  7.2740e+00],\n",
      "         [-7.0547e+01,  1.4097e+01, -2.3424e+01,  ...,  7.0582e+00,\n",
      "          -3.0725e+01,  7.9454e+01],\n",
      "         ...,\n",
      "         [-6.7748e+01, -1.2055e+01, -3.9737e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6831e+01, -1.1786e+01, -3.4453e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6794e+01, -1.2494e+01, -2.3993e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01]],\n",
      "\n",
      "        [[-1.2303e+02,  7.2536e+01,  5.5620e+01,  ..., -2.7637e+01,\n",
      "           9.8611e-03,  9.5118e+01],\n",
      "         [-0.0000e+00, -2.1169e+01,  1.7125e+01,  ..., -6.2403e+01,\n",
      "           1.1607e+02, -3.2174e+01],\n",
      "         [ 5.0120e+01,  3.0016e+01,  1.0835e+02,  ..., -0.0000e+00,\n",
      "           6.8697e+01, -3.2877e+01],\n",
      "         ...,\n",
      "         [-6.7748e+01, -1.2055e+01, -3.9737e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6831e+01, -0.0000e+00, -3.4453e+00,  ...,  0.0000e+00,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6794e+01, -1.2494e+01, -2.3993e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.2303e+02,  7.2536e+01,  5.5620e+01,  ..., -2.7637e+01,\n",
      "           9.8611e-03,  9.5118e+01],\n",
      "         [-1.5188e+02, -1.4156e+00, -4.9651e+01,  ..., -1.6306e+01,\n",
      "           1.9726e+01,  1.2007e+01],\n",
      "         [ 5.0120e+01,  3.0016e+01,  1.0835e+02,  ..., -2.9314e+00,\n",
      "           6.8697e+01, -0.0000e+00],\n",
      "         ...,\n",
      "         [-6.7748e+01, -1.2055e+01, -0.0000e+00,  ...,  0.0000e+00,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6831e+01, -1.1786e+01, -3.4453e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6794e+01, -1.2494e+01, -2.3993e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -0.0000e+00]],\n",
      "\n",
      "        [[-1.2303e+02,  0.0000e+00,  5.5620e+01,  ..., -2.7637e+01,\n",
      "           9.8611e-03,  9.5118e+01],\n",
      "         [-1.5188e+02, -1.4156e+00, -4.9651e+01,  ..., -1.6306e+01,\n",
      "           1.9726e+01,  1.2007e+01],\n",
      "         [-4.9950e+00, -3.3814e+01,  8.4068e+01,  ..., -1.9822e+01,\n",
      "           4.2320e+01,  2.4493e+01],\n",
      "         ...,\n",
      "         [-6.7748e+01, -1.2055e+01, -3.9737e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-0.0000e+00, -1.1786e+01, -3.4453e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -0.0000e+00],\n",
      "         [-6.6794e+01, -1.2494e+01, -2.3993e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01]],\n",
      "\n",
      "        [[-1.2303e+02,  7.2536e+01,  5.5620e+01,  ..., -2.7637e+01,\n",
      "           9.8611e-03,  9.5118e+01],\n",
      "         [ 5.5828e-01,  6.8135e+01,  8.1356e+01,  ...,  0.0000e+00,\n",
      "           4.0909e+01,  5.5648e+01],\n",
      "         [-1.5180e+02, -2.4685e+00, -4.9549e+01,  ..., -1.6306e+01,\n",
      "           1.9726e+01,  1.2007e+01],\n",
      "         ...,\n",
      "         [-6.7748e+01, -1.2055e+01, -3.9737e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6831e+01, -1.1786e+01, -3.4453e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -0.0000e+00],\n",
      "         [-6.6794e+01, -1.2494e+01, -2.3993e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01]]], device='cuda:0',\n",
      "       grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 91, 2048])\n",
      "tensor([[[-2.2102e+00,  3.1410e+00,  2.0310e+00,  ...,  1.7124e+00,\n",
      "          -2.0470e-01,  2.7403e+00],\n",
      "         [ 2.1743e+00,  3.0021e+00,  2.8147e+00,  ...,  3.6681e-01,\n",
      "          -1.0614e+00,  1.4733e+00],\n",
      "         [ 1.9296e+00, -1.1161e+00,  3.8176e+00,  ...,  2.2708e+00,\n",
      "          -5.6638e-01,  1.7065e+00],\n",
      "         ...,\n",
      "         [-6.4348e-01,  9.3559e-01,  2.0703e-01,  ...,  3.8855e+00,\n",
      "           1.3559e+00, -4.4220e-02],\n",
      "         [ 4.7237e-01,  1.0906e+00,  4.2621e-01,  ...,  3.4131e+00,\n",
      "          -5.0559e-01, -4.4381e-01],\n",
      "         [ 4.9171e-01,  4.0135e-01,  0.0000e+00,  ...,  3.7692e+00,\n",
      "           1.0388e+00, -2.4448e-01]],\n",
      "\n",
      "        [[-2.1152e+00,  3.4773e+00,  1.9591e+00,  ...,  1.0670e+00,\n",
      "          -3.3215e-01,  1.1399e+00],\n",
      "         [ 1.9862e+00, -1.8042e-01,  4.4029e+00,  ...,  2.7639e+00,\n",
      "          -1.4383e+00,  0.0000e+00],\n",
      "         [ 4.1295e-01,  1.4363e+00,  2.2060e+00,  ...,  1.9973e+00,\n",
      "          -1.0572e+00,  2.1496e+00],\n",
      "         ...,\n",
      "         [-2.4111e-01,  1.2751e+00, -3.9005e-01,  ...,  3.2171e+00,\n",
      "           7.7732e-01, -1.7682e-01],\n",
      "         [-3.6615e-01,  8.8532e-01, -2.2243e-03,  ...,  3.0301e+00,\n",
      "           5.2730e-01, -3.3916e-01],\n",
      "         [ 0.0000e+00,  4.3119e-01,  1.6047e+00,  ...,  3.0594e+00,\n",
      "           9.3614e-01,  2.9201e-01]],\n",
      "\n",
      "        [[-2.0709e+00,  3.2919e+00,  2.3445e+00,  ...,  7.0191e-01,\n",
      "           3.6103e-01,  2.9105e+00],\n",
      "         [ 1.3362e+00,  9.1017e-01,  2.6389e+00,  ...,  1.4085e-01,\n",
      "           0.0000e+00,  7.0899e-01],\n",
      "         [ 2.3159e+00,  8.8942e-01,  4.2052e+00,  ...,  1.5601e+00,\n",
      "           9.7834e-01,  8.0364e-01],\n",
      "         ...,\n",
      "         [-3.6598e-01,  8.1134e-01, -4.9727e-01,  ...,  3.6239e+00,\n",
      "           1.0941e+00, -2.7392e-04],\n",
      "         [ 2.3523e-01,  1.2125e+00,  6.3039e-01,  ...,  1.8908e+00,\n",
      "           1.3057e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  4.3877e-01,  1.0101e+00,  ...,  3.2482e+00,\n",
      "           1.0982e+00, -2.2437e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.8317e+00,  3.1223e+00,  2.2963e+00,  ...,  3.7656e-02,\n",
      "          -8.5375e-01,  3.0301e+00],\n",
      "         [-1.8465e+00,  2.0273e+00,  4.2208e-01,  ...,  1.3863e+00,\n",
      "           5.8346e-01,  1.9643e+00],\n",
      "         [ 3.0082e+00,  1.2830e+00,  3.6257e+00,  ...,  1.6289e+00,\n",
      "           1.2990e+00,  1.6428e+00],\n",
      "         ...,\n",
      "         [-5.4585e-01,  1.0272e+00,  4.4783e-02,  ...,  1.5741e+00,\n",
      "           8.4775e-01,  2.2549e-03],\n",
      "         [ 6.9967e-01,  1.4804e+00,  3.9970e-01,  ...,  3.2026e+00,\n",
      "           1.5580e+00,  8.6727e-02],\n",
      "         [ 4.8687e-01,  8.5927e-01,  1.5042e+00,  ...,  3.2808e+00,\n",
      "           1.1001e+00,  2.0004e+00]],\n",
      "\n",
      "        [[-2.1576e+00,  1.7623e+00,  1.7809e+00,  ...,  9.5238e-01,\n",
      "          -3.0757e-01,  3.7512e+00],\n",
      "         [-8.8476e-01,  2.0703e+00,  1.2247e+00,  ...,  1.5727e+00,\n",
      "           2.5963e-01,  1.4634e+00],\n",
      "         [ 9.5552e-01, -7.3155e-01,  3.5647e+00,  ...,  2.0998e+00,\n",
      "           4.0760e-01,  1.9006e+00],\n",
      "         ...,\n",
      "         [-0.0000e+00,  1.5501e+00,  1.2266e+00,  ...,  3.7944e+00,\n",
      "           1.3743e+00,  7.4885e-01],\n",
      "         [ 1.4572e+00,  1.5153e+00,  1.1639e+00,  ...,  0.0000e+00,\n",
      "           1.2342e+00,  0.0000e+00],\n",
      "         [ 3.7115e-01,  1.0050e+00,  2.2997e+00,  ...,  0.0000e+00,\n",
      "           1.2045e+00,  2.5153e-01]],\n",
      "\n",
      "        [[-2.3283e+00,  3.5455e+00,  0.0000e+00,  ...,  6.2276e-01,\n",
      "           2.5274e-02,  3.0900e+00],\n",
      "         [ 1.6550e+00,  2.9343e+00,  3.7458e+00,  ...,  1.2328e+00,\n",
      "           6.1687e-01,  1.2785e+00],\n",
      "         [-1.7469e+00,  8.5105e-01,  1.1921e+00,  ...,  1.0757e+00,\n",
      "          -1.6737e-01,  2.0111e+00],\n",
      "         ...,\n",
      "         [-1.1437e+00,  1.0677e+00, -1.9914e-01,  ...,  3.4887e+00,\n",
      "           1.7739e+00,  1.3491e-01],\n",
      "         [ 8.9700e-01,  1.6204e+00,  0.0000e+00,  ...,  3.1370e+00,\n",
      "           1.3109e+00,  6.9006e-01],\n",
      "         [ 4.0395e-01,  1.4233e+00,  1.3249e+00,  ...,  3.3688e+00,\n",
      "           1.5043e+00, -4.1614e-01]]], device='cuda:0',\n",
      "       grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 91, 2048])\n",
      "tensor([[[-1.2894,  2.5872,  2.3792,  ...,  1.7803, -0.2110,  2.3273],\n",
      "         [ 2.7224,  1.9061,  3.8967,  ...,  1.3353, -1.1672,  0.9935],\n",
      "         [ 2.3730, -0.0000,  4.7054,  ...,  2.0127, -0.7396,  1.7979],\n",
      "         ...,\n",
      "         [-0.2520,  0.8430, -0.0697,  ...,  3.4229,  0.1815,  0.5614],\n",
      "         [ 2.1058,  1.2310,  0.0000,  ...,  3.4046, -0.0000,  0.5689],\n",
      "         [ 1.7727, -0.3743,  1.6482,  ...,  3.2045,  0.0860,  0.6893]],\n",
      "\n",
      "        [[-0.0000,  2.5892,  2.2142,  ...,  1.7783, -0.9460,  1.7529],\n",
      "         [ 1.9484, -0.0501,  4.3221,  ...,  2.8691, -1.4610,  1.3830],\n",
      "         [ 0.0000, -0.1115,  3.5626,  ...,  2.4817, -1.2389,  1.7599],\n",
      "         ...,\n",
      "         [ 0.0966,  0.7417, -0.3419,  ...,  0.0000, -0.3845,  0.7425],\n",
      "         [ 0.7887,  1.1029,  0.4659,  ...,  2.5886, -0.3036,  1.1672],\n",
      "         [ 0.9665,  0.2293,  0.0000,  ...,  2.6460, -0.1908,  0.0000]],\n",
      "\n",
      "        [[-0.6809,  2.4660,  2.7177,  ...,  1.7763,  0.0000,  2.4410],\n",
      "         [ 2.3108,  0.4338,  3.7732,  ...,  0.7288,  0.0795,  1.2360],\n",
      "         [ 0.0000, -0.0000,  4.8504,  ...,  1.7096, -0.3094,  0.8857],\n",
      "         ...,\n",
      "         [-0.0287,  0.3615, -0.2654,  ...,  2.9792,  0.2643,  0.7682],\n",
      "         [ 0.0000,  1.1812,  1.0516,  ...,  2.4453,  0.5068,  0.7385],\n",
      "         [ 1.0053, -0.2880,  0.0000,  ...,  3.1581,  0.0000,  0.6324]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.7745,  2.2215,  2.6883,  ...,  1.2944, -1.4552,  2.3928],\n",
      "         [ 0.2319,  1.5794,  2.7071,  ...,  1.9203, -0.1154,  2.2109],\n",
      "         [ 2.9747,  0.3181,  4.8555,  ...,  2.0275,  0.4334,  1.6272],\n",
      "         ...,\n",
      "         [ 0.3065,  1.1836, -0.0344,  ...,  1.8093,  0.2723,  1.2589],\n",
      "         [ 1.9159,  0.0000,  0.7435,  ...,  0.0000,  0.5051,  0.7311],\n",
      "         [ 1.7028,  0.5722,  2.5858,  ...,  3.1339,  0.2050,  1.8301]],\n",
      "\n",
      "        [[-0.8345,  1.6254,  2.6918,  ...,  1.5117, -0.7764,  3.1157],\n",
      "         [ 0.5009,  1.3323,  2.7746,  ...,  2.1928, -0.7814,  1.2999],\n",
      "         [ 1.6987, -1.2815,  4.5275,  ...,  2.6501, -0.1364,  1.3979],\n",
      "         ...,\n",
      "         [ 0.1469,  1.4314,  1.2003,  ...,  3.4685,  0.5207,  0.0000],\n",
      "         [ 2.2993,  0.9968,  1.4113,  ...,  0.0000,  0.3847,  0.6078],\n",
      "         [ 0.9584,  0.2507,  3.4737,  ...,  1.2239,  0.3862,  0.4032]],\n",
      "\n",
      "        [[-0.6879,  0.0000,  1.1460,  ...,  1.1938, -0.2493,  2.7330],\n",
      "         [ 1.9454,  0.0000,  4.4812,  ...,  1.6622,  0.0645,  1.8373],\n",
      "         [ 0.2931, -0.0666,  3.1101,  ...,  0.0000, -0.1849,  2.0462],\n",
      "         ...,\n",
      "         [ 0.1064,  0.8226,  0.1223,  ...,  3.1771,  0.7683,  1.1468],\n",
      "         [ 1.6785,  0.0000,  0.2033,  ...,  2.5231,  0.2593,  1.2766],\n",
      "         [ 1.7941,  0.6936,  2.3856,  ...,  2.7755,  0.3253,  1.4023]]],\n",
      "       device='cuda:0', grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 91, 2048])\n",
      "tensor([[[-1.0753e+00,  1.3110e+00,  1.7787e+00,  ...,  2.0382e+00,\n",
      "          -9.3116e-01,  1.9049e+00],\n",
      "         [ 2.0127e+00,  5.5029e-01,  2.8063e+00,  ...,  1.7745e+00,\n",
      "          -1.0701e+00,  1.4400e+00],\n",
      "         [ 1.7820e+00, -1.2807e+00,  4.1559e+00,  ...,  1.9711e+00,\n",
      "          -1.0200e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [-4.5032e-01,  2.6980e-01, -6.6465e-01,  ...,  2.6146e+00,\n",
      "          -2.7080e-01,  1.3531e+00],\n",
      "         [ 1.5446e+00,  3.4891e-01, -1.5688e-01,  ...,  2.7440e+00,\n",
      "          -7.1919e-01,  1.3238e+00],\n",
      "         [ 1.3019e+00, -5.2165e-01,  1.5077e+00,  ...,  0.0000e+00,\n",
      "          -4.5314e-01,  1.2298e+00]],\n",
      "\n",
      "        [[-1.6473e-01,  1.7108e+00,  1.3617e+00,  ...,  1.6812e+00,\n",
      "          -5.6279e-01,  2.2535e+00],\n",
      "         [ 0.0000e+00, -5.7669e-01,  3.3083e+00,  ...,  2.3271e+00,\n",
      "          -1.1470e+00,  1.9570e+00],\n",
      "         [ 1.0193e-01, -1.6330e+00,  3.4368e+00,  ...,  2.3144e+00,\n",
      "          -1.2325e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [-4.2417e-01,  3.4573e-01, -1.0411e+00,  ...,  9.7457e-01,\n",
      "          -8.8464e-01,  1.4088e+00],\n",
      "         [ 5.1013e-01,  0.0000e+00,  1.8869e-01,  ...,  2.1686e+00,\n",
      "          -8.9424e-01,  2.0101e+00],\n",
      "         [ 7.1723e-01, -3.7227e-01,  0.0000e+00,  ...,  2.1262e+00,\n",
      "          -0.0000e+00,  1.1958e+00]],\n",
      "\n",
      "        [[-8.5585e-01,  0.0000e+00,  1.8300e+00,  ...,  2.3248e+00,\n",
      "          -5.9586e-02,  0.0000e+00],\n",
      "         [ 1.4811e+00, -6.2770e-02,  3.7770e+00,  ...,  1.8691e+00,\n",
      "          -2.0324e-01,  1.9783e+00],\n",
      "         [ 4.1453e-01, -1.6891e+00,  4.0426e+00,  ...,  1.9474e+00,\n",
      "          -3.4046e-01,  1.5529e+00],\n",
      "         ...,\n",
      "         [-1.9528e-01,  2.8270e-01, -5.4382e-01,  ...,  2.3731e+00,\n",
      "          -7.5481e-02,  1.3803e+00],\n",
      "         [ 1.8895e-01,  6.6632e-01,  4.7186e-01,  ...,  2.4264e+00,\n",
      "           1.0635e-01,  1.1954e+00],\n",
      "         [ 3.6600e-01, -6.8057e-01,  1.0437e+00,  ...,  2.6928e+00,\n",
      "          -0.0000e+00,  1.4118e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.7871e-01,  1.5216e+00,  9.4900e-01,  ...,  1.2516e+00,\n",
      "          -1.2242e+00,  2.6047e+00],\n",
      "         [ 6.1519e-01,  1.0307e+00,  3.1298e+00,  ...,  1.8395e+00,\n",
      "          -0.0000e+00,  2.1950e+00],\n",
      "         [ 0.0000e+00, -1.2623e+00,  3.9623e+00,  ...,  1.6033e+00,\n",
      "          -1.1057e-01,  2.1448e+00],\n",
      "         ...,\n",
      "         [ 8.4737e-02,  9.3144e-01, -0.0000e+00,  ...,  1.2680e+00,\n",
      "          -0.0000e+00,  1.8316e+00],\n",
      "         [ 1.4498e+00,  5.5663e-01,  3.3177e-01,  ...,  0.0000e+00,\n",
      "          -0.0000e+00,  1.3082e+00],\n",
      "         [ 1.4691e+00, -1.7590e-01,  2.6026e+00,  ...,  2.1901e+00,\n",
      "          -0.0000e+00,  2.3659e+00]],\n",
      "\n",
      "        [[-1.3359e+00,  1.7342e+00,  2.1216e+00,  ...,  1.5021e+00,\n",
      "          -0.0000e+00,  2.6992e+00],\n",
      "         [ 0.0000e+00,  5.1515e-01,  2.9202e+00,  ...,  2.3304e+00,\n",
      "          -1.0545e+00,  1.7278e+00],\n",
      "         [ 1.1684e+00, -1.6261e+00,  0.0000e+00,  ...,  2.3125e+00,\n",
      "          -2.4466e-01,  1.4653e+00],\n",
      "         ...,\n",
      "         [-9.6758e-02,  5.1334e-01, -2.6151e-01,  ...,  2.7431e+00,\n",
      "          -2.9101e-04,  9.4280e-01],\n",
      "         [ 8.4178e-01,  7.0217e-01,  9.5643e-01,  ...,  1.1681e+00,\n",
      "          -9.4816e-02,  1.3014e+00],\n",
      "         [ 8.1955e-01, -4.6541e-01,  2.7440e+00,  ...,  1.6902e+00,\n",
      "           9.4309e-02,  1.2420e+00]],\n",
      "\n",
      "        [[-3.6860e-01,  4.9054e-01,  0.0000e+00,  ...,  1.5861e+00,\n",
      "          -4.2309e-01,  2.4295e+00],\n",
      "         [ 1.6068e+00, -7.9346e-02,  2.9371e+00,  ...,  1.9784e+00,\n",
      "          -3.3438e-01,  2.2713e+00],\n",
      "         [ 9.3196e-01, -0.0000e+00,  3.0505e+00,  ...,  1.4804e+00,\n",
      "          -5.7826e-01,  1.9358e+00],\n",
      "         ...,\n",
      "         [-0.0000e+00,  0.0000e+00, -4.4999e-01,  ...,  2.4782e+00,\n",
      "           2.6163e-01,  1.7510e+00],\n",
      "         [ 1.0788e+00,  1.3329e-01, -1.4160e-01,  ...,  1.9961e+00,\n",
      "          -1.4237e-01,  1.7405e+00],\n",
      "         [ 1.1892e+00, -1.2467e-01,  2.4720e+00,  ...,  2.0493e+00,\n",
      "          -1.2251e-01,  1.7824e+00]]], device='cuda:0',\n",
      "       grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 91, 2048])\n",
      "tensor([[[-1.8849,  1.0897,  0.1156,  ...,  0.0000, -0.8478,  2.1345],\n",
      "         [ 0.0000,  0.5297,  1.6501,  ...,  1.6364, -0.8930,  1.6736],\n",
      "         [ 0.0000, -1.3809,  2.7686,  ...,  1.9975, -0.6725,  1.0952],\n",
      "         ...,\n",
      "         [-1.8366,  0.3716, -1.9019,  ...,  2.3930, -0.5636,  1.4480],\n",
      "         [-0.1106,  0.6267, -1.0521,  ...,  2.6973, -0.8102,  0.0000],\n",
      "         [-0.0648, -0.1506,  0.0000,  ...,  0.8004, -0.6311,  1.7502]],\n",
      "\n",
      "        [[-1.5940,  1.0000, -0.4739,  ...,  1.7803, -0.9751,  2.2453],\n",
      "         [-0.8880,  0.1111,  2.0202,  ...,  2.2506, -1.0464,  2.2646],\n",
      "         [-0.4210, -1.8535,  2.2867,  ...,  1.9447, -0.9231,  1.2190],\n",
      "         ...,\n",
      "         [-1.4850,  0.3095, -2.0535,  ...,  1.2379, -0.8375,  2.4130],\n",
      "         [-0.4092,  0.4169, -0.8028,  ...,  1.9629, -0.9597,  2.1545],\n",
      "         [-0.3627, -0.1907,  0.2951,  ...,  1.9063, -0.3909,  2.2148]],\n",
      "\n",
      "        [[-0.0000,  1.1053,  0.0000,  ...,  2.1891, -0.1061,  0.0000],\n",
      "         [ 0.6508,  0.1328,  1.3493,  ...,  2.5244, -0.1730,  1.7225],\n",
      "         [ 0.2650, -0.0000,  2.4487,  ...,  0.0000, -0.2407,  1.6914],\n",
      "         ...,\n",
      "         [-1.8739,  0.5688, -1.8352,  ...,  2.0149, -0.2783,  2.2888],\n",
      "         [-0.1864,  0.7540, -0.8368,  ...,  2.4070, -0.0687,  2.2503],\n",
      "         [ 0.1419, -0.4279,  0.6906,  ...,  2.4647, -0.2183,  1.8659]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.5926,  1.3158,  0.6973,  ...,  0.0000, -0.0000,  2.1992],\n",
      "         [-0.1160,  0.7666,  1.5610,  ...,  1.6702, -0.3000,  2.5592],\n",
      "         [ 0.0495, -1.0753,  2.8217,  ...,  1.7146, -0.0000,  2.5543],\n",
      "         ...,\n",
      "         [-0.8089,  0.0000, -1.9221,  ...,  1.5087, -0.4383,  2.1061],\n",
      "         [ 0.5068,  1.1054, -0.5673,  ...,  0.0000, -0.6465,  1.8348],\n",
      "         [ 0.5549, -0.6408,  1.6704,  ...,  2.0571, -0.4652,  2.4941]],\n",
      "\n",
      "        [[-2.6747,  0.0000,  0.7043,  ...,  1.8766, -0.1591,  0.0000],\n",
      "         [-0.4049,  0.5342,  0.0000,  ...,  2.5240, -0.9935,  2.0066],\n",
      "         [-0.1759, -1.1092,  0.8190,  ...,  2.1423, -0.7860,  1.6601],\n",
      "         ...,\n",
      "         [-1.2761,  0.3246, -1.5543,  ...,  2.3734, -0.4860,  1.7635],\n",
      "         [-0.0830,  0.9848, -0.4337,  ...,  0.0000, -0.5715,  1.8024],\n",
      "         [-0.0000, -0.2292,  0.0000,  ...,  1.6644, -0.3272,  1.8478]],\n",
      "\n",
      "        [[-1.5721,  0.4602, -0.4667,  ...,  1.7046, -0.3195,  2.2172],\n",
      "         [ 0.2653,  0.2578,  1.7781,  ...,  1.7568, -0.3429,  2.1025],\n",
      "         [-0.1699, -0.0000,  1.8352,  ...,  1.5038, -0.7082,  1.9179],\n",
      "         ...,\n",
      "         [-1.5124,  0.5898, -2.0360,  ...,  2.1160,  0.0160,  1.9479],\n",
      "         [ 0.4680,  0.7796, -1.1622,  ...,  2.0910, -0.2828,  2.2049],\n",
      "         [ 0.2926,  0.0000,  1.1084,  ...,  2.1282, -0.5011,  2.0083]]],\n",
      "       device='cuda:0', grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 90, 2048])\n",
      "tensor([[[  86.3852,   49.8759,    6.1185,  ...,   77.6506,  -21.4817,\n",
      "           -41.2875],\n",
      "         [ -13.4382,   34.8706,   15.1650,  ...,   50.2014,  -11.3914,\n",
      "            41.3254],\n",
      "         [ -33.9975, -115.8752,  -22.3115,  ...,   45.6282,  -53.5214,\n",
      "           -13.3266],\n",
      "         ...,\n",
      "         [ -68.7001,  -13.0567,   -0.0000,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         [ -67.7476,  -12.0546,   -3.9737,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         [ -66.8313,  -11.7860,   -3.4453,  ...,   79.5327,   67.9524,\n",
      "           -78.4697]],\n",
      "\n",
      "        [[  26.5089,   43.0538,   24.9530,  ...,  -23.1409,  -25.1675,\n",
      "            17.3203],\n",
      "         [  -7.2561,   23.8632, -107.4267,  ...,   39.4555,  -61.7758,\n",
      "            34.0713],\n",
      "         [ -66.7766,  -13.3099,   -1.8372,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         ...,\n",
      "         [ -68.7001,  -13.0567,   -3.5143,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         [ -67.7476,  -12.0546,   -3.9737,  ...,   79.5327,    0.0000,\n",
      "           -78.4697],\n",
      "         [ -66.8313,  -11.7860,   -3.4453,  ...,   79.5327,   67.9524,\n",
      "           -78.4697]],\n",
      "\n",
      "        [[ -28.4509,   34.1837,   42.0306,  ...,  -71.1576,   35.5508,\n",
      "           -48.2908],\n",
      "         [ -34.4809,   -0.0000,    0.0000,  ...,   24.3731,    2.0244,\n",
      "             7.0977],\n",
      "         [ -66.7766,  -13.3099,   -0.0000,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         ...,\n",
      "         [  -0.0000,  -13.0567,   -3.5143,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         [ -67.7476,  -12.0546,   -3.9737,  ...,    0.0000,   67.9524,\n",
      "           -78.4697],\n",
      "         [  -0.0000,  -11.7860,   -3.4453,  ...,   79.5327,   67.9524,\n",
      "           -78.4697]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  57.7647,  -21.1693,  -31.5478,  ...,   15.1750,  -51.9438,\n",
      "           -38.8285],\n",
      "         [  -3.5841,   50.0599,  101.8671,  ...,    0.0000,   -8.0914,\n",
      "             7.4169],\n",
      "         [  21.2588,  -33.8548,    2.6155,  ...,  -12.0731,    0.6595,\n",
      "            67.8677],\n",
      "         ...,\n",
      "         [ -68.7001,  -13.0567,   -3.5143,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         [ -67.7476,  -12.0546,   -3.9737,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         [ -66.8313,  -11.7860,   -3.4453,  ...,   79.5327,    0.0000,\n",
      "           -78.4697]],\n",
      "\n",
      "        [[ -28.4509,   34.1837,   42.0306,  ...,  -71.1576,   35.5508,\n",
      "           -48.2908],\n",
      "         [   6.7287,    0.0000,    0.0000,  ...,   -0.0000,  -42.2055,\n",
      "            28.5059],\n",
      "         [  23.9633,  -49.1509,  105.5970,  ...,  -17.8846,   90.6564,\n",
      "           -11.7819],\n",
      "         ...,\n",
      "         [ -68.7001,  -13.0567,   -3.5143,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         [ -67.7476,  -12.0546,   -0.0000,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         [ -66.8313,  -11.7860,   -3.4453,  ...,   79.5327,   67.9524,\n",
      "           -78.4697]],\n",
      "\n",
      "        [[  86.3852,   49.8759,    0.0000,  ...,    0.0000,  -21.4817,\n",
      "           -41.2875],\n",
      "         [ -13.4382,   34.8706,   15.1650,  ...,   50.2014,   -0.0000,\n",
      "            41.3254],\n",
      "         [ -66.7766,  -13.3099,   -1.8372,  ...,   79.5327,   67.9524,\n",
      "            -0.0000],\n",
      "         ...,\n",
      "         [ -68.7001,  -13.0567,   -3.5143,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         [ -67.7476,  -12.0546,   -3.9737,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         [ -66.8313,   -0.0000,   -3.4453,  ...,   79.5327,    0.0000,\n",
      "           -78.4697]]], device='cuda:0', grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 90, 2048])\n",
      "tensor([[[ 2.8613e+00,  0.0000e+00,  9.0017e-01,  ...,  3.8325e+00,\n",
      "          -5.5115e-01,  9.6353e-01],\n",
      "         [ 1.5221e+00,  2.3784e+00,  1.7952e+00,  ...,  2.8564e+00,\n",
      "           1.0480e-01,  2.7928e+00],\n",
      "         [ 1.0911e+00, -2.3529e+00,  1.6807e+00,  ...,  2.3926e+00,\n",
      "          -7.8722e-01,  2.0370e+00],\n",
      "         ...,\n",
      "         [-3.5690e-01,  3.8975e-01,  1.1099e+00,  ...,  3.8014e+00,\n",
      "           1.4784e+00, -1.6948e-01],\n",
      "         [ 1.6572e-01,  1.3116e+00,  9.4275e-02,  ...,  3.4900e+00,\n",
      "           1.0956e+00,  0.0000e+00],\n",
      "         [ 1.6655e+00,  1.6724e+00,  2.9708e-01,  ...,  0.0000e+00,\n",
      "           1.1032e+00, -3.3694e-02]],\n",
      "\n",
      "        [[ 1.6141e+00,  2.8301e+00,  1.7591e+00,  ...,  0.0000e+00,\n",
      "          -7.5546e-01,  2.4664e+00],\n",
      "         [ 1.8259e+00,  0.0000e+00, -1.3214e-01,  ...,  3.3374e+00,\n",
      "          -1.0247e+00,  2.2907e+00],\n",
      "         [ 9.2880e-01,  7.7911e-03,  2.5789e+00,  ...,  3.9873e+00,\n",
      "           1.7483e+00,  3.6143e-03],\n",
      "         ...,\n",
      "         [-0.0000e+00,  9.8295e-02,  7.4028e-01,  ...,  3.4988e+00,\n",
      "           1.4185e+00, -1.4822e-01],\n",
      "         [ 2.9465e-02,  1.1570e+00,  5.7116e-01,  ...,  4.2034e+00,\n",
      "           1.9661e-01, -1.6261e-01],\n",
      "         [ 6.1259e-01,  1.3384e+00,  6.6929e-01,  ...,  3.9735e+00,\n",
      "           1.7628e+00,  1.6434e-01]],\n",
      "\n",
      "        [[ 2.1724e-01,  2.9335e+00,  1.4852e+00,  ...,  3.0929e-01,\n",
      "          -6.6617e-03,  1.4336e+00],\n",
      "         [ 2.3136e-02,  0.0000e+00,  1.6037e+00,  ...,  3.3289e+00,\n",
      "          -4.0598e-01,  2.3595e+00],\n",
      "         [ 1.2292e+00, -1.7609e-02,  2.5649e+00,  ...,  3.1865e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 2.2998e-01,  1.4633e-01,  2.7509e-01,  ...,  3.2333e+00,\n",
      "           1.0209e+00,  2.4630e-01],\n",
      "         [-1.1423e-01,  1.6944e+00, -2.7102e-01,  ...,  1.9693e+00,\n",
      "           0.0000e+00,  2.8926e-01],\n",
      "         [ 1.5436e+00,  1.6767e+00,  3.9255e-01,  ...,  3.5244e+00,\n",
      "           0.0000e+00,  7.9548e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 2.5404e+00,  2.3028e+00,  3.6300e-01,  ...,  3.0543e+00,\n",
      "          -9.3369e-01,  1.1078e+00],\n",
      "         [ 2.7345e+00,  3.2390e+00,  4.2062e+00,  ...,  2.2409e+00,\n",
      "           1.2731e-02,  2.3642e+00],\n",
      "         [ 2.3151e+00, -7.0381e-01,  2.5106e+00,  ...,  1.6032e+00,\n",
      "           7.0381e-01,  3.4371e+00],\n",
      "         ...,\n",
      "         [-1.0145e+00,  4.4054e-01,  8.1678e-02,  ...,  4.1138e+00,\n",
      "           1.7061e+00,  0.0000e+00],\n",
      "         [-1.0573e-01,  9.5109e-01, -3.1583e-01,  ...,  4.4661e+00,\n",
      "           1.7997e+00,  6.2100e-01],\n",
      "         [ 4.4047e-01,  1.1421e+00,  5.5811e-01,  ...,  3.7935e+00,\n",
      "          -6.6122e-01,  1.0241e-01]],\n",
      "\n",
      "        [[ 2.7607e-01,  2.4023e+00,  2.3345e+00,  ...,  1.5232e+00,\n",
      "           7.8080e-01,  1.0070e+00],\n",
      "         [ 1.3540e+00,  1.4194e+00,  1.5124e+00,  ...,  1.8314e+00,\n",
      "          -3.4614e-01,  2.8767e+00],\n",
      "         [ 2.7594e+00, -4.6273e-01,  4.0480e+00,  ...,  1.4498e+00,\n",
      "           2.2977e+00,  1.7706e+00],\n",
      "         ...,\n",
      "         [-0.0000e+00,  1.4822e-01,  5.8063e-01,  ...,  4.1999e+00,\n",
      "           0.0000e+00, -1.4784e-01],\n",
      "         [ 1.2787e-02,  1.1433e+00, -3.8421e-01,  ...,  4.0882e+00,\n",
      "           1.7972e+00,  5.1025e-01],\n",
      "         [ 9.3085e-01,  1.2515e+00,  9.0054e-01,  ...,  4.2069e+00,\n",
      "           2.1767e+00,  6.0192e-01]],\n",
      "\n",
      "        [[ 2.5899e+00,  2.1588e+00,  8.2425e-01,  ...,  1.3970e+00,\n",
      "          -6.7261e-01,  1.3592e+00],\n",
      "         [ 0.0000e+00,  2.0845e+00,  1.8897e+00,  ...,  3.1693e+00,\n",
      "           1.4549e+00,  2.6317e+00],\n",
      "         [ 0.0000e+00, -4.7232e-02,  2.5058e+00,  ...,  3.9205e+00,\n",
      "           0.0000e+00,  1.4619e+00],\n",
      "         ...,\n",
      "         [-9.0574e-01, -1.0976e-01,  1.0339e+00,  ...,  3.6944e+00,\n",
      "           1.3591e+00, -1.6863e-01],\n",
      "         [-5.2002e-02,  1.2539e+00,  4.4753e-01,  ...,  3.1375e+00,\n",
      "           1.2966e+00,  2.9815e-02],\n",
      "         [ 1.1191e+00,  1.5053e+00,  8.3605e-01,  ...,  3.0896e+00,\n",
      "          -2.2368e-01, -1.9940e-01]]], device='cuda:0',\n",
      "       grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 90, 2048])\n",
      "tensor([[[ 1.6933, -0.2120,  0.9155,  ...,  4.2844, -0.3526,  0.0000],\n",
      "         [ 2.4134,  1.0028,  2.4728,  ...,  3.6600,  0.0317,  3.7096],\n",
      "         [ 1.7195, -3.2270,  2.1525,  ...,  3.0839, -0.5189,  3.0373],\n",
      "         ...,\n",
      "         [-0.8382, -1.2421,  0.9523,  ...,  4.3215,  0.3456,  1.4706],\n",
      "         [ 0.2649,  0.7281, -0.7739,  ...,  4.1421,  1.2605,  1.4377],\n",
      "         [ 2.5619,  1.3211, -0.2422,  ...,  1.9031,  1.1266,  1.2977]],\n",
      "\n",
      "        [[ 1.0110,  1.8614,  1.9539,  ...,  1.3427,  0.0608,  3.2858],\n",
      "         [ 2.0024, -0.9323,  1.5227,  ...,  3.6781, -0.2973,  3.1036],\n",
      "         [ 1.5786, -2.0911,  3.8261,  ...,  4.4601,  0.0000,  2.0470],\n",
      "         ...,\n",
      "         [-0.0000, -1.5861,  1.0945,  ...,  4.1997,  1.3158,  1.6937],\n",
      "         [ 0.0000,  0.4529,  0.5264,  ...,  4.7258,  0.6846,  1.5395],\n",
      "         [ 1.3086,  0.0000,  0.8087,  ...,  4.5748,  0.0000,  2.4335]],\n",
      "\n",
      "        [[ 0.0000,  1.8679,  1.0889,  ...,  0.0000,  0.3614,  2.7557],\n",
      "         [ 0.0000, -0.2582,  2.2096,  ...,  3.6924, -0.8973,  2.7114],\n",
      "         [ 1.7975, -0.0000,  3.5396,  ...,  3.6982,  0.2896,  1.4815],\n",
      "         ...,\n",
      "         [-0.1911, -1.4970,  0.6663,  ...,  3.6883,  0.0591,  1.6975],\n",
      "         [ 0.0133,  0.6074, -0.7973,  ...,  3.1702,  0.3070,  1.6681],\n",
      "         [ 2.3783,  1.0463,  0.0000,  ...,  3.8296,  0.4979,  1.4367]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 2.0929,  0.0000,  0.8892,  ...,  3.6904, -0.9320,  2.5855],\n",
      "         [ 3.7351,  1.7906,  4.4041,  ...,  3.1589, -0.1914,  3.2478],\n",
      "         [ 0.0000, -1.9200,  3.2108,  ...,  2.6852,  0.5997,  3.8056],\n",
      "         ...,\n",
      "         [-1.1783, -0.8917,  0.4626,  ...,  4.4205,  1.3887,  0.0000],\n",
      "         [ 0.5206,  0.0000, -0.6030,  ...,  4.9366,  1.3594,  1.9039],\n",
      "         [ 1.7292,  0.6330,  0.9249,  ...,  4.2215, -0.6906,  2.0159]],\n",
      "\n",
      "        [[ 0.6938,  1.0300,  2.4802,  ...,  0.0000,  0.6214,  2.4515],\n",
      "         [ 2.1134,  0.1836,  2.6020,  ...,  2.8893,  0.0782,  3.5759],\n",
      "         [ 3.4015, -2.0215,  4.3948,  ...,  3.1316,  1.8539,  3.1672],\n",
      "         ...,\n",
      "         [-0.3482, -1.4641,  0.6510,  ...,  4.6019,  0.5133,  1.3736],\n",
      "         [ 0.9396, -0.1703, -0.5755,  ...,  4.5286,  1.4882,  2.1269],\n",
      "         [ 1.9938,  0.3801,  0.7443,  ...,  4.4771,  0.0000,  2.0232]],\n",
      "\n",
      "        [[ 1.2761,  1.1324,  0.8278,  ...,  2.5530, -0.3033,  3.0851],\n",
      "         [ 0.8354,  1.0387,  0.0000,  ...,  3.8085,  0.0000,  3.6855],\n",
      "         [ 1.2898, -1.8372,  3.4140,  ...,  4.3946, -0.1932,  2.8477],\n",
      "         ...,\n",
      "         [-1.0696, -1.7033,  1.1682,  ...,  4.4681,  1.0959,  1.8960],\n",
      "         [-0.0382,  0.0000,  0.2102,  ...,  3.6966,  1.3427,  2.3419],\n",
      "         [ 2.1588,  1.0268,  0.6700,  ...,  0.0000,  0.1267,  0.0000]]],\n",
      "       device='cuda:0', grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 90, 2048])\n",
      "tensor([[[ 0.1993, -1.0299,  0.0222,  ...,  3.8705,  0.2654,  1.5519],\n",
      "         [ 1.5142, -0.5736,  1.8391,  ...,  3.4463,  0.2727,  3.5388],\n",
      "         [ 1.1798, -3.8243,  1.9745,  ...,  3.3244,  0.1601,  3.1640],\n",
      "         ...,\n",
      "         [-1.7663, -2.4489, -0.0000,  ...,  4.1977,  0.6038,  2.4921],\n",
      "         [-0.3543, -0.9656, -0.0000,  ...,  3.8930,  1.0730,  2.3836],\n",
      "         [ 1.9939,  0.0486, -0.6436,  ...,  3.0590,  0.7332,  2.6941]],\n",
      "\n",
      "        [[ 0.0769,  0.4944,  1.1326,  ...,  2.3871,  0.9412,  3.5296],\n",
      "         [ 1.2343, -1.6902,  1.9225,  ...,  3.5529,  0.2508,  0.0000],\n",
      "         [ 1.4159, -3.4670,  3.4521,  ...,  4.1229,  0.0000,  2.7890],\n",
      "         ...,\n",
      "         [-0.8548, -2.8895,  0.0000,  ...,  4.2938,  1.0248,  2.5841],\n",
      "         [-0.0498, -0.9389, -0.7846,  ...,  4.1452,  0.0000,  3.0493],\n",
      "         [ 1.5070, -0.5838,  0.0323,  ...,  4.3171,  0.0000,  2.7390]],\n",
      "\n",
      "        [[-0.3091,  0.0824,  0.4298,  ...,  1.7305,  0.5052,  2.8141],\n",
      "         [ 0.2308, -1.4483,  2.3907,  ...,  3.6241, -0.2996,  0.0000],\n",
      "         [ 1.7261, -2.0681,  3.0439,  ...,  3.8912,  0.1116,  2.3720],\n",
      "         ...,\n",
      "         [-1.2836, -2.8287, -0.0000,  ...,  3.9904,  0.5071,  2.6299],\n",
      "         [-0.4786, -0.7730, -1.2589,  ...,  3.5012,  0.1972,  2.9079],\n",
      "         [ 1.8377, -0.0287, -0.3589,  ...,  3.7851,  0.5071,  2.1856]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0000, -0.8393,  0.6245,  ...,  3.8627, -0.2831,  3.2175],\n",
      "         [ 2.7473, -0.3601,  3.2532,  ...,  3.2810,  0.2301,  3.7409],\n",
      "         [ 0.9725, -3.3927,  2.7893,  ...,  3.5706,  0.5782,  3.7967],\n",
      "         ...,\n",
      "         [-0.0000, -2.3072, -0.0217,  ...,  4.3078,  0.5379,  1.8655],\n",
      "         [ 0.2438, -0.7380, -1.2753,  ...,  4.6533,  0.9647,  2.5831],\n",
      "         [ 0.0000, -0.0000,  0.1035,  ...,  3.9678, -0.0000,  2.8994]],\n",
      "\n",
      "        [[ 0.0280, -0.3779,  1.8049,  ...,  1.9343,  0.5729,  3.0301],\n",
      "         [ 1.6442, -1.3063,  0.0000,  ...,  3.2502,  0.0883,  3.7018],\n",
      "         [ 0.0000, -3.6029,  3.2957,  ...,  3.2842,  0.4192,  3.5153],\n",
      "         ...,\n",
      "         [-1.1361, -0.0000, -0.0000,  ...,  4.2525,  0.0000,  2.5698],\n",
      "         [ 0.3282, -1.2499, -0.9298,  ...,  4.1606,  1.0728,  3.1136],\n",
      "         [ 1.8050, -0.0000,  0.0000,  ...,  4.2921,  0.3481,  0.0000]],\n",
      "\n",
      "        [[ 0.0336, -0.2106,  0.1864,  ...,  0.0000, -0.6576,  3.3431],\n",
      "         [ 0.9724, -0.7812,  1.2003,  ...,  3.7904,  0.3413,  3.9161],\n",
      "         [ 0.0000, -0.0000,  3.1072,  ...,  4.2203, -0.6209,  3.3639],\n",
      "         ...,\n",
      "         [-1.7114, -3.2220,  0.2146,  ...,  4.5006,  0.0000,  2.8257],\n",
      "         [-0.6697, -1.1513, -1.2325,  ...,  3.7859,  0.9730,  2.8673],\n",
      "         [ 1.3865, -0.4568,  0.0103,  ...,  1.8880,  0.2730,  1.8819]]],\n",
      "       device='cuda:0', grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 90, 2048])\n",
      "tensor([[[-1.1183, -0.0000, -0.5314,  ...,  3.6547,  0.1548,  2.9772],\n",
      "         [-0.0357, -1.1050,  1.1443,  ...,  0.0000,  0.0963,  3.4753],\n",
      "         [ 0.0000, -3.9170,  0.0000,  ...,  3.5058, -0.0000,  3.2907],\n",
      "         ...,\n",
      "         [-3.5149, -2.7228, -1.3750,  ...,  3.8511,  0.5433,  2.6290],\n",
      "         [-0.0000, -0.9013, -1.8928,  ...,  3.8068,  0.0000,  3.2483],\n",
      "         [ 0.0000, -0.3350, -1.8786,  ...,  3.4404,  0.5857,  3.4414]],\n",
      "\n",
      "        [[-1.0310, -0.2671, -0.0000,  ...,  3.0825,  0.7411,  3.9258],\n",
      "         [ 0.2527, -0.0000,  1.1286,  ...,  3.4893,  0.2668,  2.0451],\n",
      "         [ 0.3051, -3.7671,  2.0587,  ...,  3.8775,  0.3270,  3.4663],\n",
      "         ...,\n",
      "         [-2.4918, -3.2363, -1.7171,  ...,  4.0639,  0.7126,  3.3146],\n",
      "         [-1.4644, -1.4204, -0.0000,  ...,  3.9228,  0.5821,  3.4984],\n",
      "         [ 0.3717, -0.9487, -0.0000,  ...,  3.9058,  0.1730,  3.2607]],\n",
      "\n",
      "        [[-1.7959, -0.7589, -1.3257,  ...,  2.6102,  0.4949,  3.4510],\n",
      "         [-0.5087, -0.0000,  0.0000,  ...,  3.6264,  0.1346,  1.6789],\n",
      "         [ 0.8095, -3.2253,  1.7184,  ...,  3.8224,  0.2855,  3.0017],\n",
      "         ...,\n",
      "         [-2.5729, -3.2659, -1.4585,  ...,  3.7064,  0.6301,  3.2407],\n",
      "         [-1.7697, -1.2071, -2.5416,  ...,  3.4262,  0.6847,  3.4419],\n",
      "         [ 0.7046, -0.4150, -1.7722,  ...,  3.3830,  0.6244,  3.1543]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0000, -0.0000, -0.6337,  ...,  0.0000,  0.0891,  3.2507],\n",
      "         [ 1.1218, -1.0311,  1.7455,  ...,  3.3364,  0.4406,  3.7360],\n",
      "         [ 0.6953, -3.4413,  1.1717,  ...,  3.6538,  0.8732,  3.8097],\n",
      "         ...,\n",
      "         [-1.9544, -3.0545, -1.6143,  ...,  4.0603,  0.8349,  2.4685],\n",
      "         [-0.7082, -0.8282, -2.6620,  ...,  4.1544,  0.8533,  3.0022],\n",
      "         [-0.0565, -0.4208, -1.3185,  ...,  3.7226,  0.5783,  3.3619]],\n",
      "\n",
      "        [[-1.0221, -0.0000,  0.4399,  ...,  0.0000,  0.7402,  3.3512],\n",
      "         [ 0.5349, -1.7956,  0.1459,  ...,  3.5740,  0.3417,  3.9183],\n",
      "         [ 0.0139, -3.6578,  1.4517,  ...,  3.9962,  0.2567,  3.5436],\n",
      "         ...,\n",
      "         [-2.4969, -1.6560, -1.7610,  ...,  4.0521,  0.2415,  3.3959],\n",
      "         [-0.9912, -0.0000, -2.7606,  ...,  3.9284,  0.3143,  3.6172],\n",
      "         [ 0.5996, -0.6524, -1.2379,  ...,  4.0497,  0.7750,  1.8498]],\n",
      "\n",
      "        [[-1.5899, -0.4307, -0.7424,  ...,  0.0000, -0.3532,  3.4573],\n",
      "         [ 0.0000, -1.2192,  0.4947,  ...,  3.5814,  0.0000,  0.0000],\n",
      "         [-0.3460, -2.0087,  0.0000,  ...,  3.9618, -0.5787,  3.7108],\n",
      "         ...,\n",
      "         [-2.9913, -0.0000, -1.0049,  ...,  3.9003,  0.3034,  2.9542],\n",
      "         [-1.9120, -1.1724, -2.5019,  ...,  3.7758,  0.0000,  3.2683],\n",
      "         [-0.1386, -0.3500, -1.2657,  ...,  0.0000,  0.3314,  3.0207]]],\n",
      "       device='cuda:0', grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 91, 2048])\n",
      "tensor([[[-1.2303e+02,  7.2536e+01,  5.5620e+01,  ..., -2.7637e+01,\n",
      "           9.8585e-03,  9.5118e+01],\n",
      "         [-3.8542e+01, -1.2968e+00, -2.7728e+01,  ...,  3.7590e+01,\n",
      "          -1.2779e+01,  2.3897e+00],\n",
      "         [-3.3997e+01, -1.1588e+02, -2.2311e+01,  ...,  4.5628e+01,\n",
      "          -5.3521e+01, -1.3327e+01],\n",
      "         ...,\n",
      "         [-6.7748e+01, -1.2055e+01, -3.9737e+00,  ...,  7.9533e+01,\n",
      "           0.0000e+00, -7.8470e+01],\n",
      "         [-0.0000e+00, -1.1786e+01, -3.4453e+00,  ...,  7.9533e+01,\n",
      "           0.0000e+00, -7.8470e+01],\n",
      "         [-6.6794e+01, -1.2494e+01, -2.3993e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01]],\n",
      "\n",
      "        [[-1.2303e+02,  7.2536e+01,  5.5620e+01,  ..., -2.7637e+01,\n",
      "           9.8585e-03,  9.5118e+01],\n",
      "         [ 2.7444e+01,  4.2551e+01,  2.5877e+01,  ..., -2.3141e+01,\n",
      "          -2.5168e+01,  0.0000e+00],\n",
      "         [-7.1808e+00,  2.2810e+01, -0.0000e+00,  ...,  3.9456e+01,\n",
      "          -6.1776e+01,  3.4071e+01],\n",
      "         ...,\n",
      "         [-6.7748e+01, -1.2055e+01, -3.9737e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-0.0000e+00, -1.1786e+01, -0.0000e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -0.0000e+00],\n",
      "         [-6.6794e+01, -1.2494e+01, -0.0000e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -0.0000e+00]],\n",
      "\n",
      "        [[-1.2303e+02,  7.2536e+01,  5.5620e+01,  ..., -2.7637e+01,\n",
      "           9.8585e-03,  9.5118e+01],\n",
      "         [-1.5188e+02, -1.4156e+00, -4.9651e+01,  ..., -1.6306e+01,\n",
      "           1.9726e+01,  1.2007e+01],\n",
      "         [ 5.0120e+01,  3.0016e+01,  1.0835e+02,  ..., -2.9314e+00,\n",
      "           0.0000e+00, -3.2877e+01],\n",
      "         ...,\n",
      "         [-6.7748e+01, -1.2055e+01, -3.9737e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -0.0000e+00],\n",
      "         [-6.6831e+01, -1.1786e+01, -3.4453e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -0.0000e+00],\n",
      "         [-6.6794e+01, -1.2494e+01, -2.3993e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.2303e+02,  7.2536e+01,  0.0000e+00,  ..., -2.7637e+01,\n",
      "           9.8585e-03,  9.5118e+01],\n",
      "         [ 4.8139e+00, -2.6053e+01,  2.4412e+01,  ..., -1.9299e+00,\n",
      "           0.0000e+00,  5.7904e+01],\n",
      "         [-0.0000e+00,  3.3148e+00, -3.9157e+01,  ...,  0.0000e+00,\n",
      "          -3.4195e+01, -6.3004e+00],\n",
      "         ...,\n",
      "         [-1.5277e+02, -1.2132e+00, -5.1686e+01,  ..., -1.6306e+01,\n",
      "           1.9726e+01,  1.2007e+01],\n",
      "         [ 1.3379e+00, -0.0000e+00,  5.8012e+00,  ...,  4.6034e+01,\n",
      "          -5.8067e+01, -9.6222e+01],\n",
      "         [-2.8527e+01,  3.6579e+01,  7.9639e+00,  ..., -5.7187e+01,\n",
      "           0.0000e+00, -1.1274e+01]],\n",
      "\n",
      "        [[-1.2303e+02,  7.2536e+01,  0.0000e+00,  ..., -2.7637e+01,\n",
      "           9.8585e-03,  9.5118e+01],\n",
      "         [-0.0000e+00, -1.4156e+00, -4.9651e+01,  ..., -1.6306e+01,\n",
      "           1.9726e+01,  0.0000e+00],\n",
      "         [ 5.0120e+01,  3.0016e+01,  0.0000e+00,  ..., -2.9314e+00,\n",
      "           6.8697e+01, -3.2877e+01],\n",
      "         ...,\n",
      "         [-6.7748e+01, -1.2055e+01, -0.0000e+00,  ...,  7.9533e+01,\n",
      "           0.0000e+00, -7.8470e+01],\n",
      "         [-6.6831e+01, -1.1786e+01, -0.0000e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6794e+01, -1.2494e+01, -2.3993e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01]],\n",
      "\n",
      "        [[-1.2303e+02,  7.2536e+01,  5.5620e+01,  ..., -2.7637e+01,\n",
      "           9.8585e-03,  9.5118e+01],\n",
      "         [-1.5188e+02, -1.4156e+00, -4.9651e+01,  ..., -0.0000e+00,\n",
      "           1.9726e+01,  1.2007e+01],\n",
      "         [-1.5180e+02, -2.4685e+00, -4.9549e+01,  ..., -1.6306e+01,\n",
      "           1.9726e+01,  1.2007e+01],\n",
      "         ...,\n",
      "         [-6.7748e+01, -0.0000e+00, -0.0000e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6831e+01, -1.1786e+01, -3.4453e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6794e+01, -1.2494e+01, -2.3993e+00,  ...,  0.0000e+00,\n",
      "           6.7952e+01, -7.8470e+01]]], device='cuda:0',\n",
      "       grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 91, 2048])\n",
      "tensor([[[-2.2572,  3.7232,  2.1575,  ...,  0.7079, -0.8175,  2.5669],\n",
      "         [ 0.3373,  0.0000,  1.3238,  ...,  3.1681, -0.4351,  0.7091],\n",
      "         [ 0.5833, -1.5369,  2.2146,  ...,  2.3517, -1.3629,  0.9466],\n",
      "         ...,\n",
      "         [-0.9634,  1.2145, -0.7586,  ...,  3.7537,  0.0335, -0.4996],\n",
      "         [ 1.2831,  0.7369, -0.0972,  ...,  3.7478, -0.2994, -0.6716],\n",
      "         [ 0.0000, -0.0000,  1.0496,  ...,  3.6073,  1.2028, -0.5178]],\n",
      "\n",
      "        [[-2.2844,  3.6387,  1.7171,  ...,  0.9854, -0.0000,  3.3376],\n",
      "         [ 1.4928,  2.8170,  2.9021,  ...,  1.5192,  0.5780,  1.8295],\n",
      "         [ 1.9437,  1.4929,  0.6206,  ...,  2.7470, -0.6249,  1.8155],\n",
      "         ...,\n",
      "         [-1.3674,  1.0193,  0.0695,  ...,  3.5009,  0.9869, -0.2839],\n",
      "         [ 1.1935,  1.8484,  0.6680,  ...,  4.0615,  0.7602,  1.2465],\n",
      "         [ 0.0501,  1.3200,  0.9801,  ...,  0.0000,  1.3744,  2.0869]],\n",
      "\n",
      "        [[-2.3712,  3.2342,  1.9387,  ...,  1.1106,  0.1278,  2.8066],\n",
      "         [-0.0000,  1.7023,  0.7296,  ...,  1.7020,  0.1527,  1.5296],\n",
      "         [ 1.9446,  0.7592,  4.1464,  ...,  1.5180,  0.1159,  1.2768],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000, -0.0603,  ...,  0.0000,  1.1814,  1.3411],\n",
      "         [-0.3560,  1.9396, -0.2145,  ...,  3.5089,  0.9316,  1.2384],\n",
      "         [ 0.1174,  0.9481,  1.0209,  ...,  3.7875,  0.8776, -0.0945]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.2631,  3.2970,  1.0850,  ...,  0.0000, -0.1078,  2.7689],\n",
      "         [ 2.0340,  1.1440,  2.4075,  ...,  1.3865, -0.0769,  2.5259],\n",
      "         [ 1.8511,  0.3229,  1.2508,  ...,  0.0000, -0.9370,  1.6430],\n",
      "         ...,\n",
      "         [-2.9787,  1.2367, -1.6408,  ...,  1.5078,  0.6643,  1.5389],\n",
      "         [ 1.4363,  0.0000,  1.1770,  ...,  3.0427, -1.3171, -0.0000],\n",
      "         [ 1.1280,  2.9448,  1.8825,  ...,  0.0742, -0.2523,  0.7783]],\n",
      "\n",
      "        [[-2.6054,  3.4331,  0.9505,  ...,  0.7536, -0.1936,  3.2876],\n",
      "         [ 1.4928,  1.7872,  1.0256,  ...,  1.8310,  0.5674,  1.6452],\n",
      "         [ 2.0528,  0.0000,  2.1857,  ...,  1.6765,  0.9295,  1.4114],\n",
      "         ...,\n",
      "         [-0.8387,  1.4255,  0.3139,  ...,  3.2583, -0.5443, -0.4261],\n",
      "         [-0.1332,  1.7021,  0.5889,  ...,  3.6596,  0.6493, -0.0526],\n",
      "         [ 0.1383,  1.1538,  0.7553,  ...,  3.4689,  1.1045, -0.5965]],\n",
      "\n",
      "        [[-2.1666,  3.7555,  1.8400,  ...,  0.7235, -0.0658,  2.9579],\n",
      "         [-1.5268,  1.7045,  0.4288,  ...,  1.4946,  0.9091,  2.2905],\n",
      "         [-2.4214,  0.8510,  1.3827,  ...,  1.7474,  0.3631,  1.7077],\n",
      "         ...,\n",
      "         [-1.1932,  1.4177, -0.3921,  ...,  3.5051,  0.0000, -0.0000],\n",
      "         [-0.5377,  1.3827,  0.8097,  ...,  3.4359,  1.3339,  0.6122],\n",
      "         [ 0.3172,  0.9531,  1.1552,  ...,  0.0000,  0.8413,  0.2070]]],\n",
      "       device='cuda:0', grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 91, 2048])\n",
      "tensor([[[-1.5220e+00,  2.5887e+00,  2.6058e+00,  ...,  1.7047e+00,\n",
      "          -1.5531e+00,  2.0238e+00],\n",
      "         [ 0.0000e+00, -2.1351e-01,  3.5515e+00,  ...,  3.1535e+00,\n",
      "          -7.4264e-01,  5.7995e-01],\n",
      "         [ 0.0000e+00, -2.0553e+00,  4.0702e+00,  ...,  2.2586e+00,\n",
      "          -1.4508e+00,  1.0464e+00],\n",
      "         ...,\n",
      "         [-4.5763e-01,  1.1983e+00, -7.5011e-01,  ...,  3.4566e+00,\n",
      "          -6.0024e-01,  2.1372e-01],\n",
      "         [ 1.7567e+00,  1.0212e+00,  1.3218e-01,  ...,  3.7551e+00,\n",
      "          -8.1688e-01, -5.7787e-02],\n",
      "         [ 9.1077e-01, -0.0000e+00,  1.7328e+00,  ...,  3.4748e+00,\n",
      "          -3.1039e-02,  6.3613e-01]],\n",
      "\n",
      "        [[-9.3568e-01,  2.5760e+00,  1.5771e+00,  ...,  1.9423e+00,\n",
      "          -2.7259e-01,  2.6687e+00],\n",
      "         [ 1.5112e+00,  1.9543e+00,  3.6869e+00,  ...,  2.7726e+00,\n",
      "           1.1766e-01,  2.1232e+00],\n",
      "         [ 1.9970e+00, -1.3565e-01,  2.0699e+00,  ...,  3.4150e+00,\n",
      "          -3.2563e-01,  1.5843e+00],\n",
      "         ...,\n",
      "         [-5.8537e-01,  3.6168e-01, -4.2802e-01,  ...,  3.3259e+00,\n",
      "           7.5672e-02,  1.0434e+00],\n",
      "         [ 2.4141e+00,  1.6731e+00,  1.1450e+00,  ...,  0.0000e+00,\n",
      "           1.6754e-01,  0.0000e+00],\n",
      "         [ 1.3242e+00,  3.0799e-01,  2.1070e+00,  ...,  1.2850e+00,\n",
      "           0.0000e+00,  1.8931e+00]],\n",
      "\n",
      "        [[-1.3274e+00,  2.3863e+00,  1.9004e+00,  ...,  1.8181e+00,\n",
      "           3.3878e-02,  1.9758e+00],\n",
      "         [ 1.0651e+00,  1.2400e+00,  2.3272e+00,  ...,  0.0000e+00,\n",
      "          -4.0415e-03,  1.4979e+00],\n",
      "         [ 2.1608e+00, -6.5656e-01,  4.5178e+00,  ...,  2.0151e+00,\n",
      "          -5.1983e-02,  1.3860e+00],\n",
      "         ...,\n",
      "         [-1.2119e-01,  3.5741e-01, -3.8199e-01,  ...,  1.3712e+00,\n",
      "           7.2108e-01,  1.6777e+00],\n",
      "         [ 7.6467e-01,  1.4044e+00, -4.7155e-02,  ...,  3.0632e+00,\n",
      "           4.8202e-01,  1.7344e+00],\n",
      "         [ 1.7373e+00,  3.2473e-01,  1.9311e+00,  ...,  3.6699e+00,\n",
      "          -2.7270e-02,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.1978e+00,  3.0991e+00,  1.7196e+00,  ...,  9.7159e-01,\n",
      "          -0.0000e+00,  2.2331e+00],\n",
      "         [ 2.4957e+00,  7.2672e-01,  3.5535e+00,  ...,  2.0686e+00,\n",
      "          -1.1929e+00,  2.6897e+00],\n",
      "         [ 2.2864e+00, -3.0749e-01,  3.6927e+00,  ...,  1.4004e+00,\n",
      "          -1.2478e+00,  1.9576e+00],\n",
      "         ...,\n",
      "         [-2.1239e+00,  9.7434e-01, -6.3471e-01,  ...,  1.9278e+00,\n",
      "          -1.0789e-01,  1.6974e+00],\n",
      "         [ 0.0000e+00,  7.1227e-01,  1.3273e+00,  ...,  3.0101e+00,\n",
      "          -1.3998e+00,  5.7348e-01],\n",
      "         [ 2.2007e+00,  1.6678e+00,  3.0968e+00,  ...,  1.0413e+00,\n",
      "          -1.0524e+00,  1.1931e+00]],\n",
      "\n",
      "        [[-1.4801e+00,  2.3200e+00,  1.1325e+00,  ...,  1.4517e+00,\n",
      "          -5.6321e-01,  2.3841e+00],\n",
      "         [ 2.3846e+00,  1.4431e+00,  2.7790e+00,  ...,  2.4133e+00,\n",
      "          -8.7980e-01,  1.6207e+00],\n",
      "         [ 2.0088e+00, -0.0000e+00,  0.0000e+00,  ...,  1.9788e+00,\n",
      "          -2.1464e-01,  1.4857e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  1.3242e+00,  4.4751e-01,  ...,  2.9630e+00,\n",
      "          -1.1727e+00,  5.1430e-01],\n",
      "         [ 9.1777e-01,  1.8785e+00,  1.1679e+00,  ...,  3.2142e+00,\n",
      "          -2.8915e-01,  7.9240e-01],\n",
      "         [ 1.7700e+00,  1.0367e+00,  2.1716e+00,  ...,  3.2842e+00,\n",
      "          -1.3323e-01,  4.9296e-01]],\n",
      "\n",
      "        [[-7.4260e-01,  0.0000e+00,  2.1449e+00,  ...,  1.6575e+00,\n",
      "          -2.8061e-01,  2.6056e+00],\n",
      "         [ 1.6144e-01,  0.0000e+00,  2.7049e+00,  ...,  2.1897e+00,\n",
      "           0.0000e+00,  2.4158e+00],\n",
      "         [-1.1212e+00, -7.4894e-01,  3.4113e+00,  ...,  2.1665e+00,\n",
      "          -3.5604e-01,  2.0274e+00],\n",
      "         ...,\n",
      "         [-1.0953e+00,  7.0930e-01, -9.0261e-02,  ...,  3.2054e+00,\n",
      "          -6.2745e-01,  7.7254e-01],\n",
      "         [ 6.0134e-01,  0.0000e+00,  0.0000e+00,  ...,  3.2193e+00,\n",
      "           5.9287e-01,  1.3443e+00],\n",
      "         [ 9.2233e-01,  2.8157e-01,  0.0000e+00,  ...,  1.1364e+00,\n",
      "           1.5786e-01,  1.1168e+00]]], device='cuda:0',\n",
      "       grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 91, 2048])\n",
      "tensor([[[-0.9829,  1.5448,  0.0000,  ...,  2.2033, -1.1007,  1.6344],\n",
      "         [ 0.4511, -0.8628,  0.0000,  ...,  2.9327, -0.7607,  1.3572],\n",
      "         [ 0.4553, -2.0883,  3.0661,  ...,  1.9311, -1.1430,  1.7236],\n",
      "         ...,\n",
      "         [-0.2259,  0.0000, -1.0555,  ...,  2.9690, -0.5180,  1.6373],\n",
      "         [ 0.8897,  0.8735, -0.1540,  ...,  3.3540, -1.1799,  0.0000],\n",
      "         [ 0.6862, -0.9469,  2.0097,  ...,  2.9579, -0.8247,  1.1597]],\n",
      "\n",
      "        [[-0.0000,  1.7871,  1.3314,  ...,  2.8370, -0.8608,  2.6353],\n",
      "         [ 1.0478,  0.2518,  0.0000,  ...,  0.0000, -0.0798,  2.4840],\n",
      "         [ 0.9825, -1.1978,  2.1153,  ...,  3.0238, -0.4202,  1.8432],\n",
      "         ...,\n",
      "         [-1.1136,  0.0000, -1.2673,  ...,  3.1619, -0.3546,  2.0842],\n",
      "         [ 1.5919,  1.3502,  0.1668,  ...,  1.3251, -0.0276,  0.8107],\n",
      "         [ 0.8824, -0.4335,  1.6277,  ...,  2.1328, -0.0000,  2.1607]],\n",
      "\n",
      "        [[-0.6466,  0.7755,  1.5303,  ...,  0.0000, -0.3830,  2.2739],\n",
      "         [ 0.0000,  0.3424,  2.6432,  ...,  1.7421, -0.6144,  1.8924],\n",
      "         [ 1.2726, -1.8705,  3.8456,  ...,  1.8552, -0.5417,  1.6840],\n",
      "         ...,\n",
      "         [-0.9983, -0.1354, -0.0000,  ...,  2.0179, -0.1539,  1.8339],\n",
      "         [ 0.5366,  0.5556, -0.1388,  ...,  2.6212, -0.0520,  2.4434],\n",
      "         [ 1.1807, -0.5945,  1.7533,  ...,  2.9104, -0.1307,  1.2507]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0000,  1.6973,  1.0301,  ...,  0.0000, -0.8659,  1.8744],\n",
      "         [ 1.2227,  0.4105,  3.6167,  ...,  2.1993, -1.1938,  2.4450],\n",
      "         [ 1.6417, -1.1425,  0.0000,  ...,  1.8379, -1.1575,  1.9541],\n",
      "         ...,\n",
      "         [-1.5397,  0.2859, -0.4959,  ...,  1.9837, -0.6050,  1.8461],\n",
      "         [ 0.4255,  0.7627,  0.4622,  ...,  2.7231, -1.2007,  1.3702],\n",
      "         [ 1.5492,  0.2573,  2.6062,  ...,  1.5059, -0.8751,  1.5280]],\n",
      "\n",
      "        [[-1.2948,  0.7541,  0.7410,  ...,  1.4916, -0.8424,  2.0515],\n",
      "         [ 1.5307,  0.5286,  2.8685,  ...,  2.6047, -1.0889,  1.6047],\n",
      "         [ 1.6730, -1.2405,  1.9035,  ...,  2.1016, -1.0693,  1.5451],\n",
      "         ...,\n",
      "         [-0.0170,  0.0000, -0.1688,  ...,  2.1091, -1.2719,  0.9855],\n",
      "         [ 0.5564,  0.6932,  0.1411,  ...,  2.5593, -0.8294,  0.0000],\n",
      "         [ 0.0000, -0.4446,  1.5099,  ...,  2.5397, -0.6106,  1.0508]],\n",
      "\n",
      "        [[-1.2710,  0.0000,  1.1891,  ...,  1.9465,  0.0510,  0.0000],\n",
      "         [ 0.2854, -0.7838,  2.2462,  ...,  2.2817,  0.0846,  2.3998],\n",
      "         [-0.4927, -1.6295,  3.0253,  ...,  1.9108, -0.1666,  2.3542],\n",
      "         ...,\n",
      "         [-1.6221,  0.4304, -0.7967,  ...,  0.0000, -0.5945,  1.7443],\n",
      "         [ 0.7033,  0.3408, -0.2256,  ...,  2.5623, -0.2503,  1.8180],\n",
      "         [ 0.5869,  0.1160,  1.2416,  ...,  1.9433, -0.0000,  1.6941]]],\n",
      "       device='cuda:0', grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 91, 2048])\n",
      "tensor([[[-2.0313,  1.7823, -0.5303,  ...,  2.6964, -0.7482,  0.0000],\n",
      "         [-0.0000, -0.1138,  0.0000,  ...,  2.4868, -0.0000,  1.8263],\n",
      "         [-0.0619, -1.5988,  1.6533,  ...,  0.0000, -1.1558,  0.0000],\n",
      "         ...,\n",
      "         [-1.3557,  0.9017, -1.7682,  ...,  2.3358, -0.9136,  1.9018],\n",
      "         [-0.3031,  1.5033, -0.0000,  ...,  2.3900, -1.3244,  1.5906],\n",
      "         [-0.2816, -0.3803,  0.5546,  ...,  2.5892, -1.2887,  1.5602]],\n",
      "\n",
      "        [[-1.3315,  0.0000,  0.0830,  ...,  2.3838, -0.7786,  2.2636],\n",
      "         [-0.2618,  0.5768,  0.0000,  ...,  1.1521, -0.3637,  2.6209],\n",
      "         [ 0.1305, -1.3599,  1.5630,  ...,  0.0000, -0.5209,  2.0653],\n",
      "         ...,\n",
      "         [-2.3942,  0.7605, -2.4952,  ...,  2.7105, -0.4335,  2.2858],\n",
      "         [ 0.3476,  1.5408, -1.2494,  ...,  2.0463, -0.4358,  1.5773],\n",
      "         [-0.3205, -0.2769,  0.0000,  ...,  2.1000, -0.0000,  2.1644]],\n",
      "\n",
      "        [[-0.0000,  0.0000,  0.3726,  ...,  1.1019, -0.5891,  2.7661],\n",
      "         [-0.9484, -0.0373,  1.9337,  ...,  2.0847, -0.3723,  1.7340],\n",
      "         [-0.1563, -0.0000,  2.4457,  ...,  1.9383, -0.2448,  1.5524],\n",
      "         ...,\n",
      "         [-2.0820, -0.0452, -0.0000,  ...,  2.1648, -0.6772,  2.3161],\n",
      "         [-0.5163,  0.8019, -1.0413,  ...,  2.1983, -0.5337,  2.8077],\n",
      "         [-0.3413, -0.5610,  1.1710,  ...,  2.1350, -0.3336,  1.7046]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.5667,  1.4566,  0.2688,  ...,  1.3441, -0.8135,  2.1580],\n",
      "         [ 0.1540,  0.6132,  0.0000,  ...,  1.8708, -1.0156,  2.6385],\n",
      "         [ 0.1532, -1.2221,  0.6821,  ...,  0.0000, -0.8114,  1.9551],\n",
      "         ...,\n",
      "         [-0.0000,  0.5260, -1.5260,  ...,  2.0321, -0.6536,  2.2417],\n",
      "         [-0.1635,  0.7399, -0.7247,  ...,  2.5810, -1.2272,  1.8989],\n",
      "         [ 0.2339, -0.1234,  1.2854,  ...,  1.5743, -0.8441,  0.0000]],\n",
      "\n",
      "        [[-1.8613,  1.3381, -0.0605,  ...,  1.8213, -0.8619,  2.0842],\n",
      "         [-0.0560,  0.5690,  1.7107,  ...,  2.4132, -0.8093,  2.1557],\n",
      "         [ 0.0234, -1.2100,  1.8333,  ...,  1.9562, -0.9564,  1.7446],\n",
      "         ...,\n",
      "         [-1.5348,  0.7228, -1.1991,  ...,  1.7510, -0.9220,  1.4965],\n",
      "         [-0.5403,  0.9285, -0.8896,  ...,  2.0216, -0.7531,  0.9212],\n",
      "         [-0.6828,  0.1745,  0.9740,  ...,  0.0000, -0.7739,  1.4529]],\n",
      "\n",
      "        [[-2.5592,  0.0000, -0.0936,  ...,  1.6898, -0.2874,  1.0043],\n",
      "         [-0.6685, -0.2161,  1.6374,  ...,  1.9260, -0.3607,  2.6227],\n",
      "         [-0.0000, -1.3919,  2.0517,  ...,  1.8354, -0.3564,  2.1190],\n",
      "         ...,\n",
      "         [-0.0000,  0.5248, -0.0000,  ...,  1.2854, -0.3915,  1.8522],\n",
      "         [-0.9036,  0.9576, -1.4694,  ...,  2.0894, -0.0432,  2.4545],\n",
      "         [-0.8018, -0.4681,  0.6995,  ...,  1.8723,  0.0423,  0.0000]]],\n",
      "       device='cuda:0', grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 90, 2048])\n",
      "tensor([[[ 86.3851,  49.8759,   6.1185,  ...,  77.6506, -21.4817, -41.2875],\n",
      "         [-13.4382,  34.8706,  15.1650,  ...,  50.2014, -11.3914,  41.3254],\n",
      "         [ 27.7895,  95.3227, -12.3497,  ...,  55.1011,  52.1685,  16.2631],\n",
      "         ...,\n",
      "         [-68.7001, -13.0567,  -3.5143,  ...,  79.5327,   0.0000,  -0.0000],\n",
      "         [ -0.0000, -12.0546,  -3.9737,  ...,  79.5327,  67.9524, -78.4697],\n",
      "         [-66.8313, -11.7860,  -3.4453,  ...,  79.5327,   0.0000, -78.4697]],\n",
      "\n",
      "        [[ 35.0285,  38.4456,   8.3708,  ..., -46.3975, -31.2534,  75.6588],\n",
      "         [-16.8374, -51.5558, -52.0346,  ..., -59.3605,  24.9618,  10.1207],\n",
      "         [-37.1251,  -0.0000, -48.1470,  ...,  83.3735, -80.1455,   0.0000],\n",
      "         ...,\n",
      "         [-68.7001, -13.0567,  -3.5143,  ...,  79.5327,  67.9524, -78.4697],\n",
      "         [-67.7476, -12.0546,  -3.9737,  ...,  79.5327,  67.9524, -78.4697],\n",
      "         [ -0.0000, -11.7860,  -0.0000,  ...,  79.5327,  67.9524, -78.4697]],\n",
      "\n",
      "        [[ -4.5191,  50.5624, 100.9430,  ...,   5.9596,  -8.0914,   7.4169],\n",
      "         [ 21.1834, -32.8019,   2.5135,  ..., -12.0731,   0.6595,  67.8677],\n",
      "         [  0.0000, -25.4420, -53.7334,  ...,  51.1212, -22.2395, -41.2825],\n",
      "         ...,\n",
      "         [-68.7001,  -0.0000,  -0.0000,  ...,  79.5327,  67.9524, -78.4697],\n",
      "         [-67.7476, -12.0546,  -3.9737,  ...,  79.5327,  67.9524, -78.4697],\n",
      "         [-66.8313, -11.7860,  -3.4453,  ...,  79.5327,  67.9524, -78.4697]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -0.0000,  -0.0000, -35.9108,  ..., -90.3908,  61.2125,  -9.6167],\n",
      "         [ -3.5841,  50.0599, 101.8671,  ...,   5.9596,  -8.0914,   7.4169],\n",
      "         [ 37.1697, -26.5859,  46.9943,  ...,   0.1346,   0.0000, -37.7670],\n",
      "         ...,\n",
      "         [-68.7001, -13.0567,  -3.5143,  ...,  79.5327,  67.9524, -78.4697],\n",
      "         [ -0.0000, -12.0546,  -3.9737,  ...,  79.5327,  67.9524, -78.4697],\n",
      "         [-66.8313, -11.7860,  -3.4453,  ...,  79.5327,  67.9524, -78.4697]],\n",
      "\n",
      "        [[-64.7824,   5.7054,  13.4799,  ...,  -0.0000,  15.9771, 120.2854],\n",
      "         [-30.0246,  18.0659, -24.2466,  ...,   8.6317, -38.3618, -35.5220],\n",
      "         [-19.3007,  19.7216, -30.7949,  ...,  22.1281,  95.2851,  91.5541],\n",
      "         ...,\n",
      "         [-68.7001, -13.0567,  -3.5143,  ...,  79.5327,  67.9524, -78.4697],\n",
      "         [-67.7476, -12.0546,  -3.9737,  ...,  79.5327,  67.9524, -78.4697],\n",
      "         [-66.8313, -11.7860,  -3.4453,  ...,  79.5327,  67.9524, -78.4697]],\n",
      "\n",
      "        [[ 17.9719,  -3.3860,  64.3502,  ...,  -0.0000,   0.0000, -39.6767],\n",
      "         [-47.9444,  -2.7819,  56.1960,  ...,  -2.3555, -45.8903,  11.5187],\n",
      "         [-88.0759,  77.0733, -87.3161,  ...,  52.0768,   0.0000,  29.5546],\n",
      "         ...,\n",
      "         [-68.7001, -13.0567,  -3.5143,  ...,  79.5327,  67.9524, -78.4697],\n",
      "         [ -0.0000, -12.0546,  -3.9737,  ...,  79.5327,   0.0000, -78.4697],\n",
      "         [-66.8313, -11.7860,  -3.4453,  ...,  79.5327,  67.9524, -78.4697]]],\n",
      "       device='cuda:0', grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 90, 2048])\n",
      "tensor([[[ 2.5276,  2.6918,  1.6392,  ...,  0.0000, -1.0611,  0.6954],\n",
      "         [ 0.9211,  1.5544,  1.7158,  ...,  3.1349,  0.1808,  3.1380],\n",
      "         [ 3.0123,  0.0000,  2.1465,  ...,  2.5215,  1.1949,  2.6391],\n",
      "         ...,\n",
      "         [-0.0000,  0.2657,  0.8539,  ...,  3.7383,  0.2388,  0.9745],\n",
      "         [ 1.7423,  0.9122,  0.3001,  ...,  3.1209,  0.8791, -0.4467],\n",
      "         [ 0.7570,  1.5357,  0.4545,  ...,  0.0000, -0.4624, -0.6953]],\n",
      "\n",
      "        [[ 1.5814,  2.9442,  0.3171,  ...,  1.6659,  0.0703,  3.5461],\n",
      "         [ 0.0000, -0.2958,  0.3330,  ...,  1.1154,  0.7541,  2.7062],\n",
      "         [ 1.3119,  0.5082,  0.6806,  ...,  0.0000, -0.0000,  2.4584],\n",
      "         ...,\n",
      "         [-1.3593, -0.8268,  0.0000,  ...,  4.1958,  1.6870, -0.2844],\n",
      "         [-0.5946,  0.0000,  0.4335,  ...,  4.0360,  0.7532, -0.0000],\n",
      "         [ 2.0254,  0.7971,  0.0000,  ...,  4.3009,  1.3168, -0.5193]],\n",
      "\n",
      "        [[ 1.8070,  2.1047,  3.4161,  ...,  1.8976,  0.9275,  2.1382],\n",
      "         [ 1.4869,  0.0000,  2.8364,  ...,  1.7740,  0.0138,  3.0291],\n",
      "         [ 2.1176, -0.1406,  0.9862,  ...,  3.1134, -0.9246,  0.8031],\n",
      "         ...,\n",
      "         [-0.1951,  0.2070,  1.1471,  ...,  4.1114,  0.0000,  0.3720],\n",
      "         [ 0.3485,  0.0630,  0.3409,  ...,  4.4377,  1.7597,  0.2980],\n",
      "         [ 0.9907,  1.0166,  1.0058,  ...,  0.0000,  1.9781, -0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.5138,  0.0000,  0.5724,  ...,  0.6186,  0.6129,  0.0000],\n",
      "         [ 1.8183,  2.5166,  3.6305,  ...,  2.4165, -0.3960,  1.9915],\n",
      "         [ 3.3418,  0.0247,  3.3006,  ...,  2.6038,  0.0000,  1.0818],\n",
      "         ...,\n",
      "         [-1.6445, -0.9654,  1.0373,  ...,  3.9811,  2.0907, -0.0170],\n",
      "         [ 1.2160,  0.6929,  0.2191,  ...,  4.2613,  1.7251, -0.4708],\n",
      "         [ 0.0000,  1.0034,  0.9333,  ...,  4.0497,  1.1017,  0.0567]],\n",
      "\n",
      "        [[-0.6392,  1.7026,  1.5969,  ...,  1.6798,  1.2900,  4.6379],\n",
      "         [ 1.3642,  1.2614,  2.2093,  ...,  0.0000, -0.6427,  1.3655],\n",
      "         [ 1.7467,  0.2985,  1.2166,  ...,  2.5196,  1.7453,  3.8989],\n",
      "         ...,\n",
      "         [-0.8032,  0.1871,  0.5538,  ...,  3.8766,  1.6914, -0.3020],\n",
      "         [ 0.3995,  1.9095,  0.3016,  ...,  3.5702,  1.9654,  0.0000],\n",
      "         [ 1.1204,  1.2859,  0.9212,  ...,  3.4095,  1.6590, -0.0654]],\n",
      "\n",
      "        [[ 1.2535,  0.7714,  2.6290,  ...,  0.0000,  0.3196,  1.4820],\n",
      "         [ 1.5779,  1.2286,  2.8014,  ...,  2.1587, -0.4247,  2.8482],\n",
      "         [-0.0400,  2.4452,  0.4329,  ...,  4.1204,  0.2565,  2.2637],\n",
      "         ...,\n",
      "         [-0.5929, -0.3930,  0.8333,  ...,  4.6430,  1.2665,  0.4263],\n",
      "         [ 1.5219,  0.0000, -0.6929,  ...,  4.4250, -0.8986,  0.4896],\n",
      "         [ 0.5355,  0.8212,  0.0000,  ...,  4.3611,  0.7682,  0.4184]]],\n",
      "       device='cuda:0', grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 90, 2048])\n",
      "tensor([[[ 1.5627e+00,  1.3307e+00,  1.3788e+00,  ...,  1.3248e+00,\n",
      "          -0.0000e+00,  2.1894e+00],\n",
      "         [ 1.7405e+00,  6.2884e-01,  2.9200e+00,  ...,  3.4460e+00,\n",
      "           3.8648e-01,  3.2415e+00],\n",
      "         [ 3.5853e+00, -1.5399e+00,  3.1041e+00,  ...,  3.3602e+00,\n",
      "           1.0891e+00,  3.3063e+00],\n",
      "         ...,\n",
      "         [-6.5474e-01, -1.1867e+00,  6.5935e-01,  ...,  0.0000e+00,\n",
      "           4.4420e-01,  2.1737e+00],\n",
      "         [ 1.6991e+00,  5.0227e-01, -1.7286e-01,  ...,  3.5413e+00,\n",
      "           5.7691e-01,  1.2878e+00],\n",
      "         [ 2.0735e+00,  1.2918e+00,  4.1304e-01,  ...,  1.4299e+00,\n",
      "          -9.3301e-02,  9.5407e-01]],\n",
      "\n",
      "        [[ 1.2360e+00,  2.1196e+00,  3.9580e-01,  ...,  2.8369e+00,\n",
      "           6.0393e-01,  4.1342e+00],\n",
      "         [ 1.7133e+00, -9.2852e-01,  1.3207e+00,  ...,  2.9612e+00,\n",
      "           7.1027e-01,  3.3923e+00],\n",
      "         [ 2.3542e+00, -1.5405e+00,  2.2011e+00,  ...,  2.1128e+00,\n",
      "           0.0000e+00,  3.4945e+00],\n",
      "         ...,\n",
      "         [-9.8845e-01, -2.1649e+00,  3.3901e-01,  ...,  4.6072e+00,\n",
      "           0.0000e+00,  1.5395e+00],\n",
      "         [-1.5869e-01, -1.5192e-01,  4.4228e-01,  ...,  4.6388e+00,\n",
      "           7.6340e-01,  1.9692e+00],\n",
      "         [ 3.1546e+00,  5.1138e-01,  3.2276e-01,  ...,  4.9040e+00,\n",
      "           1.6205e+00,  1.4682e+00]],\n",
      "\n",
      "        [[ 1.5698e+00,  1.0301e+00,  3.1185e+00,  ...,  2.6955e+00,\n",
      "           2.4726e-01,  2.8834e+00],\n",
      "         [ 0.0000e+00, -9.6133e-01,  3.9968e+00,  ...,  2.8303e+00,\n",
      "           8.4895e-03,  3.2429e+00],\n",
      "         [ 2.5860e+00, -0.0000e+00,  2.4943e+00,  ...,  3.8706e+00,\n",
      "          -4.6562e-01,  1.7757e+00],\n",
      "         ...,\n",
      "         [-7.3541e-01, -1.2180e+00,  9.5616e-01,  ...,  4.6028e+00,\n",
      "           4.9151e-01,  1.8676e+00],\n",
      "         [ 7.3218e-01, -2.8744e-01, -4.7664e-01,  ...,  4.6937e+00,\n",
      "           1.6421e+00,  1.9068e+00],\n",
      "         [ 1.7826e+00,  2.2755e-01,  1.0482e+00,  ...,  1.7405e+00,\n",
      "           1.7991e+00,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.5692e-01, -6.7981e-01,  1.2524e+00,  ...,  1.9040e+00,\n",
      "           5.1913e-01,  1.9889e+00],\n",
      "         [ 2.4771e+00,  9.9323e-01,  3.7819e+00,  ...,  3.1040e+00,\n",
      "          -1.0327e+00,  2.9315e+00],\n",
      "         [ 3.5734e+00, -0.0000e+00,  3.8337e+00,  ...,  3.0544e+00,\n",
      "           7.3710e-02,  2.3977e+00],\n",
      "         ...,\n",
      "         [-1.6768e+00, -2.0993e+00,  0.0000e+00,  ...,  4.4466e+00,\n",
      "           1.9616e+00,  1.3060e+00],\n",
      "         [ 1.0687e+00, -5.2199e-02, -3.6152e-02,  ...,  4.4392e+00,\n",
      "           1.0187e+00,  1.1943e+00],\n",
      "         [ 0.0000e+00,  2.9353e-01,  1.1573e+00,  ...,  4.2464e+00,\n",
      "           0.0000e+00,  1.7165e+00]],\n",
      "\n",
      "        [[-2.8205e-01,  7.3925e-01,  1.8389e+00,  ...,  2.8171e+00,\n",
      "           0.0000e+00,  4.9572e+00],\n",
      "         [ 2.4362e+00, -1.4470e-01,  3.3696e+00,  ...,  0.0000e+00,\n",
      "          -0.0000e+00,  2.6451e+00],\n",
      "         [ 2.2886e+00, -2.0334e+00,  2.3838e+00,  ...,  3.1872e+00,\n",
      "           1.3282e+00,  4.4493e+00],\n",
      "         ...,\n",
      "         [-1.1001e+00, -1.6705e+00,  6.4549e-01,  ...,  4.5087e+00,\n",
      "           1.7511e+00,  1.3807e+00],\n",
      "         [ 5.8032e-01,  6.9585e-01,  1.7215e-01,  ...,  0.0000e+00,\n",
      "           1.3038e+00,  1.6934e+00],\n",
      "         [ 2.3957e+00,  4.6250e-01,  9.0421e-01,  ...,  0.0000e+00,\n",
      "           1.5923e+00,  1.8364e+00]],\n",
      "\n",
      "        [[ 1.4768e+00, -1.3442e-01,  2.2954e+00,  ...,  1.6437e+00,\n",
      "          -6.0990e-02,  2.8878e+00],\n",
      "         [ 2.2600e+00,  8.6163e-02,  3.1301e+00,  ...,  3.2895e+00,\n",
      "          -0.0000e+00,  4.0024e+00],\n",
      "         [ 1.7273e+00, -1.7573e-01,  0.0000e+00,  ...,  4.6458e+00,\n",
      "           9.1304e-04,  3.0298e+00],\n",
      "         ...,\n",
      "         [-9.7840e-01, -0.0000e+00,  8.7773e-01,  ...,  4.8092e+00,\n",
      "           1.0372e+00,  1.9214e+00],\n",
      "         [ 1.9858e+00, -6.5178e-01, -7.1918e-01,  ...,  4.8419e+00,\n",
      "          -4.0861e-01,  2.1266e+00],\n",
      "         [ 1.6978e+00,  1.3787e-01,  3.3727e-01,  ...,  4.5774e+00,\n",
      "           2.3861e-01,  2.5253e+00]]], device='cuda:0',\n",
      "       grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 90, 2048])\n",
      "tensor([[[ 0.0000,  0.0278,  0.6482,  ...,  0.0000, -0.2613,  2.5678],\n",
      "         [ 1.2662, -0.9868,  2.7475,  ...,  3.7973,  0.4429,  3.1924],\n",
      "         [ 2.8473, -2.8784,  2.8498,  ...,  3.7628,  0.0000,  3.4405],\n",
      "         ...,\n",
      "         [-1.6089, -2.2443, -0.2184,  ...,  2.0853,  0.8321,  2.7807],\n",
      "         [ 0.7069, -0.3408, -0.9834,  ...,  3.7917,  0.7807,  2.4372],\n",
      "         [ 1.7156,  0.1776, -0.3381,  ...,  0.0000,  0.5821,  2.2477]],\n",
      "\n",
      "        [[ 0.8029,  0.4688,  0.2940,  ...,  3.4719,  0.1793,  3.7120],\n",
      "         [ 1.9707, -1.6389,  1.3992,  ...,  3.4235,  0.6601,  3.4808],\n",
      "         [ 2.4259, -0.0000,  2.2239,  ...,  3.2913,  0.2795,  3.6542],\n",
      "         ...,\n",
      "         [-1.3601, -3.3250, -0.0000,  ...,  4.0567,  0.3753,  2.5814],\n",
      "         [-0.4433, -1.4119, -1.0470,  ...,  4.5323,  1.0321,  3.0559],\n",
      "         [ 2.4842, -0.0000, -0.2233,  ...,  4.2551,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.6611, -0.4065,  1.9017,  ...,  3.1300,  0.3441,  3.4571],\n",
      "         [ 0.8569, -1.7486,  3.5296,  ...,  3.1045,  0.3585,  3.7876],\n",
      "         [ 2.0851, -2.1583,  2.4207,  ...,  3.5267, -0.0000,  2.6801],\n",
      "         ...,\n",
      "         [-1.3904, -2.5244,  0.1663,  ...,  4.1078,  0.4861,  3.2375],\n",
      "         [ 0.0000, -1.2018, -0.9057,  ...,  4.2556,  1.3126,  2.7824],\n",
      "         [ 1.4632, -0.9845,  0.1558,  ...,  2.5988,  1.6382,  1.9079]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.3165, -1.1142,  0.7809,  ...,  2.9813,  0.6513,  2.7925],\n",
      "         [ 2.0010, -0.7374,  2.9635,  ...,  3.2705, -0.3940,  3.4529],\n",
      "         [ 2.4551, -2.6753,  2.9807,  ...,  3.7748,  0.4131,  0.0000],\n",
      "         ...,\n",
      "         [-1.8463, -3.1617, -0.0876,  ...,  4.3237,  1.4041,  2.4400],\n",
      "         [ 0.1836, -1.2092, -1.1371,  ...,  0.0000,  0.9710,  2.2373],\n",
      "         [ 0.6780, -0.3359,  0.2040,  ...,  3.7541,  0.4524,  2.5291]],\n",
      "\n",
      "        [[-0.6602, -0.0000,  0.8584,  ...,  3.2393,  0.4970,  4.0614],\n",
      "         [ 1.8936, -1.5003,  0.0000,  ...,  2.1135,  0.3971,  3.2089],\n",
      "         [ 1.5546, -3.8310,  2.5759,  ...,  3.5155,  1.2031,  0.0000],\n",
      "         ...,\n",
      "         [-2.0128, -3.3346,  0.2015,  ...,  4.3111,  1.4555,  2.4654],\n",
      "         [ 0.2441, -0.8084, -1.1598,  ...,  2.0859,  1.3652,  2.7147],\n",
      "         [ 2.0900, -0.6724,  0.1626,  ...,  2.0185,  0.0000,  3.0296]],\n",
      "\n",
      "        [[ 0.0000, -0.9741,  0.0000,  ...,  2.7744, -0.0061,  3.3021],\n",
      "         [ 2.0355, -1.4424,  2.2977,  ...,  3.6631,  0.3000,  4.1377],\n",
      "         [ 1.3891, -2.3247,  0.8700,  ...,  4.3474,  0.0755,  2.8980],\n",
      "         ...,\n",
      "         [-1.6485, -2.3884,  0.2200,  ...,  4.2552,  0.0000,  3.0340],\n",
      "         [ 1.0148, -1.4157, -1.5987,  ...,  4.3056, -0.0292,  3.0068],\n",
      "         [ 1.4838, -0.6188, -0.3888,  ...,  0.0000, -0.3437,  2.7692]]],\n",
      "       device='cuda:0', grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 90, 2048])\n",
      "tensor([[[-1.0858, -0.4011, -0.7420,  ...,  1.8061, -0.0596,  2.9933],\n",
      "         [ 0.7674, -1.6067,  1.4134,  ...,  3.6278,  0.2738,  3.2622],\n",
      "         [ 0.0000, -3.4220,  1.4884,  ...,  4.0346,  0.0444,  3.1800],\n",
      "         ...,\n",
      "         [-2.5890, -2.7384, -1.5958,  ...,  3.1116,  0.6517,  3.1421],\n",
      "         [-0.7095, -0.6792, -2.3492,  ...,  0.0000,  0.5604,  2.8962],\n",
      "         [ 0.9468, -0.4468, -0.0000,  ...,  2.0410,  0.7126,  2.7181]],\n",
      "\n",
      "        [[-0.5901, -0.3111, -0.6661,  ...,  3.3442,  0.7169,  3.6618],\n",
      "         [ 0.7672, -1.6233,  0.5949,  ...,  0.0000,  0.6592,  3.5958],\n",
      "         [ 1.3818, -2.1745,  1.4993,  ...,  3.3377,  0.5667,  3.6314],\n",
      "         ...,\n",
      "         [-2.4734, -3.3380, -1.1161,  ...,  3.7179,  0.8000,  3.0991],\n",
      "         [-1.2539, -0.0000, -2.3527,  ...,  0.0000,  0.3619,  3.2598],\n",
      "         [ 1.2068, -0.0000, -1.3752,  ...,  3.6600,  0.4929,  1.9146]],\n",
      "\n",
      "        [[-1.2554, -0.5659,  0.0470,  ...,  3.6640,  0.6958,  3.7748],\n",
      "         [ 0.0803, -0.0000,  1.6416,  ...,  3.1953,  0.6368,  0.0000],\n",
      "         [ 0.9235, -2.7526,  1.2461,  ...,  3.3708,  0.0000,  2.9944],\n",
      "         ...,\n",
      "         [-2.7413, -2.7732, -0.0000,  ...,  0.0000,  0.0236,  3.2815],\n",
      "         [-1.1911, -1.1809, -2.2865,  ...,  3.9458,  1.1524,  3.2472],\n",
      "         [ 0.3766, -0.0000, -1.2765,  ...,  3.0558,  1.0965,  3.0360]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.2144, -1.2054, -0.9102,  ...,  3.4274,  0.6240,  3.1026],\n",
      "         [ 0.5090, -1.5775,  1.2849,  ...,  3.4943, -0.1146,  3.6868],\n",
      "         [ 1.0720, -3.2440,  1.6807,  ...,  3.6210,  0.4171,  1.6024],\n",
      "         ...,\n",
      "         [-2.8926, -2.9065, -0.0000,  ...,  4.0279,  1.1938,  3.0359],\n",
      "         [-0.8714, -0.0000, -2.5387,  ...,  2.0318,  0.9042,  3.0274],\n",
      "         [-0.0405, -0.5112, -1.4317,  ...,  3.7446,  0.5750,  3.2264]],\n",
      "\n",
      "        [[-1.3295, -0.4020, -0.3809,  ...,  3.4389,  0.8982,  3.8474],\n",
      "         [ 0.5171, -1.7039,  0.1180,  ...,  2.7428,  0.4792,  3.5321],\n",
      "         [ 0.4382, -4.0802,  1.4758,  ...,  3.7883,  0.9564,  1.7711],\n",
      "         ...,\n",
      "         [-3.5847, -3.6204, -1.8128,  ...,  4.2474,  0.6305,  2.7801],\n",
      "         [-1.4060, -1.4722, -0.0000,  ...,  3.0500,  1.0844,  3.2155],\n",
      "         [ 0.4607, -0.9901, -1.3105,  ...,  0.0000,  0.4224,  3.3796]],\n",
      "\n",
      "        [[-0.9563, -0.0000, -0.8538,  ...,  3.2511,  0.2327,  3.4569],\n",
      "         [ 0.8710, -1.8339,  1.0292,  ...,  3.7518,  0.6489,  3.8986],\n",
      "         [ 0.8151, -3.3355,  0.0000,  ...,  3.8479,  0.1538,  3.3736],\n",
      "         ...,\n",
      "         [-3.0495, -2.9484, -1.2947,  ...,  4.1712,  0.0935,  2.8327],\n",
      "         [-0.3779, -1.5766, -3.0752,  ...,  3.9888,  0.1410,  3.2534],\n",
      "         [ 0.4071, -0.9018, -1.5084,  ...,  1.7609,  0.0000,  3.4703]]],\n",
      "       device='cuda:0', grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 91, 2048])\n",
      "tensor([[[-0.0000e+00,  7.2536e+01,  5.5620e+01,  ..., -2.7637e+01,\n",
      "           9.8531e-03,  9.5118e+01],\n",
      "         [ 2.7714e+01,  9.6376e+01, -1.2452e+01,  ...,  5.5101e+01,\n",
      "           5.2169e+01,  1.6263e+01],\n",
      "         [ 4.7403e+01, -2.0879e+01, -2.6240e+00,  ...,  1.0854e+02,\n",
      "          -1.3351e+01, -5.9973e+01],\n",
      "         ...,\n",
      "         [-6.7748e+01, -1.2055e+01, -3.9737e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -0.0000e+00],\n",
      "         [-6.6831e+01, -1.1786e+01, -3.4453e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6794e+01, -0.0000e+00, -2.3993e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01]],\n",
      "\n",
      "        [[-1.2303e+02,  7.2536e+01,  5.5620e+01,  ..., -2.7637e+01,\n",
      "           9.8531e-03,  0.0000e+00],\n",
      "         [ 3.5964e+01,  3.7943e+01,  0.0000e+00,  ..., -4.6398e+01,\n",
      "          -3.1253e+01,  0.0000e+00],\n",
      "         [-1.7107e+01, -0.0000e+00, -5.2614e+00,  ..., -1.5923e+01,\n",
      "           2.5699e+01,  5.4434e+00],\n",
      "         ...,\n",
      "         [-6.7748e+01, -1.2055e+01, -3.9737e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6831e+01, -1.1786e+01, -3.4453e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -0.0000e+00],\n",
      "         [-6.6794e+01, -1.2494e+01, -2.3993e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01]],\n",
      "\n",
      "        [[-1.2303e+02,  7.2536e+01,  5.5620e+01,  ..., -2.7637e+01,\n",
      "           9.8531e-03,  9.5118e+01],\n",
      "         [ 2.9221e+01,  2.2842e+01, -3.2537e+01,  ...,  7.0587e+00,\n",
      "           3.0977e+01, -3.9303e+00],\n",
      "         [-1.2181e+02,  3.3243e+01,  0.0000e+00,  ..., -5.0501e+01,\n",
      "          -5.0309e+00, -0.0000e+00],\n",
      "         ...,\n",
      "         [-6.7748e+01, -1.2055e+01, -3.9737e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6831e+01, -0.0000e+00, -0.0000e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -0.0000e+00],\n",
      "         [-0.0000e+00, -1.2494e+01, -2.3993e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.2303e+02,  7.2536e+01,  0.0000e+00,  ..., -2.7637e+01,\n",
      "           9.8531e-03,  9.5118e+01],\n",
      "         [-1.5188e+02, -1.4156e+00, -4.9651e+01,  ..., -1.6306e+01,\n",
      "           1.9726e+01,  1.2007e+01],\n",
      "         [ 5.0120e+01,  0.0000e+00,  1.0835e+02,  ..., -2.9314e+00,\n",
      "           6.8697e+01, -3.2877e+01],\n",
      "         ...,\n",
      "         [-6.7748e+01, -1.2055e+01, -3.9737e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6831e+01, -1.1786e+01, -3.4453e+00,  ...,  7.9533e+01,\n",
      "           0.0000e+00, -7.8470e+01],\n",
      "         [-0.0000e+00, -1.2494e+01, -2.3993e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01]],\n",
      "\n",
      "        [[-1.2303e+02,  0.0000e+00,  5.5620e+01,  ..., -2.7637e+01,\n",
      "           9.8531e-03,  9.5118e+01],\n",
      "         [ 4.8139e+00, -2.6053e+01,  2.4412e+01,  ..., -1.9299e+00,\n",
      "           0.0000e+00,  5.7904e+01],\n",
      "         [-1.5180e+02, -2.4685e+00, -4.9549e+01,  ..., -1.6306e+01,\n",
      "           1.9726e+01,  1.2007e+01],\n",
      "         ...,\n",
      "         [-6.7748e+01, -0.0000e+00, -3.9737e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6831e+01, -1.1786e+01, -3.4453e+00,  ...,  7.9533e+01,\n",
      "           0.0000e+00, -7.8470e+01],\n",
      "         [-6.6794e+01, -1.2494e+01, -2.3993e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01]],\n",
      "\n",
      "        [[-1.2303e+02,  0.0000e+00,  5.5620e+01,  ..., -2.7637e+01,\n",
      "           9.8531e-03,  0.0000e+00],\n",
      "         [ 4.8139e+00, -0.0000e+00,  2.4412e+01,  ..., -1.9299e+00,\n",
      "           1.0275e+01,  5.7904e+01],\n",
      "         [-1.5077e+01, -7.4410e+01, -2.8388e+00,  ...,  6.4503e+01,\n",
      "          -4.0917e+00,  9.5945e+00],\n",
      "         ...,\n",
      "         [-6.7748e+01, -1.2055e+01, -3.9737e+00,  ...,  7.9533e+01,\n",
      "           0.0000e+00, -7.8470e+01],\n",
      "         [-6.6831e+01, -1.1786e+01, -3.4453e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6794e+01, -1.2494e+01, -2.3993e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01]]], device='cuda:0',\n",
      "       grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 91, 2048])\n",
      "tensor([[[ 1.4873,  3.8568,  2.7102,  ...,  1.2719, -0.2009,  2.7699],\n",
      "         [ 2.4115,  3.8271,  0.0000,  ...,  3.7162,  0.0000,  0.9402],\n",
      "         [ 3.8346, -0.3734,  2.3451,  ...,  0.0000,  0.0000,  0.0807],\n",
      "         ...,\n",
      "         [ 0.0213,  0.0000,  0.1031,  ...,  4.5277,  1.4818,  1.3876],\n",
      "         [ 1.0298,  1.5539,  0.7687,  ...,  4.2877,  1.1935, -0.4017],\n",
      "         [ 0.1876,  1.3963,  1.3492,  ...,  3.6292,  0.9401,  0.4416]],\n",
      "\n",
      "        [[-2.3146,  3.0437,  2.4135,  ...,  1.1787, -0.0000,  0.0000],\n",
      "         [ 1.8444,  1.0911,  1.7715,  ...,  0.8402, -0.1556,  1.2110],\n",
      "         [ 2.2448, -0.1242,  2.6499,  ...,  1.5172,  0.4181,  2.1333],\n",
      "         ...,\n",
      "         [-0.4374,  1.6390, -0.0691,  ...,  3.8308,  1.5021, -0.3196],\n",
      "         [ 0.8259,  0.0000,  1.4739,  ...,  3.7408,  1.9830,  1.1963],\n",
      "         [ 1.1866,  0.2987,  1.4893,  ...,  3.4688,  1.9359, -0.6264]],\n",
      "\n",
      "        [[-2.1784,  3.1980,  2.4283,  ...,  0.9617, -0.1557,  3.6029],\n",
      "         [ 1.9092,  2.0892,  1.8084,  ...,  1.7415,  0.6296,  1.7401],\n",
      "         [-0.9935,  0.0000,  0.0000,  ...,  1.2320, -0.1164,  1.5517],\n",
      "         ...,\n",
      "         [-1.0491,  0.0000, -0.3572,  ...,  3.4509,  0.3025, -0.1913],\n",
      "         [-0.5120,  0.0000,  0.4521,  ...,  3.0770,  0.1669,  1.0720],\n",
      "         [ 1.5269,  0.7724,  1.7429,  ...,  3.2392,  0.2570, -0.2047]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.0021,  3.5619,  1.4232,  ...,  1.1409,  0.0206,  2.8923],\n",
      "         [-2.1948,  1.5697,  1.0665,  ...,  1.8138,  0.1686,  1.5742],\n",
      "         [ 2.2418,  0.3321,  4.1778,  ...,  0.0000,  1.2261,  0.7086],\n",
      "         ...,\n",
      "         [-0.6514,  1.1217,  0.0241,  ...,  0.0000,  0.5051,  0.4422],\n",
      "         [-0.1354,  1.5821,  0.3587,  ...,  3.5501, -0.8828,  0.1172],\n",
      "         [ 1.6222,  0.6600,  0.7867,  ...,  3.2109,  0.0000, -0.0000]],\n",
      "\n",
      "        [[-2.1385,  2.6802,  1.9175,  ...,  0.9470, -0.2233,  0.0000],\n",
      "         [ 1.4600,  0.9007,  2.7676,  ...,  1.5864, -0.5800,  2.0937],\n",
      "         [-1.5044,  0.8704,  1.1496,  ...,  1.3696,  0.6895,  1.5745],\n",
      "         ...,\n",
      "         [-1.2134,  0.7209, -0.5784,  ...,  4.1100,  1.4544,  0.2681],\n",
      "         [ 0.1539,  1.6415,  0.0000,  ...,  4.4695, -0.1175,  0.4030],\n",
      "         [ 0.2438,  0.0000,  1.5392,  ...,  3.6723,  0.0000,  0.1998]],\n",
      "\n",
      "        [[-1.9641,  1.7385,  2.1985,  ...,  1.0747, -0.4464,  1.5554],\n",
      "         [ 0.0000,  1.1498,  0.0000,  ...,  1.5624,  0.2582,  2.1204],\n",
      "         [ 1.8210, -1.6601,  1.7320,  ...,  2.9555, -0.1000,  1.1882],\n",
      "         ...,\n",
      "         [-0.6171,  1.4346,  0.6225,  ...,  3.8806, -0.0000,  0.3085],\n",
      "         [-0.0000,  1.6105,  0.6998,  ...,  3.6664,  1.2137,  0.4633],\n",
      "         [ 0.2656,  1.0273,  0.0000,  ...,  3.5612,  1.3567,  0.4657]]],\n",
      "       device='cuda:0', grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 91, 2048])\n",
      "tensor([[[ 1.2603e+00,  0.0000e+00,  2.7634e+00,  ...,  1.7272e+00,\n",
      "          -6.1946e-01,  2.0407e+00],\n",
      "         [ 2.6538e+00,  2.3706e+00,  2.2375e+00,  ...,  3.4673e+00,\n",
      "          -5.0669e-01,  8.1993e-01],\n",
      "         [ 3.8032e+00, -5.1253e-01,  3.4938e+00,  ...,  1.3605e+00,\n",
      "          -9.0943e-02,  6.1286e-01],\n",
      "         ...,\n",
      "         [ 7.0149e-01,  1.3328e-01,  1.3833e-01,  ...,  3.9047e+00,\n",
      "           5.4026e-01,  1.7428e+00],\n",
      "         [ 2.2598e+00,  1.5167e+00,  8.8873e-01,  ...,  4.1237e+00,\n",
      "           5.0757e-01,  7.8669e-01],\n",
      "         [ 1.7257e+00,  9.1006e-01,  2.2784e+00,  ...,  3.4292e+00,\n",
      "           4.1914e-01,  8.9764e-01]],\n",
      "\n",
      "        [[-1.3524e+00,  2.1151e+00,  2.4177e+00,  ...,  1.5866e+00,\n",
      "          -8.2382e-01,  0.0000e+00],\n",
      "         [ 1.9578e+00,  2.5628e-01,  3.0318e+00,  ...,  1.1951e+00,\n",
      "          -7.9434e-01,  1.1341e+00],\n",
      "         [ 2.4633e+00, -6.4941e-01,  3.6765e+00,  ...,  1.9667e+00,\n",
      "          -7.9508e-01,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 3.9833e-01,  0.0000e+00,  5.8069e-02,  ...,  3.1189e+00,\n",
      "           4.2040e-01,  1.0430e+00],\n",
      "         [ 1.6563e+00,  6.5987e-01,  1.6773e+00,  ...,  3.0318e+00,\n",
      "           1.0668e+00,  1.6914e+00],\n",
      "         [ 2.0402e+00, -6.1131e-02,  2.4387e+00,  ...,  3.1803e+00,\n",
      "           0.0000e+00,  4.2466e-01]],\n",
      "\n",
      "        [[-1.1531e+00,  2.4304e+00,  3.0818e+00,  ...,  0.0000e+00,\n",
      "          -5.3090e-01,  2.5402e+00],\n",
      "         [ 2.2678e+00,  1.9432e+00,  3.7203e+00,  ...,  1.9915e+00,\n",
      "          -3.0531e-01,  1.7447e+00],\n",
      "         [ 4.3023e-01, -1.1331e+00,  2.2244e+00,  ...,  1.6092e+00,\n",
      "          -5.6172e-01,  1.5322e+00],\n",
      "         ...,\n",
      "         [-4.5813e-01,  6.5225e-01, -1.4578e-01,  ...,  2.9918e+00,\n",
      "          -5.2833e-01,  1.1434e+00],\n",
      "         [ 9.3044e-01,  6.1257e-01,  8.7583e-01,  ...,  2.9993e+00,\n",
      "          -2.6010e-01,  1.5382e+00],\n",
      "         [ 2.0435e+00,  5.3116e-01,  2.8063e+00,  ...,  0.0000e+00,\n",
      "          -2.8857e-01,  6.6725e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.0385e+00,  2.8468e+00,  2.1419e+00,  ...,  1.6291e+00,\n",
      "          -4.5986e-01,  0.0000e+00],\n",
      "         [-8.7827e-02,  1.1553e+00,  3.1694e+00,  ...,  1.8796e+00,\n",
      "          -6.1395e-01,  1.8718e+00],\n",
      "         [ 2.6150e+00, -3.7979e-01,  4.5298e+00,  ...,  1.0811e+00,\n",
      "          -3.2628e-02,  1.0640e+00],\n",
      "         ...,\n",
      "         [ 9.1770e-02,  5.4441e-01, -2.1035e-01,  ...,  9.7177e-01,\n",
      "          -2.0523e-02,  9.4157e-01],\n",
      "         [ 1.2151e+00,  1.0761e+00,  1.0482e-01,  ...,  3.3025e+00,\n",
      "          -1.3085e+00,  7.5167e-01],\n",
      "         [ 2.1566e+00,  1.7325e-01,  2.3904e+00,  ...,  0.0000e+00,\n",
      "          -8.2068e-01,  3.1674e-01]],\n",
      "\n",
      "        [[-1.0210e+00,  0.0000e+00,  2.2813e+00,  ...,  1.6389e+00,\n",
      "          -0.0000e+00,  8.7617e-01],\n",
      "         [ 1.9766e+00,  7.0096e-01,  4.0236e+00,  ...,  1.6391e+00,\n",
      "          -1.1997e+00,  2.2779e+00],\n",
      "         [ 4.9285e-02, -9.3990e-02,  2.9462e+00,  ...,  2.2602e+00,\n",
      "          -2.6663e-01,  1.9675e+00],\n",
      "         ...,\n",
      "         [-3.7960e-01,  8.6997e-01, -3.1112e-01,  ...,  3.9062e+00,\n",
      "           5.8293e-01,  0.0000e+00],\n",
      "         [ 1.4068e+00,  1.4404e+00,  6.8537e-01,  ...,  3.8751e+00,\n",
      "          -4.2611e-01,  1.0522e+00],\n",
      "         [ 1.2521e+00, -7.2591e-01,  2.3112e+00,  ...,  3.5186e+00,\n",
      "          -8.1449e-02,  1.5808e+00]],\n",
      "\n",
      "        [[-8.2589e-01,  1.9091e+00,  2.6275e+00,  ...,  1.3502e+00,\n",
      "          -6.5632e-01,  1.4021e+00],\n",
      "         [ 1.4816e+00,  6.9011e-01,  2.4094e+00,  ...,  1.9168e+00,\n",
      "          -3.7598e-01,  1.7754e+00],\n",
      "         [ 2.9090e+00, -2.0938e+00,  2.8852e+00,  ...,  2.8625e+00,\n",
      "          -5.8571e-01,  1.3482e+00],\n",
      "         ...,\n",
      "         [-2.8677e-03,  0.0000e+00,  6.5523e-01,  ...,  3.6755e+00,\n",
      "          -3.2919e-01,  1.1119e+00],\n",
      "         [ 1.8318e+00,  1.3712e+00,  1.1716e+00,  ...,  0.0000e+00,\n",
      "           3.0986e-01,  1.1915e+00],\n",
      "         [ 0.0000e+00,  1.7250e-01,  1.4774e+00,  ...,  0.0000e+00,\n",
      "           2.1918e-01,  1.4304e+00]]], device='cuda:0',\n",
      "       grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 91, 2048])\n",
      "tensor([[[ 0.1856,  0.6979,  1.7032,  ...,  1.6803, -0.4952,  2.1256],\n",
      "         [ 1.4920,  0.7166,  0.0000,  ...,  2.7309, -0.9839,  1.1343],\n",
      "         [ 2.3975, -1.0770,  2.9813,  ...,  1.6797, -0.3026,  1.2529],\n",
      "         ...,\n",
      "         [ 0.0351, -0.0000, -0.2666,  ...,  2.9055, -0.0000,  1.9099],\n",
      "         [ 1.8740,  1.0614,  0.1645,  ...,  3.4236, -0.2846,  1.5840],\n",
      "         [ 1.5737,  0.3011,  1.8960,  ...,  2.6966, -0.1145,  1.3338]],\n",
      "\n",
      "        [[-1.1669,  0.8748,  1.1254,  ...,  1.7633, -0.2279,  1.1185],\n",
      "         [ 0.7082,  0.0257,  2.9963,  ...,  2.0888, -0.5754,  1.3356],\n",
      "         [ 1.0817, -1.5216,  3.6139,  ...,  1.8782, -0.6872,  1.2293],\n",
      "         ...,\n",
      "         [-0.3912, -0.1046, -0.7285,  ...,  2.0993, -0.7304,  1.6207],\n",
      "         [ 0.7403,  0.6551,  0.4901,  ...,  2.5018,  0.3860,  1.9078],\n",
      "         [ 1.4070, -0.3753,  2.0455,  ...,  2.2598, -0.1970,  1.1934]],\n",
      "\n",
      "        [[-0.7829,  1.5633,  1.9372,  ...,  0.9860, -0.4643,  2.2827],\n",
      "         [ 0.0000,  1.3535,  3.8530,  ...,  2.5745, -0.3218,  1.8955],\n",
      "         [ 0.0000, -1.9844,  2.2116,  ...,  2.0566, -0.6164,  2.2005],\n",
      "         ...,\n",
      "         [-0.0000,  0.0000, -0.0000,  ...,  2.5228, -0.6262,  2.0621],\n",
      "         [ 1.0869,  1.0282,  0.2328,  ...,  2.5169, -0.4332,  1.7532],\n",
      "         [ 1.3532,  0.1088,  2.1916,  ...,  1.0401, -0.6591,  1.6248]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0000,  1.6809,  1.3391,  ...,  1.4895, -0.0000,  0.7333],\n",
      "         [ 0.0574,  0.5349,  2.5789,  ...,  1.8287, -0.5998,  2.0615],\n",
      "         [ 1.7843, -1.6552,  3.7540,  ...,  1.5112, -0.5649,  1.7269],\n",
      "         ...,\n",
      "         [-0.3953,  0.4247, -0.9316,  ...,  1.5428, -0.3457,  1.4928],\n",
      "         [ 1.1289,  0.8101,  0.3507,  ...,  2.4281, -0.9345,  1.1395],\n",
      "         [ 1.2491, -0.1993,  2.2581,  ...,  0.8876, -1.2391,  0.8523]],\n",
      "\n",
      "        [[-0.4022,  0.1631,  1.2378,  ...,  1.7561, -0.7603,  1.4445],\n",
      "         [ 0.7029,  0.1152,  3.5320,  ...,  1.5824, -0.9910,  2.2431],\n",
      "         [ 0.1528, -1.0421,  3.3444,  ...,  2.2889, -0.0000,  2.1841],\n",
      "         ...,\n",
      "         [-0.0000,  0.5055, -0.0000,  ...,  3.0624,  0.0000,  0.0000],\n",
      "         [ 1.5261,  0.8854, -0.1430,  ...,  3.5310, -0.0000,  1.9593],\n",
      "         [ 0.0000, -0.6261,  0.0000,  ...,  0.0000, -0.5304,  1.9221]],\n",
      "\n",
      "        [[-1.1752,  1.4279,  0.0000,  ...,  1.3008, -0.3476,  1.8183],\n",
      "         [ 0.0000,  0.0312,  0.0000,  ...,  1.7297, -0.5813,  1.8305],\n",
      "         [ 2.0951, -1.9197,  2.4031,  ...,  2.2586, -0.2808,  1.7251],\n",
      "         ...,\n",
      "         [-0.4154, -0.1358, -0.1313,  ...,  0.0000, -0.4610,  1.6380],\n",
      "         [ 1.5327,  0.6165,  0.0970,  ...,  1.6330, -0.3662,  1.7590],\n",
      "         [ 0.6973, -0.5104,  1.7434,  ...,  1.0353, -0.0701,  2.2487]]],\n",
      "       device='cuda:0', grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 91, 2048])\n",
      "tensor([[[-1.7738,  0.8620,  0.3977,  ...,  1.9503, -0.8408,  2.2836],\n",
      "         [ 0.2195,  0.5891,  0.0000,  ...,  2.3532, -0.9766,  0.0000],\n",
      "         [ 0.9145, -1.3705,  1.8279,  ...,  2.3323, -0.6125,  1.8888],\n",
      "         ...,\n",
      "         [-0.0000,  0.7667, -1.8069,  ...,  2.8633, -0.4096,  1.7218],\n",
      "         [ 0.0000,  0.9962, -1.5176,  ...,  2.3541, -0.4878,  2.4763],\n",
      "         [ 0.4357,  0.3212,  1.0803,  ...,  2.4330, -0.7215,  1.5391]],\n",
      "\n",
      "        [[-2.0077,  0.9221,  0.0213,  ...,  1.9188, -0.0000,  1.6652],\n",
      "         [ 0.2677,  0.0833,  0.0000,  ...,  1.6596, -0.6457,  1.4729],\n",
      "         [-0.0377, -0.9234,  2.0815,  ...,  1.7051, -0.6427,  1.1471],\n",
      "         ...,\n",
      "         [-0.0000,  0.5582, -1.7865,  ...,  1.5871, -0.7908,  1.7002],\n",
      "         [-0.4367,  1.0932, -0.6816,  ...,  0.0000, -0.0330,  1.9563],\n",
      "         [ 0.4877,  0.0900,  1.1185,  ...,  1.9761, -0.2896,  1.6564]],\n",
      "\n",
      "        [[-1.8551,  1.3452,  0.3944,  ...,  1.3562, -0.2169,  2.7379],\n",
      "         [-0.4433,  0.0000,  2.3985,  ...,  2.2331, -0.4064,  1.9143],\n",
      "         [-0.3371, -1.2678,  1.8932,  ...,  2.0957, -0.3389,  1.8441],\n",
      "         ...,\n",
      "         [-0.9429,  0.6910, -1.3656,  ...,  0.0000, -0.6682,  1.8220],\n",
      "         [ 0.0615,  1.2098, -0.9533,  ...,  1.9640, -0.3048,  2.4087],\n",
      "         [ 0.5974,  0.2077,  0.0000,  ...,  0.0000, -0.6690,  1.8461]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.1944,  1.0433,  0.1570,  ...,  1.8699, -0.2047,  0.0000],\n",
      "         [-0.3868,  0.0261,  2.0289,  ...,  1.9650, -0.5969,  2.3347],\n",
      "         [ 0.7367, -0.0000,  2.5631,  ...,  0.0000, -0.6875,  2.1893],\n",
      "         ...,\n",
      "         [-1.5678,  0.7680, -1.8066,  ...,  1.5394, -0.6678,  1.8599],\n",
      "         [-0.2378,  0.9498, -0.5272,  ...,  2.4239, -0.9437,  1.5040],\n",
      "         [ 0.1312,  0.3217,  0.8059,  ...,  1.1061, -1.0609,  1.1570]],\n",
      "\n",
      "        [[-1.3237,  0.7014,  0.2674,  ...,  1.5935, -0.2765,  1.7856],\n",
      "         [ 0.5631,  0.4811,  1.7276,  ...,  1.7576, -0.8955,  2.0596],\n",
      "         [-0.2934, -1.4384,  2.1107,  ...,  2.7387, -0.0000,  2.1712],\n",
      "         ...,\n",
      "         [-1.5903,  0.9858, -1.5941,  ...,  2.2959, -0.3393,  1.2272],\n",
      "         [ 0.0321,  0.8313, -1.0640,  ...,  2.8653, -0.3029,  2.0488],\n",
      "         [-1.0140, -0.2759, -0.0000,  ...,  1.0183, -0.6465,  0.0000]],\n",
      "\n",
      "        [[-1.5384,  1.5194, -0.5288,  ...,  1.2282, -0.6339,  2.0666],\n",
      "         [-0.0000,  0.5345,  0.4162,  ...,  1.8172, -0.4542,  2.3535],\n",
      "         [ 0.0000, -1.4121,  1.9435,  ...,  1.7039, -0.4359,  1.8179],\n",
      "         ...,\n",
      "         [-1.4266,  0.0209, -1.4968,  ...,  1.0296, -0.6639,  0.0000],\n",
      "         [ 0.3644,  0.9145, -0.0000,  ...,  1.9318, -0.4908,  2.3537],\n",
      "         [ 0.0484, -0.6848,  0.7882,  ...,  0.0000, -0.4184,  2.2311]]],\n",
      "       device='cuda:0', grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 90, 2048])\n",
      "tensor([[[  29.7911,   31.9680,  -14.0038,  ...,   21.4909,   67.4089,\n",
      "           129.3064],\n",
      "         [   3.1243,   93.0681,  -42.7770,  ...,   56.0454,  -41.6853,\n",
      "           -64.2715],\n",
      "         [ -19.3007,   19.7215,  -30.7949,  ...,   22.1281,   95.2851,\n",
      "            91.5541],\n",
      "         ...,\n",
      "         [ -68.7001,  -13.0567,   -3.5143,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         [ -67.7476,  -12.0546,   -3.9737,  ...,   79.5327,    0.0000,\n",
      "           -78.4697],\n",
      "         [ -66.8313,  -11.7860,   -3.4453,  ...,   79.5327,   67.9524,\n",
      "            -0.0000]],\n",
      "\n",
      "        [[ -41.4305,    1.7337,  -12.8695,  ...,   39.5312,  -28.4177,\n",
      "             0.0000],\n",
      "         [   0.0000,   12.0937,   51.1031,  ...,   32.4809,    3.8348,\n",
      "            29.7627],\n",
      "         [-151.8005,   -2.4685,  -49.5494,  ...,  -16.3063,   19.7265,\n",
      "            12.0072],\n",
      "         ...,\n",
      "         [ -68.7001,  -13.0567,   -3.5143,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         [ -67.7476,  -12.0546,   -0.0000,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         [  -0.0000,  -11.7860,   -3.4453,  ...,   79.5327,   67.9524,\n",
      "           -78.4697]],\n",
      "\n",
      "        [[  28.2858,   23.3442,  -33.4608,  ...,    7.0587,   30.9774,\n",
      "            -3.9303],\n",
      "         [  64.2797,  -57.7711, -105.9327,  ...,   58.8417,  -44.3641,\n",
      "           -91.7171],\n",
      "         [  58.0309,   49.0246,   53.9005,  ...,  -37.6445,  118.8311,\n",
      "           151.5005],\n",
      "         ...,\n",
      "         [ -68.7001,   -0.0000,   -3.5143,  ...,    0.0000,   67.9524,\n",
      "           -78.4697],\n",
      "         [ -67.7476,  -12.0546,   -3.9737,  ...,   79.5327,   67.9524,\n",
      "            -0.0000],\n",
      "         [ -66.8313,  -11.7860,   -3.4453,  ...,   79.5327,   67.9524,\n",
      "           -78.4697]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -28.4509,   34.1838,   42.0307,  ...,   -0.0000,   35.5508,\n",
      "           -48.2908],\n",
      "         [  57.5196,   63.2465,    0.0000,  ...,  -58.6891,   -0.0000,\n",
      "            -4.4856],\n",
      "         [  -0.0000,    0.0000,   17.2505,  ...,  -48.6557,  -27.9734,\n",
      "             8.0617],\n",
      "         ...,\n",
      "         [  -0.0000,  -13.0567,   -3.5143,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         [ -67.7476,   -0.0000,   -3.9737,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         [ -66.8313,  -11.7860,   -3.4453,  ...,   79.5327,   67.9524,\n",
      "           -78.4697]],\n",
      "\n",
      "        [[  86.3852,   49.8759,    6.1185,  ...,   77.6506,  -21.4817,\n",
      "           -41.2875],\n",
      "         [ -13.4382,   34.8707,   15.1650,  ...,   50.2013,  -11.3913,\n",
      "            41.3254],\n",
      "         [ -42.1113,   35.2900,  -60.1875,  ...,   -0.0000,  -12.6206,\n",
      "            42.8785],\n",
      "         ...,\n",
      "         [ -68.7001,  -13.0567,   -3.5143,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         [ -67.7476,  -12.0546,   -0.0000,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         [  -0.0000,  -11.7860,   -3.4453,  ...,   79.5327,   67.9524,\n",
      "           -78.4697]],\n",
      "\n",
      "        [[  35.0285,   38.4456,    8.3708,  ...,  -46.3975,  -31.2534,\n",
      "            75.6588],\n",
      "         [ -28.8154,  -43.7542,   13.7089,  ...,  -32.7796,  -13.9760,\n",
      "            43.9597],\n",
      "         [  -2.8867,   29.0287,   59.5451,  ...,  -48.6407,    0.7576,\n",
      "            -9.3746],\n",
      "         ...,\n",
      "         [ -68.7001,  -13.0567,   -3.5143,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         [ -67.7476,  -12.0546,   -0.0000,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         [ -66.8313,  -11.7860,   -3.4453,  ...,   79.5327,   67.9524,\n",
      "           -78.4697]]], device='cuda:0', grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 90, 2048])\n",
      "tensor([[[ 2.2312,  2.6775,  0.8864,  ...,  3.4719,  1.9632,  4.3995],\n",
      "         [ 2.1044,  3.3758,  0.6101,  ...,  4.5800, -0.7961,  0.6897],\n",
      "         [ 0.6338,  1.3151,  1.7704,  ...,  3.9565,  2.4713,  3.6649],\n",
      "         ...,\n",
      "         [-1.1090, -0.0000,  0.6383,  ...,  4.8781,  1.4394,  0.3268],\n",
      "         [ 0.1132,  0.9157, -0.0516,  ...,  4.3455,  0.2768, -0.1934],\n",
      "         [ 0.8479,  0.9959,  0.7271,  ...,  4.0888,  0.6699,  2.0809]],\n",
      "\n",
      "        [[ 1.1287,  0.8163,  1.1719,  ...,  3.4436, -0.7275,  2.3996],\n",
      "         [ 1.6937,  1.3244,  2.3127,  ...,  3.2663, -0.0098,  1.6914],\n",
      "         [-0.5054, -0.0164,  1.3426,  ...,  0.0000, -0.5864,  2.5942],\n",
      "         ...,\n",
      "         [-0.8020, -1.0245,  0.3486,  ...,  3.7197,  1.2062,  0.5913],\n",
      "         [ 0.2828,  0.7376,  0.1626,  ...,  3.6581,  1.7643,  0.9412],\n",
      "         [ 2.4872,  0.6736,  0.0000,  ...,  3.7148,  1.1021,  0.2777]],\n",
      "\n",
      "        [[ 2.2977,  1.4390, -0.6330,  ...,  2.6610,  0.4477,  1.5954],\n",
      "         [ 3.2786, -0.1973, -0.0000,  ...,  3.2896, -1.4075,  0.0444],\n",
      "         [ 3.4765,  0.9131,  2.8849,  ...,  0.0000,  2.9478,  4.4465],\n",
      "         ...,\n",
      "         [-1.3492,  0.3000,  0.0000,  ...,  2.7380,  1.4766, -0.0605],\n",
      "         [ 0.0705,  1.1408,  0.1156,  ...,  4.2248,  1.0889,  1.7965],\n",
      "         [ 0.9820,  1.5736,  0.7556,  ...,  4.1514,  1.0635,  0.0416]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.2848,  3.2261,  2.1756,  ...,  2.3692,  0.9617,  1.0990],\n",
      "         [ 3.3761,  2.5243,  1.4910,  ...,  0.6350,  0.2182,  1.5170],\n",
      "         [ 0.0000,  0.0000,  1.7708,  ...,  0.0000, -0.4082,  1.6893],\n",
      "         ...,\n",
      "         [ 0.2702,  0.1413,  0.4262,  ...,  4.2167,  2.0253,  0.3196],\n",
      "         [-0.0000,  1.5083, -0.4167,  ...,  0.0000,  1.5642,  0.0000],\n",
      "         [ 0.5532,  1.3476,  0.6256,  ...,  4.2650,  1.6300, -0.1763]],\n",
      "\n",
      "        [[ 3.7292,  2.2719,  0.5952,  ...,  0.0000, -0.6791,  0.4067],\n",
      "         [ 0.0000,  1.6854,  2.2193,  ...,  3.2285,  0.5797,  2.3359],\n",
      "         [ 1.3563,  1.0694,  1.5930,  ...,  0.0000, -0.1394,  3.1895],\n",
      "         ...,\n",
      "         [-0.4401, -0.6568,  0.0000,  ...,  3.4371,  1.3673,  0.0707],\n",
      "         [ 0.0000,  0.8037, -0.1830,  ...,  3.8196,  0.0000,  0.1501],\n",
      "         [ 2.3389,  1.3730,  0.8215,  ...,  3.5762,  1.4796,  0.0898]],\n",
      "\n",
      "        [[ 1.7175,  0.0000,  1.7854,  ...,  0.8378, -0.6627,  3.8146],\n",
      "         [ 0.0000,  0.2993,  2.6638,  ...,  1.3446, -0.3613,  3.2529],\n",
      "         [ 1.6745,  0.4217,  3.6661,  ...,  0.0996, -0.5480,  2.1883],\n",
      "         ...,\n",
      "         [-0.5766, -0.1963,  1.0899,  ...,  3.8138,  2.0817, -0.4425],\n",
      "         [ 0.6803,  0.8588,  0.2431,  ...,  4.2610,  2.0102,  0.5220],\n",
      "         [ 1.2684,  0.0000,  0.4835,  ...,  4.2432,  2.0557, -0.0000]]],\n",
      "       device='cuda:0', grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 90, 2048])\n",
      "tensor([[[ 2.0011,  1.5859,  1.1377,  ...,  4.4721,  1.5625,  4.7293],\n",
      "         [ 2.5995,  0.0000,  1.6241,  ...,  5.1872, -1.0190,  2.3682],\n",
      "         [ 1.6730, -0.0000,  3.0617,  ...,  4.4597,  1.8418,  4.1374],\n",
      "         ...,\n",
      "         [-1.2869, -1.4137,  0.0000,  ...,  5.4079,  1.4076,  2.0097],\n",
      "         [ 0.8834,  0.3590, -0.5384,  ...,  4.9073,  0.1794,  1.1876],\n",
      "         [ 2.1023,  0.0000,  0.9708,  ...,  4.6612,  0.5969,  3.3567]],\n",
      "\n",
      "        [[ 1.2627,  0.0735,  1.4338,  ...,  4.3253, -0.3488,  3.3289],\n",
      "         [ 2.1548, -0.0958,  2.7592,  ...,  3.7095, -0.1041,  2.4379],\n",
      "         [ 1.5859, -1.5678,  0.0000,  ...,  2.0609, -0.7158,  3.4297],\n",
      "         ...,\n",
      "         [-0.8340, -0.0000,  0.3315,  ...,  4.1644,  1.2659,  1.6131],\n",
      "         [ 0.6548, -0.2336, -0.4102,  ...,  4.4668,  0.9016,  1.7854],\n",
      "         [ 3.1375,  0.0254, -0.4018,  ...,  3.9977,  1.3449,  1.2755]],\n",
      "\n",
      "        [[ 1.7481,  0.3827,  0.0000,  ...,  3.3871, -0.0000,  2.9844],\n",
      "         [ 3.6955, -0.9670,  1.4982,  ...,  3.5369, -0.9312,  2.0990],\n",
      "         [ 3.7176, -0.8861,  3.6471,  ...,  1.6989,  1.8334,  4.9728],\n",
      "         ...,\n",
      "         [-1.7094, -1.0326,  0.1250,  ...,  3.3219,  0.0000,  2.2535],\n",
      "         [ 0.4433,  0.5040, -0.0071,  ...,  4.4285,  0.6024,  2.8907],\n",
      "         [ 2.2524,  1.0558,  1.0061,  ...,  0.0000,  0.5388,  2.0564]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.4586,  1.8377,  2.0747,  ...,  3.4872,  0.7650,  1.9464],\n",
      "         [ 3.3757,  0.9084,  2.0269,  ...,  0.0000,  0.5309,  2.3211],\n",
      "         [ 1.7377, -1.8060,  0.0000,  ...,  1.8416, -0.0631,  2.3469],\n",
      "         ...,\n",
      "         [-0.4199, -1.1956,  0.5400,  ...,  4.9734,  1.5752,  1.4487],\n",
      "         [ 0.4502,  0.6725, -0.8419,  ...,  1.8411,  1.4705,  0.0000],\n",
      "         [ 1.4516,  0.0000,  0.4985,  ...,  4.6236,  1.2151,  1.1587]],\n",
      "\n",
      "        [[ 2.5591,  1.3151,  0.7611,  ...,  0.0000, -0.1478,  1.9015],\n",
      "         [ 1.0777,  0.4978,  2.6403,  ...,  3.8302,  0.0000,  3.4975],\n",
      "         [ 0.0000, -1.0982,  2.4670,  ...,  1.9707, -0.1413,  3.5631],\n",
      "         ...,\n",
      "         [-0.8304, -1.9442,  0.1603,  ...,  3.9956,  1.2653,  2.0819],\n",
      "         [ 0.5167, -0.1748, -0.3477,  ...,  4.3035,  0.6361,  0.0000],\n",
      "         [ 2.5974,  0.6969,  0.0000,  ...,  3.9536,  1.3996,  1.6308]],\n",
      "\n",
      "        [[ 0.0000, -0.1768,  0.0000,  ...,  2.1432, -0.4258,  4.0786],\n",
      "         [ 1.0781, -0.7397,  3.4854,  ...,  2.7303, -0.2205,  3.4608],\n",
      "         [ 2.4532, -1.3536,  4.5856,  ...,  1.3148, -0.5441,  3.1776],\n",
      "         ...,\n",
      "         [-1.0303, -2.0082,  1.0650,  ...,  0.0000,  1.6751,  1.4088],\n",
      "         [ 0.8722, -0.0000,  0.4687,  ...,  4.7171,  1.4150,  1.8935],\n",
      "         [ 2.3203, -0.3576,  0.0000,  ...,  4.7824,  1.9263,  1.3973]]],\n",
      "       device='cuda:0', grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 90, 2048])\n",
      "tensor([[[ 0.0000e+00,  7.5115e-02,  6.9822e-01,  ...,  4.1793e+00,\n",
      "           1.1238e+00,  4.0811e+00],\n",
      "         [ 1.9559e+00, -0.0000e+00,  1.7029e+00,  ...,  4.6121e+00,\n",
      "           2.0647e-01,  2.8563e+00],\n",
      "         [ 1.7343e+00, -2.2219e+00,  2.7950e+00,  ...,  4.5530e+00,\n",
      "           1.2244e+00,  4.0550e+00],\n",
      "         ...,\n",
      "         [-1.6478e+00, -2.9037e+00, -3.8505e-02,  ...,  0.0000e+00,\n",
      "           9.8809e-01,  2.8743e+00],\n",
      "         [ 6.8461e-01, -7.6848e-01, -1.6633e+00,  ...,  4.1815e+00,\n",
      "           5.3470e-01,  2.6444e+00],\n",
      "         [ 1.8001e+00, -7.0587e-01,  1.8421e-01,  ...,  4.0756e+00,\n",
      "           5.6506e-01,  3.7357e+00]],\n",
      "\n",
      "        [[ 0.0000e+00, -9.8173e-01,  7.6332e-01,  ...,  4.1096e+00,\n",
      "           3.6196e-01,  3.2780e+00],\n",
      "         [ 1.9376e+00, -1.4565e+00,  0.0000e+00,  ...,  3.6431e+00,\n",
      "           0.0000e+00,  3.0090e+00],\n",
      "         [ 1.9280e+00, -3.2658e+00,  1.1459e+00,  ...,  3.2633e+00,\n",
      "           3.9137e-02,  3.5335e+00],\n",
      "         ...,\n",
      "         [-0.0000e+00, -2.2794e+00, -0.0000e+00,  ...,  3.9478e+00,\n",
      "           9.7683e-01,  2.6980e+00],\n",
      "         [ 0.0000e+00, -0.0000e+00, -1.0506e+00,  ...,  4.0064e+00,\n",
      "           9.1137e-01,  2.3857e+00],\n",
      "         [ 2.5723e+00, -8.0516e-01, -8.1730e-01,  ...,  0.0000e+00,\n",
      "           1.1646e+00,  2.6501e+00]],\n",
      "\n",
      "        [[ 9.6911e-01, -7.7577e-01,  1.4474e-01,  ...,  3.5335e+00,\n",
      "          -4.5385e-01,  3.4890e+00],\n",
      "         [ 2.5186e+00, -1.5809e+00,  1.7148e+00,  ...,  3.8498e+00,\n",
      "          -1.1245e-01,  2.9454e+00],\n",
      "         [ 2.5819e+00, -2.7236e+00,  2.5625e+00,  ...,  3.0013e+00,\n",
      "           9.4158e-01,  4.3610e+00],\n",
      "         ...,\n",
      "         [-2.1099e+00, -0.0000e+00, -8.7797e-01,  ...,  3.8106e+00,\n",
      "           5.5304e-02,  3.3627e+00],\n",
      "         [ 5.5824e-02, -6.5311e-01, -9.8765e-01,  ...,  4.0279e+00,\n",
      "           6.1432e-02,  3.3499e+00],\n",
      "         [ 1.3552e+00, -0.0000e+00, -5.5940e-02,  ...,  1.7470e+00,\n",
      "           1.6751e-01,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-5.6437e-03,  4.1448e-03,  1.5530e+00,  ...,  3.6405e+00,\n",
      "           5.3301e-01,  2.9390e+00],\n",
      "         [ 2.3605e+00, -9.5412e-01,  2.2969e+00,  ...,  2.0096e+00,\n",
      "           8.7049e-01,  2.8452e+00],\n",
      "         [ 1.7615e+00, -0.0000e+00,  1.1792e+00,  ...,  3.0076e+00,\n",
      "           3.3063e-01,  2.9661e+00],\n",
      "         ...,\n",
      "         [-1.3631e+00, -0.0000e+00, -4.8709e-02,  ...,  4.4695e+00,\n",
      "           1.2596e+00,  2.2831e+00],\n",
      "         [ 4.8216e-02, -5.0771e-01, -1.4269e+00,  ...,  2.8494e+00,\n",
      "           1.1928e+00,  1.9886e+00],\n",
      "         [ 1.1795e+00, -7.3058e-01, -1.9974e-01,  ...,  4.5110e+00,\n",
      "           0.0000e+00,  2.0799e+00]],\n",
      "\n",
      "        [[ 6.6309e-01, -1.1423e-01,  1.8904e-01,  ...,  1.8695e+00,\n",
      "           0.0000e+00,  2.3178e+00],\n",
      "         [ 9.4621e-01, -9.2802e-01,  2.4957e+00,  ...,  3.6479e+00,\n",
      "           7.5566e-01,  0.0000e+00],\n",
      "         [ 5.3934e-01, -0.0000e+00,  2.3112e+00,  ...,  2.9378e+00,\n",
      "           2.8358e-01,  3.5218e+00],\n",
      "         ...,\n",
      "         [-1.7240e+00, -0.0000e+00, -2.7743e-01,  ...,  4.0630e+00,\n",
      "           1.3869e+00,  3.0533e+00],\n",
      "         [-1.0141e-01, -0.0000e+00, -8.7783e-01,  ...,  0.0000e+00,\n",
      "          -1.1621e-01,  1.8411e+00],\n",
      "         [ 1.7122e+00, -3.4489e-01, -8.3084e-01,  ...,  4.0269e+00,\n",
      "           1.3945e+00,  2.5826e+00]],\n",
      "\n",
      "        [[ 2.6176e-02, -1.0205e+00,  3.2135e-01,  ...,  0.0000e+00,\n",
      "          -2.9521e-01,  4.1346e+00],\n",
      "         [ 0.0000e+00, -0.0000e+00,  2.9055e+00,  ...,  3.2418e+00,\n",
      "          -1.3603e-02,  3.6114e+00],\n",
      "         [ 1.7513e+00, -2.9699e+00,  3.8802e+00,  ...,  0.0000e+00,\n",
      "          -8.2508e-01,  3.6638e+00],\n",
      "         ...,\n",
      "         [-1.2605e+00, -3.2371e+00,  3.2040e-01,  ...,  1.8361e+00,\n",
      "           5.5524e-01,  2.6027e+00],\n",
      "         [ 3.3936e-01, -1.3299e+00, -2.1049e-01,  ...,  4.3980e+00,\n",
      "           7.8421e-01,  2.9101e+00],\n",
      "         [ 2.2464e+00, -0.0000e+00, -4.5487e-01,  ...,  4.2710e+00,\n",
      "           1.5706e+00,  2.5654e+00]]], device='cuda:0',\n",
      "       grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 90, 2048])\n",
      "tensor([[[-0.7142, -0.6139, -0.9621,  ...,  4.0468,  1.0069,  0.0000],\n",
      "         [ 0.9103, -0.8870,  0.9209,  ...,  4.3074,  0.4796,  3.3782],\n",
      "         [ 0.0000, -2.9150,  1.1165,  ...,  4.0993,  0.9312,  4.1670],\n",
      "         ...,\n",
      "         [-2.6674, -2.9777, -1.9625,  ...,  2.0602,  0.0000,  3.5842],\n",
      "         [-0.5754, -0.9231, -3.1188,  ...,  3.7718,  0.0664,  3.2669],\n",
      "         [ 0.8427, -0.7295, -1.4133,  ...,  3.6157,  0.6608,  3.6692]],\n",
      "\n",
      "        [[-0.0000, -1.1219, -0.0000,  ...,  0.0000,  0.8834,  2.9377],\n",
      "         [ 0.9035, -1.4662,  0.1286,  ...,  3.5435,  0.1073,  3.0152],\n",
      "         [ 0.9550, -3.8752,  0.7436,  ...,  3.3431,  0.4726,  3.5678],\n",
      "         ...,\n",
      "         [-1.8346, -2.8342, -1.8812,  ...,  3.6902,  1.3037,  2.8394],\n",
      "         [-1.1976, -0.6999, -2.4740,  ...,  3.6558,  0.8427,  2.7830],\n",
      "         [ 1.3726, -0.6079, -1.8969,  ...,  1.4900,  1.0750,  2.9321]],\n",
      "\n",
      "        [[-0.4323, -0.0000, -0.6996,  ...,  3.6766,  0.0000,  3.6479],\n",
      "         [ 0.7788, -1.6580,  0.4578,  ...,  3.8201,  0.1874,  3.3920],\n",
      "         [ 1.1260, -3.3245,  1.2525,  ...,  3.6703,  0.8086,  0.0000],\n",
      "         ...,\n",
      "         [-2.9992, -1.5191, -1.8911,  ...,  0.0000,  0.1107,  3.5067],\n",
      "         [-0.0000, -0.9249, -2.4468,  ...,  3.8619,  0.1572,  3.6335],\n",
      "         [ 0.3306, -0.2745, -1.6010,  ...,  2.6889, -0.0000,  2.1382]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.4536, -0.5086,  0.0306,  ...,  3.4276,  0.3928,  3.0231],\n",
      "         [ 1.0644, -1.5255,  1.2295,  ...,  2.8875,  0.7477,  2.9364],\n",
      "         [ 0.6240, -1.8921,  0.6395,  ...,  3.4259,  0.5294,  2.7816],\n",
      "         ...,\n",
      "         [-2.7925, -1.6272, -1.5603,  ...,  3.8385,  1.3931,  2.4393],\n",
      "         [-1.2683, -0.0000, -2.9160,  ...,  3.4009,  1.2458,  2.8350],\n",
      "         [ 0.3721, -0.4674, -1.5050,  ...,  4.0763,  0.7820,  2.9339]],\n",
      "\n",
      "        [[-0.9724, -0.4109, -1.1830,  ...,  2.4040,  0.7367,  3.0765],\n",
      "         [ 0.0000, -1.4304,  1.1224,  ...,  3.6797,  0.8050,  0.0000],\n",
      "         [-0.1646, -1.9995,  1.1168,  ...,  3.6385,  0.0000,  3.1887],\n",
      "         ...,\n",
      "         [-2.9679, -1.5535, -2.0932,  ...,  3.8696,  1.1395,  3.5420],\n",
      "         [-1.3642, -0.4110, -2.3279,  ...,  1.9499,  0.3269,  2.5149],\n",
      "         [ 0.5803, -0.4731, -2.2058,  ...,  3.5401,  1.1598,  3.3996]],\n",
      "\n",
      "        [[-0.9734, -1.3523, -0.4260,  ...,  1.7184, -0.3874,  3.7121],\n",
      "         [-0.3421, -0.0000,  1.6211,  ...,  3.4079, -0.0207,  3.6777],\n",
      "         [ 0.6813, -3.5122,  2.0293,  ...,  1.8867, -0.3139,  3.5165],\n",
      "         ...,\n",
      "         [-2.7826, -3.0995, -0.0000,  ...,  2.6013,  0.3148,  3.1676],\n",
      "         [-0.9794, -1.5295, -1.8027,  ...,  4.0239,  0.8091,  0.0000],\n",
      "         [ 0.8449, -0.2669, -2.1066,  ...,  3.8035,  1.3452,  3.5568]]],\n",
      "       device='cuda:0', grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 91, 2048])\n",
      "tensor([[[-1.2303e+02,  7.2536e+01,  0.0000e+00,  ..., -2.7637e+01,\n",
      "           9.8484e-03,  9.5118e+01],\n",
      "         [-1.5188e+02, -1.4156e+00, -4.9651e+01,  ..., -1.6306e+01,\n",
      "           1.9726e+01,  1.2007e+01],\n",
      "         [ 5.0120e+01,  3.0016e+01,  1.0835e+02,  ..., -2.9314e+00,\n",
      "           6.8697e+01, -0.0000e+00],\n",
      "         ...,\n",
      "         [-6.7748e+01, -1.2055e+01, -3.9737e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -0.0000e+00],\n",
      "         [-6.6831e+01, -1.1786e+01, -3.4453e+00,  ...,  7.9533e+01,\n",
      "           0.0000e+00, -7.8470e+01],\n",
      "         [-6.6794e+01, -1.2494e+01, -2.3993e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01]],\n",
      "\n",
      "        [[-1.2303e+02,  0.0000e+00,  5.5620e+01,  ..., -2.7637e+01,\n",
      "           9.8484e-03,  9.5118e+01],\n",
      "         [-4.0496e+01,  0.0000e+00, -1.1945e+01,  ...,  3.9531e+01,\n",
      "          -0.0000e+00,  4.7337e+01],\n",
      "         [ 2.5161e+00,  1.1041e+01,  5.1205e+01,  ...,  3.2481e+01,\n",
      "           3.8348e+00,  2.9763e+01],\n",
      "         ...,\n",
      "         [-6.7748e+01, -1.2055e+01, -0.0000e+00,  ...,  0.0000e+00,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6831e+01, -1.1786e+01, -0.0000e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6794e+01, -1.2494e+01, -2.3993e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01]],\n",
      "\n",
      "        [[-1.2303e+02,  7.2536e+01,  5.5620e+01,  ..., -2.7637e+01,\n",
      "           0.0000e+00,  9.5118e+01],\n",
      "         [-0.0000e+00, -1.1223e+01,  1.0604e+01,  ..., -1.9363e+01,\n",
      "          -4.3592e+01,  4.8487e+01],\n",
      "         [ 5.6516e+00, -0.0000e+00, -5.5329e+01,  ...,  2.8529e-01,\n",
      "           1.4261e+00, -4.8541e+01],\n",
      "         ...,\n",
      "         [-6.7748e+01, -1.2055e+01, -3.9737e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6831e+01, -1.1786e+01, -3.4453e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-0.0000e+00, -1.2494e+01, -2.3993e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.2303e+02,  7.2536e+01,  5.5620e+01,  ..., -2.7637e+01,\n",
      "           0.0000e+00,  9.5118e+01],\n",
      "         [-1.5188e+02, -1.4156e+00, -4.9651e+01,  ..., -1.6306e+01,\n",
      "           1.9726e+01,  0.0000e+00],\n",
      "         [ 5.0120e+01,  3.0016e+01,  1.0835e+02,  ..., -0.0000e+00,\n",
      "           6.8697e+01, -3.2877e+01],\n",
      "         ...,\n",
      "         [-6.7748e+01, -1.2055e+01, -3.9737e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6831e+01, -0.0000e+00, -3.4453e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-0.0000e+00, -1.2494e+01, -2.3993e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01]],\n",
      "\n",
      "        [[-1.2303e+02,  7.2536e+01,  0.0000e+00,  ..., -2.7637e+01,\n",
      "           9.8484e-03,  9.5118e+01],\n",
      "         [-0.0000e+00,  3.6343e+01, -6.0290e+01,  ..., -0.0000e+00,\n",
      "          -1.2621e+01,  4.2879e+01],\n",
      "         [-8.1019e+01,  4.0549e+01,  2.6001e+01,  ..., -7.6764e+01,\n",
      "           0.0000e+00,  1.6434e+00],\n",
      "         ...,\n",
      "         [-6.7748e+01, -1.2055e+01, -0.0000e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6831e+01, -1.1786e+01, -0.0000e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6794e+01, -1.2494e+01, -0.0000e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01]],\n",
      "\n",
      "        [[-1.2303e+02,  7.2536e+01,  5.5620e+01,  ..., -2.7637e+01,\n",
      "           9.8484e-03,  9.5118e+01],\n",
      "         [ 3.5964e+01,  3.7943e+01,  9.2949e+00,  ..., -4.6398e+01,\n",
      "          -0.0000e+00,  7.5659e+01],\n",
      "         [-0.0000e+00, -4.4807e+01,  1.3811e+01,  ..., -3.2780e+01,\n",
      "          -1.3976e+01,  4.3960e+01],\n",
      "         ...,\n",
      "         [-6.7748e+01, -1.2055e+01, -3.9737e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6831e+01, -1.1786e+01, -0.0000e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6794e+01, -0.0000e+00, -2.3993e+00,  ...,  7.9533e+01,\n",
      "           0.0000e+00, -7.8470e+01]]], device='cuda:0',\n",
      "       grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 91, 2048])\n",
      "tensor([[[-2.3513,  0.0000,  1.3804,  ...,  0.9279, -0.1610,  2.7753],\n",
      "         [-1.5570,  1.9968,  0.7077,  ...,  1.9249,  0.4416,  1.8460],\n",
      "         [ 2.2905,  1.1803,  4.0439,  ...,  1.8714,  0.9944,  1.3239],\n",
      "         ...,\n",
      "         [-0.5106,  2.0354, -0.2440,  ...,  3.6552,  0.0000,  1.3999],\n",
      "         [-0.1427,  1.8691,  0.4376,  ...,  3.4431,  0.0160,  0.0388],\n",
      "         [ 0.3526,  0.8437,  0.0000,  ...,  3.4450,  0.8500, -0.4090]],\n",
      "\n",
      "        [[-1.5511,  2.7029,  2.4912,  ...,  1.6271, -0.6408,  3.0320],\n",
      "         [ 0.3196,  1.8272,  2.1488,  ...,  0.0000, -0.7963,  1.8626],\n",
      "         [ 1.3790,  0.0204,  3.1376,  ...,  2.9809, -0.4089,  1.7819],\n",
      "         ...,\n",
      "         [-1.1153,  1.1046, -0.2321,  ...,  2.6168,  0.4733, -0.2014],\n",
      "         [ 0.5274,  1.5806,  0.0000,  ...,  4.3987,  0.6408,  0.1921],\n",
      "         [-0.1888,  0.5953,  1.9337,  ...,  4.1949,  1.3843,  0.0520]],\n",
      "\n",
      "        [[-1.9341,  3.3071,  2.0994,  ...,  1.0150, -0.5693,  3.0342],\n",
      "         [ 1.2070,  1.4900,  2.2574,  ...,  1.2284, -0.8009,  2.5860],\n",
      "         [ 1.8153,  0.1950,  0.7895,  ...,  0.0000,  0.0401,  0.7090],\n",
      "         ...,\n",
      "         [-0.3418,  0.6078, -0.0000,  ...,  3.4119,  1.0315, -0.0988],\n",
      "         [ 0.0389,  1.3543,  0.2931,  ...,  3.1132,  0.8689,  0.0000],\n",
      "         [ 1.4102,  0.5864,  1.4064,  ...,  3.0336,  0.0000, -0.2486]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.4207,  3.3457,  2.4380,  ...,  0.0000, -0.1357,  3.0277],\n",
      "         [-2.7516,  2.2214,  0.4848,  ...,  0.0000,  0.0000,  2.3922],\n",
      "         [ 2.2712,  0.5339,  4.5683,  ...,  1.8333,  1.5102,  0.0000],\n",
      "         ...,\n",
      "         [-0.7538,  1.4365, -0.3615,  ...,  3.6183,  1.4000,  0.0047],\n",
      "         [ 0.3568,  1.4169,  0.5915,  ...,  2.8712,  1.8846,  0.0392],\n",
      "         [ 1.5661,  0.8919,  0.0000,  ...,  0.0000,  1.1608, -0.1013]],\n",
      "\n",
      "        [[-0.0000,  3.4888,  1.3213,  ...,  0.7452, -0.3093,  3.4905],\n",
      "         [ 2.2224,  1.8977,  1.4554,  ...,  1.8734, -0.0000,  0.0000],\n",
      "         [-0.1041,  1.4289,  0.0000,  ..., -0.3114, -0.0603,  1.0385],\n",
      "         ...,\n",
      "         [-0.0000,  0.6019, -0.0000,  ...,  3.4550,  1.0346, -0.2932],\n",
      "         [-0.0000,  1.5149,  0.6535,  ...,  3.2100,  1.2446,  0.3870],\n",
      "         [-0.2681,  1.1019,  0.0000,  ...,  3.9564,  0.0000, -0.3558]],\n",
      "\n",
      "        [[-2.0101,  3.6568,  2.3377,  ...,  1.0758, -0.4800,  2.6746],\n",
      "         [ 2.6978,  1.2769,  1.7732,  ...,  0.9991,  0.8910,  2.8918],\n",
      "         [ 2.3105, -0.4413,  0.0000,  ...,  0.8115,  0.0000,  2.9045],\n",
      "         ...,\n",
      "         [-0.5396,  1.2194,  0.0000,  ...,  3.5430,  1.0003, -0.0000],\n",
      "         [ 0.0381,  1.6727,  0.8220,  ...,  3.3122,  1.0956, -0.4755],\n",
      "         [-0.2189,  1.4844,  1.2504,  ...,  3.8780,  0.0909,  0.4339]]],\n",
      "       device='cuda:0', grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 91, 2048])\n",
      "tensor([[[-1.1342e+00,  4.4515e-01,  2.0139e+00,  ...,  1.4476e+00,\n",
      "          -1.0703e+00,  2.2219e+00],\n",
      "         [ 9.2979e-02,  1.5553e+00,  2.3100e+00,  ...,  0.0000e+00,\n",
      "          -4.3796e-01,  1.3997e+00],\n",
      "         [ 0.0000e+00,  1.1433e-01,  5.0716e+00,  ...,  2.0742e+00,\n",
      "          -2.0487e-01,  1.3969e+00],\n",
      "         ...,\n",
      "         [ 2.1304e-03,  1.8473e+00, -2.7488e-01,  ...,  0.0000e+00,\n",
      "          -4.2254e-01,  0.0000e+00],\n",
      "         [ 1.2858e+00,  1.7901e+00,  9.5198e-01,  ...,  3.2400e+00,\n",
      "          -4.0431e-01,  6.2789e-01],\n",
      "         [ 1.7830e+00,  6.7965e-01,  1.4779e+00,  ...,  3.0283e+00,\n",
      "           1.6347e-01,  3.7590e-01]],\n",
      "\n",
      "        [[-2.3186e-01,  0.0000e+00,  2.4804e+00,  ...,  2.6189e+00,\n",
      "          -8.0623e-01,  2.9563e+00],\n",
      "         [ 1.0528e+00,  1.5022e+00,  3.8209e+00,  ...,  1.3769e+00,\n",
      "          -1.0511e+00,  1.6450e+00],\n",
      "         [ 2.3334e+00, -8.9990e-01,  4.6217e+00,  ...,  3.2995e+00,\n",
      "          -1.3812e+00,  1.9221e+00],\n",
      "         ...,\n",
      "         [-3.5582e-01,  1.0948e+00,  1.0690e-01,  ...,  3.1182e+00,\n",
      "          -1.7110e-01,  1.1408e+00],\n",
      "         [ 1.2995e+00,  1.7538e+00,  3.5934e-01,  ...,  4.1332e+00,\n",
      "          -2.1464e-01,  9.1119e-01],\n",
      "         [ 1.1678e+00,  5.0712e-01,  2.6655e+00,  ...,  4.0292e+00,\n",
      "           3.0965e-01,  9.8852e-01]],\n",
      "\n",
      "        [[-6.5400e-01,  2.6129e+00,  1.6497e+00,  ...,  1.6346e+00,\n",
      "          -7.8463e-01,  2.2590e+00],\n",
      "         [ 1.4878e+00,  4.4104e-01,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          -9.8003e-01,  0.0000e+00],\n",
      "         [ 2.4617e+00, -9.0067e-01,  3.0626e+00,  ...,  1.1085e+00,\n",
      "          -3.2852e-01,  8.8570e-01],\n",
      "         ...,\n",
      "         [-5.8511e-02,  6.7921e-01,  1.0131e-01,  ...,  2.9893e+00,\n",
      "           1.7487e-01,  5.7871e-01],\n",
      "         [ 1.4775e+00,  1.0912e+00,  9.0052e-01,  ...,  3.1614e+00,\n",
      "           2.3190e-01,  7.9203e-01],\n",
      "         [ 2.3616e+00, -4.9711e-01,  2.3681e+00,  ...,  2.9446e+00,\n",
      "          -5.9833e-01,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.0276e+00,  2.8198e+00,  2.5063e+00,  ...,  9.0235e-01,\n",
      "          -5.8397e-01,  2.3523e+00],\n",
      "         [-7.2817e-01,  2.0392e+00,  2.2695e+00,  ...,  1.2672e+00,\n",
      "          -0.0000e+00,  2.6803e+00],\n",
      "         [ 2.2542e+00, -4.2432e-01,  4.6592e+00,  ...,  2.1426e+00,\n",
      "           5.1028e-01,  9.8326e-01],\n",
      "         ...,\n",
      "         [-5.4811e-01,  1.0939e+00, -4.6447e-01,  ...,  3.2642e+00,\n",
      "           3.2484e-01,  9.3759e-01],\n",
      "         [ 0.0000e+00,  0.0000e+00,  6.0183e-01,  ...,  2.8503e+00,\n",
      "           5.8942e-01,  6.9062e-01],\n",
      "         [ 2.8470e+00,  5.8470e-01,  0.0000e+00,  ...,  1.3344e+00,\n",
      "          -9.3530e-02,  1.2107e+00]],\n",
      "\n",
      "        [[-0.0000e+00,  2.0177e+00,  2.1478e+00,  ...,  1.0384e+00,\n",
      "          -6.0738e-01,  2.8543e+00],\n",
      "         [ 2.3808e+00,  9.8140e-01,  0.0000e+00,  ...,  2.3343e+00,\n",
      "          -7.9605e-01,  8.6004e-01],\n",
      "         [ 6.7544e-01, -2.6717e-01,  2.4105e+00,  ...,  8.7497e-01,\n",
      "          -9.6334e-01,  1.2953e+00],\n",
      "         ...,\n",
      "         [-5.1674e-01,  2.0628e-01,  2.4435e-01,  ...,  3.0921e+00,\n",
      "           1.9447e-01,  5.9729e-01],\n",
      "         [ 1.1202e+00,  1.5044e+00,  9.8932e-01,  ...,  3.2500e+00,\n",
      "          -1.5528e-01,  1.1717e+00],\n",
      "         [ 5.7093e-01,  3.0902e-01,  0.0000e+00,  ...,  3.6922e+00,\n",
      "          -7.7306e-01,  8.3052e-01]],\n",
      "\n",
      "        [[-3.9673e-01,  2.9696e+00,  2.6734e+00,  ...,  2.0015e+00,\n",
      "          -6.3525e-01,  2.6161e+00],\n",
      "         [ 2.8694e+00,  4.0095e-01,  2.9984e+00,  ...,  1.7879e+00,\n",
      "           4.9226e-01,  2.8483e+00],\n",
      "         [ 2.9282e+00, -1.0205e+00,  2.1141e+00,  ...,  1.2859e+00,\n",
      "          -7.8014e-01,  2.4054e+00],\n",
      "         ...,\n",
      "         [ 2.7448e-01,  9.9304e-01, -4.6119e-01,  ...,  3.4513e+00,\n",
      "           3.4436e-01,  9.4359e-01],\n",
      "         [ 1.4306e+00,  1.6120e+00,  4.7294e-01,  ...,  0.0000e+00,\n",
      "           2.5693e-01,  5.3757e-01],\n",
      "         [ 1.0177e+00,  0.0000e+00,  2.2489e+00,  ...,  3.6314e+00,\n",
      "          -1.7287e-01,  1.4281e+00]]], device='cuda:0',\n",
      "       grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 91, 2048])\n",
      "tensor([[[-1.1558,  0.6123,  1.5642,  ...,  1.6705, -0.7140,  1.7488],\n",
      "         [ 0.7767,  0.0376,  2.3298,  ...,  0.0000, -0.6345,  1.4138],\n",
      "         [ 0.3560, -0.0000,  4.4642,  ...,  2.0504, -0.6366,  1.9467],\n",
      "         ...,\n",
      "         [-0.3058,  0.0000, -0.6891,  ...,  1.0677, -0.2907,  1.5315],\n",
      "         [ 1.4831,  0.9534,  0.0000,  ...,  2.1663, -0.5231,  1.0914],\n",
      "         [ 1.2131,  0.1857,  2.0054,  ...,  2.8084, -0.2645,  1.3074]],\n",
      "\n",
      "        [[-0.9283,  0.0224,  1.5588,  ...,  0.0000, -0.0000,  2.6320],\n",
      "         [ 0.8122,  0.2415,  3.3578,  ...,  2.3679, -0.9024,  1.7858],\n",
      "         [ 1.5133, -1.8236,  3.6490,  ...,  3.4734, -1.1862,  2.3116],\n",
      "         ...,\n",
      "         [-0.5124,  0.5210, -0.6070,  ...,  2.7490, -0.5440,  1.6928],\n",
      "         [ 1.0781,  1.0972, -0.0000,  ...,  3.3943, -0.4242,  1.8997],\n",
      "         [ 1.2275, -0.2889,  2.3034,  ...,  3.4583, -0.4384,  1.6072]],\n",
      "\n",
      "        [[-0.6413,  1.1040,  1.5672,  ...,  1.7236, -0.8731,  1.7293],\n",
      "         [ 1.2258,  0.0643,  2.1207,  ...,  1.6305, -0.7792,  0.8701],\n",
      "         [ 0.0000, -1.8645,  3.5762,  ...,  0.0000, -0.6295,  1.2923],\n",
      "         ...,\n",
      "         [-0.3474,  0.2996, -0.2756,  ...,  2.1625, -0.2392,  1.3132],\n",
      "         [ 1.3571,  0.6137,  0.7258,  ...,  2.5479, -0.3540,  1.4000],\n",
      "         [ 1.6260, -0.5980,  2.1552,  ...,  2.5628, -0.7297,  1.2956]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.2539,  1.3526,  2.1106,  ...,  1.5068, -0.8117,  1.9339],\n",
      "         [ 0.0091,  1.0796,  2.2714,  ...,  1.6606, -0.5270,  2.3292],\n",
      "         [ 1.4064, -1.3291,  3.5258,  ...,  2.2280, -0.1571,  1.4970],\n",
      "         ...,\n",
      "         [-0.4861,  0.1393, -0.0000,  ...,  2.7560, -0.1111,  1.3891],\n",
      "         [ 0.3757,  0.4452,  0.2942,  ...,  0.0000, -0.0554,  1.6596],\n",
      "         [ 1.2775,  0.1020,  0.5324,  ...,  1.8710, -0.0000,  1.3663]],\n",
      "\n",
      "        [[-0.1210,  1.1121,  1.9699,  ...,  1.5436, -0.8606,  2.5887],\n",
      "         [ 1.4671,  0.0910,  2.0825,  ...,  0.0000, -1.0913,  1.0980],\n",
      "         [ 0.6652, -1.3399,  0.0000,  ...,  1.4234, -1.1603,  1.3133],\n",
      "         ...,\n",
      "         [-0.4216,  0.1234, -0.2011,  ...,  2.4955, -0.0000,  1.3918],\n",
      "         [ 1.3057,  0.7026,  0.8984,  ...,  0.0000, -0.6694,  0.0000],\n",
      "         [ 0.6380, -0.6439,  1.5128,  ...,  0.0000, -1.0863,  1.1477]],\n",
      "\n",
      "        [[-1.1999,  1.9126,  2.3656,  ...,  2.2949, -0.2805,  2.3807],\n",
      "         [ 2.5384, -0.4103,  3.0214,  ...,  2.1310,  0.2303,  2.0550],\n",
      "         [ 2.1373, -1.4932,  2.5520,  ...,  1.4349, -0.3653,  2.2734],\n",
      "         ...,\n",
      "         [-0.7319,  0.5457, -0.6874,  ...,  2.9592,  0.0480,  1.6801],\n",
      "         [ 1.2820,  0.6673,  0.1496,  ...,  1.2910, -0.0154,  1.2391],\n",
      "         [ 0.4967, -0.1431,  1.9857,  ...,  2.5404, -0.4382,  0.0000]]],\n",
      "       device='cuda:0', grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 91, 2048])\n",
      "tensor([[[-1.9526e+00,  1.0236e+00,  3.3140e-01,  ...,  1.5538e+00,\n",
      "          -3.9497e-01,  1.9891e+00],\n",
      "         [ 6.3792e-01,  2.2191e-01,  1.7866e+00,  ...,  9.4820e-01,\n",
      "          -4.7314e-01,  1.4299e+00],\n",
      "         [ 1.2905e-01, -7.2055e-01,  2.8988e+00,  ...,  0.0000e+00,\n",
      "          -3.8080e-01,  1.6961e+00],\n",
      "         ...,\n",
      "         [-1.8557e+00,  7.5206e-01, -0.0000e+00,  ...,  1.2959e+00,\n",
      "           1.3844e-03,  1.4116e+00],\n",
      "         [ 2.5145e-01,  1.2449e+00, -0.0000e+00,  ...,  1.8899e+00,\n",
      "          -1.9656e-01,  1.6519e+00],\n",
      "         [ 0.0000e+00,  1.9420e-01,  9.8579e-01,  ...,  2.1940e+00,\n",
      "          -5.9150e-01,  1.6597e+00]],\n",
      "\n",
      "        [[-1.8862e+00,  4.6220e-02,  3.6865e-01,  ...,  9.8398e-01,\n",
      "          -0.0000e+00,  1.9792e+00],\n",
      "         [ 1.0903e-01, -4.3258e-02,  2.1043e+00,  ...,  0.0000e+00,\n",
      "          -6.4945e-01,  1.8694e+00],\n",
      "         [ 1.3079e-01, -1.2921e+00,  2.2197e+00,  ...,  2.7776e+00,\n",
      "          -1.0000e+00,  2.0327e+00],\n",
      "         ...,\n",
      "         [-1.5644e+00,  6.0652e-01, -2.2972e+00,  ...,  2.2906e+00,\n",
      "          -7.6053e-01,  2.1059e+00],\n",
      "         [-2.7241e-01,  1.0560e+00, -1.0846e+00,  ...,  3.2946e+00,\n",
      "          -7.9451e-01,  1.9736e+00],\n",
      "         [ 9.7849e-02, -1.2869e-01,  7.7136e-01,  ...,  2.6094e+00,\n",
      "          -5.7416e-01,  1.9451e+00]],\n",
      "\n",
      "        [[-1.7287e+00,  7.2033e-01,  0.0000e+00,  ...,  1.6776e+00,\n",
      "          -9.4393e-01,  1.7875e+00],\n",
      "         [ 1.0809e-01, -1.2444e-01,  1.7590e+00,  ...,  0.0000e+00,\n",
      "          -6.2987e-01,  1.2024e+00],\n",
      "         [-5.9349e-01, -1.5599e+00,  2.4662e+00,  ...,  7.0708e-01,\n",
      "          -6.8592e-01,  0.0000e+00],\n",
      "         ...,\n",
      "         [-1.4725e+00,  3.8291e-01, -1.5212e+00,  ...,  1.7856e+00,\n",
      "          -3.5023e-01,  1.5965e+00],\n",
      "         [ 1.8017e-02,  1.1034e+00, -0.0000e+00,  ...,  2.1183e+00,\n",
      "          -4.7681e-01,  1.5925e+00],\n",
      "         [ 7.4732e-02, -2.3975e-01,  9.8236e-01,  ...,  0.0000e+00,\n",
      "          -9.4623e-01,  1.6391e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.6520e+00,  1.5987e+00,  8.1130e-01,  ...,  1.8341e+00,\n",
      "          -2.9260e-01,  1.7917e+00],\n",
      "         [-5.0913e-01,  9.1123e-01,  1.2225e+00,  ...,  1.8505e+00,\n",
      "          -6.1306e-01,  2.4218e+00],\n",
      "         [ 1.4286e-01, -1.3817e+00,  0.0000e+00,  ...,  2.1386e+00,\n",
      "          -3.6086e-01,  2.0787e+00],\n",
      "         ...,\n",
      "         [-1.9979e+00,  4.8375e-01, -9.8602e-01,  ...,  2.1066e+00,\n",
      "          -2.5545e-01,  1.7960e+00],\n",
      "         [-5.6301e-01,  1.0015e+00, -1.0421e+00,  ...,  8.8988e-01,\n",
      "          -5.6809e-01,  2.2872e+00],\n",
      "         [-1.0897e-02,  0.0000e+00,  1.1347e-01,  ...,  1.8840e+00,\n",
      "          -4.2225e-01,  2.2277e+00]],\n",
      "\n",
      "        [[-1.3493e+00,  1.2307e+00,  7.1554e-01,  ...,  2.2181e+00,\n",
      "          -1.0219e+00,  1.9696e+00],\n",
      "         [ 1.5867e-01,  1.4793e-01,  2.1709e+00,  ...,  1.1733e+00,\n",
      "          -9.0587e-01,  1.7118e+00],\n",
      "         [-3.1098e-01, -2.0860e+00,  8.9278e-01,  ...,  1.4853e+00,\n",
      "          -7.9227e-01,  0.0000e+00],\n",
      "         ...,\n",
      "         [-2.1777e+00,  5.7373e-01, -1.5935e+00,  ...,  2.4030e+00,\n",
      "          -2.2613e-01,  1.8373e+00],\n",
      "         [ 2.1507e-02,  6.7458e-01, -3.6960e-01,  ...,  9.4816e-01,\n",
      "          -6.1022e-01,  1.3684e+00],\n",
      "         [-3.8321e-01, -2.5127e-01,  7.9774e-01,  ...,  1.3016e+00,\n",
      "          -9.3258e-01,  1.5745e+00]],\n",
      "\n",
      "        [[-1.1745e+00,  8.7266e-01,  7.2060e-01,  ...,  2.3392e+00,\n",
      "          -1.5514e-01,  2.5693e+00],\n",
      "         [ 3.8798e-01,  2.6870e-01,  1.6194e+00,  ...,  2.2764e+00,\n",
      "           8.9352e-02,  2.6368e+00],\n",
      "         [ 1.0672e+00, -1.1700e+00,  1.8680e+00,  ...,  1.6885e+00,\n",
      "          -2.2728e-01,  2.1804e+00],\n",
      "         ...,\n",
      "         [-1.8600e+00,  0.0000e+00, -1.7959e+00,  ...,  2.3128e+00,\n",
      "          -0.0000e+00,  2.2090e+00],\n",
      "         [ 6.5439e-01,  1.1403e+00, -9.0870e-01,  ...,  1.4533e+00,\n",
      "          -0.0000e+00,  1.5817e+00],\n",
      "         [-1.9180e-01, -4.6820e-01,  5.4261e-01,  ...,  2.1450e+00,\n",
      "          -4.6664e-01,  1.7062e+00]]], device='cuda:0',\n",
      "       grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 90, 2048])\n",
      "tensor([[[ -64.7824,    0.0000,   13.4799,  ...,   -0.0000,   15.9771,\n",
      "           120.2854],\n",
      "         [  32.1103,  -11.5790,   -9.0660,  ...,  -24.0485,  -38.4529,\n",
      "            39.7281],\n",
      "         [  64.3550,  -58.8240, -105.8307,  ...,   58.8417,  -44.3641,\n",
      "           -91.7171],\n",
      "         ...,\n",
      "         [ -68.7001,  -13.0567,   -3.5143,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         [ -67.7476,  -12.0546,   -0.0000,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         [ -66.8313,  -11.7860,   -3.4453,  ...,   79.5327,   67.9524,\n",
      "           -78.4697]],\n",
      "\n",
      "        [[  47.5857, -126.8375,  -76.6064,  ...,   32.9708,   23.2197,\n",
      "            40.2663],\n",
      "         [ -66.8520,  -12.2570,   -1.9392,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         [ -66.7766,  -13.3099,   -1.8372,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         ...,\n",
      "         [ -68.7001,  -13.0567,   -3.5143,  ...,   79.5327,    0.0000,\n",
      "           -78.4697],\n",
      "         [ -67.7476,  -12.0546,   -3.9737,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         [ -66.8313,  -11.7860,   -0.0000,  ...,   79.5327,   67.9524,\n",
      "           -78.4697]],\n",
      "\n",
      "        [[  86.3852,   49.8759,    6.1185,  ...,   77.6506,  -21.4816,\n",
      "            -0.0000],\n",
      "         [ -13.4382,   34.8707,   15.1650,  ...,   50.2013,  -11.3913,\n",
      "            41.3254],\n",
      "         [ -66.7766,   -0.0000,   -1.8372,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         ...,\n",
      "         [ -68.7001,   -0.0000,   -3.5143,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         [ -67.7476,  -12.0546,   -3.9737,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         [ -66.8313,  -11.7860,   -3.4453,  ...,   79.5327,   67.9524,\n",
      "            -0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  -4.5191,   50.5624,  100.9430,  ...,    5.9596,   -8.0915,\n",
      "             7.4169],\n",
      "         [  21.1834,  -32.8019,    2.5135,  ...,  -12.0731,    0.6595,\n",
      "            67.8677],\n",
      "         [  27.7895,    0.0000,  -12.3497,  ...,   55.1011,   52.1685,\n",
      "            16.2631],\n",
      "         ...,\n",
      "         [ -68.7001,  -13.0567,   -3.5143,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         [ -67.7476,  -12.0546,   -3.9737,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         [ -66.8313,  -11.7860,   -3.4453,  ...,   79.5327,   67.9524,\n",
      "           -78.4697]],\n",
      "\n",
      "        [[  86.3852,   49.8759,    6.1185,  ...,   77.6506,  -21.4816,\n",
      "           -41.2875],\n",
      "         [ -13.4382,   34.8707,   15.1650,  ...,   50.2013,   -0.0000,\n",
      "            41.3254],\n",
      "         [  -0.0000,  -13.3099,   -1.8372,  ...,   79.5327,   67.9524,\n",
      "            -0.0000],\n",
      "         ...,\n",
      "         [ -68.7001,  -13.0567,   -3.5143,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         [ -67.7476,  -12.0546,   -3.9737,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         [ -66.8313,  -11.7860,   -3.4453,  ...,   79.5327,   67.9524,\n",
      "           -78.4697]],\n",
      "\n",
      "        [[ -28.4509,   34.1838,   42.0307,  ...,  -71.1576,   35.5508,\n",
      "            -0.0000],\n",
      "         [ -66.8520,  -12.2570,   -1.9392,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         [ -66.7766,  -13.3099,   -1.8372,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         ...,\n",
      "         [ -68.7001,  -13.0567,   -3.5143,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         [ -67.7476,  -12.0546,   -3.9737,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         [ -66.8313,  -11.7860,   -3.4453,  ...,    0.0000,   67.9524,\n",
      "           -78.4697]]], device='cuda:0', grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 90, 2048])\n",
      "tensor([[[-0.5546,  1.6641,  1.5275,  ...,  3.1609,  0.0000,  4.1746],\n",
      "         [ 2.6938,  0.7158,  1.9532,  ...,  1.5716, -0.7816,  0.0000],\n",
      "         [ 3.5095, -1.5110,  0.0000,  ...,  3.2680, -0.8452,  0.2275],\n",
      "         ...,\n",
      "         [-1.5284,  0.5671,  0.0000,  ...,  4.1844,  1.6116, -0.3102],\n",
      "         [ 0.4149,  1.8514, -0.0000,  ...,  4.4746,  1.9773, -0.1295],\n",
      "         [ 0.3358,  1.5567,  0.0000,  ...,  3.5578,  1.5642,  0.2812]],\n",
      "\n",
      "        [[ 2.0129, -0.9846, -0.0000,  ...,  2.2509,  0.5607,  3.0923],\n",
      "         [ 0.8740,  0.3078,  2.6604,  ...,  3.5482,  0.0000,  0.5952],\n",
      "         [ 1.0845, -0.7898,  2.4712,  ...,  3.6327,  1.1452,  0.5823],\n",
      "         ...,\n",
      "         [-0.9973,  0.1327,  0.7738,  ...,  3.2666, -0.2071,  0.3021],\n",
      "         [-0.3670,  1.0153,  0.0766,  ...,  0.0000,  0.0000,  0.1682],\n",
      "         [ 0.8716,  0.8292,  0.9568,  ...,  3.4354,  1.1277,  0.2837]],\n",
      "\n",
      "        [[ 2.6426,  2.6228,  1.2086,  ...,  3.5434, -0.5934,  1.4937],\n",
      "         [ 1.1159,  2.3390,  1.8424,  ...,  2.9681,  0.2008,  2.8753],\n",
      "         [ 0.0000, -0.0990,  2.3821,  ...,  3.6809,  1.3958, -0.0643],\n",
      "         ...,\n",
      "         [-0.0000,  0.0948,  0.6129,  ...,  3.6008,  1.4293, -0.3720],\n",
      "         [-0.2068,  1.1204,  0.0621,  ...,  3.4586,  1.8700, -0.0000],\n",
      "         [ 1.1194,  0.0000,  0.9450,  ...,  3.8155,  1.5974,  1.5842]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.2523,  3.4590,  2.9843,  ...,  1.6882,  0.2716,  1.5468],\n",
      "         [ 1.9176,  1.0247,  1.6020,  ...,  1.6438,  0.0000,  3.3074],\n",
      "         [ 1.7779,  0.3546,  2.7740,  ...,  3.5320,  0.8417,  2.2641],\n",
      "         ...,\n",
      "         [-1.7024, -0.5480,  0.0897,  ...,  3.6048,  1.6460, -0.6219],\n",
      "         [-0.6231, -0.0461, -0.1537,  ...,  3.6780,  1.0169, -0.3550],\n",
      "         [ 0.0381,  0.3792,  0.5721,  ...,  4.0199,  1.5460, -0.3106]],\n",
      "\n",
      "        [[ 2.2537,  2.8628,  1.2390,  ...,  3.9091, -0.3739,  0.7483],\n",
      "         [ 0.0000,  2.0251,  1.6457,  ...,  2.9494,  1.2783,  2.8328],\n",
      "         [ 2.3770, -0.3427,  2.7571,  ...,  0.0000,  1.5108,  1.6262],\n",
      "         ...,\n",
      "         [-0.8552,  0.1848,  0.9255,  ...,  3.9592,  1.5409, -0.1965],\n",
      "         [-0.0581,  1.7558,  0.3822,  ...,  4.0697,  1.8471, -0.0000],\n",
      "         [ 1.0331,  1.5255,  0.8553,  ...,  3.9011,  1.7560, -0.2954]],\n",
      "\n",
      "        [[ 0.0664,  2.7160,  1.8089,  ...,  0.3934,  0.7577,  1.2353],\n",
      "         [ 0.8735,  0.9342,  2.0737,  ...,  4.0729,  0.8508, -0.2509],\n",
      "         [ 0.7206,  0.0347,  1.5698,  ...,  3.8650,  0.0000, -0.1790],\n",
      "         ...,\n",
      "         [-2.1495,  0.1689,  0.0974,  ...,  4.3709,  1.0469, -0.6147],\n",
      "         [-0.0000,  1.4555, -0.2911,  ...,  3.8905,  0.8094, -0.4071],\n",
      "         [ 0.0000,  1.5750,  0.0893,  ...,  1.9541,  0.8948, -0.0000]]],\n",
      "       device='cuda:0', grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 90, 2048])\n",
      "tensor([[[ 4.1957e-01,  1.1654e+00,  1.8410e+00,  ...,  4.0229e+00,\n",
      "           4.1566e-01,  4.2822e+00],\n",
      "         [ 2.9962e+00, -3.3257e-01,  3.0559e+00,  ...,  2.8450e+00,\n",
      "          -1.2207e+00,  1.4082e+00],\n",
      "         [ 3.8409e+00, -2.3680e+00,  2.0445e+00,  ...,  3.8656e+00,\n",
      "          -4.0605e-01,  2.0149e+00],\n",
      "         ...,\n",
      "         [-1.2592e+00, -1.1985e+00,  6.6955e-01,  ...,  4.6965e+00,\n",
      "           1.3403e+00,  1.1049e+00],\n",
      "         [ 1.0767e+00,  1.0082e+00, -7.1864e-02,  ...,  0.0000e+00,\n",
      "           1.6974e+00,  1.3516e+00],\n",
      "         [ 1.8167e+00,  9.6347e-01,  5.9680e-01,  ...,  4.3289e+00,\n",
      "           1.2060e+00,  1.6463e+00]],\n",
      "\n",
      "        [[ 1.7169e+00, -9.5165e-01,  5.8043e-01,  ...,  2.6372e+00,\n",
      "          -2.4438e-01,  3.9523e+00],\n",
      "         [ 2.0351e+00, -0.0000e+00,  3.5979e+00,  ...,  2.7261e+00,\n",
      "          -5.4253e-01,  0.0000e+00],\n",
      "         [ 2.3388e+00, -0.0000e+00,  0.0000e+00,  ...,  3.1416e+00,\n",
      "           2.3970e-01,  2.4182e+00],\n",
      "         ...,\n",
      "         [-1.3552e+00, -1.2600e+00,  6.4870e-01,  ...,  0.0000e+00,\n",
      "          -5.3329e-01,  2.1110e+00],\n",
      "         [ 5.2194e-01, -4.9223e-01,  3.1927e-02,  ...,  1.0554e+00,\n",
      "          -4.6080e-01,  0.0000e+00],\n",
      "         [ 1.9970e+00,  1.8532e-01,  8.1368e-01,  ...,  3.7502e+00,\n",
      "           4.0628e-01,  2.2841e+00]],\n",
      "\n",
      "        [[ 1.6839e+00,  1.3380e+00,  1.1602e+00,  ...,  4.0919e+00,\n",
      "          -9.1462e-01,  0.0000e+00],\n",
      "         [ 1.6019e+00,  7.2137e-01,  0.0000e+00,  ...,  3.4805e+00,\n",
      "           0.0000e+00,  3.3512e+00],\n",
      "         [ 1.2072e+00, -1.7049e+00,  3.4742e+00,  ...,  3.8952e+00,\n",
      "           1.1115e+00,  1.3325e+00],\n",
      "         ...,\n",
      "         [-7.7301e-01, -1.7234e+00,  5.7667e-01,  ...,  0.0000e+00,\n",
      "           1.0155e+00,  1.1759e+00],\n",
      "         [ 4.7194e-03,  3.3525e-01, -5.0645e-01,  ...,  3.7839e+00,\n",
      "           2.1288e+00,  1.5854e+00],\n",
      "         [ 1.7843e+00, -1.5314e-01,  7.0451e-01,  ...,  4.3043e+00,\n",
      "           1.7081e+00,  2.5038e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.3675e+00,  0.0000e+00,  2.2774e+00,  ...,  2.8051e+00,\n",
      "           3.2613e-01,  2.7022e+00],\n",
      "         [ 2.7410e+00,  1.2641e-01,  2.3330e+00,  ...,  2.6310e+00,\n",
      "           3.5389e-01,  3.8774e+00],\n",
      "         [ 2.9918e+00, -1.6270e+00,  3.6094e+00,  ...,  4.2178e+00,\n",
      "           8.9162e-01,  3.0975e+00],\n",
      "         ...,\n",
      "         [-1.5279e+00, -1.9221e+00, -2.4029e-01,  ...,  4.1607e+00,\n",
      "           0.0000e+00,  1.6927e+00],\n",
      "         [-1.4994e-02, -5.9637e-01, -5.3321e-01,  ...,  4.1541e+00,\n",
      "           1.1846e+00,  0.0000e+00],\n",
      "         [ 1.1601e+00, -1.7911e-01,  4.4298e-01,  ...,  4.5885e+00,\n",
      "           1.4372e+00,  1.9280e+00]],\n",
      "\n",
      "        [[ 1.1592e+00,  0.0000e+00,  1.0208e+00,  ...,  3.8579e+00,\n",
      "          -0.0000e+00,  1.6835e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  2.2868e+00,  ...,  0.0000e+00,\n",
      "           1.6058e+00,  3.7285e+00],\n",
      "         [ 2.6180e+00, -1.9239e+00,  3.3828e+00,  ...,  1.7416e+00,\n",
      "           1.0445e+00,  2.2362e+00],\n",
      "         ...,\n",
      "         [-1.3604e+00, -1.4045e+00,  8.1076e-01,  ...,  4.1397e+00,\n",
      "           1.5660e+00,  1.2266e+00],\n",
      "         [ 2.4595e-01,  9.8357e-01, -1.1871e-01,  ...,  0.0000e+00,\n",
      "           1.6754e+00,  1.4570e+00],\n",
      "         [ 1.7994e+00,  1.2096e+00,  7.6811e-01,  ...,  4.3506e+00,\n",
      "           9.0100e-01,  0.0000e+00]],\n",
      "\n",
      "        [[-2.2266e-01,  2.0463e+00,  1.7901e+00,  ...,  1.9676e+00,\n",
      "           7.3814e-02,  2.1468e+00],\n",
      "         [ 1.3161e+00,  3.4963e-01,  3.0064e+00,  ...,  4.1244e+00,\n",
      "           1.6743e-03,  8.9622e-01],\n",
      "         [ 1.5009e+00, -1.4237e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          -3.5862e-02,  1.3578e+00],\n",
      "         ...,\n",
      "         [-1.8704e+00, -1.5162e+00,  1.3968e-01,  ...,  4.3797e+00,\n",
      "           8.0132e-01,  1.4743e+00],\n",
      "         [-0.0000e+00,  5.4449e-01, -3.6664e-01,  ...,  3.8966e+00,\n",
      "           4.3473e-01,  1.2609e+00],\n",
      "         [ 1.3161e+00,  9.7539e-01,  1.1448e-01,  ...,  2.5991e+00,\n",
      "           2.7844e-01,  1.6077e+00]]], device='cuda:0',\n",
      "       grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 90, 2048])\n",
      "tensor([[[-0.2436,  0.1663,  0.7811,  ...,  3.8094,  0.4759,  4.1558],\n",
      "         [ 2.2094, -1.2762,  0.0000,  ...,  3.2674, -0.5626,  2.3650],\n",
      "         [ 2.7840, -3.4480,  2.3031,  ...,  3.7899, -0.7122,  2.8040],\n",
      "         ...,\n",
      "         [-2.2712, -2.7668,  0.0830,  ...,  4.3824,  0.8765,  1.9647],\n",
      "         [ 0.2254, -0.5986, -0.6831,  ...,  2.2957,  1.1895,  2.6736],\n",
      "         [ 1.3753, -0.3647,  0.1110,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.4771, -1.6068,  0.6035,  ...,  3.0790, -0.6575,  3.8730],\n",
      "         [ 1.9115, -0.0000,  0.0000,  ...,  2.6599, -0.0000,  2.0707],\n",
      "         [ 2.0772, -2.6104,  1.0092,  ...,  3.4401,  0.0500,  2.6781],\n",
      "         ...,\n",
      "         [-1.8106, -2.9582,  0.2692,  ...,  1.7256, -0.3300,  3.1560],\n",
      "         [ 0.1058, -1.6875, -0.6568,  ...,  2.1557,  0.0877,  2.1216],\n",
      "         [ 1.4554, -0.9420, -0.0902,  ...,  3.4719,  0.0577,  3.7864]],\n",
      "\n",
      "        [[ 0.1693, -0.0073, -0.0538,  ...,  0.0000, -0.3025,  0.0000],\n",
      "         [ 1.2867, -0.7590,  0.5991,  ...,  3.6895,  0.0000,  0.0000],\n",
      "         [ 1.0319, -3.1926,  0.0000,  ...,  0.0000,  0.5186,  2.2167],\n",
      "         ...,\n",
      "         [-1.4188, -2.8413, -0.3114,  ...,  2.0706,  0.6864,  0.0000],\n",
      "         [-0.0500, -0.0000, -1.6558,  ...,  3.6139,  1.5124,  2.2657],\n",
      "         [ 1.3934, -0.9017, -0.1733,  ...,  4.1212,  0.4482,  2.8923]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.4862, -0.6227,  1.1478,  ...,  3.4076,  0.6288,  2.8896],\n",
      "         [ 2.1864, -1.0911,  2.1600,  ...,  2.9639,  0.5070,  3.4616],\n",
      "         [ 2.3475, -3.0254,  2.9564,  ...,  4.0490,  0.0000,  3.4838],\n",
      "         ...,\n",
      "         [-2.1258, -2.7709, -0.6006,  ...,  4.0829, -0.2998,  2.5353],\n",
      "         [-0.2060, -1.2600, -1.0873,  ...,  3.8584,  0.9657,  1.7359],\n",
      "         [ 1.1666, -1.0147, -0.2589,  ...,  4.1582,  1.3066,  2.9031]],\n",
      "\n",
      "        [[-0.3003, -0.7209,  0.2124,  ...,  3.7215,  0.2501,  2.1849],\n",
      "         [-0.1179, -1.1651,  2.2139,  ...,  1.8359,  1.2442,  3.4864],\n",
      "         [ 2.0864, -3.4132,  2.8542,  ...,  2.8950,  0.6763,  2.6408],\n",
      "         ...,\n",
      "         [-2.1790, -2.4755,  0.0169,  ...,  3.7685,  0.8585,  2.0259],\n",
      "         [-0.6405, -0.5087, -1.1663,  ...,  1.7751,  1.3227,  0.0000],\n",
      "         [ 0.9069, -0.1333, -0.1356,  ...,  0.0000,  0.9530,  1.7481]],\n",
      "\n",
      "        [[-0.1519,  0.0000,  1.4240,  ...,  2.5366, -0.2611,  2.3721],\n",
      "         [ 0.8120, -1.1890,  2.4819,  ...,  3.7138,  0.3076,  0.0000],\n",
      "         [ 1.8170, -2.7441,  1.3676,  ...,  1.6299,  0.0165,  2.9380],\n",
      "         ...,\n",
      "         [-2.4396, -2.9741, -0.3448,  ...,  3.7783,  0.7209,  2.7254],\n",
      "         [-0.3968, -0.6656, -0.0000,  ...,  3.4840,  0.7773,  2.5963],\n",
      "         [ 0.0000,  0.1133, -0.3919,  ...,  3.2154,  0.2189,  0.0000]]],\n",
      "       device='cuda:0', grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 90, 2048])\n",
      "tensor([[[-0.7721, -0.1308, -0.2738,  ...,  3.9289,  0.5127,  3.6934],\n",
      "         [ 0.8435, -0.0000,  0.0000,  ...,  3.6932, -0.1272,  2.8423],\n",
      "         [ 1.5111, -3.4722,  1.2490,  ...,  3.6087, -0.0000,  0.0000],\n",
      "         ...,\n",
      "         [-3.2213, -2.9315, -1.2439,  ...,  4.0063,  0.7041,  2.5760],\n",
      "         [-1.3753, -0.9088, -2.0416,  ...,  3.1235,  1.1339,  3.3389],\n",
      "         [ 0.3529, -0.6314, -1.3306,  ...,  1.8346,  0.5075,  1.6939]],\n",
      "\n",
      "        [[-0.8129, -1.1865, -1.1437,  ...,  3.2280, -0.5789,  4.1229],\n",
      "         [ 0.2972, -1.2103, -0.1323,  ...,  3.4771, -0.0065,  0.0000],\n",
      "         [ 1.1200, -3.1478,  0.6008,  ...,  3.3179, -0.1681,  3.1581],\n",
      "         ...,\n",
      "         [-2.5698, -3.1703, -1.9022,  ...,  2.6927, -0.0069,  3.4934],\n",
      "         [-1.0459, -1.7258, -2.2670,  ...,  2.7167, -0.1968,  3.0335],\n",
      "         [ 0.1918, -1.0119, -1.7114,  ...,  3.5898, -0.3659,  3.8901]],\n",
      "\n",
      "        [[-1.4555, -0.4781, -0.9627,  ...,  1.7409,  0.2944,  1.8194],\n",
      "         [-0.1019, -1.1842,  0.3316,  ...,  3.6494,  0.5077,  1.8288],\n",
      "         [ 0.2133, -3.4321,  0.2165,  ...,  2.1017, -0.1454,  2.6115],\n",
      "         ...,\n",
      "         [-2.8341, -3.1776, -1.6204,  ...,  2.8443,  0.8360,  1.6653],\n",
      "         [-1.2382, -0.7994, -2.8199,  ...,  3.5918,  1.1525,  2.5777],\n",
      "         [-0.0696, -0.4821, -1.5571,  ...,  3.9138,  0.5518,  3.1041]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.6471, -0.0000, -0.7245,  ...,  3.3883,  0.7626,  3.3068],\n",
      "         [ 0.8264, -1.1222,  0.0000,  ...,  3.2130,  0.0000,  3.3864],\n",
      "         [ 0.0000, -3.1711,  1.7280,  ...,  3.9560,  0.2573,  2.9230],\n",
      "         ...,\n",
      "         [-3.0896, -2.5755, -2.1973,  ...,  3.8863, -0.2496,  2.6206],\n",
      "         [-1.1704, -1.2504, -2.3207,  ...,  3.6987,  1.2245,  2.5330],\n",
      "         [ 0.0000, -0.4442, -1.8141,  ...,  4.1718,  1.1335,  3.2577]],\n",
      "\n",
      "        [[-1.4604, -0.6815, -0.0000,  ...,  3.6715,  0.5098,  0.0000],\n",
      "         [-0.4873, -0.0000,  1.4357,  ...,  3.0352,  1.0464,  3.3178],\n",
      "         [ 0.6743, -0.0000,  1.8497,  ...,  3.3411,  0.7900,  2.5431],\n",
      "         ...,\n",
      "         [-3.0834, -2.9528, -1.3676,  ...,  3.4258,  0.8174,  2.3480],\n",
      "         [-1.3422, -0.7822, -0.0000,  ...,  0.0000,  1.4466,  1.7129],\n",
      "         [-0.0587, -0.5363, -1.2806,  ...,  2.0612,  1.1922,  2.4251]],\n",
      "\n",
      "        [[-1.3989, -0.3823, -0.2162,  ...,  2.9702,  0.3362,  3.4276],\n",
      "         [ 0.3508, -1.6821,  1.1337,  ...,  3.6662,  0.2246,  2.0667],\n",
      "         [ 0.0000, -3.5220,  0.9702,  ...,  2.4355,  0.2750,  3.8153],\n",
      "         ...,\n",
      "         [-3.8851, -3.3834, -0.0000,  ...,  3.7703,  1.0144,  3.7109],\n",
      "         [-1.3645, -1.2606, -1.8541,  ...,  3.1008,  0.6682,  3.5642],\n",
      "         [-0.5710, -0.1675, -1.8311,  ...,  3.5874,  0.8431,  2.1916]]],\n",
      "       device='cuda:0', grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 91, 2048])\n",
      "tensor([[[-1.2303e+02,  7.2536e+01,  5.5620e+01,  ..., -2.7637e+01,\n",
      "           9.8439e-03,  0.0000e+00],\n",
      "         [ 7.1001e+01, -1.4398e+00, -0.0000e+00,  ...,  1.2045e+02,\n",
      "          -2.6118e+01,  3.4277e+01],\n",
      "         [-5.2585e+01,  6.0261e+01,  6.6111e+01,  ...,  5.0270e+00,\n",
      "          -2.8446e+01,  6.3791e+01],\n",
      "         ...,\n",
      "         [-6.7748e+01, -1.2055e+01, -0.0000e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6831e+01, -1.1786e+01, -3.4453e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6794e+01, -1.2494e+01, -2.3993e+00,  ...,  7.9533e+01,\n",
      "           0.0000e+00, -7.8470e+01]],\n",
      "\n",
      "        [[-1.2303e+02,  0.0000e+00,  5.5620e+01,  ..., -0.0000e+00,\n",
      "           9.8439e-03,  9.5118e+01],\n",
      "         [ 4.8521e+01, -1.2734e+02, -7.5682e+01,  ...,  3.2971e+01,\n",
      "           0.0000e+00,  4.0266e+01],\n",
      "         [-1.0710e+01, -5.4303e+00,  7.8653e+01,  ..., -2.1362e+00,\n",
      "          -5.0717e+01,  2.2382e+00],\n",
      "         ...,\n",
      "         [-0.0000e+00, -1.2055e+01, -3.9737e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -0.0000e+00],\n",
      "         [-6.6831e+01, -1.1786e+01, -0.0000e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6794e+01, -1.2494e+01, -2.3993e+00,  ...,  0.0000e+00,\n",
      "           6.7952e+01, -7.8470e+01]],\n",
      "\n",
      "        [[-1.2303e+02,  7.2536e+01,  5.5620e+01,  ..., -2.7637e+01,\n",
      "           9.8439e-03,  9.5118e+01],\n",
      "         [-1.5188e+02, -1.4156e+00, -4.9652e+01,  ..., -1.6306e+01,\n",
      "           1.9727e+01,  1.2007e+01],\n",
      "         [-1.5180e+02, -2.4685e+00, -4.9549e+01,  ..., -1.6306e+01,\n",
      "           1.9727e+01,  1.2007e+01],\n",
      "         ...,\n",
      "         [-6.7748e+01, -1.2055e+01, -3.9737e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6831e+01, -1.1786e+01, -3.4453e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6794e+01, -1.2494e+01, -2.3993e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.2303e+02,  7.2536e+01,  5.5620e+01,  ..., -2.7637e+01,\n",
      "           9.8439e-03,  9.5118e+01],\n",
      "         [ 2.9221e+01,  0.0000e+00, -3.2537e+01,  ...,  7.0587e+00,\n",
      "           3.0977e+01, -0.0000e+00],\n",
      "         [-1.2181e+02,  3.3243e+01,  8.3063e+01,  ..., -5.0501e+01,\n",
      "          -5.0309e+00, -2.4845e+01],\n",
      "         ...,\n",
      "         [-6.7748e+01, -1.2055e+01, -3.9737e+00,  ...,  7.9533e+01,\n",
      "           0.0000e+00, -7.8470e+01],\n",
      "         [-6.6831e+01, -1.1786e+01, -3.4453e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6794e+01, -1.2494e+01, -2.3993e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01]],\n",
      "\n",
      "        [[-1.2303e+02,  7.2536e+01,  5.5620e+01,  ..., -2.7637e+01,\n",
      "           9.8439e-03,  0.0000e+00],\n",
      "         [-1.5188e+02, -1.4156e+00, -4.9652e+01,  ..., -1.6306e+01,\n",
      "           1.9727e+01,  0.0000e+00],\n",
      "         [-1.5180e+02, -2.4685e+00, -4.9549e+01,  ..., -1.6306e+01,\n",
      "           1.9727e+01,  1.2007e+01],\n",
      "         ...,\n",
      "         [-6.7748e+01, -1.2055e+01, -3.9737e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6831e+01, -1.1786e+01, -3.4453e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -0.0000e+00],\n",
      "         [-6.6794e+01, -1.2494e+01, -2.3993e+00,  ...,  7.9533e+01,\n",
      "           0.0000e+00, -7.8470e+01]],\n",
      "\n",
      "        [[-1.2303e+02,  7.2536e+01,  5.5620e+01,  ..., -2.7637e+01,\n",
      "           9.8439e-03,  9.5118e+01],\n",
      "         [-0.0000e+00, -1.4156e+00, -4.9652e+01,  ..., -1.6306e+01,\n",
      "           1.9727e+01,  1.2007e+01],\n",
      "         [ 0.0000e+00,  3.0016e+01,  1.0835e+02,  ..., -2.9314e+00,\n",
      "           6.8697e+01, -3.2877e+01],\n",
      "         ...,\n",
      "         [-6.7748e+01, -1.2055e+01, -3.9737e+00,  ...,  7.9533e+01,\n",
      "           0.0000e+00, -7.8470e+01],\n",
      "         [-6.6831e+01, -1.1786e+01, -3.4453e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6794e+01, -0.0000e+00, -2.3993e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01]]], device='cuda:0',\n",
      "       grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 91, 2048])\n",
      "tensor([[[-2.5260,  4.0858,  2.2634,  ...,  0.9178, -0.0495,  1.7708],\n",
      "         [ 3.0288,  0.8425,  0.0000,  ...,  3.6741, -0.4644,  2.2396],\n",
      "         [ 0.6039,  2.1225,  3.8401,  ...,  1.0042, -0.1119,  2.3715],\n",
      "         ...,\n",
      "         [-0.0000,  1.2927, -0.3544,  ...,  0.0000,  0.8427, -0.0679],\n",
      "         [ 0.3769,  1.7096,  0.0000,  ...,  2.9320,  0.4501, -0.0694],\n",
      "         [ 0.4903,  0.4372,  1.7311,  ...,  3.3779, -0.0000,  0.0694]],\n",
      "\n",
      "        [[-0.0000,  2.0637,  1.8969,  ...,  1.6153, -0.3924,  2.8882],\n",
      "         [ 0.0000, -1.1448,  0.4617,  ...,  1.9222,  0.2544,  1.5950],\n",
      "         [ 1.1885,  0.3429,  3.2547,  ...,  1.4105, -0.0000,  1.4341],\n",
      "         ...,\n",
      "         [ 0.3483,  0.7884, -0.4381,  ...,  3.5405,  0.9818,  0.9849],\n",
      "         [ 1.1685,  1.5267, -0.0770,  ...,  3.7762,  0.8318, -0.5522],\n",
      "         [ 0.7404,  0.8991,  1.7944,  ...,  0.0000,  1.3094,  0.5877]],\n",
      "\n",
      "        [[-2.2098,  3.6998,  2.1041,  ...,  1.2111, -0.0707,  2.7866],\n",
      "         [-1.7904,  1.5635,  0.3579,  ...,  1.5549,  0.3948,  1.6759],\n",
      "         [-0.0000,  0.5385,  0.0000,  ...,  1.4134,  0.2504,  1.5511],\n",
      "         ...,\n",
      "         [-0.2966,  1.3341,  0.0287,  ...,  3.6555,  1.0805,  0.2113],\n",
      "         [-0.1420,  1.2830,  0.4993,  ...,  3.4337,  1.1416,  0.2827],\n",
      "         [-0.2687,  0.8571,  0.0000,  ...,  3.1502,  1.0459,  2.0303]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.1041,  3.4589,  1.7867,  ...,  1.1788, -0.1795,  2.6851],\n",
      "         [ 0.0000,  1.5186,  0.0000,  ...,  2.1890,  0.2673,  1.0977],\n",
      "         [-0.7030,  0.0000,  3.5811,  ...,  0.0000, -0.0000,  1.0695],\n",
      "         ...,\n",
      "         [-0.9937,  1.4156, -0.3491,  ...,  3.2331, -0.4415, -0.1744],\n",
      "         [ 0.6391,  1.5362, -0.1994,  ...,  3.7382,  0.4103, -0.0804],\n",
      "         [ 0.0430,  0.8454,  1.3584,  ...,  3.2377,  0.3497,  0.0961]],\n",
      "\n",
      "        [[-2.7245,  3.2511,  2.0907,  ...,  0.9934, -0.3308,  1.4049],\n",
      "         [-1.9148,  1.9220,  0.7322,  ...,  1.5421, -0.1306,  1.8971],\n",
      "         [-1.9941,  0.7935,  1.0085,  ...,  1.4903,  0.1983,  2.1931],\n",
      "         ...,\n",
      "         [-0.7008,  0.0000, -1.0228,  ...,  0.0000,  1.0763,  0.3031],\n",
      "         [ 0.2046,  1.3061, -0.1260,  ...,  3.9659,  1.0731,  1.2507],\n",
      "         [ 0.0290,  0.6618,  1.5320,  ...,  3.3599,  0.1215, -0.2777]],\n",
      "\n",
      "        [[-2.6884,  3.4517,  1.8333,  ...,  0.8929, -0.4442,  0.0000],\n",
      "         [ 1.0127,  1.2594,  0.6272,  ...,  1.9003,  0.5383,  2.1393],\n",
      "         [ 1.1657,  0.8327,  3.6890,  ...,  1.8177,  1.7015,  1.3940],\n",
      "         ...,\n",
      "         [-0.6200,  0.9991, -0.1801,  ...,  3.3296,  0.1428,  0.4130],\n",
      "         [ 0.2564,  1.3550,  0.2108,  ...,  3.9578,  1.2637,  0.4256],\n",
      "         [ 0.4066,  0.8203,  1.3151,  ...,  3.5895,  1.3809, -0.2364]]],\n",
      "       device='cuda:0', grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 91, 2048])\n",
      "tensor([[[-1.5702,  3.0862,  2.9293,  ...,  1.2613, -0.5742,  2.0484],\n",
      "         [ 2.4857,  0.2877,  1.8742,  ...,  2.9236, -0.7175,  1.7604],\n",
      "         [ 1.8838,  0.6585,  4.7169,  ...,  1.4233, -0.5270,  1.8476],\n",
      "         ...,\n",
      "         [ 0.2625,  1.1166, -0.1650,  ...,  0.9963,  0.3666,  1.0486],\n",
      "         [ 1.3428,  1.1956,  0.8794,  ...,  2.9899, -0.2022,  0.9885],\n",
      "         [ 0.9883, -0.2511,  2.7627,  ...,  3.0385, -0.5320,  0.6830]],\n",
      "\n",
      "        [[ 0.0108,  1.7716,  1.7770,  ...,  2.3398, -0.5972,  2.1318],\n",
      "         [ 1.2499, -0.7466,  1.9221,  ...,  2.5856, -0.1145,  1.7879],\n",
      "         [ 1.9278, -0.3706,  4.3368,  ...,  0.0000, -0.0000,  1.2402],\n",
      "         ...,\n",
      "         [ 0.8006,  0.5484, -0.8160,  ...,  3.7174, -0.0202,  1.7791],\n",
      "         [ 1.8506,  1.5350,  0.4758,  ...,  3.8189, -0.3691,  0.8575],\n",
      "         [ 1.5322,  0.5270,  2.8589,  ...,  1.7435, -0.0000,  1.5251]],\n",
      "\n",
      "        [[-1.6554,  2.7516,  2.5044,  ...,  1.7973, -0.0000,  1.8157],\n",
      "         [-0.1109,  1.0011,  2.1988,  ...,  2.2072, -0.3618,  1.5735],\n",
      "         [ 1.0309, -0.4151,  2.0736,  ...,  1.9611, -0.8943,  1.5241],\n",
      "         ...,\n",
      "         [-0.1575,  0.9256,  0.4583,  ...,  3.5056, -0.2569,  1.0977],\n",
      "         [ 1.3183,  1.1572,  0.8749,  ...,  3.1874,  0.1336,  0.7259],\n",
      "         [ 1.3406,  0.0000,  1.4395,  ...,  3.1838, -0.1285,  2.2741]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.6599,  2.5858,  2.7287,  ...,  0.0000, -0.0000,  2.2400],\n",
      "         [ 1.2128,  0.6737,  0.0000,  ...,  0.0000, -0.6024,  1.2989],\n",
      "         [ 0.8342, -1.0990,  4.4435,  ...,  1.1220, -0.3092,  1.4261],\n",
      "         ...,\n",
      "         [-0.2590,  0.9465, -0.5613,  ...,  2.8525, -0.0000,  1.1854],\n",
      "         [ 1.8226,  1.4161,  0.3364,  ...,  2.9981, -0.3174,  0.7168],\n",
      "         [ 1.6312,  0.0753,  2.3969,  ...,  3.0200, -0.3007,  1.2269]],\n",
      "\n",
      "        [[-1.2798,  2.8734,  0.0000,  ...,  1.7226, -0.7524,  1.8098],\n",
      "         [ 0.0000,  1.2928,  2.7467,  ...,  1.9072, -0.9869,  1.9576],\n",
      "         [-0.5175, -0.4806,  3.0524,  ...,  2.0105, -0.2308,  2.1047],\n",
      "         ...,\n",
      "         [ 0.1636,  0.5719, -0.9952,  ...,  1.0035,  0.2278,  1.3772],\n",
      "         [ 1.1663,  0.0000,  0.4930,  ...,  3.3722,  0.0063,  1.1922],\n",
      "         [ 1.0169,  0.3129,  2.6659,  ...,  2.8432, -0.6334,  0.7682]],\n",
      "\n",
      "        [[-1.5138,  2.4917,  2.1123,  ...,  1.4507, -0.9794,  1.5031],\n",
      "         [ 1.6484,  1.0682,  1.9426,  ...,  2.2481, -0.1448,  2.4186],\n",
      "         [ 1.7367, -0.6296,  4.4509,  ...,  2.0287,  0.1390,  1.9807],\n",
      "         ...,\n",
      "         [-0.0487,  0.5363,  0.1588,  ...,  3.4336, -0.4758,  1.1285],\n",
      "         [ 1.8368,  0.9568,  0.8659,  ...,  3.1917,  0.0809,  1.6393],\n",
      "         [ 1.5193, -0.0235,  2.3667,  ...,  3.3442,  0.3822,  0.6036]]],\n",
      "       device='cuda:0', grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 91, 2048])\n",
      "tensor([[[-1.5165,  1.8855,  2.6945,  ...,  1.7424, -0.0218,  1.6447],\n",
      "         [ 1.7911,  0.1558,  2.8385,  ...,  2.5030, -0.7408,  1.7067],\n",
      "         [ 1.3037, -1.0629,  3.1116,  ...,  1.6351, -0.3132,  1.6197],\n",
      "         ...,\n",
      "         [-0.4300,  0.4013, -0.0000,  ...,  1.6950, -0.5586,  1.2597],\n",
      "         [ 1.2627,  0.9624, -0.2729,  ...,  2.4000, -0.3512,  1.7287],\n",
      "         [ 0.7128, -0.8177,  2.1418,  ...,  2.1949, -0.3768,  0.0000]],\n",
      "\n",
      "        [[-0.0970,  1.2741,  1.3363,  ...,  2.6935, -1.0434,  2.0469],\n",
      "         [ 1.1922, -0.5241,  2.1568,  ...,  2.8557, -0.7343,  2.6470],\n",
      "         [ 1.6128, -1.5682,  3.7092,  ...,  1.5399, -0.4326,  1.2328],\n",
      "         ...,\n",
      "         [ 0.1528,  0.3266, -1.0457,  ...,  3.4594, -0.5094,  2.0922],\n",
      "         [ 1.6689,  1.3687,  0.0000,  ...,  3.3040, -0.7299,  2.1420],\n",
      "         [ 0.0000, -0.3062,  1.7918,  ...,  2.2229, -0.1864,  1.9837]],\n",
      "\n",
      "        [[-1.5349,  1.6453,  1.4894,  ...,  0.0000, -0.2040,  2.2192],\n",
      "         [-0.0480,  0.1061,  2.1831,  ...,  2.3421, -0.4311,  1.6522],\n",
      "         [ 0.0000, -0.0000,  2.3572,  ...,  0.0000, -0.7018,  1.6569],\n",
      "         ...,\n",
      "         [-1.0212,  0.5449, -0.4749,  ...,  2.7877, -0.2800,  1.6769],\n",
      "         [ 0.3101,  1.0484,  0.0000,  ...,  2.6740, -0.2259,  1.3188],\n",
      "         [ 0.0000, -0.1966,  1.7996,  ...,  2.2182, -0.2442,  2.0708]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0000,  1.4453,  2.1366,  ...,  1.7464, -0.2788,  2.2093],\n",
      "         [ 1.0817, -0.3442,  1.4337,  ...,  0.0000, -0.6947,  2.1208],\n",
      "         [ 0.5589, -0.0000,  4.0486,  ...,  1.7504, -0.2668,  1.5836],\n",
      "         ...,\n",
      "         [-0.8893,  0.3225, -1.0997,  ...,  2.7365, -0.3291,  1.7937],\n",
      "         [ 0.7873,  1.0301,  0.1638,  ...,  0.0000, -0.7804,  1.5094],\n",
      "         [ 1.1738, -0.3190,  2.1916,  ...,  2.2740, -0.4243,  2.2076]],\n",
      "\n",
      "        [[-1.5068,  1.7862,  0.2109,  ...,  2.2485, -0.6872,  1.8015],\n",
      "         [ 0.0471, -0.0651,  2.9543,  ...,  1.8577, -0.7316,  2.2682],\n",
      "         [-0.0501, -1.3251,  2.5494,  ...,  2.2803, -0.4993,  0.0000],\n",
      "         ...,\n",
      "         [-0.7729,  0.7617, -1.0022,  ...,  1.3874, -0.3397,  2.0186],\n",
      "         [ 0.0000,  0.0000,  0.3273,  ...,  2.3459, -0.6015,  1.3846],\n",
      "         [ 1.0596, -0.6535,  2.3350,  ...,  2.0153, -1.0022,  0.0000]],\n",
      "\n",
      "        [[-1.1449,  1.3081,  1.4115,  ...,  2.0057, -0.7231,  0.0000],\n",
      "         [ 1.1778,  0.0000,  0.0000,  ...,  2.4866, -0.4397,  3.0098],\n",
      "         [ 1.9894, -0.0000,  3.5771,  ...,  0.0000, -0.5463,  2.5156],\n",
      "         ...,\n",
      "         [-0.6189,  0.5123, -0.6963,  ...,  2.8970, -0.5614,  1.9985],\n",
      "         [ 1.1026,  0.6120,  0.4238,  ...,  2.6026, -0.5098,  2.0493],\n",
      "         [ 1.7862, -0.8309,  1.8715,  ...,  2.6491, -0.4697,  1.4511]]],\n",
      "       device='cuda:0', grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 91, 2048])\n",
      "tensor([[[-1.9443,  2.0157,  1.3365,  ...,  1.6521, -0.1478,  1.9848],\n",
      "         [ 0.5871,  0.0522,  1.7654,  ...,  1.9943, -1.0710,  1.6792],\n",
      "         [ 0.0095, -1.0458,  0.0000,  ...,  1.8604, -0.3754,  1.7783],\n",
      "         ...,\n",
      "         [-1.5820,  0.5609, -1.4468,  ...,  1.4613, -0.6375,  1.4889],\n",
      "         [ 0.0774,  1.3271, -1.4967,  ...,  2.0300, -0.5348,  2.5540],\n",
      "         [-0.5282, -0.3349,  1.1733,  ...,  2.1876, -0.2424,  1.2973]],\n",
      "\n",
      "        [[-1.4839,  1.5059, -0.0377,  ...,  2.9291, -0.9559,  2.1015],\n",
      "         [ 0.0931, -0.0867,  1.1711,  ...,  3.0645, -0.9394,  3.0286],\n",
      "         [ 1.1071, -1.8999,  2.4370,  ...,  2.0729, -0.6366,  0.0000],\n",
      "         ...,\n",
      "         [-0.0000,  0.4754, -2.6158,  ...,  2.6115, -0.7167,  2.7653],\n",
      "         [ 0.3274,  1.3591, -1.0512,  ...,  2.8553, -0.3604,  2.2641],\n",
      "         [-0.9532, -0.0493,  0.5639,  ...,  0.0000, -0.5388,  2.3584]],\n",
      "\n",
      "        [[-2.1573,  1.4250,  0.4808,  ...,  0.9583, -0.1392,  2.2681],\n",
      "         [-0.0000, -0.1248,  1.4132,  ...,  1.8646, -0.6382,  1.6874],\n",
      "         [-0.0880, -1.1407,  1.7426,  ...,  0.8715, -0.7664,  2.0688],\n",
      "         ...,\n",
      "         [-1.7862,  0.0000, -2.0199,  ...,  2.0551, -0.3000,  0.0000],\n",
      "         [-0.4719,  0.7355, -0.9155,  ...,  1.8931, -0.4151,  1.4809],\n",
      "         [-0.4561, -0.0000,  0.8533,  ...,  0.0000, -0.5590,  2.3443]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.4303,  0.9188,  0.5784,  ...,  2.0947, -0.3166,  2.1935],\n",
      "         [ 0.0252, -0.3723,  1.0372,  ...,  1.1879, -0.6540,  1.8886],\n",
      "         [-0.4310, -0.7348,  0.0000,  ...,  0.0000, -0.6402,  2.6323],\n",
      "         ...,\n",
      "         [-0.0000,  0.3329, -1.8441,  ...,  2.3157, -0.7868,  0.0000],\n",
      "         [-0.3457,  1.5274, -1.1758,  ...,  0.9049, -0.9261,  1.8846],\n",
      "         [-0.2471,  0.0000,  1.2025,  ...,  2.1007, -0.7277,  2.2620]],\n",
      "\n",
      "        [[-2.0918,  1.6446,  0.0000,  ...,  2.4913, -0.6889,  2.2969],\n",
      "         [-0.2967,  0.2635,  0.0000,  ...,  1.7200, -0.5400,  1.8005],\n",
      "         [-0.2913, -1.1251,  2.1061,  ...,  0.0000, -0.5047,  0.8638],\n",
      "         ...,\n",
      "         [-1.7723,  0.9774, -0.0000,  ...,  1.5957, -0.9944,  1.7901],\n",
      "         [-0.2134,  1.2062, -0.7122,  ...,  2.2230, -0.7391,  1.5468],\n",
      "         [ 0.2228, -0.2408,  1.2668,  ...,  1.6822, -1.1102,  1.0386]],\n",
      "\n",
      "        [[-2.2112,  1.1945,  0.2966,  ...,  1.7624, -0.5308,  1.6530],\n",
      "         [ 0.0672,  0.0262,  0.5134,  ...,  0.0000, -0.4774,  2.9263],\n",
      "         [ 0.4724, -0.0000,  1.5405,  ...,  1.1524, -0.5984,  2.4609],\n",
      "         ...,\n",
      "         [-0.0000,  0.7964, -0.0000,  ...,  2.3312, -0.5321,  2.3121],\n",
      "         [ 0.5575,  0.7731, -1.0370,  ...,  2.2000, -0.5471,  2.2351],\n",
      "         [ 0.6520, -0.2358,  0.7868,  ...,  2.5634, -0.7103,  2.0419]]],\n",
      "       device='cuda:0', grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 90, 2048])\n",
      "tensor([[[   3.2772,  -31.6677,  -43.3585,  ...,  -45.0241,   71.4243,\n",
      "            10.9505],\n",
      "         [  91.1383,  -52.1178,  -19.2495,  ...,  -13.2194,  136.4496,\n",
      "            77.1255],\n",
      "         [ -45.0549,  -20.8548,   15.1696,  ...,  -36.5032,  -28.2548,\n",
      "             1.8381],\n",
      "         ...,\n",
      "         [ -68.7001,   -0.0000,   -3.5143,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         [ -67.7476,  -12.0546,   -3.9737,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         [ -66.8313,   -0.0000,   -3.4453,  ...,   79.5327,   67.9524,\n",
      "           -78.4697]],\n",
      "\n",
      "        [[ -28.4509,   34.1838,    0.0000,  ...,  -71.1576,   35.5508,\n",
      "           -48.2908],\n",
      "         [ -29.7368,  -70.1466,   65.0375,  ...,   -1.6741,  -61.8718,\n",
      "            33.3668],\n",
      "         [  21.3556,   -0.0000,  -18.4624,  ...,   77.3403,  -27.4134,\n",
      "           -48.7628],\n",
      "         ...,\n",
      "         [ -68.7001,  -13.0567,   -0.0000,  ...,   79.5327,   67.9524,\n",
      "            -0.0000],\n",
      "         [ -67.7476,  -12.0546,   -3.9737,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         [  -0.0000,  -11.7860,   -3.4453,  ...,   79.5327,   67.9524,\n",
      "           -78.4697]],\n",
      "\n",
      "        [[ -28.4509,   34.1838,   42.0307,  ...,   -0.0000,    0.0000,\n",
      "           -48.2908],\n",
      "         [  18.2824,   43.4908,   24.6238,  ...,   -1.0123,   46.7021,\n",
      "             0.0000],\n",
      "         [  -0.0000,   35.5655,   29.0997,  ...,  -27.9033,   85.5426,\n",
      "            -4.1746],\n",
      "         ...,\n",
      "         [ -68.7001,  -13.0567,   -3.5143,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         [ -67.7476,  -12.0546,   -3.9737,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         [ -66.8313,  -11.7860,   -3.4453,  ...,   79.5327,   67.9524,\n",
      "           -78.4697]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 117.5897,  -43.8340,  -45.5972,  ...,   37.9564,  -29.0097,\n",
      "           139.2590],\n",
      "         [  96.7313, -122.5283,  -37.0636,  ...,  -52.5008,   -3.2400,\n",
      "           -30.6845],\n",
      "         [  40.5470,  -15.6883,  -54.5321,  ...,  -73.7203,    0.0000,\n",
      "            -4.6726],\n",
      "         ...,\n",
      "         [ -68.7001,  -13.0567,   -3.5143,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         [ -67.7476,  -12.0546,   -3.9737,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         [ -66.8313,  -11.7860,   -3.4453,  ...,   79.5327,   67.9524,\n",
      "           -78.4697]],\n",
      "\n",
      "        [[   6.6752,    5.5055,   -8.1494,  ...,   -0.0000,  -51.4571,\n",
      "             0.0000],\n",
      "         [ -36.5925,   81.6684,   -0.0000,  ...,  114.3141,  -25.8073,\n",
      "             6.2455],\n",
      "         [  -0.0000,   49.0070,  101.9692,  ...,    5.9596,   -8.0915,\n",
      "             7.4168],\n",
      "         ...,\n",
      "         [ -68.7001,  -13.0567,   -3.5143,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         [  -0.0000,   -0.0000,   -3.9737,  ...,   79.5327,    0.0000,\n",
      "           -78.4697],\n",
      "         [ -66.8313,  -11.7860,   -3.4453,  ...,   79.5327,   67.9524,\n",
      "           -78.4697]],\n",
      "\n",
      "        [[  28.2857,   23.3442,  -33.4609,  ...,    7.0587,   30.9774,\n",
      "            -3.9303],\n",
      "         [ -30.4694,   -6.0075,    0.0000,  ...,   44.1968,   50.7365,\n",
      "            -8.5971],\n",
      "         [  31.3281,  -63.1826,   -0.0000,  ...,   -2.6463,   49.7053,\n",
      "            49.2649],\n",
      "         ...,\n",
      "         [ -68.7001,   -0.0000,   -3.5143,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         [ -67.7476,  -12.0546,   -3.9737,  ...,   79.5327,   67.9524,\n",
      "           -78.4697],\n",
      "         [ -66.8313,  -11.7860,   -3.4453,  ...,   79.5327,   67.9524,\n",
      "           -78.4697]]], device='cuda:0', grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 90, 2048])\n",
      "tensor([[[ 0.0000e+00,  9.1477e-01, -4.9805e-01,  ...,  1.2194e+00,\n",
      "           1.8003e+00,  2.4017e+00],\n",
      "         [ 3.4388e+00,  5.9426e-02,  1.9508e+00,  ...,  1.7341e+00,\n",
      "           0.0000e+00,  3.9246e+00],\n",
      "         [ 1.1704e+00, -1.3507e-01,  2.7210e+00,  ...,  1.6590e+00,\n",
      "          -0.0000e+00,  3.0286e+00],\n",
      "         ...,\n",
      "         [-8.8218e-01, -4.1579e-01,  8.1456e-02,  ...,  3.7930e+00,\n",
      "           2.1453e+00,  5.8399e-01],\n",
      "         [-2.2289e-01,  5.6101e-01, -6.5596e-01,  ...,  3.7556e+00,\n",
      "           0.0000e+00, -1.7907e-01],\n",
      "         [ 1.0152e+00,  6.7715e-01,  1.2107e+00,  ...,  0.0000e+00,\n",
      "           2.5662e+00,  7.7430e-01]],\n",
      "\n",
      "        [[ 7.2811e-01,  3.1815e+00,  1.2751e+00,  ...,  6.3410e-01,\n",
      "           0.0000e+00,  9.8050e-01],\n",
      "         [ 1.2055e+00, -0.0000e+00,  2.8003e+00,  ...,  1.6800e+00,\n",
      "          -2.4223e+00,  2.2683e+00],\n",
      "         [ 2.1929e+00,  2.3727e-01,  7.4987e-01,  ...,  4.8627e+00,\n",
      "          -0.0000e+00,  1.1121e+00],\n",
      "         ...,\n",
      "         [-0.0000e+00,  4.4384e-01,  7.0028e-01,  ...,  3.9072e+00,\n",
      "           1.4868e+00,  1.9747e+00],\n",
      "         [-3.8452e-03,  1.4718e+00, -3.2548e-01,  ...,  3.7938e+00,\n",
      "           1.2996e+00, -0.0000e+00],\n",
      "         [ 2.0326e+00,  1.3445e+00,  3.8458e-01,  ...,  3.6281e+00,\n",
      "           1.6990e+00, -5.8661e-01]],\n",
      "\n",
      "        [[ 9.0556e-01,  2.5942e+00,  1.4860e+00,  ...,  0.0000e+00,\n",
      "          -6.1707e-01,  1.0101e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  2.4663e+00,  ...,  2.1240e+00,\n",
      "           4.9841e-01,  2.2242e+00],\n",
      "         [ 1.9159e+00,  1.0853e+00,  2.2591e+00,  ...,  1.7671e+00,\n",
      "           1.4428e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [-9.5472e-01, -2.5273e-01,  1.0156e+00,  ...,  3.7400e+00,\n",
      "           0.0000e+00,  4.1090e-01],\n",
      "         [-2.2315e-01,  1.0416e+00,  2.3282e-01,  ...,  3.5991e+00,\n",
      "           1.3870e+00, -3.8305e-01],\n",
      "         [ 0.0000e+00,  1.1145e+00,  5.8439e-01,  ...,  3.7073e+00,\n",
      "           1.3601e+00,  9.2017e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 3.7098e+00,  0.0000e+00,  1.7236e-01,  ...,  2.8149e+00,\n",
      "          -6.7249e-01,  5.0148e+00],\n",
      "         [ 4.5232e+00, -1.6043e+00,  9.1454e-01,  ...,  9.9351e-01,\n",
      "          -6.7286e-01,  9.2700e-01],\n",
      "         [ 3.5728e+00, -2.0112e-01,  0.0000e+00,  ...,  1.2821e-01,\n",
      "          -3.3381e-01,  1.9998e+00],\n",
      "         ...,\n",
      "         [-1.2603e+00,  0.0000e+00,  3.4845e-01,  ...,  4.3280e+00,\n",
      "           1.1449e+00,  1.7964e-01],\n",
      "         [ 2.7336e-02,  1.1739e+00, -5.4704e-03,  ...,  3.9898e+00,\n",
      "           1.1322e+00,  4.6746e-01],\n",
      "         [ 1.1087e+00,  1.2464e+00,  4.1593e-01,  ...,  4.0572e+00,\n",
      "           1.0853e+00,  1.6062e-01]],\n",
      "\n",
      "        [[ 1.3690e+00,  2.4528e+00,  1.2304e+00,  ...,  1.7623e+00,\n",
      "          -0.0000e+00,  2.3675e+00],\n",
      "         [ 1.8221e+00,  3.4949e+00,  2.3631e+00,  ...,  5.2857e+00,\n",
      "          -2.7196e-01,  1.6808e+00],\n",
      "         [ 1.6978e+00,  1.2677e+00,  0.0000e+00,  ...,  2.4836e+00,\n",
      "           1.3591e-01,  2.5420e+00],\n",
      "         ...,\n",
      "         [-1.4598e+00, -4.9930e-01,  0.0000e+00,  ...,  3.5376e+00,\n",
      "           1.2209e+00, -4.5708e-01],\n",
      "         [ 1.2835e+00,  1.0012e+00,  8.4413e-02,  ...,  3.6283e+00,\n",
      "          -2.4964e-01,  6.0085e-01],\n",
      "         [ 1.3050e+00,  6.1138e-01,  7.3607e-01,  ...,  4.2037e+00,\n",
      "           1.4958e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 9.2271e-01,  2.1555e+00, -4.2099e-01,  ...,  0.0000e+00,\n",
      "           3.9852e-01,  1.9716e+00],\n",
      "         [ 1.6487e+00,  9.7311e-01,  1.8789e+00,  ...,  3.6038e+00,\n",
      "           1.0366e+00,  1.9453e+00],\n",
      "         [ 3.2758e+00, -1.3605e+00,  2.0802e+00,  ...,  1.9365e+00,\n",
      "           0.0000e+00,  3.7368e+00],\n",
      "         ...,\n",
      "         [-8.1755e-01, -4.2199e-01,  3.9799e-01,  ...,  4.1766e+00,\n",
      "           1.1967e+00,  2.7909e-01],\n",
      "         [ 1.2319e-01,  3.6235e-01,  5.0620e-02,  ...,  3.9808e+00,\n",
      "           1.5713e+00, -1.8582e-01],\n",
      "         [ 1.2818e+00,  8.1988e-01,  1.1617e+00,  ...,  3.9069e+00,\n",
      "           1.1933e+00, -3.6884e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 90, 2048])\n",
      "tensor([[[ 0.2856,  0.2903,  0.0588,  ...,  2.4839,  1.3616,  3.6017],\n",
      "         [ 3.4713, -0.6062,  0.0000,  ...,  2.5650,  0.0000,  0.0000],\n",
      "         [ 2.3085, -1.6370,  3.4947,  ...,  2.5981,  0.0000,  4.0178],\n",
      "         ...,\n",
      "         [-0.7352, -1.9988,  0.1622,  ...,  4.2207,  1.9693,  1.8671],\n",
      "         [ 0.0000,  0.0444, -0.9104,  ...,  4.1810,  0.3963,  1.7420],\n",
      "         [ 1.9049,  0.1780,  0.0000,  ...,  1.7500,  2.2010,  2.3742]],\n",
      "\n",
      "        [[ 0.6413,  2.2513,  1.3812,  ...,  2.2205,  0.0336,  0.0000],\n",
      "         [ 2.3353, -0.6039,  3.3798,  ...,  2.6948, -2.4744,  2.8579],\n",
      "         [ 2.7875, -1.5866,  1.6361,  ...,  4.9616,  0.0000,  2.4737],\n",
      "         ...,\n",
      "         [-0.7425, -0.9332,  0.5442,  ...,  4.2976,  1.2140,  3.1020],\n",
      "         [ 0.4286,  0.6869, -0.0000,  ...,  4.3080,  0.8793,  1.2313],\n",
      "         [ 0.0000,  0.7869,  0.2063,  ...,  4.2102,  0.8950,  1.2311]],\n",
      "\n",
      "        [[ 0.0000,  1.8286,  1.9761,  ...,  0.0000, -0.9809,  2.5262],\n",
      "         [ 0.0000, -0.7328,  2.5387,  ...,  0.0000,  0.1793,  3.0835],\n",
      "         [ 0.0000, -1.0248,  2.7885,  ...,  2.4728,  1.1131,  0.9354],\n",
      "         ...,\n",
      "         [-1.2714, -1.7681,  0.8219,  ...,  4.0354, -0.4088,  1.9266],\n",
      "         [ 0.1825,  0.3474, -0.2329,  ...,  4.3550,  0.7622,  0.9530],\n",
      "         [ 1.2520,  0.4553,  0.3608,  ...,  4.3204,  0.5738,  1.9158]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 2.5993, -0.3883,  0.8322,  ...,  3.3602, -0.1392,  4.7912],\n",
      "         [ 4.6026, -1.7835,  1.8632,  ...,  2.6140, -0.3578,  1.8795],\n",
      "         [ 3.7309, -2.0781,  2.1397,  ...,  1.3452, -0.5436,  2.8567],\n",
      "         ...,\n",
      "         [-1.2681, -1.4114,  0.7874,  ...,  4.8567,  0.8709,  1.9556],\n",
      "         [ 0.0000,  0.0000, -0.4026,  ...,  4.5166,  0.9215,  1.6417],\n",
      "         [ 2.2416,  0.7074,  0.8921,  ...,  4.5324,  0.2199,  0.0000]],\n",
      "\n",
      "        [[ 0.6128,  1.4321,  1.1607,  ...,  2.6767,  0.3993,  3.5263],\n",
      "         [ 2.3495,  1.8845,  3.2684,  ...,  5.6379, -0.1471,  3.1172],\n",
      "         [ 2.6141, -0.7753,  1.4188,  ...,  3.0418,  0.2310,  3.3455],\n",
      "         ...,\n",
      "         [-1.8881, -1.3472,  0.6040,  ...,  3.9468,  0.7921,  1.2068],\n",
      "         [ 1.1813,  0.5856,  0.0135,  ...,  4.2162,  0.2881,  2.1846],\n",
      "         [ 2.3137,  0.4672,  0.0000,  ...,  4.4960,  1.2585,  1.8132]],\n",
      "\n",
      "        [[ 0.6802,  1.4422,  0.3978,  ...,  1.5988,  0.0000,  2.7800],\n",
      "         [ 2.3319,  0.0108,  2.3630,  ...,  4.1560,  0.5465,  2.7960],\n",
      "         [ 2.8327, -2.3478,  3.0407,  ...,  2.7997, -0.5893,  0.0000],\n",
      "         ...,\n",
      "         [-1.2195, -2.0015,  0.5375,  ...,  4.6394,  1.0163,  1.4559],\n",
      "         [ 0.0000, -0.0710, -0.1009,  ...,  4.1307,  1.0698,  1.7580],\n",
      "         [ 1.9596,  0.6696,  1.1413,  ...,  0.0000,  0.7999,  1.3764]]],\n",
      "       device='cuda:0', grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 90, 2048])\n",
      "tensor([[[-0.0385, -0.5108,  0.0197,  ...,  3.0834,  0.8691,  4.0454],\n",
      "         [ 2.3051, -0.0000,  0.9910,  ...,  3.0037, -0.5009,  2.0656],\n",
      "         [ 1.6732, -3.1881,  2.8907,  ...,  2.9909,  0.4025,  4.0513],\n",
      "         ...,\n",
      "         [-1.5198, -3.1815, -0.0000,  ...,  3.9052,  1.7362,  2.9609],\n",
      "         [-0.4801, -0.9925, -1.5018,  ...,  4.0594,  0.5620,  2.7946],\n",
      "         [ 1.6333, -0.5970, -0.4898,  ...,  2.8662,  1.4854,  2.7231]],\n",
      "\n",
      "        [[-0.0281,  0.0000,  0.5456,  ...,  3.2892,  0.1914,  0.0000],\n",
      "         [ 1.9605, -1.2156,  0.0000,  ...,  0.0000, -1.4823,  3.2783],\n",
      "         [ 2.1073, -2.9609,  0.0000,  ...,  4.3463,  0.0000,  3.2454],\n",
      "         ...,\n",
      "         [-1.8845, -2.2553, -0.2656,  ...,  3.9563,  0.8569,  3.8133],\n",
      "         [-0.0000, -0.3978, -0.8773,  ...,  4.0412,  0.6839,  2.3549],\n",
      "         [ 0.3308, -0.1847, -0.0000,  ...,  4.2069,  0.7842,  2.6866]],\n",
      "\n",
      "        [[-0.2628,  0.1276,  1.0402,  ...,  2.0518, -0.0000,  3.1056],\n",
      "         [ 0.4324, -1.6681,  2.1210,  ...,  1.9883,  0.4477,  3.3140],\n",
      "         [ 0.8255, -3.1158,  2.3175,  ...,  3.2197, -0.2227,  2.2442],\n",
      "         ...,\n",
      "         [-1.8155, -2.9528, -0.5842,  ...,  3.9963, -0.0194,  3.1182],\n",
      "         [-0.1225, -0.7833, -0.0000,  ...,  4.2093, -0.1822,  2.2461],\n",
      "         [ 1.2462, -0.0000, -0.4903,  ...,  4.1379,  0.5086,  2.8894]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.3004, -1.3040,  0.2024,  ...,  3.4813, -0.1219,  4.3514],\n",
      "         [ 0.0000, -2.2362,  1.9584,  ...,  3.4468, -0.0737,  2.7074],\n",
      "         [ 2.6534, -3.5166,  2.3050,  ...,  2.7724, -0.4667,  3.2836],\n",
      "         ...,\n",
      "         [-1.9058, -2.8902, -0.1637,  ...,  4.6127,  0.5372,  2.7140],\n",
      "         [ 0.0000, -1.1967, -1.5823,  ...,  4.2999,  0.6317,  2.4993],\n",
      "         [ 1.4741, -0.5894,  0.1652,  ...,  4.7503, -0.0988,  1.6164]],\n",
      "\n",
      "        [[ 0.2879, -0.0000,  0.8723,  ...,  0.0000,  0.6531,  3.7515],\n",
      "         [ 2.0093, -0.0406,  2.5842,  ...,  0.0000, -0.1323,  3.6524],\n",
      "         [ 2.1429, -0.0000,  1.4992,  ...,  3.1856,  0.3420,  3.4808],\n",
      "         ...,\n",
      "         [-2.4437, -2.7054, -0.0000,  ...,  4.1243,  0.7207,  2.5246],\n",
      "         [ 0.2962, -0.4461, -1.3587,  ...,  3.8587,  0.0000,  3.1150],\n",
      "         [ 1.9997, -0.4364, -0.1919,  ...,  3.9340,  0.8571,  2.8104]],\n",
      "\n",
      "        [[-0.2510,  0.4730,  0.3709,  ...,  2.4006,  0.4308,  3.1419],\n",
      "         [ 1.7251, -1.1589,  2.3249,  ...,  4.1535,  0.2706,  2.7533],\n",
      "         [ 1.7487, -3.4191,  2.8154,  ...,  2.9715, -0.0937,  1.7353],\n",
      "         ...,\n",
      "         [-2.0409, -2.7393, -0.0339,  ...,  4.4497,  1.6535,  0.0000],\n",
      "         [-0.0000, -1.0978, -1.4312,  ...,  3.8197,  0.9892,  2.1214],\n",
      "         [ 1.3076, -0.2729,  0.0000,  ...,  1.9172,  0.7107,  2.3443]]],\n",
      "       device='cuda:0', grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 90, 2048])\n",
      "tensor([[[-9.4224e-01, -7.5632e-01, -8.6823e-01,  ...,  3.2771e+00,\n",
      "           6.5921e-01,  3.8596e+00],\n",
      "         [ 9.1230e-01, -9.3017e-01,  0.0000e+00,  ...,  3.1314e+00,\n",
      "           2.0921e-01,  3.0342e+00],\n",
      "         [ 6.9536e-01, -3.3242e+00,  1.5380e+00,  ...,  3.2548e+00,\n",
      "           5.5513e-01,  3.7766e+00],\n",
      "         ...,\n",
      "         [-2.4748e+00, -0.0000e+00, -1.5254e+00,  ...,  3.7350e+00,\n",
      "           1.2664e+00,  3.4098e+00],\n",
      "         [-1.0806e+00, -0.0000e+00, -3.0961e+00,  ...,  3.8925e+00,\n",
      "           6.7124e-01,  3.3535e+00],\n",
      "         [ 8.3950e-01, -4.7474e-01, -1.4951e+00,  ...,  3.1087e+00,\n",
      "           3.5818e-01,  3.4454e+00]],\n",
      "\n",
      "        [[-1.1963e+00, -5.8428e-01, -9.1505e-01,  ...,  3.3726e+00,\n",
      "           2.1100e-01,  1.9536e+00],\n",
      "         [ 6.4547e-01, -1.8048e+00,  7.1862e-02,  ...,  1.5477e+00,\n",
      "          -6.7916e-01,  3.5796e+00],\n",
      "         [ 1.1037e+00, -3.1905e+00, -2.5455e-01,  ...,  0.0000e+00,\n",
      "          -5.6160e-01,  3.2074e+00],\n",
      "         ...,\n",
      "         [-3.1028e+00, -2.9766e+00, -1.5065e+00,  ...,  3.8196e+00,\n",
      "           1.0000e+00,  3.7937e+00],\n",
      "         [-1.2452e+00, -8.9230e-01, -2.2099e+00,  ...,  3.7060e+00,\n",
      "           7.4848e-01,  2.8715e+00],\n",
      "         [-2.8264e-01, -6.4129e-01, -1.2964e+00,  ...,  3.8768e+00,\n",
      "           1.0203e+00,  3.0948e+00]],\n",
      "\n",
      "        [[-1.0934e+00, -7.3022e-01, -1.8267e-01,  ...,  3.1728e+00,\n",
      "           1.9687e-01,  3.2144e+00],\n",
      "         [-2.0194e-01, -1.7513e+00,  1.1973e+00,  ...,  2.9892e+00,\n",
      "           5.9486e-01,  0.0000e+00],\n",
      "         [ 1.7194e-01, -3.6075e+00,  1.3566e+00,  ...,  3.7430e+00,\n",
      "          -8.5289e-02,  2.6529e+00],\n",
      "         ...,\n",
      "         [-2.7661e+00, -3.3194e+00, -1.6904e+00,  ...,  3.8512e+00,\n",
      "          -3.0705e-01,  3.3045e+00],\n",
      "         [-1.2847e+00, -1.2362e+00, -1.7138e+00,  ...,  3.8807e+00,\n",
      "           2.4232e-01,  2.7487e+00],\n",
      "         [ 2.3546e-01, -4.7485e-01, -1.6577e+00,  ...,  3.9285e+00,\n",
      "           6.3295e-01,  3.2351e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-3.9805e-01, -1.2612e+00, -9.6540e-01,  ...,  3.4217e+00,\n",
      "           7.5180e-02,  4.0883e+00],\n",
      "         [-4.8278e-01, -2.0220e+00,  1.2302e+00,  ...,  3.5023e+00,\n",
      "           4.5340e-02,  3.2826e+00],\n",
      "         [ 8.3028e-01, -3.8511e+00,  1.1860e+00,  ...,  3.2505e+00,\n",
      "          -9.8899e-03,  3.9200e+00],\n",
      "         ...,\n",
      "         [-2.7169e+00, -3.0625e+00, -1.9146e+00,  ...,  3.9432e+00,\n",
      "           3.4308e-01,  2.8852e+00],\n",
      "         [-1.0732e+00, -0.0000e+00, -2.5712e+00,  ...,  3.8039e+00,\n",
      "           6.4911e-01,  3.0137e+00],\n",
      "         [ 6.7379e-01, -0.0000e+00, -1.3596e+00,  ...,  4.1509e+00,\n",
      "           3.7784e-01,  2.5708e+00]],\n",
      "\n",
      "        [[-9.5263e-01, -5.0712e-01, -2.4847e-01,  ...,  2.1252e+00,\n",
      "           6.6428e-01,  3.8763e+00],\n",
      "         [ 1.2032e+00, -0.0000e+00,  1.6314e+00,  ...,  1.7681e+00,\n",
      "           2.6835e-01,  3.7675e+00],\n",
      "         [ 9.5952e-01, -0.0000e+00,  1.0839e+00,  ...,  3.2307e+00,\n",
      "           5.5679e-01,  0.0000e+00],\n",
      "         ...,\n",
      "         [-3.1492e+00, -2.8777e+00, -1.2897e+00,  ...,  3.8889e+00,\n",
      "           0.0000e+00,  3.3400e+00],\n",
      "         [-0.0000e+00, -6.5178e-01, -0.0000e+00,  ...,  4.0236e+00,\n",
      "           6.3142e-01,  3.1450e+00],\n",
      "         [ 5.4623e-01, -5.0389e-01, -1.5230e+00,  ...,  3.7228e+00,\n",
      "           1.0141e+00,  3.3475e+00]],\n",
      "\n",
      "        [[-1.5261e+00,  7.4029e-04, -5.4289e-01,  ...,  3.0199e+00,\n",
      "           6.4120e-01,  3.2550e+00],\n",
      "         [ 7.8129e-01, -1.3126e+00,  0.0000e+00,  ...,  3.7883e+00,\n",
      "           5.0104e-01,  2.9130e+00],\n",
      "         [ 8.5363e-01, -3.4481e+00,  1.7203e+00,  ...,  3.2589e+00,\n",
      "           4.1113e-01,  2.6705e+00],\n",
      "         ...,\n",
      "         [-3.1583e+00, -2.6824e+00, -0.0000e+00,  ...,  3.9973e+00,\n",
      "           1.4347e+00,  1.4337e+00],\n",
      "         [-1.3166e+00, -1.0071e+00, -2.5033e+00,  ...,  3.6741e+00,\n",
      "           1.0844e+00,  0.0000e+00],\n",
      "         [ 2.0274e-01, -0.0000e+00, -1.4136e+00,  ...,  2.7398e+00,\n",
      "           1.0917e+00,  3.0125e+00]]], device='cuda:0',\n",
      "       grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 91, 2048])\n",
      "tensor([[[-1.2303e+02,  7.2536e+01,  5.5620e+01,  ..., -2.7637e+01,\n",
      "           9.8304e-03,  9.5118e+01],\n",
      "         [-1.5188e+02, -1.4156e+00, -4.9652e+01,  ..., -1.6306e+01,\n",
      "           1.9727e+01,  1.2007e+01],\n",
      "         [ 5.0120e+01,  3.0016e+01,  1.0835e+02,  ..., -2.9314e+00,\n",
      "           6.8697e+01, -3.2877e+01],\n",
      "         ...,\n",
      "         [-6.7748e+01, -1.2055e+01, -3.9737e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6831e+01, -1.1786e+01, -3.4453e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6794e+01, -1.2494e+01, -2.3993e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01]],\n",
      "\n",
      "        [[-1.2303e+02,  7.2536e+01,  5.5620e+01,  ..., -2.7637e+01,\n",
      "           9.8304e-03,  9.5118e+01],\n",
      "         [-0.0000e+00, -1.4156e+00, -4.9652e+01,  ..., -1.6306e+01,\n",
      "           1.9727e+01,  1.2007e+01],\n",
      "         [ 5.0120e+01,  3.0016e+01,  1.0835e+02,  ..., -2.9314e+00,\n",
      "           6.8697e+01, -3.2877e+01],\n",
      "         ...,\n",
      "         [-6.7748e+01, -1.2055e+01, -3.9737e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6831e+01, -0.0000e+00, -3.4453e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6794e+01, -1.2494e+01, -2.3993e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01]],\n",
      "\n",
      "        [[-1.2303e+02,  7.2536e+01,  5.5620e+01,  ..., -2.7637e+01,\n",
      "           9.8304e-03,  9.5118e+01],\n",
      "         [-1.5188e+02, -1.4156e+00, -4.9652e+01,  ..., -1.6306e+01,\n",
      "           1.9727e+01,  1.2007e+01],\n",
      "         [ 5.0120e+01,  3.0016e+01,  1.0835e+02,  ..., -2.9314e+00,\n",
      "           6.8697e+01, -3.2877e+01],\n",
      "         ...,\n",
      "         [-6.7748e+01, -1.2055e+01, -3.9737e+00,  ...,  0.0000e+00,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6831e+01, -1.1786e+01, -3.4453e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6794e+01, -1.2494e+01, -2.3993e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.2303e+02,  0.0000e+00,  5.5620e+01,  ..., -2.7637e+01,\n",
      "           9.8304e-03,  9.5118e+01],\n",
      "         [-0.0000e+00,  0.0000e+00, -2.6841e+01,  ..., -4.9870e+01,\n",
      "          -1.7468e+01,  3.4997e+01],\n",
      "         [-3.4712e+01,  7.9239e-01, -3.6588e+01,  ..., -1.4971e+01,\n",
      "           2.7627e+01,  5.7822e+01],\n",
      "         ...,\n",
      "         [-0.0000e+00, -1.2055e+01, -3.9737e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -0.0000e+00],\n",
      "         [-6.6831e+01, -1.1786e+01, -3.4453e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -0.0000e+00],\n",
      "         [-6.6794e+01, -1.2494e+01, -2.3993e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -0.0000e+00]],\n",
      "\n",
      "        [[-1.2303e+02,  7.2536e+01,  5.5620e+01,  ..., -2.7637e+01,\n",
      "           9.8304e-03,  9.5118e+01],\n",
      "         [-4.5854e+01, -3.6806e+01, -2.3620e+01,  ...,  3.0751e+01,\n",
      "          -7.2558e+01,  3.3138e+01],\n",
      "         [-0.0000e+00, -2.4488e+00, -1.1855e+01,  ..., -1.0778e+02,\n",
      "           8.3137e+00,  7.8599e-01],\n",
      "         ...,\n",
      "         [-0.0000e+00, -1.2055e+01, -3.9737e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-0.0000e+00, -1.1786e+01, -3.4453e+00,  ...,  0.0000e+00,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6794e+01, -1.2494e+01, -2.3993e+00,  ...,  7.9533e+01,\n",
      "           0.0000e+00, -0.0000e+00]],\n",
      "\n",
      "        [[-1.2303e+02,  7.2536e+01,  5.5620e+01,  ..., -2.7637e+01,\n",
      "           9.8304e-03,  0.0000e+00],\n",
      "         [ 2.3727e+01, -4.9275e+01,  8.3918e+01,  ...,  5.0868e+01,\n",
      "          -0.0000e+00,  7.2740e+00],\n",
      "         [-7.0547e+01,  1.4097e+01, -2.3423e+01,  ...,  7.0582e+00,\n",
      "          -3.0725e+01,  7.9454e+01],\n",
      "         ...,\n",
      "         [-6.7748e+01, -1.2055e+01, -3.9737e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6831e+01, -1.1786e+01, -3.4453e+00,  ...,  0.0000e+00,\n",
      "           6.7952e+01, -7.8470e+01],\n",
      "         [-6.6794e+01, -1.2494e+01, -2.3993e+00,  ...,  7.9533e+01,\n",
      "           6.7952e+01, -7.8470e+01]]], device='cuda:0',\n",
      "       grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 91, 2048])\n",
      "tensor([[[-1.9383,  3.6134,  2.3225,  ...,  0.9375, -0.2324,  2.2882],\n",
      "         [-1.9600,  1.7392,  1.3285,  ...,  1.4919,  0.0000,  1.5196],\n",
      "         [ 1.7913,  0.5133,  3.9309,  ...,  1.4453,  1.0579,  1.0124],\n",
      "         ...,\n",
      "         [-1.2066,  1.5334, -0.5028,  ...,  3.0593,  1.6429, -0.3819],\n",
      "         [-0.2399,  1.7933, -0.2249,  ...,  3.5277,  0.7485,  0.6846],\n",
      "         [ 0.0466,  1.0194,  1.5723,  ...,  3.3077,  1.0985, -0.3363]],\n",
      "\n",
      "        [[-2.4314,  3.6893,  2.4690,  ...,  1.2122, -0.4808,  2.3052],\n",
      "         [ 0.0000,  2.1506,  0.9138,  ...,  0.0000,  0.0000,  1.7075],\n",
      "         [ 2.4089,  0.0000,  3.5201,  ...,  2.1598,  0.6232,  0.9850],\n",
      "         ...,\n",
      "         [-0.6973,  1.1897,  0.1218,  ...,  3.8041,  0.0000, -0.1502],\n",
      "         [ 0.5430,  1.8338,  0.7405,  ...,  4.0965,  1.2520, -0.0000],\n",
      "         [ 0.0347,  0.0000,  1.6919,  ...,  3.5361,  0.9565, -0.1177]],\n",
      "\n",
      "        [[-2.6425,  3.5130,  0.0000,  ...,  1.2962, -0.0372,  2.8476],\n",
      "         [-1.8802,  1.5302,  0.8896,  ...,  1.3318,  0.5522,  1.7390],\n",
      "         [ 0.0000,  0.8212,  4.2876,  ...,  1.9011,  0.8245,  1.5459],\n",
      "         ...,\n",
      "         [-0.6214,  1.4962,  0.0410,  ...,  2.0470,  0.6780, -0.0774],\n",
      "         [ 0.0000,  0.0000, -0.1553,  ...,  3.3669,  0.0000,  0.5210],\n",
      "         [-0.2141,  0.8608,  1.8156,  ...,  3.6342,  0.8145, -0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.3214,  2.1409,  0.0000,  ...,  0.7076, -0.2188,  3.6281],\n",
      "         [ 0.9353,  2.0784,  1.2638,  ...,  0.3550, -0.1856,  2.0776],\n",
      "         [ 1.3491, -0.0000,  1.3907,  ...,  1.9194,  0.9300,  2.9097],\n",
      "         ...,\n",
      "         [ 0.3960,  1.2217, -1.3423,  ...,  0.0000,  1.2065,  1.9494],\n",
      "         [ 0.1676,  0.9662, -0.6196,  ...,  0.0000,  1.0428,  2.3510],\n",
      "         [ 0.7259,  0.6642,  1.0478,  ...,  4.3240,  1.1901,  1.5343]],\n",
      "\n",
      "        [[-1.7745,  3.3089,  2.3974,  ...,  1.1332,  0.2497,  3.0916],\n",
      "         [ 0.2584,  0.8213,  1.4964,  ...,  2.0449, -1.5143,  2.4856],\n",
      "         [ 2.2845,  0.4687,  2.0148,  ..., -0.5963,  0.3198,  1.0376],\n",
      "         ...,\n",
      "         [ 1.1177,  1.7801,  0.2467,  ...,  3.5949,  1.1547, -0.5123],\n",
      "         [ 1.5140,  1.6944,  0.9352,  ...,  2.2590,  1.0942, -0.0000],\n",
      "         [ 0.0818,  0.8327,  2.2864,  ...,  3.1571, -0.3784,  1.6940]],\n",
      "\n",
      "        [[-2.3841,  3.3800,  2.2258,  ...,  1.1289, -0.6231,  0.8377],\n",
      "         [ 1.0086,  0.3075,  4.8600,  ...,  2.9713,  0.3035,  0.9581],\n",
      "         [ 0.2470,  1.0813,  2.2692,  ...,  0.0000, -1.1911,  2.6288],\n",
      "         ...,\n",
      "         [-0.3631,  1.0052, -0.2910,  ...,  4.0117,  1.1376, -0.4511],\n",
      "         [-0.1801,  0.7793,  0.2483,  ...,  2.1913,  1.0298, -0.0886],\n",
      "         [-0.1852,  0.3874,  1.0105,  ...,  3.9885,  0.7492, -0.6228]]],\n",
      "       device='cuda:0', grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 91, 2048])\n",
      "tensor([[[-8.4103e-01,  2.8898e+00,  2.0600e+00,  ...,  1.3736e+00,\n",
      "          -1.0372e+00,  1.4900e+00],\n",
      "         [-4.4120e-01,  1.3562e+00,  2.9244e+00,  ...,  1.9933e+00,\n",
      "          -4.8257e-01,  0.0000e+00],\n",
      "         [ 2.2578e+00, -7.5677e-01,  4.7749e+00,  ...,  1.5584e+00,\n",
      "           5.6722e-02,  1.0300e+00],\n",
      "         ...,\n",
      "         [-8.6146e-01,  9.5530e-01, -3.7641e-01,  ...,  2.9532e+00,\n",
      "           1.4787e-01,  1.0721e+00],\n",
      "         [ 9.4688e-01,  0.0000e+00,  3.0998e-01,  ...,  3.3616e+00,\n",
      "          -2.4452e-01,  1.2229e+00],\n",
      "         [ 1.3741e+00,  0.0000e+00,  0.0000e+00,  ...,  3.2721e+00,\n",
      "          -0.0000e+00,  2.7759e-01]],\n",
      "\n",
      "        [[-1.2172e+00,  2.6823e+00,  2.4752e+00,  ...,  1.7603e+00,\n",
      "          -6.4566e-01,  1.4112e+00],\n",
      "         [ 7.2308e-01,  1.1331e+00,  3.0191e+00,  ...,  1.0620e+00,\n",
      "          -6.6608e-01,  1.5769e+00],\n",
      "         [ 2.8682e+00, -1.0815e+00,  4.6439e+00,  ...,  2.2263e+00,\n",
      "          -6.5788e-01,  0.0000e+00],\n",
      "         ...,\n",
      "         [-1.1788e-01,  9.0296e-01,  2.7240e-02,  ...,  3.4104e+00,\n",
      "          -4.7606e-01,  5.9148e-01],\n",
      "         [ 1.3040e+00,  0.0000e+00,  1.1489e+00,  ...,  3.6086e+00,\n",
      "           2.8813e-01,  0.0000e+00],\n",
      "         [ 0.0000e+00, -0.0000e+00,  2.7548e+00,  ...,  2.9664e+00,\n",
      "          -2.7734e-01,  5.1895e-01]],\n",
      "\n",
      "        [[-1.6733e+00,  2.3002e+00,  1.2864e+00,  ...,  2.1598e+00,\n",
      "          -3.3050e-01,  1.9900e+00],\n",
      "         [-7.2614e-02,  9.7158e-01,  2.3623e+00,  ...,  1.9184e+00,\n",
      "          -1.8209e-01,  0.0000e+00],\n",
      "         [ 0.0000e+00, -4.4119e-01,  4.8614e+00,  ...,  1.9440e+00,\n",
      "          -4.4574e-01,  1.7117e+00],\n",
      "         ...,\n",
      "         [ 1.4246e-01,  1.1544e+00,  6.8340e-02,  ...,  2.4649e+00,\n",
      "          -5.7620e-01,  9.7714e-01],\n",
      "         [ 1.3392e+00,  7.6807e-01,  7.1254e-01,  ...,  2.8575e+00,\n",
      "          -5.9539e-01,  9.7521e-01],\n",
      "         [ 1.0275e+00,  4.7698e-01,  2.4396e+00,  ...,  3.5038e+00,\n",
      "          -9.7364e-02,  7.0908e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.1946e+00,  1.9986e+00,  7.2058e-01,  ...,  1.0931e+00,\n",
      "          -8.0456e-01,  2.5869e+00],\n",
      "         [ 1.5575e+00,  1.8207e+00,  2.5548e+00,  ...,  1.0572e+00,\n",
      "          -5.8824e-01,  2.3833e+00],\n",
      "         [ 1.9418e+00, -5.9698e-01,  2.7450e+00,  ...,  2.6701e+00,\n",
      "           5.8358e-01,  2.8130e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  1.1042e+00, -9.1044e-01,  ...,  9.6997e-01,\n",
      "           0.0000e+00,  2.1612e+00],\n",
      "         [ 1.1452e+00,  1.3255e+00,  3.9285e-01,  ...,  6.0438e-01,\n",
      "           8.2953e-02,  0.0000e+00],\n",
      "         [ 1.6260e+00,  1.7572e-01,  2.0824e+00,  ...,  0.0000e+00,\n",
      "           1.0784e-01,  2.2222e+00]],\n",
      "\n",
      "        [[-8.0866e-01,  2.3981e+00,  2.0722e+00,  ...,  1.9280e+00,\n",
      "          -2.3737e-01,  2.1501e+00],\n",
      "         [ 1.8040e+00,  3.5214e-01,  2.9521e+00,  ...,  2.3694e+00,\n",
      "          -1.2856e+00,  2.1147e+00],\n",
      "         [ 2.8259e+00, -7.8108e-01,  3.1172e+00,  ...,  1.1303e+00,\n",
      "          -5.9572e-02,  1.2650e+00],\n",
      "         ...,\n",
      "         [ 1.2034e+00,  1.4664e+00,  3.0080e-01,  ...,  2.8511e+00,\n",
      "           4.0383e-01,  1.1106e+00],\n",
      "         [ 2.4853e+00,  0.0000e+00,  1.1635e+00,  ...,  2.8911e+00,\n",
      "           1.5115e-01,  0.0000e+00],\n",
      "         [ 1.4539e+00,  8.6096e-02,  2.7725e+00,  ...,  2.4924e+00,\n",
      "          -8.1861e-01,  1.7878e+00]],\n",
      "\n",
      "        [[-1.3255e+00,  0.0000e+00,  2.4382e+00,  ...,  1.6045e+00,\n",
      "          -8.3648e-01,  1.2582e+00],\n",
      "         [ 1.4480e+00,  3.3833e-01,  5.2591e+00,  ...,  3.0938e+00,\n",
      "          -5.6961e-01,  5.9483e-01],\n",
      "         [ 1.1441e+00, -3.4989e-01,  3.7129e+00,  ...,  0.0000e+00,\n",
      "          -1.2134e+00,  1.7089e+00],\n",
      "         ...,\n",
      "         [-1.1514e-01,  0.0000e+00, -2.0832e-02,  ...,  3.7342e+00,\n",
      "          -3.9382e-03,  1.7704e-02],\n",
      "         [ 1.3887e+00,  6.7562e-01,  8.6468e-01,  ...,  2.5807e+00,\n",
      "           1.6250e-01,  1.1991e+00],\n",
      "         [ 7.1331e-01, -8.9756e-02,  2.3911e+00,  ...,  3.5564e+00,\n",
      "          -2.5621e-01,  0.0000e+00]]], device='cuda:0',\n",
      "       grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 91, 2048])\n",
      "tensor([[[-1.1033,  1.7670,  1.7251,  ...,  1.4087, -1.0013,  1.0850],\n",
      "         [-0.0000, -0.1015,  2.9100,  ...,  1.9354, -0.4054,  0.6584],\n",
      "         [ 2.0991, -1.7173,  4.1056,  ...,  1.4880, -0.3472,  1.3889],\n",
      "         ...,\n",
      "         [-0.9705,  0.6740, -1.1385,  ...,  0.0000, -0.3330,  1.7546],\n",
      "         [ 0.0000, -0.2080, -0.2608,  ...,  0.0000, -0.2022,  1.5213],\n",
      "         [ 1.2746, -0.3707,  1.3240,  ...,  2.2181, -0.3097,  1.0113]],\n",
      "\n",
      "        [[-1.1094,  1.6623,  1.9140,  ...,  1.9910, -0.4304,  1.5025],\n",
      "         [ 0.2063,  0.0000,  3.0417,  ...,  1.1734, -0.4256,  0.0000],\n",
      "         [ 1.8708, -2.1534,  3.9072,  ...,  1.8974, -1.0070,  0.6653],\n",
      "         ...,\n",
      "         [-1.1093,  0.1146, -0.4700,  ...,  2.4798, -0.7931,  1.0018],\n",
      "         [ 1.0503,  0.2409, -0.1739,  ...,  2.8391, -0.7784,  1.0629],\n",
      "         [ 0.5054, -0.5939,  2.3895,  ...,  2.1817, -0.9158,  1.2477]],\n",
      "\n",
      "        [[-1.4359,  1.3183,  1.9105,  ...,  2.3981, -0.3875,  1.9460],\n",
      "         [ 0.0000,  0.7410,  2.5913,  ...,  1.9558, -0.2202,  0.0000],\n",
      "         [ 0.3192, -1.2009,  3.4811,  ...,  1.8487, -0.8451,  1.7790],\n",
      "         ...,\n",
      "         [-0.7283,  0.7573, -0.6902,  ...,  2.3289, -0.8213,  1.7156],\n",
      "         [ 1.3910,  0.9227,  0.4699,  ...,  2.6092, -0.8047,  1.7914],\n",
      "         [ 1.2891,  0.1560,  2.1120,  ...,  2.6419, -0.9534,  0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.0727,  0.9927,  1.3145,  ...,  1.6927, -0.8069,  2.6422],\n",
      "         [ 1.1949,  0.8216,  2.4013,  ...,  1.8134, -0.6553,  2.3562],\n",
      "         [ 1.8778, -1.4718,  2.9102,  ...,  2.4189, -0.0685,  2.6364],\n",
      "         ...,\n",
      "         [-0.5737,  0.2448, -0.8062,  ...,  1.3496, -0.2292,  2.2704],\n",
      "         [ 0.5705,  0.7372,  0.1519,  ...,  1.3518, -0.2749,  1.6540],\n",
      "         [ 1.6062, -0.5309,  0.0000,  ...,  1.6006, -0.2278,  2.3609]],\n",
      "\n",
      "        [[-0.1577,  1.4573,  1.0053,  ...,  2.3653, -0.0000,  2.4541],\n",
      "         [ 1.2182,  0.0861,  0.0000,  ...,  2.1645, -1.3104,  1.9436],\n",
      "         [ 0.0000, -1.5338,  2.6556,  ...,  1.6023, -0.3593,  1.6741],\n",
      "         ...,\n",
      "         [ 0.1789,  0.9827, -0.5084,  ...,  2.1994, -0.1363,  1.7457],\n",
      "         [ 1.7941,  0.1649,  0.1684,  ...,  2.0111, -0.2792,  1.0451],\n",
      "         [ 1.2279, -0.0000,  2.3770,  ...,  1.8986, -1.0159,  1.9715]],\n",
      "\n",
      "        [[-0.0000,  0.4357,  0.0000,  ...,  1.5577, -0.8302,  1.4361],\n",
      "         [ 0.6745,  0.2455,  4.0042,  ...,  2.3924, -0.6566,  0.8896],\n",
      "         [ 1.3512, -1.4042,  0.0000,  ...,  1.2109, -1.1782,  1.5234],\n",
      "         ...,\n",
      "         [-0.7721,  0.0275, -0.6398,  ...,  0.0000, -0.1554,  0.6568],\n",
      "         [ 0.9207,  0.5219,  0.5142,  ...,  2.7476, -0.0000,  1.6449],\n",
      "         [ 0.5617, -0.0000,  2.1630,  ...,  3.0536, -0.5372,  0.7984]]],\n",
      "       device='cuda:0', grad_fn=<NativeDropoutBackward0>)\n",
      "\n",
      "torch.Size([100, 91, 2048])\n",
      "tensor([[[-2.4506,  0.0000,  0.7913,  ...,  2.1278, -0.8051,  2.1245],\n",
      "         [-0.0000, -0.0083,  0.0000,  ...,  1.4228, -0.3519,  1.1568],\n",
      "         [ 0.2955, -1.7556,  2.7079,  ...,  1.4075, -0.0000,  1.5605],\n",
      "         ...,\n",
      "         [-1.9875,  0.5242, -1.8534,  ...,  1.0465, -0.6823,  2.1778],\n",
      "         [-0.4758,  0.3722, -0.0000,  ...,  0.8624, -0.6593,  1.6789],\n",
      "         [ 0.5271, -0.1924,  0.8115,  ...,  2.0641, -0.5559,  1.3423]],\n",
      "\n",
      "        [[-1.4096,  1.8231,  0.3838,  ...,  2.2364, -0.2124,  1.7090],\n",
      "         [-0.9283,  0.0000,  1.9450,  ...,  1.3568, -0.0000,  1.7382],\n",
      "         [-0.1764, -1.6102,  2.6257,  ...,  1.6769, -1.0092,  0.9091],\n",
      "         ...,\n",
      "         [-1.8473,  0.3264, -1.5007,  ...,  1.8015, -0.7066,  0.0000],\n",
      "         [-0.1174,  0.7748, -0.0000,  ...,  0.0000, -0.5219,  1.5889],\n",
      "         [-0.5163, -0.0827,  1.1602,  ...,  1.9248, -0.8825,  1.7103]],\n",
      "\n",
      "        [[-2.0808,  1.3261,  0.0938,  ...,  2.2341, -0.7253,  2.1083],\n",
      "         [ 0.0335,  0.4693,  1.6608,  ...,  2.0586, -0.0000,  1.1342],\n",
      "         [-0.0660, -0.7866,  2.0146,  ...,  1.7417, -0.9240,  1.8711],\n",
      "         ...,\n",
      "         [-1.7679,  1.1463, -1.2323,  ...,  1.9556, -0.0000,  1.9776],\n",
      "         [-0.2137,  1.3034, -0.9889,  ...,  1.6004, -0.8463,  0.0000],\n",
      "         [ 0.8367, -0.1425,  1.2865,  ...,  2.6590, -1.0391,  1.6365]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.1567,  1.0105,  0.3603,  ...,  1.7967, -0.8724,  2.5292],\n",
      "         [ 0.0501,  0.5237,  1.4308,  ...,  1.9367, -0.4462,  1.9114],\n",
      "         [ 0.2438, -1.5457,  1.7831,  ...,  2.4902, -0.5616,  2.6218],\n",
      "         ...,\n",
      "         [-1.9986,  0.6375, -1.7496,  ...,  1.4465, -0.6072,  2.0114],\n",
      "         [-0.3627,  0.0000, -0.8250,  ...,  1.7367, -0.4859,  2.2838],\n",
      "         [-0.0764, -0.9200,  0.2342,  ...,  1.6604, -0.5192,  2.2384]],\n",
      "\n",
      "        [[-1.5097,  0.0000,  0.1409,  ...,  2.1189, -0.2818,  2.1719],\n",
      "         [-0.0192,  0.3902,  0.8125,  ...,  1.8090, -0.5768,  2.2277],\n",
      "         [-0.7465, -0.0000,  1.3851,  ...,  2.2014, -0.5181,  2.1234],\n",
      "         ...,\n",
      "         [-1.5408,  1.1593, -2.2147,  ...,  2.3631, -0.3600,  1.6795],\n",
      "         [ 0.8101,  0.5499, -0.9387,  ...,  1.9557, -0.0000,  1.5055],\n",
      "         [ 0.2092,  0.0836,  1.1130,  ...,  2.2247, -0.8412,  2.1961]],\n",
      "\n",
      "        [[-1.3838,  0.7453,  0.0104,  ...,  1.8106, -0.4985,  1.3500],\n",
      "         [ 0.3930, -0.3423,  2.4543,  ...,  2.6614, -0.0000,  1.1438],\n",
      "         [ 0.3958, -1.7486,  1.2251,  ...,  1.5330, -0.7743,  1.3055],\n",
      "         ...,\n",
      "         [-2.0174,  0.5463, -1.7985,  ...,  0.0000, -0.2821,  1.4811],\n",
      "         [-0.0643,  0.8420, -0.6355,  ...,  2.4035, -0.2699,  1.7144],\n",
      "         [-0.1806, -0.0089,  1.1597,  ...,  2.6409, -0.6275,  1.8819]]],\n",
      "       device='cuda:0', grad_fn=<NativeDropoutBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m criterion \u001b[38;5;241m=\u001b[39m LossWithLS(\u001b[38;5;28mlen\u001b[39m(word_map), \u001b[38;5;241m0.2\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m---> 22\u001b[0m     loss_train \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransformer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     state \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m: epoch, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransformer\u001b[39m\u001b[38;5;124m'\u001b[39m: transformer, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransformer_optimizer\u001b[39m\u001b[38;5;124m'\u001b[39m: transformer_optimizer}\n\u001b[1;32m     25\u001b[0m     torch\u001b[38;5;241m.\u001b[39msave(state, directory \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/checkpoint_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(epoch) \u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.pth.tar\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[71], line 29\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(train_loader, transformer, criterion, epoch)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Backprop\u001b[39;00m\n\u001b[1;32m     28\u001b[0m transformer_optimizer\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 29\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m transformer_optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     32\u001b[0m sum_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m samples\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.8/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.8/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "directory = 'experiment_pretrained_1'\n",
    "\n",
    "d_model = 2048\n",
    "heads = 16\n",
    "num_layers = 5\n",
    "epochs = 100\n",
    "\n",
    "loss_history_pratrained_embed_transformer = []\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "with open('WORDMAP_corpus_KBFILKOM.json', 'r') as j:\n",
    "    word_map = json.load(j)\n",
    "    \n",
    "transformer = TransformerPreTrainedEmbedding(d_model = d_model, heads = heads, num_layers = num_layers, word_map = word_map, max_len=95)\n",
    "transformer = transformer.to(device)\n",
    "adam_optimizer = torch.optim.Adam(transformer.parameters(), lr=0.001, betas=(0.9, 0.98), eps=1e-9)\n",
    "transformer_optimizer = AdamWarmup(model_size = d_model, warmup_steps = 4000, optimizer = adam_optimizer)\n",
    "criterion = LossWithLS(len(word_map), 0.2)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss_train = train(train_loader, transformer, criterion, epoch)\n",
    "\n",
    "    state = {'epoch': epoch, 'transformer': transformer, 'transformer_optimizer': transformer_optimizer}\n",
    "    torch.save(state, directory + '/checkpoint_' + str(epoch) +'.pth.tar')\n",
    "\n",
    "    loss_history_pratrained_embed_transformer.append(loss_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists at experiment_vanilla_30624\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.35 GiB total capacity; 4.32 GiB already allocated; 4.19 MiB free; 4.42 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m     word_map \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(j)\n\u001b[1;32m     16\u001b[0m transformer \u001b[38;5;241m=\u001b[39m Transformer(d_model \u001b[38;5;241m=\u001b[39m d_model, heads \u001b[38;5;241m=\u001b[39m heads, num_layers \u001b[38;5;241m=\u001b[39m num_layers, word_map \u001b[38;5;241m=\u001b[39m word_map, max_len\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m95\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m transformer \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m adam_optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(transformer\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m, betas\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0.9\u001b[39m, \u001b[38;5;241m0.98\u001b[39m), eps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-9\u001b[39m)\n\u001b[1;32m     19\u001b[0m transformer_optimizer \u001b[38;5;241m=\u001b[39m AdamWarmup(model_size \u001b[38;5;241m=\u001b[39m d_model, warmup_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4000\u001b[39m, optimizer \u001b[38;5;241m=\u001b[39m adam_optimizer)\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.8/site-packages/torch/nn/modules/module.py:1145\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.8/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.8/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.8/site-packages/torch/nn/modules/module.py:820\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 820\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    821\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.8/site-packages/torch/nn/modules/module.py:1143\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 79.35 GiB total capacity; 4.32 GiB already allocated; 4.19 MiB free; 4.42 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "directory = 'experiment_vanilla_30624'\n",
    "create_directory(directory)\n",
    "\n",
    "d_model = 2048\n",
    "heads = 16\n",
    "num_layers = 5\n",
    "epochs = 100\n",
    "\n",
    "loss_history_vanilla_transformer = []\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "with open('WORDMAP_corpus_KBFILKOM.json', 'r') as j:\n",
    "    word_map = json.load(j)\n",
    "    \n",
    "transformer = Transformer(d_model = d_model, heads = heads, num_layers = num_layers, word_map = word_map, max_len=95)\n",
    "transformer = transformer.to(device)\n",
    "adam_optimizer = torch.optim.Adam(transformer.parameters(), lr=0.001, betas=(0.9, 0.98), eps=1e-9)\n",
    "transformer_optimizer = AdamWarmup(model_size = d_model, warmup_steps = 4000, optimizer = adam_optimizer)\n",
    "criterion = LossWithLS(len(word_map), 0.2)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss_train = train(train_loader, transformer, criterion, epoch)\n",
    "\n",
    "    state = {'epoch': epoch, 'transformer': transformer, 'transformer_optimizer': transformer_optimizer}\n",
    "    torch.save(state, directory + '/checkpoint_' + str(epoch) +'.pth.tar')\n",
    "\n",
    "    loss_history_vanilla_transformer.append(loss_train)\n",
    "\n",
    "import yaml \n",
    "\n",
    "with open(directory + '/loss_history_vanilla_transformer.yaml', 'w') as file:\n",
    "    yaml.dump(loss_history_vanilla_transformer, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla without Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists at experiment_vanillanoreg_01724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[neptune] [warning] NeptuneWarning: The following monitoring options are disabled by default in interactive sessions: 'capture_stdout', 'capture_stderr', 'capture_traceback', and 'capture_hardware_metrics'. To enable them, set each parameter to 'True' when initializing the run. The monitoring will continue until you call run.stop() or the kernel stops. Also note: Your source files can only be tracked if you pass the path(s) to the 'source_code' argument. For help, see the Neptune docs: https://docs.neptune.ai/logging/source_code/\n",
      "/home/andyalyfsyah/.conda/envs/myenv/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 26.00 MiB (GPU 0; 79.35 GiB total capacity; 4.35 GiB already allocated; 25.19 MiB free; 4.40 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m criterion \u001b[38;5;241m=\u001b[39m LossWithLS(\u001b[38;5;28mlen\u001b[39m(word_map), \u001b[38;5;241m0.2\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(parameters[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[0;32m---> 29\u001b[0m     loss_train \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransformer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     state \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m: epoch, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransformer\u001b[39m\u001b[38;5;124m'\u001b[39m: transformer, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransformer_optimizer\u001b[39m\u001b[38;5;124m'\u001b[39m: transformer_optimizer}\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;66;03m# torch.save(state, directory + '/checkpoint_' + str(epoch) +'.pth.tar')\u001b[39;00m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m# run['model_checkpoint'].upload(directory + '/checkpoint_' + str(epoch) +'.pth.tar')\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[60], line 22\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(train_loader, transformer, criterion, epoch)\u001b[0m\n\u001b[1;32m     19\u001b[0m question_mask, reply_input_mask, reply_target_mask \u001b[38;5;241m=\u001b[39m create_masks(question, reply_input, reply_target)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Get the transformer outputs\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreply_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreply_input_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Compute the loss\u001b[39;00m\n\u001b[1;32m     25\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(out, reply_target, reply_target_mask)\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[56], line 59\u001b[0m, in \u001b[0;36mTransformerNoReg.forward\u001b[0;34m(self, src_words, src_mask, target_words, target_mask)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, src_words, src_mask, target_words, target_mask):\n\u001b[1;32m     58\u001b[0m     encoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode(src_words, src_mask)\n\u001b[0;32m---> 59\u001b[0m     decoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_words\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     out \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mlog_softmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogit(decoded), dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "Cell \u001b[0;32mIn[56], line 54\u001b[0m, in \u001b[0;36mTransformerNoReg.decode\u001b[0;34m(self, tgt_embeddings, target_mask, src_embeddings, src_mask)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers):\n\u001b[1;32m     53\u001b[0m     tgt_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed(tgt_embeddings, i)\n\u001b[0;32m---> 54\u001b[0m     tgt_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtgt_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tgt_embeddings\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[55], line 31\u001b[0m, in \u001b[0;36mDecoderLayerNoReg.forward\u001b[0;34m(self, embeddings, encoded, src_mask, target_mask)\u001b[0m\n\u001b[1;32m     29\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_multihead(embeddings, embeddings, embeddings, target_mask)\n\u001b[1;32m     30\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayernorm(query \u001b[38;5;241m+\u001b[39m embeddings)\n\u001b[0;32m---> 31\u001b[0m interacted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msrc_multihead\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m interacted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayernorm(interacted \u001b[38;5;241m+\u001b[39m query)\n\u001b[1;32m     33\u001b[0m feed_forward_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeed_forward(interacted)\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[52], line 33\u001b[0m, in \u001b[0;36mMultiHeadAttention.forward\u001b[0;34m(self, query, key, value, mask)\u001b[0m\n\u001b[1;32m     31\u001b[0m scores \u001b[38;5;241m=\u001b[39m scores\u001b[38;5;241m.\u001b[39mmasked_fill(mask \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1e9\u001b[39m)    \u001b[38;5;66;03m# (batch_size, h, max_len, max_len)\u001b[39;00m\n\u001b[1;32m     32\u001b[0m weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(scores, dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)           \u001b[38;5;66;03m# (batch_size, h, max_len, max_len)\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# (batch_size, h, max_len, max_len) matmul (batch_size, h, max_len, d_k) --> (batch_size, h, max_len, d_k)\u001b[39;00m\n\u001b[1;32m     35\u001b[0m context \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(weights, value)\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.8/site-packages/torch/nn/modules/dropout.py:59\u001b[0m, in \u001b[0;36mDropout.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.8/site-packages/torch/nn/functional.py:1252\u001b[0m, in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[1;32m   1251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout probability has to be between 0 and 1, \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(p))\n\u001b[0;32m-> 1252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _VF\u001b[38;5;241m.\u001b[39mdropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 26.00 MiB (GPU 0; 79.35 GiB total capacity; 4.35 GiB already allocated; 25.19 MiB free; 4.40 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "directory = 'experiment_vanillanoreg_01724'\n",
    "create_directory(directory)\n",
    "\n",
    "run = neptune_init(directory)\n",
    "\n",
    "parameters = {\n",
    "    'd_model': 2048,\n",
    "    'heads': 16,\n",
    "    'num_layers': 5,\n",
    "    'epochs': 100,\n",
    "}\n",
    "run['parameters'] = parameters\n",
    "\n",
    "loss_history_vanillanoreg_transformer = []\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "# device = \"cpu\"\n",
    "\n",
    "with open('WORDMAP_corpus_KBFILKOM.json', 'r') as j:\n",
    "    word_map = json.load(j)\n",
    "    \n",
    "transformer = TransformerNoReg(d_model = parameters['d_model'], heads = parameters['heads'], num_layers = parameters['num_layers'], word_map = word_map, max_len=95)\n",
    "transformer = transformer.to(device)\n",
    "adam_optimizer = torch.optim.Adam(transformer.parameters(), lr=0.001, betas=(0.9, 0.98), eps=1e-9)\n",
    "transformer_optimizer = AdamWarmup(model_size = parameters['d_model'], warmup_steps = 4000, optimizer = adam_optimizer)\n",
    "criterion = LossWithLS(len(word_map), 0.2)\n",
    "\n",
    "for epoch in range(parameters['epochs']):\n",
    "    loss_train = train(train_loader, transformer, criterion, epoch)\n",
    "\n",
    "    state = {'epoch': epoch, 'transformer': transformer, 'transformer_optimizer': transformer_optimizer}\n",
    "    # torch.save(state, directory + '/checkpoint_' + str(epoch) +'.pth.tar')\n",
    "    # run['model_checkpoint'].upload(directory + '/checkpoint_' + str(epoch) +'.pth.tar')\n",
    "\n",
    "    loss_history_vanillanoreg_transformer.append(loss_train)\n",
    "    run['train/loss'].append(loss_train)\n",
    "\n",
    "with open(directory + '/loss_history_vanillanoreg_transformer.yaml', 'w') as file:\n",
    "    yaml.dump(loss_history_vanilla_transformer, file)\n",
    "\n",
    "run.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists at experiment_deconly_17624\n",
      "Epoch [0][0/12]\tLoss: 5.239\n",
      "Epoch [1][0/12]\tLoss: 5.221\n",
      "Epoch [2][0/12]\tLoss: 5.199\n",
      "Epoch [3][0/12]\tLoss: 5.175\n",
      "Epoch [4][0/12]\tLoss: 5.128\n",
      "Epoch [5][0/12]\tLoss: 5.110\n",
      "Epoch [6][0/12]\tLoss: 5.041\n",
      "Epoch [7][0/12]\tLoss: 4.960\n",
      "Epoch [8][0/12]\tLoss: 4.799\n",
      "Epoch [9][0/12]\tLoss: 4.631\n",
      "Epoch [10][0/12]\tLoss: 4.653\n",
      "Epoch [11][0/12]\tLoss: 4.376\n",
      "Epoch [12][0/12]\tLoss: 4.351\n",
      "Epoch [13][0/12]\tLoss: 4.281\n",
      "Epoch [14][0/12]\tLoss: 3.955\n",
      "Epoch [15][0/12]\tLoss: 4.113\n",
      "Epoch [16][0/12]\tLoss: 3.999\n",
      "Epoch [17][0/12]\tLoss: 3.746\n",
      "Epoch [18][0/12]\tLoss: 3.667\n",
      "Epoch [19][0/12]\tLoss: 3.705\n",
      "Epoch [20][0/12]\tLoss: 3.673\n",
      "Epoch [21][0/12]\tLoss: 3.675\n",
      "Epoch [22][0/12]\tLoss: 3.572\n",
      "Epoch [23][0/12]\tLoss: 3.544\n",
      "Epoch [24][0/12]\tLoss: 3.512\n",
      "Epoch [25][0/12]\tLoss: 3.372\n",
      "Epoch [26][0/12]\tLoss: 3.404\n",
      "Epoch [27][0/12]\tLoss: 3.416\n",
      "Epoch [28][0/12]\tLoss: 3.384\n",
      "Epoch [29][0/12]\tLoss: 3.301\n",
      "Epoch [30][0/12]\tLoss: 3.204\n",
      "Epoch [31][0/12]\tLoss: 3.153\n",
      "Epoch [32][0/12]\tLoss: 3.029\n",
      "Epoch [33][0/12]\tLoss: 3.179\n",
      "Epoch [34][0/12]\tLoss: 3.093\n",
      "Epoch [35][0/12]\tLoss: 3.095\n",
      "Epoch [36][0/12]\tLoss: 3.017\n",
      "Epoch [37][0/12]\tLoss: 3.018\n",
      "Epoch [38][0/12]\tLoss: 2.984\n",
      "Epoch [39][0/12]\tLoss: 2.728\n",
      "Epoch [40][0/12]\tLoss: 2.911\n",
      "Epoch [41][0/12]\tLoss: 2.828\n",
      "Epoch [42][0/12]\tLoss: 2.732\n",
      "Epoch [43][0/12]\tLoss: 2.841\n",
      "Epoch [44][0/12]\tLoss: 2.884\n",
      "Epoch [45][0/12]\tLoss: 2.762\n",
      "Epoch [46][0/12]\tLoss: 2.742\n",
      "Epoch [47][0/12]\tLoss: 2.751\n",
      "Epoch [48][0/12]\tLoss: 2.881\n",
      "Epoch [49][0/12]\tLoss: 2.718\n",
      "Epoch [50][0/12]\tLoss: 2.670\n",
      "Epoch [51][0/12]\tLoss: 2.834\n",
      "Epoch [52][0/12]\tLoss: 2.547\n",
      "Epoch [53][0/12]\tLoss: 2.662\n",
      "Epoch [54][0/12]\tLoss: 2.575\n",
      "Epoch [55][0/12]\tLoss: 2.741\n",
      "Epoch [56][0/12]\tLoss: 2.740\n",
      "Epoch [57][0/12]\tLoss: 2.471\n",
      "Epoch [58][0/12]\tLoss: 2.420\n",
      "Epoch [59][0/12]\tLoss: 2.501\n",
      "Epoch [60][0/12]\tLoss: 2.444\n",
      "Epoch [61][0/12]\tLoss: 2.695\n",
      "Epoch [62][0/12]\tLoss: 2.395\n",
      "Epoch [63][0/12]\tLoss: 2.557\n",
      "Epoch [64][0/12]\tLoss: 2.458\n",
      "Epoch [65][0/12]\tLoss: 2.465\n",
      "Epoch [66][0/12]\tLoss: 2.440\n",
      "Epoch [67][0/12]\tLoss: 2.442\n",
      "Epoch [68][0/12]\tLoss: 2.435\n",
      "Epoch [69][0/12]\tLoss: 2.539\n",
      "Epoch [70][0/12]\tLoss: 2.569\n",
      "Epoch [71][0/12]\tLoss: 2.416\n",
      "Epoch [72][0/12]\tLoss: 2.473\n",
      "Epoch [73][0/12]\tLoss: 2.429\n",
      "Epoch [74][0/12]\tLoss: 2.453\n",
      "Epoch [75][0/12]\tLoss: 2.478\n",
      "Epoch [76][0/12]\tLoss: 2.450\n",
      "Epoch [77][0/12]\tLoss: 2.350\n",
      "Epoch [78][0/12]\tLoss: 2.438\n",
      "Epoch [79][0/12]\tLoss: 2.515\n",
      "Epoch [80][0/12]\tLoss: 2.495\n",
      "Epoch [81][0/12]\tLoss: 2.534\n",
      "Epoch [82][0/12]\tLoss: 2.410\n",
      "Epoch [83][0/12]\tLoss: 2.426\n",
      "Epoch [84][0/12]\tLoss: 2.245\n",
      "Epoch [85][0/12]\tLoss: 2.427\n",
      "Epoch [86][0/12]\tLoss: 2.522\n",
      "Epoch [87][0/12]\tLoss: 2.553\n",
      "Epoch [88][0/12]\tLoss: 2.535\n",
      "Epoch [89][0/12]\tLoss: 2.491\n",
      "Epoch [90][0/12]\tLoss: 2.481\n",
      "Epoch [91][0/12]\tLoss: 2.238\n",
      "Epoch [92][0/12]\tLoss: 2.404\n",
      "Epoch [93][0/12]\tLoss: 2.169\n",
      "Epoch [94][0/12]\tLoss: 2.605\n",
      "Epoch [95][0/12]\tLoss: 2.449\n",
      "Epoch [96][0/12]\tLoss: 2.346\n",
      "Epoch [97][0/12]\tLoss: 2.302\n",
      "Epoch [98][0/12]\tLoss: 2.231\n",
      "Epoch [99][0/12]\tLoss: 2.523\n"
     ]
    }
   ],
   "source": [
    "directory = 'experiment_deconly_17624'\n",
    "create_directory(directory)\n",
    "\n",
    "d_model = 2048\n",
    "heads = 16\n",
    "num_layers = 5\n",
    "epochs = 100\n",
    "\n",
    "loss_history_decoder_transformer = []\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "with open('WORDMAP_corpus_KBFILKOM.json', 'r') as j:\n",
    "    word_map = json.load(j)\n",
    "    \n",
    "transformer = TransformerDecoderOnly(d_model = d_model, heads = heads, num_layers = num_layers, word_map = word_map, max_len=95)\n",
    "transformer = transformer.to(device)\n",
    "adam_optimizer = torch.optim.Adam(transformer.parameters(), lr=0.001, betas=(0.9, 0.98), eps=1e-9)\n",
    "transformer_optimizer = AdamWarmup(model_size = d_model, warmup_steps = 4000, optimizer = adam_optimizer)\n",
    "criterion = LossWithLS(len(word_map), 0.2)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss_train = train(train_loader, transformer, criterion, epoch)\n",
    "\n",
    "    state = {'epoch': epoch, 'transformer': transformer, 'transformer_optimizer': transformer_optimizer}\n",
    "    torch.save(state, directory + '/checkpoint_' + str(epoch) +'.pth.tar')\n",
    "\n",
    "    loss_history_decoder_transformer.append(loss_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM_Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andyalyfsyah/.conda/envs/myenv/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.Size([100, 90, 1024])\n",
      "tensor([[[-1.3614e-03, -4.3624e-03, -1.0824e-02,  ...,  1.4897e-04,\n",
      "          -8.0209e-03, -2.2607e-03],\n",
      "         [-1.3613e-03, -4.3624e-03, -1.0824e-02,  ...,  1.4904e-04,\n",
      "          -8.0207e-03, -2.2607e-03],\n",
      "         [-1.3614e-03, -4.3625e-03, -1.0824e-02,  ...,  1.4906e-04,\n",
      "          -8.0208e-03, -2.2607e-03],\n",
      "         ...,\n",
      "         [-1.3613e-03, -4.3625e-03, -1.0824e-02,  ...,  1.4902e-04,\n",
      "          -8.0208e-03, -2.2607e-03],\n",
      "         [-1.3613e-03, -4.3625e-03, -1.0824e-02,  ...,  1.4902e-04,\n",
      "          -8.0208e-03, -2.2607e-03],\n",
      "         [-1.3613e-03, -4.3625e-03, -1.0824e-02,  ...,  1.4902e-04,\n",
      "          -8.0208e-03, -2.2607e-03]],\n",
      "\n",
      "        [[-1.2595e-03, -7.5952e-03, -1.7628e-02,  ..., -1.2847e-03,\n",
      "          -1.3483e-02, -3.4328e-03],\n",
      "         [-1.2593e-03, -7.5956e-03, -1.7629e-02,  ..., -1.2847e-03,\n",
      "          -1.3483e-02, -3.4326e-03],\n",
      "         [-1.2597e-03, -7.5958e-03, -1.7628e-02,  ..., -1.2847e-03,\n",
      "          -1.3482e-02, -3.4327e-03],\n",
      "         ...,\n",
      "         [-1.2595e-03, -7.5957e-03, -1.7628e-02,  ..., -1.2847e-03,\n",
      "          -1.3483e-02, -3.4328e-03],\n",
      "         [-1.2595e-03, -7.5957e-03, -1.7628e-02,  ..., -1.2847e-03,\n",
      "          -1.3483e-02, -3.4328e-03],\n",
      "         [-1.2595e-03, -7.5957e-03, -1.7628e-02,  ..., -1.2847e-03,\n",
      "          -1.3483e-02, -3.4328e-03]],\n",
      "\n",
      "        [[-8.5780e-04, -9.8342e-03, -2.1955e-02,  ..., -2.6095e-03,\n",
      "          -1.6767e-02, -3.9755e-03],\n",
      "         [-8.5725e-04, -9.8344e-03, -2.1954e-02,  ..., -2.6095e-03,\n",
      "          -1.6766e-02, -3.9756e-03],\n",
      "         [-8.5783e-04, -9.8349e-03, -2.1954e-02,  ..., -2.6094e-03,\n",
      "          -1.6766e-02, -3.9760e-03],\n",
      "         ...,\n",
      "         [-8.5784e-04, -9.8342e-03, -2.1954e-02,  ..., -2.6094e-03,\n",
      "          -1.6766e-02, -3.9758e-03],\n",
      "         [-8.5784e-04, -9.8342e-03, -2.1954e-02,  ..., -2.6094e-03,\n",
      "          -1.6766e-02, -3.9758e-03],\n",
      "         [-8.5784e-04, -9.8342e-03, -2.1954e-02,  ..., -2.6094e-03,\n",
      "          -1.6766e-02, -3.9758e-03]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-6.8196e-05, -1.3804e-02, -2.9216e-02,  ..., -4.4320e-03,\n",
      "          -1.9836e-02, -4.2003e-03],\n",
      "         [-6.1045e-05, -1.3812e-02, -2.9218e-02,  ..., -4.4368e-03,\n",
      "          -1.9839e-02, -4.1961e-03],\n",
      "         [-6.2186e-05, -1.3810e-02, -2.9215e-02,  ..., -4.4344e-03,\n",
      "          -1.9837e-02, -4.1937e-03],\n",
      "         ...,\n",
      "         [-6.2841e-05, -1.3810e-02, -2.9205e-02,  ..., -4.4328e-03,\n",
      "          -1.9815e-02, -4.2125e-03],\n",
      "         [-6.2841e-05, -1.3810e-02, -2.9205e-02,  ..., -4.4328e-03,\n",
      "          -1.9815e-02, -4.2125e-03],\n",
      "         [-6.2841e-05, -1.3810e-02, -2.9205e-02,  ..., -4.4328e-03,\n",
      "          -1.9815e-02, -4.2125e-03]],\n",
      "\n",
      "        [[-6.7548e-05, -1.3804e-02, -2.9214e-02,  ..., -4.4326e-03,\n",
      "          -1.9836e-02, -4.1999e-03],\n",
      "         [-5.9781e-05, -1.3811e-02, -2.9218e-02,  ..., -4.4359e-03,\n",
      "          -1.9839e-02, -4.1946e-03],\n",
      "         [-6.1878e-05, -1.3810e-02, -2.9215e-02,  ..., -4.4349e-03,\n",
      "          -1.9837e-02, -4.1940e-03],\n",
      "         ...,\n",
      "         [-6.2659e-05, -1.3810e-02, -2.9206e-02,  ..., -4.4328e-03,\n",
      "          -1.9815e-02, -4.2122e-03],\n",
      "         [-6.2659e-05, -1.3810e-02, -2.9206e-02,  ..., -4.4328e-03,\n",
      "          -1.9815e-02, -4.2122e-03],\n",
      "         [-6.2659e-05, -1.3810e-02, -2.9206e-02,  ..., -4.4328e-03,\n",
      "          -1.9815e-02, -4.2122e-03]],\n",
      "\n",
      "        [[-6.7382e-05, -1.3804e-02, -2.9213e-02,  ..., -4.4324e-03,\n",
      "          -1.9836e-02, -4.1985e-03],\n",
      "         [-5.9071e-05, -1.3810e-02, -2.9218e-02,  ..., -4.4345e-03,\n",
      "          -1.9839e-02, -4.1944e-03],\n",
      "         [-6.2026e-05, -1.3810e-02, -2.9215e-02,  ..., -4.4343e-03,\n",
      "          -1.9836e-02, -4.1936e-03],\n",
      "         ...,\n",
      "         [-6.2491e-05, -1.3810e-02, -2.9205e-02,  ..., -4.4330e-03,\n",
      "          -1.9815e-02, -4.2122e-03],\n",
      "         [-6.2491e-05, -1.3810e-02, -2.9205e-02,  ..., -4.4330e-03,\n",
      "          -1.9815e-02, -4.2122e-03],\n",
      "         [-6.2491e-05, -1.3810e-02, -2.9205e-02,  ..., -4.4330e-03,\n",
      "          -1.9815e-02, -4.2122e-03]]], device='cuda:0',\n",
      "       grad_fn=<CudnnRnnBackward0>)\n",
      "\n",
      "torch.Size([100, 90, 1024])\n",
      "tensor([[[-6.7069e-05, -1.3804e-02, -2.9212e-02,  ..., -4.4330e-03,\n",
      "          -1.9836e-02, -4.1965e-03],\n",
      "         [-5.8737e-05, -1.3809e-02, -2.9219e-02,  ..., -4.4339e-03,\n",
      "          -1.9839e-02, -4.1942e-03],\n",
      "         [-6.1926e-05, -1.3809e-02, -2.9215e-02,  ..., -4.4343e-03,\n",
      "          -1.9835e-02, -4.1939e-03],\n",
      "         ...,\n",
      "         [-6.2593e-05, -1.3810e-02, -2.9205e-02,  ..., -4.4332e-03,\n",
      "          -1.9815e-02, -4.2122e-03],\n",
      "         [-6.2647e-05, -1.3809e-02, -2.9205e-02,  ..., -4.4330e-03,\n",
      "          -1.9815e-02, -4.2121e-03],\n",
      "         [-6.2571e-05, -1.3809e-02, -2.9205e-02,  ..., -4.4330e-03,\n",
      "          -1.9815e-02, -4.2119e-03]],\n",
      "\n",
      "        [[-6.6759e-05, -1.3804e-02, -2.9213e-02,  ..., -4.4332e-03,\n",
      "          -1.9836e-02, -4.1949e-03],\n",
      "         [-5.8946e-05, -1.3809e-02, -2.9218e-02,  ..., -4.4337e-03,\n",
      "          -1.9839e-02, -4.1934e-03],\n",
      "         [-6.2444e-05, -1.3807e-02, -2.9215e-02,  ..., -4.4336e-03,\n",
      "          -1.9835e-02, -4.1947e-03],\n",
      "         ...,\n",
      "         [-6.2562e-05, -1.3810e-02, -2.9205e-02,  ..., -4.4323e-03,\n",
      "          -1.9815e-02, -4.2118e-03],\n",
      "         [-6.2948e-05, -1.3810e-02, -2.9205e-02,  ..., -4.4324e-03,\n",
      "          -1.9815e-02, -4.2117e-03],\n",
      "         [-6.2480e-05, -1.3810e-02, -2.9206e-02,  ..., -4.4321e-03,\n",
      "          -1.9815e-02, -4.2119e-03]],\n",
      "\n",
      "        [[-6.6118e-05, -1.3805e-02, -2.9213e-02,  ..., -4.4329e-03,\n",
      "          -1.9836e-02, -4.1932e-03],\n",
      "         [-5.9408e-05, -1.3808e-02, -2.9218e-02,  ..., -4.4336e-03,\n",
      "          -1.9839e-02, -4.1936e-03],\n",
      "         [-6.1865e-05, -1.3807e-02, -2.9215e-02,  ..., -4.4336e-03,\n",
      "          -1.9836e-02, -4.1938e-03],\n",
      "         ...,\n",
      "         [-6.2634e-05, -1.3810e-02, -2.9205e-02,  ..., -4.4321e-03,\n",
      "          -1.9815e-02, -4.2116e-03],\n",
      "         [-6.2698e-05, -1.3811e-02, -2.9206e-02,  ..., -4.4322e-03,\n",
      "          -1.9815e-02, -4.2113e-03],\n",
      "         [-6.2588e-05, -1.3810e-02, -2.9206e-02,  ..., -4.4319e-03,\n",
      "          -1.9815e-02, -4.2117e-03]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-5.8988e-05, -1.3803e-02, -2.9215e-02,  ..., -4.4370e-03,\n",
      "          -1.9828e-02, -4.1865e-03],\n",
      "         [-5.8421e-05, -1.3805e-02, -2.9215e-02,  ..., -4.4386e-03,\n",
      "          -1.9830e-02, -4.1857e-03],\n",
      "         [-5.7188e-05, -1.3804e-02, -2.9215e-02,  ..., -4.4390e-03,\n",
      "          -1.9829e-02, -4.1872e-03],\n",
      "         ...,\n",
      "         [-5.8509e-05, -1.3804e-02, -2.9216e-02,  ..., -4.4370e-03,\n",
      "          -1.9830e-02, -4.1872e-03],\n",
      "         [-5.8603e-05, -1.3800e-02, -2.9215e-02,  ..., -4.4370e-03,\n",
      "          -1.9829e-02, -4.1879e-03],\n",
      "         [-5.8197e-05, -1.3804e-02, -2.9214e-02,  ..., -4.4370e-03,\n",
      "          -1.9828e-02, -4.1867e-03]],\n",
      "\n",
      "        [[-5.9568e-05, -1.3803e-02, -2.9215e-02,  ..., -4.4370e-03,\n",
      "          -1.9829e-02, -4.1863e-03],\n",
      "         [-5.8207e-05, -1.3804e-02, -2.9215e-02,  ..., -4.4382e-03,\n",
      "          -1.9829e-02, -4.1858e-03],\n",
      "         [-5.7153e-05, -1.3804e-02, -2.9215e-02,  ..., -4.4389e-03,\n",
      "          -1.9829e-02, -4.1876e-03],\n",
      "         ...,\n",
      "         [-5.8460e-05, -1.3804e-02, -2.9216e-02,  ..., -4.4372e-03,\n",
      "          -1.9830e-02, -4.1871e-03],\n",
      "         [-5.8729e-05, -1.3801e-02, -2.9215e-02,  ..., -4.4369e-03,\n",
      "          -1.9829e-02, -4.1887e-03],\n",
      "         [-5.7963e-05, -1.3804e-02, -2.9214e-02,  ..., -4.4374e-03,\n",
      "          -1.9828e-02, -4.1868e-03]],\n",
      "\n",
      "        [[-5.9160e-05, -1.3804e-02, -2.9215e-02,  ..., -4.4368e-03,\n",
      "          -1.9829e-02, -4.1873e-03],\n",
      "         [-5.7737e-05, -1.3803e-02, -2.9214e-02,  ..., -4.4385e-03,\n",
      "          -1.9829e-02, -4.1858e-03],\n",
      "         [-5.7733e-05, -1.3804e-02, -2.9215e-02,  ..., -4.4393e-03,\n",
      "          -1.9829e-02, -4.1877e-03],\n",
      "         ...,\n",
      "         [-5.8764e-05, -1.3804e-02, -2.9216e-02,  ..., -4.4368e-03,\n",
      "          -1.9829e-02, -4.1868e-03],\n",
      "         [-5.8800e-05, -1.3801e-02, -2.9216e-02,  ..., -4.4373e-03,\n",
      "          -1.9829e-02, -4.1891e-03],\n",
      "         [-5.8049e-05, -1.3804e-02, -2.9214e-02,  ..., -4.4373e-03,\n",
      "          -1.9827e-02, -4.1871e-03]]], device='cuda:0',\n",
      "       grad_fn=<CudnnRnnBackward0>)\n",
      "\n",
      "torch.Size([100, 90, 1024])\n",
      "tensor([[[-5.8777e-05, -1.3803e-02, -2.9216e-02,  ..., -4.4369e-03,\n",
      "          -1.9829e-02, -4.1880e-03],\n",
      "         [-5.7396e-05, -1.3803e-02, -2.9214e-02,  ..., -4.4389e-03,\n",
      "          -1.9829e-02, -4.1863e-03],\n",
      "         [-5.8183e-05, -1.3804e-02, -2.9216e-02,  ..., -4.4394e-03,\n",
      "          -1.9829e-02, -4.1874e-03],\n",
      "         ...,\n",
      "         [-5.8345e-05, -1.3804e-02, -2.9216e-02,  ..., -4.4368e-03,\n",
      "          -1.9829e-02, -4.1872e-03],\n",
      "         [-5.8165e-05, -1.3801e-02, -2.9215e-02,  ..., -4.4369e-03,\n",
      "          -1.9829e-02, -4.1888e-03],\n",
      "         [-5.8197e-05, -1.3804e-02, -2.9214e-02,  ..., -4.4372e-03,\n",
      "          -1.9828e-02, -4.1871e-03]],\n",
      "\n",
      "        [[-5.8376e-05, -1.3803e-02, -2.9216e-02,  ..., -4.4366e-03,\n",
      "          -1.9829e-02, -4.1882e-03],\n",
      "         [-5.7430e-05, -1.3803e-02, -2.9215e-02,  ..., -4.4389e-03,\n",
      "          -1.9829e-02, -4.1865e-03],\n",
      "         [-5.7829e-05, -1.3804e-02, -2.9216e-02,  ..., -4.4391e-03,\n",
      "          -1.9830e-02, -4.1872e-03],\n",
      "         ...,\n",
      "         [-5.7808e-05, -1.3803e-02, -2.9216e-02,  ..., -4.4372e-03,\n",
      "          -1.9828e-02, -4.1879e-03],\n",
      "         [-5.8325e-05, -1.3801e-02, -2.9215e-02,  ..., -4.4364e-03,\n",
      "          -1.9829e-02, -4.1887e-03],\n",
      "         [-5.7816e-05, -1.3804e-02, -2.9214e-02,  ..., -4.4376e-03,\n",
      "          -1.9828e-02, -4.1870e-03]],\n",
      "\n",
      "        [[-5.8564e-05, -1.3803e-02, -2.9216e-02,  ..., -4.4367e-03,\n",
      "          -1.9829e-02, -4.1885e-03],\n",
      "         [-5.7132e-05, -1.3803e-02, -2.9215e-02,  ..., -4.4385e-03,\n",
      "          -1.9829e-02, -4.1864e-03],\n",
      "         [-5.8260e-05, -1.3803e-02, -2.9216e-02,  ..., -4.4395e-03,\n",
      "          -1.9830e-02, -4.1871e-03],\n",
      "         ...,\n",
      "         [-5.7336e-05, -1.3803e-02, -2.9215e-02,  ..., -4.4370e-03,\n",
      "          -1.9828e-02, -4.1878e-03],\n",
      "         [-5.8076e-05, -1.3801e-02, -2.9215e-02,  ..., -4.4369e-03,\n",
      "          -1.9829e-02, -4.1888e-03],\n",
      "         [-5.7541e-05, -1.3804e-02, -2.9215e-02,  ..., -4.4379e-03,\n",
      "          -1.9828e-02, -4.1871e-03]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-5.9903e-05, -1.3803e-02, -2.9216e-02,  ..., -4.4391e-03,\n",
      "          -1.9828e-02, -4.1875e-03],\n",
      "         [-5.7946e-05, -1.3803e-02, -2.9214e-02,  ..., -4.4377e-03,\n",
      "          -1.9828e-02, -4.1873e-03],\n",
      "         [-5.8506e-05, -1.3802e-02, -2.9215e-02,  ..., -4.4371e-03,\n",
      "          -1.9829e-02, -4.1875e-03],\n",
      "         ...,\n",
      "         [-5.9662e-05, -1.3803e-02, -2.9215e-02,  ..., -4.4383e-03,\n",
      "          -1.9828e-02, -4.1884e-03],\n",
      "         [-5.7600e-05, -1.3802e-02, -2.9216e-02,  ..., -4.4385e-03,\n",
      "          -1.9828e-02, -4.1872e-03],\n",
      "         [-5.8634e-05, -1.3803e-02, -2.9214e-02,  ..., -4.4390e-03,\n",
      "          -1.9830e-02, -4.1869e-03]],\n",
      "\n",
      "        [[-6.0327e-05, -1.3803e-02, -2.9216e-02,  ..., -4.4394e-03,\n",
      "          -1.9829e-02, -4.1875e-03],\n",
      "         [-5.8443e-05, -1.3804e-02, -2.9214e-02,  ..., -4.4380e-03,\n",
      "          -1.9829e-02, -4.1876e-03],\n",
      "         [-5.9063e-05, -1.3803e-02, -2.9214e-02,  ..., -4.4369e-03,\n",
      "          -1.9829e-02, -4.1875e-03],\n",
      "         ...,\n",
      "         [-5.9786e-05, -1.3804e-02, -2.9215e-02,  ..., -4.4386e-03,\n",
      "          -1.9829e-02, -4.1885e-03],\n",
      "         [-5.7822e-05, -1.3802e-02, -2.9216e-02,  ..., -4.4386e-03,\n",
      "          -1.9828e-02, -4.1868e-03],\n",
      "         [-5.9358e-05, -1.3803e-02, -2.9214e-02,  ..., -4.4395e-03,\n",
      "          -1.9829e-02, -4.1868e-03]],\n",
      "\n",
      "        [[-6.0809e-05, -1.3803e-02, -2.9216e-02,  ..., -4.4393e-03,\n",
      "          -1.9829e-02, -4.1874e-03],\n",
      "         [-5.8342e-05, -1.3803e-02, -2.9215e-02,  ..., -4.4384e-03,\n",
      "          -1.9828e-02, -4.1878e-03],\n",
      "         [-5.9373e-05, -1.3802e-02, -2.9215e-02,  ..., -4.4372e-03,\n",
      "          -1.9829e-02, -4.1873e-03],\n",
      "         ...,\n",
      "         [-5.9592e-05, -1.3804e-02, -2.9216e-02,  ..., -4.4379e-03,\n",
      "          -1.9829e-02, -4.1886e-03],\n",
      "         [-5.7806e-05, -1.3802e-02, -2.9215e-02,  ..., -4.4393e-03,\n",
      "          -1.9829e-02, -4.1869e-03],\n",
      "         [-5.9564e-05, -1.3802e-02, -2.9215e-02,  ..., -4.4392e-03,\n",
      "          -1.9829e-02, -4.1864e-03]]], device='cuda:0',\n",
      "       grad_fn=<CudnnRnnBackward0>)\n",
      "\n",
      "torch.Size([100, 90, 1024])\n",
      "tensor([[[-6.1129e-05, -1.3803e-02, -2.9216e-02,  ..., -4.4394e-03,\n",
      "          -1.9828e-02, -4.1873e-03],\n",
      "         [-5.8479e-05, -1.3803e-02, -2.9215e-02,  ..., -4.4382e-03,\n",
      "          -1.9828e-02, -4.1880e-03],\n",
      "         [-5.9927e-05, -1.3802e-02, -2.9215e-02,  ..., -4.4376e-03,\n",
      "          -1.9829e-02, -4.1876e-03],\n",
      "         ...,\n",
      "         [-5.9012e-05, -1.3804e-02, -2.9216e-02,  ..., -4.4380e-03,\n",
      "          -1.9829e-02, -4.1885e-03],\n",
      "         [-5.7981e-05, -1.3802e-02, -2.9216e-02,  ..., -4.4394e-03,\n",
      "          -1.9829e-02, -4.1875e-03],\n",
      "         [-5.9383e-05, -1.3802e-02, -2.9215e-02,  ..., -4.4389e-03,\n",
      "          -1.9829e-02, -4.1860e-03]],\n",
      "\n",
      "        [[-6.1195e-05, -1.3803e-02, -2.9216e-02,  ..., -4.4392e-03,\n",
      "          -1.9828e-02, -4.1873e-03],\n",
      "         [-5.7884e-05, -1.3803e-02, -2.9215e-02,  ..., -4.4384e-03,\n",
      "          -1.9828e-02, -4.1877e-03],\n",
      "         [-5.9757e-05, -1.3802e-02, -2.9215e-02,  ..., -4.4378e-03,\n",
      "          -1.9829e-02, -4.1875e-03],\n",
      "         ...,\n",
      "         [-5.8543e-05, -1.3804e-02, -2.9216e-02,  ..., -4.4379e-03,\n",
      "          -1.9829e-02, -4.1880e-03],\n",
      "         [-5.8084e-05, -1.3802e-02, -2.9216e-02,  ..., -4.4396e-03,\n",
      "          -1.9829e-02, -4.1878e-03],\n",
      "         [-5.9546e-05, -1.3802e-02, -2.9216e-02,  ..., -4.4390e-03,\n",
      "          -1.9829e-02, -4.1860e-03]],\n",
      "\n",
      "        [[-6.0922e-05, -1.3804e-02, -2.9216e-02,  ..., -4.4391e-03,\n",
      "          -1.9828e-02, -4.1871e-03],\n",
      "         [-5.8000e-05, -1.3803e-02, -2.9216e-02,  ..., -4.4384e-03,\n",
      "          -1.9828e-02, -4.1876e-03],\n",
      "         [-5.9089e-05, -1.3802e-02, -2.9215e-02,  ..., -4.4374e-03,\n",
      "          -1.9829e-02, -4.1873e-03],\n",
      "         ...,\n",
      "         [-5.8796e-05, -1.3805e-02, -2.9216e-02,  ..., -4.4382e-03,\n",
      "          -1.9829e-02, -4.1878e-03],\n",
      "         [-5.8267e-05, -1.3802e-02, -2.9216e-02,  ..., -4.4396e-03,\n",
      "          -1.9829e-02, -4.1884e-03],\n",
      "         [-5.9418e-05, -1.3803e-02, -2.9216e-02,  ..., -4.4392e-03,\n",
      "          -1.9829e-02, -4.1863e-03]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-5.7360e-05, -1.3803e-02, -2.9219e-02,  ..., -4.4380e-03,\n",
      "          -1.9830e-02, -4.1884e-03],\n",
      "         [-6.0193e-05, -1.3802e-02, -2.9215e-02,  ..., -4.4393e-03,\n",
      "          -1.9830e-02, -4.1877e-03],\n",
      "         [-5.8397e-05, -1.3803e-02, -2.9216e-02,  ..., -4.4365e-03,\n",
      "          -1.9829e-02, -4.1899e-03],\n",
      "         ...,\n",
      "         [-6.0039e-05, -1.3803e-02, -2.9215e-02,  ..., -4.4393e-03,\n",
      "          -1.9827e-02, -4.1888e-03],\n",
      "         [-5.8945e-05, -1.3803e-02, -2.9216e-02,  ..., -4.4383e-03,\n",
      "          -1.9830e-02, -4.1872e-03],\n",
      "         [-5.8563e-05, -1.3805e-02, -2.9217e-02,  ..., -4.4389e-03,\n",
      "          -1.9829e-02, -4.1885e-03]],\n",
      "\n",
      "        [[-5.7052e-05, -1.3803e-02, -2.9218e-02,  ..., -4.4386e-03,\n",
      "          -1.9830e-02, -4.1889e-03],\n",
      "         [-5.9696e-05, -1.3802e-02, -2.9215e-02,  ..., -4.4385e-03,\n",
      "          -1.9830e-02, -4.1880e-03],\n",
      "         [-5.8262e-05, -1.3803e-02, -2.9216e-02,  ..., -4.4367e-03,\n",
      "          -1.9829e-02, -4.1896e-03],\n",
      "         ...,\n",
      "         [-6.0183e-05, -1.3803e-02, -2.9215e-02,  ..., -4.4392e-03,\n",
      "          -1.9828e-02, -4.1888e-03],\n",
      "         [-5.8264e-05, -1.3803e-02, -2.9217e-02,  ..., -4.4383e-03,\n",
      "          -1.9829e-02, -4.1874e-03],\n",
      "         [-5.9050e-05, -1.3804e-02, -2.9216e-02,  ..., -4.4389e-03,\n",
      "          -1.9829e-02, -4.1888e-03]],\n",
      "\n",
      "        [[-5.7030e-05, -1.3803e-02, -2.9218e-02,  ..., -4.4383e-03,\n",
      "          -1.9830e-02, -4.1890e-03],\n",
      "         [-5.9358e-05, -1.3802e-02, -2.9215e-02,  ..., -4.4384e-03,\n",
      "          -1.9830e-02, -4.1877e-03],\n",
      "         [-5.8142e-05, -1.3804e-02, -2.9216e-02,  ..., -4.4367e-03,\n",
      "          -1.9829e-02, -4.1894e-03],\n",
      "         ...,\n",
      "         [-6.0269e-05, -1.3802e-02, -2.9214e-02,  ..., -4.4393e-03,\n",
      "          -1.9828e-02, -4.1880e-03],\n",
      "         [-5.7866e-05, -1.3803e-02, -2.9217e-02,  ..., -4.4381e-03,\n",
      "          -1.9829e-02, -4.1877e-03],\n",
      "         [-5.9268e-05, -1.3804e-02, -2.9216e-02,  ..., -4.4386e-03,\n",
      "          -1.9829e-02, -4.1888e-03]]], device='cuda:0',\n",
      "       grad_fn=<CudnnRnnBackward0>)\n",
      "\n",
      "torch.Size([100, 90, 1024])\n",
      "tensor([[[-5.6765e-05, -1.3803e-02, -2.9218e-02,  ..., -4.4383e-03,\n",
      "          -1.9830e-02, -4.1890e-03],\n",
      "         [-5.9095e-05, -1.3802e-02, -2.9214e-02,  ..., -4.4384e-03,\n",
      "          -1.9830e-02, -4.1874e-03],\n",
      "         [-5.8102e-05, -1.3804e-02, -2.9216e-02,  ..., -4.4364e-03,\n",
      "          -1.9829e-02, -4.1891e-03],\n",
      "         ...,\n",
      "         [-6.0038e-05, -1.3802e-02, -2.9215e-02,  ..., -4.4389e-03,\n",
      "          -1.9827e-02, -4.1881e-03],\n",
      "         [-5.8059e-05, -1.3803e-02, -2.9216e-02,  ..., -4.4377e-03,\n",
      "          -1.9829e-02, -4.1880e-03],\n",
      "         [-5.9515e-05, -1.3804e-02, -2.9216e-02,  ..., -4.4378e-03,\n",
      "          -1.9829e-02, -4.1889e-03]],\n",
      "\n",
      "        [[-5.6960e-05, -1.3803e-02, -2.9218e-02,  ..., -4.4380e-03,\n",
      "          -1.9830e-02, -4.1886e-03],\n",
      "         [-5.8172e-05, -1.3802e-02, -2.9215e-02,  ..., -4.4377e-03,\n",
      "          -1.9829e-02, -4.1875e-03],\n",
      "         [-5.7872e-05, -1.3803e-02, -2.9216e-02,  ..., -4.4374e-03,\n",
      "          -1.9829e-02, -4.1891e-03],\n",
      "         ...,\n",
      "         [-5.9728e-05, -1.3802e-02, -2.9215e-02,  ..., -4.4385e-03,\n",
      "          -1.9827e-02, -4.1880e-03],\n",
      "         [-5.7483e-05, -1.3803e-02, -2.9216e-02,  ..., -4.4380e-03,\n",
      "          -1.9830e-02, -4.1879e-03],\n",
      "         [-5.9255e-05, -1.3804e-02, -2.9216e-02,  ..., -4.4373e-03,\n",
      "          -1.9829e-02, -4.1891e-03]],\n",
      "\n",
      "        [[-5.7044e-05, -1.3803e-02, -2.9217e-02,  ..., -4.4381e-03,\n",
      "          -1.9830e-02, -4.1882e-03],\n",
      "         [-5.8118e-05, -1.3802e-02, -2.9215e-02,  ..., -4.4373e-03,\n",
      "          -1.9829e-02, -4.1875e-03],\n",
      "         [-5.7536e-05, -1.3802e-02, -2.9216e-02,  ..., -4.4382e-03,\n",
      "          -1.9829e-02, -4.1889e-03],\n",
      "         ...,\n",
      "         [-5.8806e-05, -1.3802e-02, -2.9215e-02,  ..., -4.4386e-03,\n",
      "          -1.9827e-02, -4.1878e-03],\n",
      "         [-5.7343e-05, -1.3804e-02, -2.9216e-02,  ..., -4.4379e-03,\n",
      "          -1.9830e-02, -4.1882e-03],\n",
      "         [-5.8835e-05, -1.3804e-02, -2.9216e-02,  ..., -4.4376e-03,\n",
      "          -1.9829e-02, -4.1882e-03]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-5.8053e-05, -1.3803e-02, -2.9215e-02,  ..., -4.4361e-03,\n",
      "          -1.9828e-02, -4.1886e-03],\n",
      "         [-6.0439e-05, -1.3802e-02, -2.9216e-02,  ..., -4.4390e-03,\n",
      "          -1.9828e-02, -4.1873e-03],\n",
      "         [-5.8827e-05, -1.3804e-02, -2.9217e-02,  ..., -4.4393e-03,\n",
      "          -1.9828e-02, -4.1864e-03],\n",
      "         ...,\n",
      "         [-5.8171e-05, -1.3802e-02, -2.9217e-02,  ..., -4.4384e-03,\n",
      "          -1.9830e-02, -4.1873e-03],\n",
      "         [-5.8520e-05, -1.3804e-02, -2.9215e-02,  ..., -4.4374e-03,\n",
      "          -1.9829e-02, -4.1870e-03],\n",
      "         [-5.8159e-05, -1.3803e-02, -2.9215e-02,  ..., -4.4388e-03,\n",
      "          -1.9828e-02, -4.1882e-03]],\n",
      "\n",
      "        [[-5.8294e-05, -1.3802e-02, -2.9215e-02,  ..., -4.4365e-03,\n",
      "          -1.9828e-02, -4.1886e-03],\n",
      "         [-6.0149e-05, -1.3802e-02, -2.9216e-02,  ..., -4.4393e-03,\n",
      "          -1.9828e-02, -4.1873e-03],\n",
      "         [-5.8476e-05, -1.3804e-02, -2.9217e-02,  ..., -4.4388e-03,\n",
      "          -1.9828e-02, -4.1870e-03],\n",
      "         ...,\n",
      "         [-5.7851e-05, -1.3803e-02, -2.9217e-02,  ..., -4.4380e-03,\n",
      "          -1.9829e-02, -4.1874e-03],\n",
      "         [-5.8312e-05, -1.3804e-02, -2.9215e-02,  ..., -4.4371e-03,\n",
      "          -1.9830e-02, -4.1872e-03],\n",
      "         [-5.8154e-05, -1.3803e-02, -2.9215e-02,  ..., -4.4386e-03,\n",
      "          -1.9828e-02, -4.1879e-03]],\n",
      "\n",
      "        [[-5.8589e-05, -1.3802e-02, -2.9215e-02,  ..., -4.4369e-03,\n",
      "          -1.9827e-02, -4.1888e-03],\n",
      "         [-5.9405e-05, -1.3803e-02, -2.9216e-02,  ..., -4.4393e-03,\n",
      "          -1.9828e-02, -4.1873e-03],\n",
      "         [-5.8111e-05, -1.3804e-02, -2.9217e-02,  ..., -4.4385e-03,\n",
      "          -1.9827e-02, -4.1872e-03],\n",
      "         ...,\n",
      "         [-5.7331e-05, -1.3802e-02, -2.9217e-02,  ..., -4.4380e-03,\n",
      "          -1.9829e-02, -4.1871e-03],\n",
      "         [-5.8526e-05, -1.3803e-02, -2.9216e-02,  ..., -4.4365e-03,\n",
      "          -1.9830e-02, -4.1873e-03],\n",
      "         [-5.8227e-05, -1.3803e-02, -2.9215e-02,  ..., -4.4386e-03,\n",
      "          -1.9828e-02, -4.1880e-03]]], device='cuda:0',\n",
      "       grad_fn=<CudnnRnnBackward0>)\n",
      "\n",
      "torch.Size([100, 90, 1024])\n",
      "tensor([[[-5.8836e-05, -1.3802e-02, -2.9216e-02,  ..., -4.4369e-03,\n",
      "          -1.9827e-02, -4.1881e-03],\n",
      "         [-5.9412e-05, -1.3803e-02, -2.9216e-02,  ..., -4.4391e-03,\n",
      "          -1.9828e-02, -4.1869e-03],\n",
      "         [-5.8128e-05, -1.3804e-02, -2.9217e-02,  ..., -4.4389e-03,\n",
      "          -1.9827e-02, -4.1872e-03],\n",
      "         ...,\n",
      "         [-5.7510e-05, -1.3802e-02, -2.9218e-02,  ..., -4.4380e-03,\n",
      "          -1.9829e-02, -4.1874e-03],\n",
      "         [-5.8537e-05, -1.3803e-02, -2.9216e-02,  ..., -4.4366e-03,\n",
      "          -1.9830e-02, -4.1872e-03],\n",
      "         [-5.7931e-05, -1.3803e-02, -2.9215e-02,  ..., -4.4385e-03,\n",
      "          -1.9828e-02, -4.1878e-03]],\n",
      "\n",
      "        [[-5.8756e-05, -1.3802e-02, -2.9215e-02,  ..., -4.4367e-03,\n",
      "          -1.9828e-02, -4.1875e-03],\n",
      "         [-5.9262e-05, -1.3803e-02, -2.9217e-02,  ..., -4.4385e-03,\n",
      "          -1.9828e-02, -4.1869e-03],\n",
      "         [-5.7817e-05, -1.3804e-02, -2.9217e-02,  ..., -4.4387e-03,\n",
      "          -1.9827e-02, -4.1871e-03],\n",
      "         ...,\n",
      "         [-5.7755e-05, -1.3803e-02, -2.9218e-02,  ..., -4.4379e-03,\n",
      "          -1.9829e-02, -4.1873e-03],\n",
      "         [-5.8719e-05, -1.3803e-02, -2.9216e-02,  ..., -4.4371e-03,\n",
      "          -1.9830e-02, -4.1877e-03],\n",
      "         [-5.8024e-05, -1.3802e-02, -2.9215e-02,  ..., -4.4385e-03,\n",
      "          -1.9829e-02, -4.1878e-03]],\n",
      "\n",
      "        [[-5.9100e-05, -1.3802e-02, -2.9215e-02,  ..., -4.4366e-03,\n",
      "          -1.9829e-02, -4.1875e-03],\n",
      "         [-5.9747e-05, -1.3803e-02, -2.9217e-02,  ..., -4.4380e-03,\n",
      "          -1.9829e-02, -4.1868e-03],\n",
      "         [-5.7664e-05, -1.3804e-02, -2.9216e-02,  ..., -4.4380e-03,\n",
      "          -1.9827e-02, -4.1872e-03],\n",
      "         ...,\n",
      "         [-5.7635e-05, -1.3803e-02, -2.9218e-02,  ..., -4.4381e-03,\n",
      "          -1.9829e-02, -4.1877e-03],\n",
      "         [-5.8424e-05, -1.3803e-02, -2.9215e-02,  ..., -4.4378e-03,\n",
      "          -1.9830e-02, -4.1877e-03],\n",
      "         [-5.8199e-05, -1.3802e-02, -2.9215e-02,  ..., -4.4383e-03,\n",
      "          -1.9829e-02, -4.1879e-03]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-5.9277e-05, -1.3802e-02, -2.9216e-02,  ..., -4.4367e-03,\n",
      "          -1.9830e-02, -4.1873e-03],\n",
      "         [-5.8596e-05, -1.3803e-02, -2.9216e-02,  ..., -4.4375e-03,\n",
      "          -1.9829e-02, -4.1865e-03],\n",
      "         [-5.7449e-05, -1.3804e-02, -2.9218e-02,  ..., -4.4378e-03,\n",
      "          -1.9828e-02, -4.1862e-03],\n",
      "         ...,\n",
      "         [-5.8764e-05, -1.3801e-02, -2.9216e-02,  ..., -4.4380e-03,\n",
      "          -1.9829e-02, -4.1853e-03],\n",
      "         [-5.8503e-05, -1.3802e-02, -2.9216e-02,  ..., -4.4392e-03,\n",
      "          -1.9829e-02, -4.1870e-03],\n",
      "         [-5.7730e-05, -1.3804e-02, -2.9216e-02,  ..., -4.4385e-03,\n",
      "          -1.9828e-02, -4.1865e-03]],\n",
      "\n",
      "        [[-5.9127e-05, -1.3803e-02, -2.9216e-02,  ..., -4.4367e-03,\n",
      "          -1.9830e-02, -4.1872e-03],\n",
      "         [-5.8833e-05, -1.3803e-02, -2.9215e-02,  ..., -4.4385e-03,\n",
      "          -1.9829e-02, -4.1864e-03],\n",
      "         [-5.7497e-05, -1.3804e-02, -2.9218e-02,  ..., -4.4381e-03,\n",
      "          -1.9828e-02, -4.1863e-03],\n",
      "         ...,\n",
      "         [-5.8778e-05, -1.3801e-02, -2.9216e-02,  ..., -4.4382e-03,\n",
      "          -1.9829e-02, -4.1857e-03],\n",
      "         [-5.9019e-05, -1.3803e-02, -2.9216e-02,  ..., -4.4395e-03,\n",
      "          -1.9829e-02, -4.1869e-03],\n",
      "         [-5.7672e-05, -1.3804e-02, -2.9216e-02,  ..., -4.4382e-03,\n",
      "          -1.9828e-02, -4.1864e-03]],\n",
      "\n",
      "        [[-5.9007e-05, -1.3803e-02, -2.9216e-02,  ..., -4.4367e-03,\n",
      "          -1.9830e-02, -4.1865e-03],\n",
      "         [-5.8714e-05, -1.3803e-02, -2.9216e-02,  ..., -4.4391e-03,\n",
      "          -1.9829e-02, -4.1865e-03],\n",
      "         [-5.7692e-05, -1.3804e-02, -2.9218e-02,  ..., -4.4380e-03,\n",
      "          -1.9828e-02, -4.1866e-03],\n",
      "         ...,\n",
      "         [-5.8354e-05, -1.3801e-02, -2.9216e-02,  ..., -4.4383e-03,\n",
      "          -1.9828e-02, -4.1857e-03],\n",
      "         [-5.9255e-05, -1.3803e-02, -2.9215e-02,  ..., -4.4399e-03,\n",
      "          -1.9829e-02, -4.1870e-03],\n",
      "         [-5.7312e-05, -1.3803e-02, -2.9216e-02,  ..., -4.4378e-03,\n",
      "          -1.9828e-02, -4.1863e-03]]], device='cuda:0',\n",
      "       grad_fn=<CudnnRnnBackward0>)\n",
      "\n",
      "torch.Size([100, 90, 1024])\n",
      "tensor([[[-5.9115e-05, -1.3803e-02, -2.9216e-02,  ..., -4.4364e-03,\n",
      "          -1.9830e-02, -4.1868e-03],\n",
      "         [-5.8801e-05, -1.3803e-02, -2.9215e-02,  ..., -4.4398e-03,\n",
      "          -1.9830e-02, -4.1869e-03],\n",
      "         [-5.7911e-05, -1.3804e-02, -2.9218e-02,  ..., -4.4382e-03,\n",
      "          -1.9829e-02, -4.1866e-03],\n",
      "         ...,\n",
      "         [-5.8698e-05, -1.3801e-02, -2.9216e-02,  ..., -4.4387e-03,\n",
      "          -1.9828e-02, -4.1866e-03],\n",
      "         [-5.9812e-05, -1.3803e-02, -2.9216e-02,  ..., -4.4397e-03,\n",
      "          -1.9829e-02, -4.1873e-03],\n",
      "         [-5.6939e-05, -1.3803e-02, -2.9216e-02,  ..., -4.4383e-03,\n",
      "          -1.9828e-02, -4.1862e-03]],\n",
      "\n",
      "        [[-5.9750e-05, -1.3802e-02, -2.9216e-02,  ..., -4.4372e-03,\n",
      "          -1.9830e-02, -4.1872e-03],\n",
      "         [-5.8651e-05, -1.3803e-02, -2.9215e-02,  ..., -4.4397e-03,\n",
      "          -1.9829e-02, -4.1866e-03],\n",
      "         [-5.8254e-05, -1.3805e-02, -2.9217e-02,  ..., -4.4384e-03,\n",
      "          -1.9829e-02, -4.1870e-03],\n",
      "         ...,\n",
      "         [-5.9176e-05, -1.3801e-02, -2.9216e-02,  ..., -4.4386e-03,\n",
      "          -1.9829e-02, -4.1867e-03],\n",
      "         [-5.9555e-05, -1.3803e-02, -2.9216e-02,  ..., -4.4394e-03,\n",
      "          -1.9829e-02, -4.1868e-03],\n",
      "         [-5.7306e-05, -1.3803e-02, -2.9216e-02,  ..., -4.4381e-03,\n",
      "          -1.9828e-02, -4.1865e-03]],\n",
      "\n",
      "        [[-6.0260e-05, -1.3802e-02, -2.9215e-02,  ..., -4.4367e-03,\n",
      "          -1.9830e-02, -4.1873e-03],\n",
      "         [-5.8295e-05, -1.3803e-02, -2.9215e-02,  ..., -4.4397e-03,\n",
      "          -1.9829e-02, -4.1867e-03],\n",
      "         [-5.8033e-05, -1.3805e-02, -2.9217e-02,  ..., -4.4381e-03,\n",
      "          -1.9829e-02, -4.1875e-03],\n",
      "         ...,\n",
      "         [-5.9511e-05, -1.3802e-02, -2.9216e-02,  ..., -4.4382e-03,\n",
      "          -1.9828e-02, -4.1867e-03],\n",
      "         [-5.8946e-05, -1.3803e-02, -2.9217e-02,  ..., -4.4391e-03,\n",
      "          -1.9829e-02, -4.1869e-03],\n",
      "         [-5.7229e-05, -1.3802e-02, -2.9216e-02,  ..., -4.4377e-03,\n",
      "          -1.9828e-02, -4.1866e-03]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-5.7531e-05, -1.3803e-02, -2.9215e-02,  ..., -4.4381e-03,\n",
      "          -1.9829e-02, -4.1880e-03],\n",
      "         [-5.7015e-05, -1.3803e-02, -2.9216e-02,  ..., -4.4384e-03,\n",
      "          -1.9829e-02, -4.1857e-03],\n",
      "         [-5.9112e-05, -1.3803e-02, -2.9215e-02,  ..., -4.4388e-03,\n",
      "          -1.9829e-02, -4.1884e-03],\n",
      "         ...,\n",
      "         [-5.8387e-05, -1.3803e-02, -2.9216e-02,  ..., -4.4382e-03,\n",
      "          -1.9829e-02, -4.1880e-03],\n",
      "         [-6.0299e-05, -1.3804e-02, -2.9216e-02,  ..., -4.4383e-03,\n",
      "          -1.9829e-02, -4.1886e-03],\n",
      "         [-5.8215e-05, -1.3804e-02, -2.9217e-02,  ..., -4.4393e-03,\n",
      "          -1.9829e-02, -4.1863e-03]],\n",
      "\n",
      "        [[-5.7744e-05, -1.3803e-02, -2.9215e-02,  ..., -4.4377e-03,\n",
      "          -1.9829e-02, -4.1883e-03],\n",
      "         [-5.7002e-05, -1.3803e-02, -2.9216e-02,  ..., -4.4383e-03,\n",
      "          -1.9829e-02, -4.1859e-03],\n",
      "         [-5.9210e-05, -1.3803e-02, -2.9215e-02,  ..., -4.4380e-03,\n",
      "          -1.9829e-02, -4.1886e-03],\n",
      "         ...,\n",
      "         [-5.8370e-05, -1.3803e-02, -2.9216e-02,  ..., -4.4384e-03,\n",
      "          -1.9829e-02, -4.1879e-03],\n",
      "         [-6.0148e-05, -1.3803e-02, -2.9216e-02,  ..., -4.4384e-03,\n",
      "          -1.9828e-02, -4.1884e-03],\n",
      "         [-5.8640e-05, -1.3804e-02, -2.9217e-02,  ..., -4.4393e-03,\n",
      "          -1.9829e-02, -4.1864e-03]],\n",
      "\n",
      "        [[-5.8078e-05, -1.3803e-02, -2.9214e-02,  ..., -4.4383e-03,\n",
      "          -1.9829e-02, -4.1891e-03],\n",
      "         [-5.7225e-05, -1.3803e-02, -2.9217e-02,  ..., -4.4382e-03,\n",
      "          -1.9829e-02, -4.1858e-03],\n",
      "         [-5.9296e-05, -1.3803e-02, -2.9215e-02,  ..., -4.4380e-03,\n",
      "          -1.9829e-02, -4.1881e-03],\n",
      "         ...,\n",
      "         [-5.8446e-05, -1.3803e-02, -2.9216e-02,  ..., -4.4382e-03,\n",
      "          -1.9829e-02, -4.1877e-03],\n",
      "         [-5.9737e-05, -1.3803e-02, -2.9216e-02,  ..., -4.4378e-03,\n",
      "          -1.9828e-02, -4.1881e-03],\n",
      "         [-5.8394e-05, -1.3804e-02, -2.9218e-02,  ..., -4.4394e-03,\n",
      "          -1.9829e-02, -4.1861e-03]]], device='cuda:0',\n",
      "       grad_fn=<CudnnRnnBackward0>)\n",
      "\n",
      "torch.Size([100, 90, 1024])\n",
      "tensor([[[-5.7965e-05, -1.3803e-02, -2.9214e-02,  ..., -4.4385e-03,\n",
      "          -1.9829e-02, -4.1889e-03],\n",
      "         [-5.7147e-05, -1.3803e-02, -2.9217e-02,  ..., -4.4380e-03,\n",
      "          -1.9829e-02, -4.1855e-03],\n",
      "         [-5.9008e-05, -1.3803e-02, -2.9215e-02,  ..., -4.4386e-03,\n",
      "          -1.9829e-02, -4.1878e-03],\n",
      "         ...,\n",
      "         [-5.7760e-05, -1.3802e-02, -2.9216e-02,  ..., -4.4383e-03,\n",
      "          -1.9829e-02, -4.1876e-03],\n",
      "         [-5.9560e-05, -1.3803e-02, -2.9215e-02,  ..., -4.4376e-03,\n",
      "          -1.9828e-02, -4.1876e-03],\n",
      "         [-5.8373e-05, -1.3804e-02, -2.9218e-02,  ..., -4.4395e-03,\n",
      "          -1.9829e-02, -4.1862e-03]],\n",
      "\n",
      "        [[-5.8567e-05, -1.3802e-02, -2.9214e-02,  ..., -4.4388e-03,\n",
      "          -1.9829e-02, -4.1892e-03],\n",
      "         [-5.7184e-05, -1.3803e-02, -2.9217e-02,  ..., -4.4381e-03,\n",
      "          -1.9829e-02, -4.1853e-03],\n",
      "         [-5.8898e-05, -1.3803e-02, -2.9215e-02,  ..., -4.4390e-03,\n",
      "          -1.9829e-02, -4.1874e-03],\n",
      "         ...,\n",
      "         [-5.8234e-05, -1.3801e-02, -2.9216e-02,  ..., -4.4382e-03,\n",
      "          -1.9829e-02, -4.1882e-03],\n",
      "         [-5.9373e-05, -1.3803e-02, -2.9215e-02,  ..., -4.4370e-03,\n",
      "          -1.9828e-02, -4.1877e-03],\n",
      "         [-5.8149e-05, -1.3805e-02, -2.9218e-02,  ..., -4.4394e-03,\n",
      "          -1.9828e-02, -4.1867e-03]],\n",
      "\n",
      "        [[-5.8781e-05, -1.3802e-02, -2.9214e-02,  ..., -4.4391e-03,\n",
      "          -1.9829e-02, -4.1888e-03],\n",
      "         [-5.8267e-05, -1.3803e-02, -2.9217e-02,  ..., -4.4385e-03,\n",
      "          -1.9830e-02, -4.1853e-03],\n",
      "         [-5.8434e-05, -1.3803e-02, -2.9216e-02,  ..., -4.4390e-03,\n",
      "          -1.9829e-02, -4.1870e-03],\n",
      "         ...,\n",
      "         [-5.8103e-05, -1.3801e-02, -2.9216e-02,  ..., -4.4380e-03,\n",
      "          -1.9830e-02, -4.1887e-03],\n",
      "         [-5.9562e-05, -1.3803e-02, -2.9215e-02,  ..., -4.4373e-03,\n",
      "          -1.9829e-02, -4.1875e-03],\n",
      "         [-5.7578e-05, -1.3805e-02, -2.9218e-02,  ..., -4.4396e-03,\n",
      "          -1.9828e-02, -4.1867e-03]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-5.8019e-05, -1.3802e-02, -2.9215e-02,  ..., -4.4385e-03,\n",
      "          -1.9828e-02, -4.1870e-03],\n",
      "         [-5.7517e-05, -1.3801e-02, -2.9216e-02,  ..., -4.4381e-03,\n",
      "          -1.9828e-02, -4.1869e-03],\n",
      "         [-5.8476e-05, -1.3803e-02, -2.9216e-02,  ..., -4.4380e-03,\n",
      "          -1.9829e-02, -4.1885e-03],\n",
      "         ...,\n",
      "         [-5.8444e-05, -1.3802e-02, -2.9216e-02,  ..., -4.4374e-03,\n",
      "          -1.9830e-02, -4.1873e-03],\n",
      "         [-5.7329e-05, -1.3803e-02, -2.9213e-02,  ..., -4.4378e-03,\n",
      "          -1.9829e-02, -4.1891e-03],\n",
      "         [-5.8746e-05, -1.3803e-02, -2.9216e-02,  ..., -4.4386e-03,\n",
      "          -1.9828e-02, -4.1871e-03]],\n",
      "\n",
      "        [[-5.7761e-05, -1.3802e-02, -2.9216e-02,  ..., -4.4386e-03,\n",
      "          -1.9829e-02, -4.1875e-03],\n",
      "         [-5.7383e-05, -1.3801e-02, -2.9216e-02,  ..., -4.4379e-03,\n",
      "          -1.9827e-02, -4.1871e-03],\n",
      "         [-5.8552e-05, -1.3803e-02, -2.9216e-02,  ..., -4.4379e-03,\n",
      "          -1.9829e-02, -4.1884e-03],\n",
      "         ...,\n",
      "         [-5.8514e-05, -1.3801e-02, -2.9216e-02,  ..., -4.4369e-03,\n",
      "          -1.9829e-02, -4.1876e-03],\n",
      "         [-5.7463e-05, -1.3803e-02, -2.9213e-02,  ..., -4.4384e-03,\n",
      "          -1.9829e-02, -4.1892e-03],\n",
      "         [-5.9298e-05, -1.3803e-02, -2.9216e-02,  ..., -4.4386e-03,\n",
      "          -1.9828e-02, -4.1875e-03]],\n",
      "\n",
      "        [[-5.7710e-05, -1.3802e-02, -2.9216e-02,  ..., -4.4385e-03,\n",
      "          -1.9829e-02, -4.1880e-03],\n",
      "         [-5.7051e-05, -1.3802e-02, -2.9216e-02,  ..., -4.4374e-03,\n",
      "          -1.9827e-02, -4.1870e-03],\n",
      "         [-5.9053e-05, -1.3804e-02, -2.9216e-02,  ..., -4.4377e-03,\n",
      "          -1.9829e-02, -4.1883e-03],\n",
      "         ...,\n",
      "         [-5.8535e-05, -1.3801e-02, -2.9215e-02,  ..., -4.4372e-03,\n",
      "          -1.9829e-02, -4.1881e-03],\n",
      "         [-5.7451e-05, -1.3803e-02, -2.9214e-02,  ..., -4.4384e-03,\n",
      "          -1.9829e-02, -4.1890e-03],\n",
      "         [-5.9850e-05, -1.3803e-02, -2.9216e-02,  ..., -4.4386e-03,\n",
      "          -1.9828e-02, -4.1876e-03]]], device='cuda:0',\n",
      "       grad_fn=<CudnnRnnBackward0>)\n",
      "\n",
      "torch.Size([100, 90, 1024])\n",
      "tensor([[[-5.7872e-05, -1.3803e-02, -2.9216e-02,  ..., -4.4383e-03,\n",
      "          -1.9829e-02, -4.1884e-03],\n",
      "         [-5.7129e-05, -1.3802e-02, -2.9216e-02,  ..., -4.4377e-03,\n",
      "          -1.9827e-02, -4.1872e-03],\n",
      "         [-5.8790e-05, -1.3803e-02, -2.9216e-02,  ..., -4.4379e-03,\n",
      "          -1.9829e-02, -4.1879e-03],\n",
      "         ...,\n",
      "         [-5.8519e-05, -1.3801e-02, -2.9215e-02,  ..., -4.4376e-03,\n",
      "          -1.9829e-02, -4.1885e-03],\n",
      "         [-5.7464e-05, -1.3803e-02, -2.9214e-02,  ..., -4.4388e-03,\n",
      "          -1.9829e-02, -4.1885e-03],\n",
      "         [-6.0049e-05, -1.3803e-02, -2.9217e-02,  ..., -4.4385e-03,\n",
      "          -1.9828e-02, -4.1869e-03]],\n",
      "\n",
      "        [[-5.8092e-05, -1.3803e-02, -2.9216e-02,  ..., -4.4389e-03,\n",
      "          -1.9829e-02, -4.1889e-03],\n",
      "         [-5.7359e-05, -1.3803e-02, -2.9216e-02,  ..., -4.4376e-03,\n",
      "          -1.9827e-02, -4.1870e-03],\n",
      "         [-5.8861e-05, -1.3803e-02, -2.9216e-02,  ..., -4.4378e-03,\n",
      "          -1.9829e-02, -4.1879e-03],\n",
      "         ...,\n",
      "         [-5.7992e-05, -1.3801e-02, -2.9215e-02,  ..., -4.4380e-03,\n",
      "          -1.9829e-02, -4.1883e-03],\n",
      "         [-5.7712e-05, -1.3803e-02, -2.9214e-02,  ..., -4.4386e-03,\n",
      "          -1.9830e-02, -4.1877e-03],\n",
      "         [-5.9347e-05, -1.3803e-02, -2.9217e-02,  ..., -4.4383e-03,\n",
      "          -1.9828e-02, -4.1872e-03]],\n",
      "\n",
      "        [[-5.7969e-05, -1.3802e-02, -2.9216e-02,  ..., -4.4388e-03,\n",
      "          -1.9828e-02, -4.1892e-03],\n",
      "         [-5.7715e-05, -1.3803e-02, -2.9216e-02,  ..., -4.4374e-03,\n",
      "          -1.9828e-02, -4.1869e-03],\n",
      "         [-5.9062e-05, -1.3803e-02, -2.9215e-02,  ..., -4.4379e-03,\n",
      "          -1.9830e-02, -4.1879e-03],\n",
      "         ...,\n",
      "         [-5.7754e-05, -1.3801e-02, -2.9215e-02,  ..., -4.4384e-03,\n",
      "          -1.9829e-02, -4.1882e-03],\n",
      "         [-5.8217e-05, -1.3803e-02, -2.9214e-02,  ..., -4.4392e-03,\n",
      "          -1.9830e-02, -4.1874e-03],\n",
      "         [-5.8259e-05, -1.3803e-02, -2.9217e-02,  ..., -4.4377e-03,\n",
      "          -1.9828e-02, -4.1871e-03]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-5.6776e-05, -1.3804e-02, -2.9216e-02,  ..., -4.4387e-03,\n",
      "          -1.9829e-02, -4.1887e-03],\n",
      "         [-5.7175e-05, -1.3803e-02, -2.9217e-02,  ..., -4.4378e-03,\n",
      "          -1.9829e-02, -4.1867e-03],\n",
      "         [-5.8978e-05, -1.3803e-02, -2.9216e-02,  ..., -4.4371e-03,\n",
      "          -1.9829e-02, -4.1869e-03],\n",
      "         ...,\n",
      "         [-5.9807e-05, -1.3802e-02, -2.9215e-02,  ..., -4.4381e-03,\n",
      "          -1.9829e-02, -4.1864e-03],\n",
      "         [-5.8994e-05, -1.3802e-02, -2.9217e-02,  ..., -4.4379e-03,\n",
      "          -1.9828e-02, -4.1861e-03],\n",
      "         [-5.9909e-05, -1.3802e-02, -2.9215e-02,  ..., -4.4381e-03,\n",
      "          -1.9827e-02, -4.1884e-03]],\n",
      "\n",
      "        [[-5.6310e-05, -1.3804e-02, -2.9216e-02,  ..., -4.4387e-03,\n",
      "          -1.9829e-02, -4.1879e-03],\n",
      "         [-5.7508e-05, -1.3802e-02, -2.9217e-02,  ..., -4.4383e-03,\n",
      "          -1.9830e-02, -4.1863e-03],\n",
      "         [-5.9240e-05, -1.3803e-02, -2.9216e-02,  ..., -4.4378e-03,\n",
      "          -1.9830e-02, -4.1864e-03],\n",
      "         ...,\n",
      "         [-5.9559e-05, -1.3802e-02, -2.9216e-02,  ..., -4.4392e-03,\n",
      "          -1.9829e-02, -4.1867e-03],\n",
      "         [-5.8435e-05, -1.3802e-02, -2.9217e-02,  ..., -4.4374e-03,\n",
      "          -1.9828e-02, -4.1864e-03],\n",
      "         [-5.9194e-05, -1.3802e-02, -2.9216e-02,  ..., -4.4382e-03,\n",
      "          -1.9827e-02, -4.1888e-03]],\n",
      "\n",
      "        [[-5.6330e-05, -1.3803e-02, -2.9216e-02,  ..., -4.4383e-03,\n",
      "          -1.9829e-02, -4.1872e-03],\n",
      "         [-5.8345e-05, -1.3802e-02, -2.9217e-02,  ..., -4.4382e-03,\n",
      "          -1.9829e-02, -4.1863e-03],\n",
      "         [-5.9393e-05, -1.3803e-02, -2.9217e-02,  ..., -4.4388e-03,\n",
      "          -1.9830e-02, -4.1866e-03],\n",
      "         ...,\n",
      "         [-5.8944e-05, -1.3802e-02, -2.9216e-02,  ..., -4.4393e-03,\n",
      "          -1.9830e-02, -4.1871e-03],\n",
      "         [-5.9012e-05, -1.3803e-02, -2.9217e-02,  ..., -4.4376e-03,\n",
      "          -1.9828e-02, -4.1870e-03],\n",
      "         [-5.8806e-05, -1.3802e-02, -2.9215e-02,  ..., -4.4384e-03,\n",
      "          -1.9827e-02, -4.1883e-03]]], device='cuda:0',\n",
      "       grad_fn=<CudnnRnnBackward0>)\n",
      "\n",
      "torch.Size([100, 90, 1024])\n",
      "tensor([[[-5.6607e-05, -1.3802e-02, -2.9216e-02,  ..., -4.4381e-03,\n",
      "          -1.9829e-02, -4.1867e-03],\n",
      "         [-5.8642e-05, -1.3802e-02, -2.9216e-02,  ..., -4.4384e-03,\n",
      "          -1.9830e-02, -4.1868e-03],\n",
      "         [-5.9041e-05, -1.3803e-02, -2.9217e-02,  ..., -4.4388e-03,\n",
      "          -1.9830e-02, -4.1865e-03],\n",
      "         ...,\n",
      "         [-5.8434e-05, -1.3802e-02, -2.9216e-02,  ..., -4.4391e-03,\n",
      "          -1.9829e-02, -4.1881e-03],\n",
      "         [-5.9113e-05, -1.3803e-02, -2.9216e-02,  ..., -4.4378e-03,\n",
      "          -1.9827e-02, -4.1871e-03],\n",
      "         [-5.8539e-05, -1.3803e-02, -2.9216e-02,  ..., -4.4388e-03,\n",
      "          -1.9827e-02, -4.1881e-03]],\n",
      "\n",
      "        [[-5.6617e-05, -1.3802e-02, -2.9216e-02,  ..., -4.4377e-03,\n",
      "          -1.9829e-02, -4.1869e-03],\n",
      "         [-5.8516e-05, -1.3802e-02, -2.9216e-02,  ..., -4.4383e-03,\n",
      "          -1.9829e-02, -4.1869e-03],\n",
      "         [-5.8977e-05, -1.3803e-02, -2.9217e-02,  ..., -4.4388e-03,\n",
      "          -1.9830e-02, -4.1864e-03],\n",
      "         ...,\n",
      "         [-5.8305e-05, -1.3802e-02, -2.9216e-02,  ..., -4.4388e-03,\n",
      "          -1.9829e-02, -4.1882e-03],\n",
      "         [-5.9076e-05, -1.3803e-02, -2.9216e-02,  ..., -4.4377e-03,\n",
      "          -1.9827e-02, -4.1876e-03],\n",
      "         [-5.8131e-05, -1.3803e-02, -2.9216e-02,  ..., -4.4388e-03,\n",
      "          -1.9828e-02, -4.1880e-03]],\n",
      "\n",
      "        [[-5.6831e-05, -1.3802e-02, -2.9216e-02,  ..., -4.4377e-03,\n",
      "          -1.9829e-02, -4.1869e-03],\n",
      "         [-5.8447e-05, -1.3802e-02, -2.9215e-02,  ..., -4.4386e-03,\n",
      "          -1.9829e-02, -4.1870e-03],\n",
      "         [-5.9324e-05, -1.3803e-02, -2.9217e-02,  ..., -4.4388e-03,\n",
      "          -1.9830e-02, -4.1860e-03],\n",
      "         ...,\n",
      "         [-5.8607e-05, -1.3802e-02, -2.9217e-02,  ..., -4.4393e-03,\n",
      "          -1.9829e-02, -4.1889e-03],\n",
      "         [-5.8697e-05, -1.3804e-02, -2.9216e-02,  ..., -4.4373e-03,\n",
      "          -1.9828e-02, -4.1877e-03],\n",
      "         [-5.7770e-05, -1.3802e-02, -2.9216e-02,  ..., -4.4386e-03,\n",
      "          -1.9828e-02, -4.1878e-03]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-5.8312e-05, -1.3802e-02, -2.9216e-02,  ..., -4.4390e-03,\n",
      "          -1.9829e-02, -4.1874e-03],\n",
      "         [-5.8232e-05, -1.3803e-02, -2.9217e-02,  ..., -4.4394e-03,\n",
      "          -1.9829e-02, -4.1885e-03],\n",
      "         [-5.6800e-05, -1.3804e-02, -2.9216e-02,  ..., -4.4387e-03,\n",
      "          -1.9828e-02, -4.1855e-03],\n",
      "         ...,\n",
      "         [-5.8812e-05, -1.3804e-02, -2.9216e-02,  ..., -4.4373e-03,\n",
      "          -1.9829e-02, -4.1878e-03],\n",
      "         [-5.8811e-05, -1.3803e-02, -2.9217e-02,  ..., -4.4383e-03,\n",
      "          -1.9828e-02, -4.1871e-03],\n",
      "         [-5.8146e-05, -1.3802e-02, -2.9216e-02,  ..., -4.4378e-03,\n",
      "          -1.9829e-02, -4.1878e-03]],\n",
      "\n",
      "        [[-5.8501e-05, -1.3802e-02, -2.9216e-02,  ..., -4.4384e-03,\n",
      "          -1.9829e-02, -4.1876e-03],\n",
      "         [-5.8441e-05, -1.3803e-02, -2.9217e-02,  ..., -4.4395e-03,\n",
      "          -1.9828e-02, -4.1885e-03],\n",
      "         [-5.6835e-05, -1.3804e-02, -2.9216e-02,  ..., -4.4387e-03,\n",
      "          -1.9828e-02, -4.1854e-03],\n",
      "         ...,\n",
      "         [-5.8247e-05, -1.3804e-02, -2.9216e-02,  ..., -4.4370e-03,\n",
      "          -1.9829e-02, -4.1880e-03],\n",
      "         [-5.8516e-05, -1.3803e-02, -2.9218e-02,  ..., -4.4388e-03,\n",
      "          -1.9828e-02, -4.1873e-03],\n",
      "         [-5.7928e-05, -1.3803e-02, -2.9215e-02,  ..., -4.4380e-03,\n",
      "          -1.9829e-02, -4.1877e-03]],\n",
      "\n",
      "        [[-5.9394e-05, -1.3803e-02, -2.9216e-02,  ..., -4.4381e-03,\n",
      "          -1.9829e-02, -4.1875e-03],\n",
      "         [-5.8978e-05, -1.3804e-02, -2.9217e-02,  ..., -4.4394e-03,\n",
      "          -1.9828e-02, -4.1881e-03],\n",
      "         [-5.6830e-05, -1.3804e-02, -2.9216e-02,  ..., -4.4385e-03,\n",
      "          -1.9829e-02, -4.1859e-03],\n",
      "         ...,\n",
      "         [-5.7798e-05, -1.3804e-02, -2.9216e-02,  ..., -4.4371e-03,\n",
      "          -1.9829e-02, -4.1876e-03],\n",
      "         [-5.8764e-05, -1.3803e-02, -2.9218e-02,  ..., -4.4388e-03,\n",
      "          -1.9828e-02, -4.1874e-03],\n",
      "         [-5.8141e-05, -1.3803e-02, -2.9215e-02,  ..., -4.4382e-03,\n",
      "          -1.9830e-02, -4.1870e-03]]], device='cuda:0',\n",
      "       grad_fn=<CudnnRnnBackward0>)\n",
      "torch.Size([10, 91, 1024])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected hidden[1] size (10, 91, 1024), got [10, 90, 1024]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 24\u001b[0m\n\u001b[1;32m     20\u001b[0m criterion \u001b[38;5;241m=\u001b[39m LossWithLS(\u001b[38;5;28mlen\u001b[39m(word_map), \u001b[38;5;241m0.2\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m---> 24\u001b[0m     loss_train \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransformer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     state \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m: epoch, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransformer\u001b[39m\u001b[38;5;124m'\u001b[39m: transformer, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransformer_optimizer\u001b[39m\u001b[38;5;124m'\u001b[39m: transformer_optimizer}\n\u001b[1;32m     27\u001b[0m     torch\u001b[38;5;241m.\u001b[39msave(state, directory \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/checkpoint_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(epoch) \u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.pth.tar\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[26], line 22\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(train_loader, transformer, criterion, epoch)\u001b[0m\n\u001b[1;32m     19\u001b[0m question_mask, reply_input_mask, reply_target_mask \u001b[38;5;241m=\u001b[39m create_masks(question, reply_input, reply_target)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Get the transformer outputs\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreply_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreply_input_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Compute the loss\u001b[39;00m\n\u001b[1;32m     25\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(out, reply_target, reply_target_mask)\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[35], line 68\u001b[0m, in \u001b[0;36mTransformerLSTM.forward\u001b[0;34m(self, src_words, src_mask, target_words, target_mask)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, src_words, src_mask, target_words, target_mask):\n\u001b[1;32m     67\u001b[0m     encoded, encoder_hidden, cell_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode(src_words, src_mask)\n\u001b[0;32m---> 68\u001b[0m     decoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_words\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_hidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m     out \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mlog_softmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogit(decoded), dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "Cell \u001b[0;32mIn[35], line 62\u001b[0m, in \u001b[0;36mTransformerLSTM.decode\u001b[0;34m(self, tgt_embeddings, target_mask, src_embeddings, src_mask, encoder_hidden, cell_state)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mprint\u001b[39m(decoder_hidden\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers):\n\u001b[0;32m---> 62\u001b[0m     tgt_embeddings, decoder_hidden, cell_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtgt_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_hidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m     tgt_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(tgt_embeddings, src_embeddings, src_mask, target_mask)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tgt_embeddings\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[18], line 47\u001b[0m, in \u001b[0;36mEmbeddingsLSTM.forward\u001b[0;34m(self, embedding, layer_idx, hidden, cell_state)\u001b[0m\n\u001b[1;32m     45\u001b[0m     embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed(embedding) \u001b[38;5;241m*\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_model)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Pass the embeddings through the LSTM\\\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m embedding, (hidden, cell_state) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell_state\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(embedding\u001b[38;5;241m.\u001b[39msize())\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:810\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    806\u001b[0m     \u001b[38;5;66;03m# Each batch of the hidden state should match the input sequence that\u001b[39;00m\n\u001b[1;32m    807\u001b[0m     \u001b[38;5;66;03m# the user believes he/she is passing in.\u001b[39;00m\n\u001b[1;32m    808\u001b[0m     hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[0;32m--> 810\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_forward_args\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    811\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    812\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers,\n\u001b[1;32m    813\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first)\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:733\u001b[0m, in \u001b[0;36mLSTM.check_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_input(\u001b[38;5;28minput\u001b[39m, batch_sizes)\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_hidden_size(hidden[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_hidden_size(\u001b[38;5;28minput\u001b[39m, batch_sizes),\n\u001b[1;32m    732\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected hidden[0] size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 733\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_hidden_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_expected_cell_size\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[43m                       \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mExpected hidden[1] size \u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m, got \u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:239\u001b[0m, in \u001b[0;36mRNNBase.check_hidden_size\u001b[0;34m(self, hx, expected_hidden_size, msg)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_hidden_size\u001b[39m(\u001b[38;5;28mself\u001b[39m, hx: Tensor, expected_hidden_size: Tuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m],\n\u001b[1;32m    237\u001b[0m                       msg: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected hidden size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hx\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m!=\u001b[39m expected_hidden_size:\n\u001b[0;32m--> 239\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mformat(expected_hidden_size, \u001b[38;5;28mlist\u001b[39m(hx\u001b[38;5;241m.\u001b[39msize())))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected hidden[1] size (10, 91, 1024), got [10, 90, 1024]"
     ]
    }
   ],
   "source": [
    "directory = 'experiment_2_lstm'\n",
    "\n",
    "d_model = 1024\n",
    "heads = 32\n",
    "num_layers = 10\n",
    "epochs = 100\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "loss_history_lstm_transformer = []\n",
    "\n",
    "with open('WORDMAP_corpus_KBFILKOM.json', 'r') as j:\n",
    "    word_map = json.load(j)\n",
    "    \n",
    "transformer = TransformerLSTM(d_model = d_model, heads = heads, num_layers = num_layers, word_map = word_map, max_len=90)\n",
    "transformer = transformer.to(device)\n",
    "adam_optimizer = torch.optim.Adam(transformer.parameters(), lr=0.001, betas=(0.9, 0.98), eps=1e-9)\n",
    "transformer_optimizer = AdamWarmup(model_size = d_model, warmup_steps = 4000, optimizer = adam_optimizer)\n",
    "criterion = LossWithLS(len(word_map), 0.2)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss_train = train(train_loader, transformer, criterion, epoch)\n",
    "\n",
    "    state = {'epoch': epoch, 'transformer': transformer, 'transformer_optimizer': transformer_optimizer}\n",
    "    torch.save(state, directory + '/checkpoint_' + str(epoch) +'.pth.tar')\n",
    "\n",
    "    loss_history_lstm_transformer.append(loss_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "with open(directory + '/loss_history_lstm_transformer.yaml', 'w') as file:\n",
    "    yaml.dump(loss_history_lstm_transformer, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<unk>\n"
     ]
    }
   ],
   "source": [
    "directory = 'experiment_1'\n",
    "checkpoint = torch.load(directory + '/checkpoint_99.pth.tar')\n",
    "transformer = checkpoint['transformer']\n",
    "\n",
    "question = \"Visi FILKOM\" \n",
    "max_len = 50\n",
    "enc_qus = [word_map.get(word, word_map['<unk>']) for word in question.split()]\n",
    "question = torch.LongTensor(enc_qus).to(device).unsqueeze(0)\n",
    "question_mask = (question!=0).to(device).unsqueeze(1).unsqueeze(1)  \n",
    "sentence = evaluate(transformer, question, question_mask, int(max_len), word_map)\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epoch': 99,\n",
       " 'transformer': Transformer(\n",
       "   (embed): Embeddings(\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "     (embed): Embedding(952, 2048)\n",
       "   )\n",
       "   (encoder): EncoderLayer(\n",
       "     (layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "     (self_multihead): MultiHeadAttention(\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "       (query): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "       (key): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "       (value): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "       (concat): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "     )\n",
       "     (feed_forward): FeedForward(\n",
       "       (fc1): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "       (fc2): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (decoder): DecoderLayer(\n",
       "     (layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "     (self_multihead): MultiHeadAttention(\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "       (query): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "       (key): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "       (value): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "       (concat): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "     )\n",
       "     (src_multihead): MultiHeadAttention(\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "       (query): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "       (key): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "       (value): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "       (concat): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "     )\n",
       "     (feed_forward): FeedForward(\n",
       "       (fc1): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "       (fc2): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (logit): Linear(in_features=2048, out_features=952, bias=True)\n",
       " ),\n",
       " 'transformer_optimizer': <__main__.AdamWarmup at 0x7f91b4d37a00>}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reset Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |      0 B   | 194560 B   | 194560 B   | 194560 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   | 194560 B   | 194560 B   | 194560 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |      0 B   | 194560 B   | 194560 B   | 194560 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   | 194560 B   | 194560 B   | 194560 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |      0 B   | 194560 B   | 194560 B   | 194560 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   | 194560 B   | 194560 B   | 194560 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |      0 B   |   2048 KiB |   2048 KiB |   2048 KiB |\n",
      "|       from large pool |      0 B   |      0 KiB |      0 KiB |      0 KiB |\n",
      "|       from small pool |      0 B   |   2048 KiB |   2048 KiB |   2048 KiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |      0 B   |   1858 KiB |   1858 KiB |   1858 KiB |\n",
      "|       from large pool |      0 B   |      0 KiB |      0 KiB |      0 KiB |\n",
      "|       from small pool |      0 B   |   1858 KiB |   1858 KiB |   1858 KiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       1    |       1    |       1    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       1    |       1    |       1    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       1    |       1    |       1    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       1    |       1    |       1    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       1    |       1    |       1    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       1    |       1    |       1    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       1    |       1    |       1    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       1    |       1    |       1    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "print(torch.cuda.memory_summary(device=None, abbreviated=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My Environment",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
