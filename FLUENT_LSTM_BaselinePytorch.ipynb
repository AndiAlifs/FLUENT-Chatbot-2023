{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pJAWnBFlkE2w"
   },
   "source": [
    "# LSTM Bot\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "In this project, you will build a chatbot that can converse with you at the command line. The chatbot will use a Sequence to Sequence text generation architecture with an LSTM as it's memory unit. You will also learn to use pretrained word embeddings to improve the performance of the model. At the conclusion of the project, you will be able to show your chatbot to potential employers.\n",
    "\n",
    "Additionally, you have the option to use pretrained word embeddings in your model. We have loaded Brown Embeddings from Gensim in the starter code below. You can compare the performance of your model with pre-trained embeddings against a model without the embeddings.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "A sequence to sequence model (Seq2Seq) has two components:\n",
    "- An Encoder consisting of an embedding layer and LSTM unit.\n",
    "- A Decoder consisting of an embedding layer, LSTM unit, and linear output unit.\n",
    "\n",
    "The Seq2Seq model works by accepting an input into the Encoder, passing the hidden state from the Encoder to the Decoder, which the Decoder uses to output a series of token predictions.\n",
    "\n",
    "## Dependencies\n",
    "\n",
    "- Pytorch\n",
    "- Numpy\n",
    "- Pandas\n",
    "- NLTK\n",
    "- Gzip\n",
    "- Gensim\n",
    "\n",
    "\n",
    "Please choose a dataset from the Torchtext website. We recommend looking at the Squad dataset first. Here is a link to the website where you can view your options:\n",
    "\n",
    "- https://pytorch.org/text/stable/datasets.html\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstring\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mneptune\u001b[39;00m\n\u001b[1;32m      7\u001b[0m stemmer \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mstem\u001b[38;5;241m.\u001b[39msnowball\u001b[38;5;241m.\u001b[39mSnowballStemmer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/__init__.py:798\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mamp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m autocast\n\u001b[1;32m    797\u001b[0m \u001b[38;5;66;03m# Shared memory manager needs to know the exact location of manager executable\u001b[39;00m\n\u001b[0;32m--> 798\u001b[0m \u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initExtension\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmanager_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m manager_path\n\u001b[1;32m    801\u001b[0m \u001b[38;5;66;03m# Appease the type checker: it can't deal with direct setting of globals().\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# Note that we will see \"too many\" functions when reexporting this way; there\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;66;03m# is not a good way to fix this problem.  Perhaps, try to redesign VariableFunctions\u001b[39;00m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;66;03m# so that this import is good enough\u001b[39;00m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:216\u001b[0m, in \u001b[0;36m_lock_unlock_module\u001b[0;34m(name)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import string\n",
    "import torch\n",
    "import neptune\n",
    "\n",
    "stemmer = nltk.stem.snowball.SnowballStemmer('english')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def getDict(dataPipe):\n",
    "\n",
    "    data_dict = {\n",
    "        'Question': [],\n",
    "        'Answer': []\n",
    "    }\n",
    "    \n",
    "    for _, question, answers, _ in dataPipe:\n",
    "        data_dict['Question'].append(question)\n",
    "        data_dict['Answer'].append(answers[0])\n",
    "        \n",
    "    return data_dict\n",
    "\n",
    "\n",
    "def loadDF(path):\n",
    "    # load data\n",
    "    train_data, val_data = torchtext.datasets.SQuAD2|(path)\n",
    "    \n",
    "    # convert dataPipe to dictionary \n",
    "    train_dict, val_dict = getDict(train_data), getDict(val_data)\n",
    "    \n",
    "    # convert Dictionaries to Pandas DataFrame\n",
    "    train_df = pd.DataFrame(train_dict)    \n",
    "    validation_df = pd.DataFrame(val_dict)    \n",
    "    \n",
    "    return train_df.append(validation_df)\n",
    "\n",
    "\n",
    "def prepare_text(sentence):\n",
    "    # clean text and tokenize it \n",
    "    sentence = ''.join([s.lower() for s in sentence if s not in string.punctuation])\n",
    "    sentence = ' '.join(stemmer.stem(w) for w in sentence.split())\n",
    "    tokens = nltk.tokenize.RegexpTokenizer(r'\\w+').tokenize(sentence)\n",
    "\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def toTensor(vocab, sentence):\n",
    "    # convert list of words \"sentence\" to a torch tensor of indices\n",
    "    indices = [vocab.word2index[word] for word in sentence.split(' ')]\n",
    "    indices.append(vocab.word2index[''])\n",
    "    return torch.Tensor(indices).long().to(device).view(-1, 1)\n",
    "\n",
    "\n",
    "def getPairs(df):\n",
    "    # convert df to list of pairs\n",
    "    temp1 = df['Question'].apply(lambda x: \" \".join(x) ).to_list()\n",
    "    temp2 = df['Answer'].apply(lambda x: \" \".join(x) ).to_list()\n",
    "    return [list(i) for i in zip(temp1, temp2)]\n",
    "\n",
    "\n",
    "def getMaxLen(pairs):\n",
    "    max_src = 0 \n",
    "    max_trg = 0\n",
    "    \n",
    "    for p in pairs:\n",
    "        max_src = len(p[0].split()) if len(p[0].split()) > max_src else max_src\n",
    "        max_trg = len(p[1].split()) if len(p[1].split()) > max_trg else max_trg\n",
    "        \n",
    "    return max_src, max_trg\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arsitektur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import random \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(self.input_size, self.hidden_size)\n",
    "        self.input = nn.Linear(self.input_size, self.hidden_size)\n",
    "        self.lstm = nn.LSTM(self.hidden_size, self.hidden_size)\n",
    "\n",
    "    def forward(self, x, hidden, cell_state):\n",
    "        x = self.embedding(x)\n",
    "        x = x.view(1, 1, -1)\n",
    "        x, (hidden, cell_state) = self.lstm(x, (hidden, cell_state))\n",
    "        return x, hidden, cell_state\n",
    "        \n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_size, self.hidden_size)\n",
    "        self.lstm = nn.LSTM(self.hidden_size, self.hidden_size)\n",
    "        self.fc = nn.Linear(self.hidden_size, self.output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim= 1)\n",
    "\n",
    "    def forward(self, x, hidden, cell_state):\n",
    "        x = self.embedding(x)\n",
    "        x = x.view(1, 1, -1)\n",
    "        x, (hidden, cell_state) = self.lstm(x, (hidden, cell_state))\n",
    "        x = self.softmax(self.fc(x[0]))\n",
    "        return x, hidden, cell_state\n",
    "    \n",
    "    \n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.encoder = Encoder(self.input_size, self.hidden_size)\n",
    "        self.decoder = Decoder(self.hidden_size, self.output_size)\n",
    "        \n",
    "    def forward(self, src, trg, src_len, trg_len, teacher_force=1):\n",
    "        \n",
    "        output = {\n",
    "            'decoder_output':[]\n",
    "        }\n",
    "        \n",
    "        encoder_hidden = torch.zeros([1, 1, self.hidden_size]).to(device) # 1 = number of LSTM layers\n",
    "        cell_state = torch.zeros([1, 1, self.hidden_size]).to(device)  \n",
    "        \n",
    "        for i in range(src_len):\n",
    "            encoder_output, encoder_hidden, cell_state = self.encoder(src[i], encoder_hidden, cell_state)\n",
    "\n",
    "        decoder_input = torch.Tensor([[0]]).long().to(device) # 0 = SOS_token\n",
    "        decoder_hidden = encoder_hidden\n",
    "        \n",
    "        for i in range(trg_len):\n",
    "            decoder_output, decoder_hidden, cell_state = self.decoder(decoder_input, decoder_hidden, cell_state)\n",
    "            output['decoder_output'].append(decoder_output)\n",
    "            \n",
    "            if self.training: # Model not in eval mode\n",
    "                decoder_input = target_tensor[i] if random.random() > teacher_force else decoder_output.argmax(1) # teacher forcing\n",
    "            else:\n",
    "                _, top_index = decoder_output.data.topk(1)\n",
    "                decoder_input = top_index.squeeze().detach()\n",
    "                \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "project = \"andialifs/fluent-tesis-24\"\n",
    "api_token = \"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJjZTY2YWQ3My04OTBkLTQ2OWUtYTc1Ni1jYjk0MGZhMWFiNGEifQ==\"\n",
    "\n",
    "def neptune_init(name):\n",
    "    run = neptune.init_run(\n",
    "        project=project,\n",
    "        api_token=api_token,\n",
    "        name=name\n",
    "    )\n",
    "    return run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def train(source_data, target_data, model, epochs, batch_size, print_every, learning_rate):\n",
    "    model.to(device)\n",
    "    total_training_loss = 0\n",
    "    total_valid_loss = 0\n",
    "    loss = 0\n",
    "    \n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    # use cross validation\n",
    "    kf = KFold(n_splits=4, shuffle=True)\n",
    "\n",
    "    run = neptune_init(\"LSTM_FLUENT_Baseline_2\")\n",
    "\n",
    "    for e, (train_index, test_index) in enumerate(kf.split(source_data), 1):\n",
    "        model.to(device)\n",
    "        model.train()\n",
    "        for i in range(0, len(train_index)):\n",
    "\n",
    "            src = source_data[i]\n",
    "            trg = target_data[i]\n",
    "\n",
    "            output = model(src, trg, src.size(0), trg.size(0))\n",
    "\n",
    "            current_loss = 0\n",
    "            for (s, t) in zip(output[\"decoder_output\"], trg): \n",
    "                current_loss += criterion(s, t)\n",
    "\n",
    "            loss += current_loss\n",
    "            total_training_loss += (current_loss.item() / trg.size(0)) # add the iteration loss\n",
    "\n",
    "            if i % batch_size == 0 or i == (len(train_index)-1):\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                loss = 0\n",
    "\n",
    "\n",
    "        # validation set \n",
    "        model.eval()\n",
    "        for i in range(0, len(test_index)):\n",
    "            src = source_data[i]\n",
    "            trg = target_data[i]\n",
    "\n",
    "            output = model(src, trg, src.size(0), trg.size(0))\n",
    "\n",
    "            current_loss = 0\n",
    "            for (s, t) in zip(output[\"decoder_output\"], trg): \n",
    "                current_loss += criterion(s, t)\n",
    "\n",
    "            total_valid_loss += (current_loss.item() / trg.size(0)) # add the iteration loss\n",
    "\n",
    "\n",
    "        if e % print_every == 0:\n",
    "            training_loss_average = total_training_loss / (len(train_index)*print_every)\n",
    "            validation_loss_average = total_valid_loss / (len(test_index)*print_every)\n",
    "            print(\"{}/{} Epoch  -  Training Loss = {:.4f}  -  Validation Loss = {:.4f}\".format(e, epochs, training_loss_average, validation_loss_average))\n",
    "            run['train/loss'].append(training_loss_average)\n",
    "            total_training_loss = 0\n",
    "            total_valid_loss = 0 \n",
    "    \n",
    "    run.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class Vocab:\n",
    "    def __init__(self):\n",
    "        self.word2index = {\"\": SOS_token, \"\": EOS_token}\n",
    "        self.index2word = {SOS_token: \"\", EOS_token: \"\"}\n",
    "        self.words_count = len(self.word2index)\n",
    "\n",
    "    def add_words(self, sentence):\n",
    "        for word in sentence.split(\" \"):\n",
    "            if word not in self.word2index:\n",
    "                self.word2index[word] = self.words_count\n",
    "                self.index2word[self.words_count] = word\n",
    "                self.words_count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "learning_rate = 0.0001\n",
    "hidden_size = 500 # encoder and decoder hidden size\n",
    "batch_size = 50\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "knowledgebase = pd.read_excel('https://raw.githubusercontent.com/AndiAlifs/FLUENT-Chatbot-2023/main/KnowledgeBaseFilkom.xlsx', engine='openpyxl')\n",
    "knowledgebase = pd.read_excel('https://raw.githubusercontent.com/AndiAlifs/FLUENT-Chatbot-2023/main/KnowledgeBaseFilkom_simple.xlsx', engine='openpyxl')\n",
    "knowledgebase.head()\n",
    "\n",
    "qa_paired = knowledgebase.drop(columns=knowledgebase.columns.drop(['Pertanyaan', 'Jawaban']))\n",
    "qa_paired.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# data_df = loadDF('data')\n",
    "# I will take only the first 5,000 Q&A to avoid CUDA out of memory error due to the large dataset\n",
    "# data_df = data_df.iloc[:5000, :]\n",
    "data_df = pd.DataFrame(columns=['Question', 'Answer'])\n",
    "data_df['Question'] = qa_paired['Pertanyaan']\n",
    "data_df['Answer'] = qa_paired['Jawaban']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">  visi FILKOM \n",
      "<  Menjadi Fakultas yang berdaya saing internasional dan berkontribusi kepada pengembangan Teknologi Informasi dan Ilmu Komputer untuk menunjang industri dan masyarakat dengan menyelaraskan pelaksanaan Pendidikan, Penelitian, dan Pengabdian kepada Masyarakat \n",
      "\n",
      ">  misi FILKOM \n",
      "<  Menyelenggarakan pendidikan di bidang Teknologi Informasi dan Ilmu Komputer yang berkualitas dan berstandar internasional secara berkelanjutan.\n",
      "Meningkatkan kemampuan sivitas akademika dalam pengembangan penelitian dan pengabdian yang selaras dengan kebutuhan industri dan masyarakat.\n",
      "Mengintegrasikan pengembangan pendidikan, penelitian, dan pengabdian kepada masyarakat yang ditunjang dengan tatakelola organisasi yang transparan, akuntabel, efektif, dan efisien.\n",
      "Mewujudkan kerja sama yang berkelanjutan di bidang pendidikan, penelitian, dan pengabdian kepada masyarakat dalam skala nasional dan internasional. \n",
      "\n",
      ">  apa tujuan filkom? \n",
      "<  Menghasilkan lulusan yang kompeten , profesional, berbudi pekerti luhur, berjiwa entrepreneur dan berdaya saing internasional.\n",
      "Menghasilkan sivitas akademika yang mampu mengembangkan penelitiandan pengabdian yang berorientasi pada pembaruan dan teknologi tepat guna untuk industri dan masyarakat.\n",
      "Terwujudnya suasana akademik yang kondusif dalam bidang pendidikan, penelitian, dan pengabdian kepada masyarakat yang berdaya saing unggul.\n",
      "Terwujudnya tata kelola organisasi yang transparan, akuntabel, efektif, dan efisien.\n",
      "Meningkatnya kuantitas dan kualitas kerja sama yang berkelanjutan di bidang pendidikan, penelitian, dan pengabdian kepada masyarakat dalam skala nasional dan internasional. \n",
      "\n",
      ">  sasaran pendidikan FILKOM \n",
      "<  1. Meningkatkan kompetensi dan kualifikasi pendidikan Dosen\n",
      "2. Meningkatkan sarana dan prasarana pembelajaran\n",
      "3. Mengembangkan kurikulum mengkuti perkembangan dan kebutuhan pemangku kepentingan\n",
      "4. Meningkatkan mutu lulusan yang berkualitas\n",
      "5. Mempercepat masa studi\n",
      "6. Meningkatkan kompetensi lulusan tersertifikasi bidang TIK\n",
      "7. Meningkatkan prestasi mahasiswa\n",
      "8. Meningkatkan mutu kelembagaan \n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 4 is out of bounds for axis 0 with size 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m25\u001b[39m): \u001b[38;5;66;03m# first 5 Q&A\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m> \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mdata_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m< \u001b[39m\u001b[38;5;124m\"\u001b[39m, data_df\u001b[38;5;241m.\u001b[39miloc[i,\u001b[38;5;241m1\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexing.py:1066\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1064\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(com\u001b[38;5;241m.\u001b[39mapply_if_callable(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m key)\n\u001b[1;32m   1065\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m-> 1066\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtakeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_takeable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1067\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_tuple(key)\n\u001b[1;32m   1068\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1069\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:3915\u001b[0m, in \u001b[0;36mDataFrame._get_value\u001b[0;34m(self, index, col, takeable)\u001b[0m\n\u001b[1;32m   3913\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m takeable:\n\u001b[1;32m   3914\u001b[0m     series \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ixs(col, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m-> 3915\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mseries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   3917\u001b[0m series \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_item_cache(col)\n\u001b[1;32m   3918\u001b[0m engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_engine\n",
      "\u001b[0;31mIndexError\u001b[0m: index 4 is out of bounds for axis 0 with size 4"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for i in range(0, 25): # first 5 Q&A\n",
    "    print(\"> \", data_df.iloc[i,0], \"\\n< \", data_df.iloc[i,1], \"\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "data_df['Question'] = data_df['Question'].apply(prepare_text)\n",
    "data_df['Answer'] = data_df['Answer'].apply(prepare_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "pairs = getPairs(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "max_src, max_trg = getMaxLen(pairs)\n",
    "max_trg, max_src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "Q_vocab = Vocab()\n",
    "A_vocab = Vocab()\n",
    "\n",
    "# build vocabularies for questions \"source\" and answers \"target\"\n",
    "for pair in pairs:\n",
    "    Q_vocab.add_words(pair[0])\n",
    "    A_vocab.add_words(pair[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "source_data = [toTensor(Q_vocab, pair[0]) for pair in pairs]\n",
    "target_data = [toTensor(A_vocab, pair[1]) for pair in pairs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/andialifs/fluent-tesis-24/e/FLUENT24-108\n",
      "1/100 Epoch  -  Training Loss = 4.6740  -  Validation Loss = 4.6546\n",
      "2/100 Epoch  -  Training Loss = 4.6631  -  Validation Loss = 4.6664\n",
      "3/100 Epoch  -  Training Loss = 4.6659  -  Validation Loss = 4.6631\n",
      "4/100 Epoch  -  Training Loss = 4.6618  -  Validation Loss = 4.6560\n",
      "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
      "[neptune] [info   ] Done!\n",
      "[neptune] [info   ] Waiting for the remaining 4 operations to synchronize with Neptune. Do not kill this process.\n",
      "[neptune] [info   ] All 4 operations synced, thanks for waiting!\n",
      "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/andialifs/fluent-tesis-24/e/FLUENT24-108/metadata\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "seq2seq = Seq2Seq(Q_vocab.words_count, hidden_size, A_vocab.words_count)\n",
    "\n",
    "train(source_data = source_data,\n",
    "      target_data = target_data,\n",
    "      model = seq2seq,\n",
    "      print_every = 1,\n",
    "      epochs = epochs,\n",
    "      learning_rate = learning_rate,\n",
    "      batch_size = batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('encoder.embedding.weight',\n",
       "              tensor([[ 0.9643, -0.7359,  0.6100,  ...,  1.0356,  1.7872, -0.5752],\n",
       "                      [ 0.5445,  0.0289,  0.0945,  ..., -0.2531, -1.3197, -0.2233],\n",
       "                      [-0.8957, -0.8302, -0.0946,  ..., -0.1658,  1.1437,  0.3709],\n",
       "                      ...,\n",
       "                      [ 0.3184,  1.7109, -0.5536,  ..., -0.4618, -0.7470, -0.2984],\n",
       "                      [-1.1281,  1.1663,  0.9051,  ...,  0.4806,  0.3894, -0.6681],\n",
       "                      [-0.7249,  0.6202, -1.5260,  ..., -0.9074, -1.3313, -0.3148]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.input.weight',\n",
       "              tensor([[ 0.0189,  0.0245,  0.0260,  ..., -0.0126, -0.0209,  0.0183],\n",
       "                      [-0.0069,  0.0316,  0.0056,  ...,  0.0128, -0.0025,  0.0071],\n",
       "                      [-0.0023,  0.0229, -0.0128,  ...,  0.0089, -0.0274,  0.0149],\n",
       "                      ...,\n",
       "                      [-0.0078,  0.0259,  0.0362,  ...,  0.0264, -0.0088, -0.0259],\n",
       "                      [-0.0297,  0.0040, -0.0092,  ..., -0.0046, -0.0238,  0.0004],\n",
       "                      [ 0.0348, -0.0220, -0.0175,  ..., -0.0004,  0.0321, -0.0004]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.input.bias',\n",
       "              tensor([ 3.5148e-02,  5.4568e-03, -3.2135e-02,  8.1840e-03,  3.5969e-03,\n",
       "                       3.3669e-02, -9.4566e-03, -2.8642e-02, -2.6829e-02, -6.6998e-03,\n",
       "                      -6.2480e-03,  1.7950e-02, -3.6543e-02, -1.4745e-02,  1.2168e-02,\n",
       "                       2.8531e-02, -3.0636e-02, -2.5420e-02, -2.1096e-02, -2.9236e-02,\n",
       "                      -1.2689e-02,  2.0388e-02,  2.5121e-02, -2.7964e-02, -1.7657e-02,\n",
       "                       8.8290e-03, -8.4015e-03,  1.6235e-02, -1.5239e-02,  7.8218e-03,\n",
       "                       2.4116e-02, -9.8773e-03, -2.8549e-02,  2.5424e-02, -9.6860e-03,\n",
       "                       1.8407e-03,  3.1278e-02,  2.9369e-02, -3.5767e-02,  4.4279e-03,\n",
       "                       2.3039e-02, -1.5542e-02,  2.0859e-02,  6.2384e-03, -2.3541e-02,\n",
       "                       1.3501e-02, -3.1334e-02,  2.9744e-02, -3.2594e-02, -2.9075e-02,\n",
       "                      -2.8924e-02,  1.9839e-02, -2.7606e-02, -2.1639e-02,  1.6111e-02,\n",
       "                      -7.7309e-03, -2.7272e-02,  7.6177e-03,  1.9548e-02, -3.2253e-03,\n",
       "                       1.2815e-02, -2.4995e-03, -5.2025e-03,  1.0929e-02, -3.2285e-02,\n",
       "                      -1.0039e-02, -2.9996e-02,  2.2291e-02,  1.3759e-02, -1.2788e-02,\n",
       "                      -2.6393e-02, -1.0788e-02, -1.4863e-02, -3.0433e-02,  2.0623e-02,\n",
       "                       3.7315e-03, -2.6752e-02, -3.5520e-02, -1.8669e-03, -1.2416e-02,\n",
       "                      -1.0438e-02,  2.2118e-03, -1.0914e-03,  2.9660e-02, -1.2228e-02,\n",
       "                       2.6539e-02, -2.9012e-02,  5.2215e-03,  1.2592e-02, -2.9664e-02,\n",
       "                      -2.5251e-02,  9.1165e-03,  2.8947e-02, -1.5606e-02, -9.3303e-03,\n",
       "                       2.3368e-02,  2.8912e-02,  1.7802e-02, -3.2181e-02, -3.4067e-02,\n",
       "                      -8.7667e-03,  4.9469e-03, -9.8647e-04,  3.8582e-03, -1.6305e-03,\n",
       "                       1.4420e-03,  2.6658e-02,  3.1056e-02, -8.2773e-03, -4.5836e-03,\n",
       "                       7.3953e-04,  1.5729e-03, -3.2197e-02, -2.2303e-02,  2.3267e-03,\n",
       "                       1.1078e-03,  8.0758e-03, -1.5933e-02, -2.5240e-03, -2.8860e-02,\n",
       "                      -1.8016e-02, -2.2438e-02,  3.1650e-02,  7.3470e-03,  2.5385e-02,\n",
       "                      -1.1146e-02,  3.0884e-02, -1.4129e-02,  3.3956e-02,  1.4939e-02,\n",
       "                       3.5345e-02, -2.1245e-02, -9.8001e-04,  6.0346e-03,  8.0622e-03,\n",
       "                       1.9414e-02,  4.9458e-03,  5.8062e-03,  1.5289e-02, -2.9682e-02,\n",
       "                       3.0037e-02,  6.5378e-03, -3.3619e-02,  3.2921e-02, -3.5641e-02,\n",
       "                      -8.6939e-03, -2.3414e-02,  2.8988e-02, -2.6845e-02,  1.5644e-02,\n",
       "                       2.0252e-02, -1.9640e-02, -2.7989e-02, -2.5576e-02, -2.2878e-02,\n",
       "                      -1.4084e-02, -1.9465e-03, -2.8970e-02, -4.9270e-03, -3.4273e-02,\n",
       "                      -1.6252e-02, -2.2096e-02,  1.1485e-02, -3.3937e-02,  3.1988e-02,\n",
       "                      -1.9947e-03, -2.1289e-02, -1.7780e-02, -2.8544e-02,  1.3875e-02,\n",
       "                       1.1948e-02,  2.7520e-02, -1.1614e-02, -2.8381e-02, -2.0835e-02,\n",
       "                      -1.5295e-02, -3.3441e-02, -1.8890e-02, -2.1285e-02, -3.3796e-02,\n",
       "                      -2.6785e-03,  2.2344e-02, -2.2364e-02,  2.7793e-02,  2.1730e-02,\n",
       "                       3.2743e-02,  3.1022e-02, -7.4311e-03, -5.7872e-03,  3.9836e-03,\n",
       "                       2.6224e-02, -1.4679e-02, -3.5105e-02, -1.4381e-02, -2.8670e-02,\n",
       "                       2.2813e-02, -2.4456e-02, -2.7729e-02, -7.7899e-03, -5.8721e-03,\n",
       "                       1.0950e-02,  3.2101e-02, -1.2712e-02, -1.6770e-02,  2.1890e-02,\n",
       "                      -2.1285e-02, -3.4886e-02, -3.6087e-02, -1.0805e-02, -2.4589e-02,\n",
       "                       3.0772e-02,  1.7894e-02, -2.7285e-02,  3.5454e-02,  3.2965e-02,\n",
       "                       7.9169e-04,  2.6702e-02,  1.3725e-02, -3.0144e-03, -2.9613e-02,\n",
       "                      -9.4002e-03, -3.1861e-02, -1.6570e-02, -2.3001e-02, -3.3088e-02,\n",
       "                      -9.5554e-03,  1.5174e-02, -2.9366e-02, -2.1312e-02, -2.9059e-03,\n",
       "                       1.9336e-02,  2.5282e-02,  1.9373e-02, -3.3152e-02,  2.3230e-03,\n",
       "                       2.1351e-02, -1.2883e-02,  2.4906e-02, -2.0771e-02, -3.1525e-02,\n",
       "                      -1.3897e-02, -3.1070e-02, -1.9996e-02, -2.7222e-02,  3.6373e-02,\n",
       "                       3.3151e-02, -1.7634e-02, -1.8242e-02,  6.5504e-03, -3.6523e-02,\n",
       "                      -2.6050e-02,  1.6138e-02,  2.3996e-02,  2.6634e-02, -2.6570e-03,\n",
       "                      -3.0849e-02,  2.8081e-02,  1.3536e-02, -2.6185e-02,  3.2540e-03,\n",
       "                      -6.2065e-05, -1.9709e-02, -1.4242e-02,  1.2713e-02,  2.9195e-02,\n",
       "                       1.2363e-03, -2.8261e-02,  1.0337e-03,  2.4222e-02, -2.5169e-02,\n",
       "                      -1.2479e-03,  3.1835e-02, -2.8580e-03,  9.5676e-03,  5.4026e-03,\n",
       "                      -3.2512e-02, -2.0569e-02,  1.2461e-02, -1.8235e-04, -2.1335e-02,\n",
       "                       5.7665e-03, -1.4300e-02, -3.2921e-03,  1.5078e-03,  5.1881e-03,\n",
       "                       3.4441e-02, -2.0960e-02, -1.5396e-02,  1.4286e-02, -3.6782e-03,\n",
       "                      -3.1957e-02,  1.7824e-02,  3.4573e-02,  2.1033e-02,  2.7724e-02,\n",
       "                      -3.4971e-02, -6.0936e-03, -2.1476e-02,  8.2215e-03,  2.3880e-02,\n",
       "                      -2.2956e-02,  8.1023e-03, -1.8965e-02, -3.7390e-03, -3.6495e-02,\n",
       "                       1.4338e-02,  1.4231e-02, -1.9472e-02,  3.0522e-02,  1.0630e-02,\n",
       "                       1.0893e-02, -9.2861e-03, -2.6439e-03,  1.9817e-02,  2.8561e-02,\n",
       "                      -1.4763e-03, -3.1711e-02, -2.1697e-02, -7.2730e-03,  2.6193e-02,\n",
       "                       2.0744e-02, -2.0019e-02,  3.3179e-02,  3.2139e-02,  1.4055e-02,\n",
       "                      -1.0676e-02, -2.5108e-02,  1.0715e-02,  2.2679e-02, -5.6075e-03,\n",
       "                       2.7244e-02, -1.9469e-02,  7.0495e-03,  2.6954e-02,  3.6592e-03,\n",
       "                       4.8181e-03, -2.5529e-02, -3.4636e-03, -4.1587e-03,  2.6549e-02,\n",
       "                      -2.9127e-02,  3.8815e-03,  2.3073e-02,  2.2370e-02,  1.0857e-03,\n",
       "                       1.6913e-03,  1.2637e-02,  9.5831e-03,  2.9627e-02,  2.0048e-02,\n",
       "                       2.6900e-02, -2.1842e-02, -2.2586e-02, -1.7415e-02, -3.4112e-02,\n",
       "                       2.7285e-02,  2.6672e-02, -6.0705e-03,  2.0509e-02, -1.9654e-02,\n",
       "                      -9.7120e-03, -7.0504e-03, -5.9332e-04, -1.6412e-02,  1.5447e-02,\n",
       "                      -1.3293e-02, -1.4812e-03,  1.2330e-02, -6.9225e-03,  2.6361e-02,\n",
       "                       1.3659e-02,  2.3239e-03,  3.6425e-02, -1.0054e-02, -1.9606e-05,\n",
       "                       1.7257e-02, -2.2426e-02, -8.9221e-03,  3.6326e-04, -1.2668e-02,\n",
       "                      -2.5720e-02, -1.9735e-03, -2.3316e-02,  2.7640e-02,  1.5932e-02,\n",
       "                       2.9939e-02,  2.5648e-03,  2.2707e-02,  2.5907e-02,  2.8688e-02,\n",
       "                      -1.1546e-02, -3.1433e-02,  2.9530e-02,  1.2638e-02,  2.9428e-02,\n",
       "                      -2.3944e-02,  2.9385e-02, -1.9384e-02,  3.5386e-02, -1.1075e-02,\n",
       "                       1.5496e-02,  3.1361e-02, -3.2181e-02, -3.1028e-02,  2.5211e-03,\n",
       "                      -2.1884e-02, -1.1650e-02, -2.0975e-02, -2.3874e-02, -3.1969e-02,\n",
       "                      -1.1580e-02,  1.7364e-02, -3.4907e-02, -2.5165e-02, -2.7602e-02,\n",
       "                       1.3793e-02,  2.1622e-03, -1.6646e-02,  3.5378e-02, -3.3346e-02,\n",
       "                       3.5020e-02, -1.4794e-03, -2.2466e-03,  1.4487e-02, -2.0667e-03,\n",
       "                      -2.9582e-02, -2.5942e-03,  2.1824e-02,  1.0103e-02,  3.2120e-02,\n",
       "                      -1.1680e-02,  2.0214e-02,  1.6030e-02, -3.3812e-03,  3.4165e-02,\n",
       "                      -3.2266e-02, -3.2461e-02, -1.7696e-02, -1.1942e-03,  3.0896e-02,\n",
       "                      -3.2573e-02, -8.8598e-03,  3.3642e-02, -3.2873e-02,  1.8612e-02,\n",
       "                       3.3212e-02,  3.0519e-02, -7.3923e-04, -1.9614e-02, -3.2481e-03,\n",
       "                       4.9984e-03,  1.0581e-02, -1.3286e-02,  9.0472e-03,  3.2056e-02,\n",
       "                      -1.6005e-02, -3.3907e-02,  1.0398e-02,  2.5595e-02,  6.3388e-03,\n",
       "                       3.2900e-03, -1.7070e-02,  2.6368e-02, -3.6494e-03, -2.8735e-02,\n",
       "                       3.2222e-02,  8.6842e-03,  1.0976e-02,  3.1744e-02,  5.8108e-03,\n",
       "                      -2.4860e-02, -5.3819e-03, -2.5486e-02, -3.6360e-02, -5.5850e-03,\n",
       "                      -4.0872e-03, -8.0786e-04,  2.5359e-02,  7.7133e-03,  1.9661e-02,\n",
       "                      -3.5794e-02,  3.1107e-03, -3.0768e-02, -1.2679e-02, -2.5207e-02,\n",
       "                      -1.5967e-02, -2.4411e-02,  5.6543e-03, -1.8947e-02,  2.6479e-02,\n",
       "                      -2.8296e-02,  3.0187e-02,  1.5798e-02, -1.3601e-02, -7.1542e-03,\n",
       "                       3.3789e-03, -2.3180e-02, -2.6506e-02, -2.7484e-03,  2.0605e-02],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.lstm.weight_ih_l0',\n",
       "              tensor([[ 0.0324,  0.0344,  0.0011,  ...,  0.0252, -0.0053, -0.0005],\n",
       "                      [-0.0219,  0.0324, -0.0050,  ..., -0.0383,  0.0191, -0.0180],\n",
       "                      [-0.0371, -0.0035,  0.0300,  ...,  0.0178, -0.0021, -0.0430],\n",
       "                      ...,\n",
       "                      [ 0.0078,  0.0379, -0.0070,  ...,  0.0340, -0.0295,  0.0192],\n",
       "                      [ 0.0315, -0.0277,  0.0063,  ...,  0.0374, -0.0202, -0.0169],\n",
       "                      [ 0.0035,  0.0024, -0.0256,  ...,  0.0200,  0.0294,  0.0339]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.lstm.weight_hh_l0',\n",
       "              tensor([[-0.0379,  0.0178,  0.0376,  ...,  0.0262, -0.0211, -0.0427],\n",
       "                      [ 0.0102, -0.0082, -0.0291,  ...,  0.0419, -0.0001, -0.0190],\n",
       "                      [-0.0020,  0.0005, -0.0056,  ..., -0.0287,  0.0003, -0.0097],\n",
       "                      ...,\n",
       "                      [ 0.0199,  0.0382,  0.0365,  ..., -0.0198, -0.0213, -0.0099],\n",
       "                      [ 0.0250, -0.0091,  0.0170,  ...,  0.0347, -0.0182,  0.0009],\n",
       "                      [ 0.0154, -0.0346,  0.0053,  ..., -0.0236, -0.0323, -0.0299]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.lstm.bias_ih_l0',\n",
       "              tensor([ 0.0145,  0.0441,  0.0083,  ...,  0.0435, -0.0048,  0.0085],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.lstm.bias_hh_l0',\n",
       "              tensor([ 0.0173, -0.0140,  0.0205,  ..., -0.0109, -0.0103,  0.0020],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.embedding.weight',\n",
       "              tensor([[ 2.0408,  2.1897,  0.4812,  ..., -1.7181,  0.2306, -0.0446],\n",
       "                      [-1.2245,  0.2259,  0.7299,  ...,  0.6457, -0.0315,  1.2110],\n",
       "                      [-0.6629, -1.5911, -1.0893,  ..., -1.3987, -1.3878, -0.1253],\n",
       "                      ...,\n",
       "                      [-0.6397,  2.7178,  0.0438,  ..., -1.4203,  0.4566,  0.5324],\n",
       "                      [ 0.0093, -0.2458,  1.0911,  ..., -0.7453,  0.5011,  1.7602],\n",
       "                      [ 0.5468,  0.2099,  0.1175,  ...,  2.4103, -1.0215, -0.0044]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.lstm.weight_ih_l0',\n",
       "              tensor([[ 0.0190, -0.0057,  0.0386,  ...,  0.0314, -0.0131,  0.0365],\n",
       "                      [ 0.0046,  0.0088,  0.0266,  ..., -0.0355,  0.0339, -0.0414],\n",
       "                      [ 0.0053,  0.0205, -0.0321,  ...,  0.0218, -0.0345,  0.0079],\n",
       "                      ...,\n",
       "                      [-0.0509, -0.0003,  0.0314,  ...,  0.0194,  0.0184, -0.0285],\n",
       "                      [-0.0133, -0.0268, -0.0215,  ...,  0.0426, -0.0198, -0.0430],\n",
       "                      [ 0.0408,  0.0222,  0.0311,  ...,  0.0019, -0.0178, -0.0171]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.lstm.weight_hh_l0',\n",
       "              tensor([[ 0.0106, -0.0011,  0.0195,  ..., -0.0176, -0.0443,  0.0017],\n",
       "                      [-0.0106,  0.0301,  0.0178,  ...,  0.0286, -0.0359, -0.0362],\n",
       "                      [ 0.0068, -0.0197, -0.0353,  ...,  0.0347,  0.0196, -0.0296],\n",
       "                      ...,\n",
       "                      [ 0.0423, -0.0018, -0.0003,  ...,  0.0448,  0.0097,  0.0098],\n",
       "                      [-0.0030, -0.0274,  0.0096,  ..., -0.0365, -0.0236,  0.0263],\n",
       "                      [ 0.0459,  0.0439, -0.0039,  ..., -0.0345,  0.0213, -0.0301]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.lstm.bias_ih_l0',\n",
       "              tensor([ 0.0093, -0.0164,  0.0209,  ...,  0.0488,  0.0124, -0.0325],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.lstm.bias_hh_l0',\n",
       "              tensor([ 0.0430,  0.0097,  0.0128,  ...,  0.0424, -0.0166, -0.0106],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.fc.weight',\n",
       "              tensor([[-0.0440, -0.0367, -0.0185,  ...,  0.0351,  0.0253,  0.0408],\n",
       "                      [ 0.0308,  0.0164, -0.0048,  ..., -0.1561, -0.0565, -0.0090],\n",
       "                      [-0.0299, -0.0389, -0.0201,  ..., -0.0360, -0.0238, -0.0348],\n",
       "                      ...,\n",
       "                      [-0.0388,  0.0256, -0.0181,  ..., -0.0233, -0.0231, -0.0246],\n",
       "                      [ 0.0401,  0.0134, -0.0036,  ..., -0.0177, -0.0021,  0.0040],\n",
       "                      [ 0.0411,  0.0383,  0.0274,  ..., -0.0280, -0.0029, -0.0089]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.fc.bias',\n",
       "              tensor([-0.0122,  0.2834,  0.0050,  ...,  0.0227, -0.0435,  0.0016],\n",
       "                     device='cuda:0'))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2seq.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(740, 500)\n",
       "    (input): Linear(in_features=740, out_features=500, bias=True)\n",
       "    (lstm): LSTM(500, 500)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(2655, 500)\n",
       "    (lstm): LSTM(500, 500)\n",
       "    (fc): Linear(in_features=500, out_features=2655, bias=True)\n",
       "    (softmax): LogSoftmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model_path = 'seq2seq.pt'\n",
    "\n",
    "torch.save(seq2seq, model_path)\n",
    "\n",
    "seq2seq = torch.load(model_path, map_location=torch.device('cuda'))\n",
    "seq2seq.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type 'exit' to finish the chat.\n",
      " ------------------------------ \n",
      "\n",
      "< pengajuan \n",
      "< s1 \n",
      "< s1 \n",
      "< s1 \n",
      "< s1 \n",
      "< s1 \n",
      "< s1 \n",
      "< s1 \n",
      "< s1 \n",
      "< s1 \n",
      "< s1 \n",
      "< s1 \n",
      "< 1 \n",
      "< 1 \n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'kemarjuan'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m src\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexit\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m output \u001b[38;5;241m=\u001b[39m seq2seq(\u001b[43mtoTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mQ_vocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m)\u001b[49m, toTensor(A_vocab, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;28mlen\u001b[39m(src\u001b[38;5;241m.\u001b[39msplit()), \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      7\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder_output\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "Cell \u001b[0;32mIn[2], line 49\u001b[0m, in \u001b[0;36mtoTensor\u001b[0;34m(vocab, sentence)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtoTensor\u001b[39m(vocab, sentence):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;66;03m# convert list of words \"sentence\" to a torch tensor of indices\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m     indices \u001b[38;5;241m=\u001b[39m [vocab\u001b[38;5;241m.\u001b[39mword2index[word] \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m sentence\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[1;32m     50\u001b[0m     indices\u001b[38;5;241m.\u001b[39mappend(vocab\u001b[38;5;241m.\u001b[39mword2index[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mTensor(indices)\u001b[38;5;241m.\u001b[39mlong()\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtoTensor\u001b[39m(vocab, sentence):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;66;03m# convert list of words \"sentence\" to a torch tensor of indices\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m     indices \u001b[38;5;241m=\u001b[39m [\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword2index\u001b[49m\u001b[43m[\u001b[49m\u001b[43mword\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m sentence\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[1;32m     50\u001b[0m     indices\u001b[38;5;241m.\u001b[39mappend(vocab\u001b[38;5;241m.\u001b[39mword2index[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mTensor(indices)\u001b[38;5;241m.\u001b[39mlong()\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'kemarjuan'"
     ]
    }
   ],
   "source": [
    "print(\"Type 'exit' to finish the chat.\\n\", \"-\"*30, '\\n')\n",
    "while (True):\n",
    "    src = input(\"> \")\n",
    "    if src.strip() == \"exit\":\n",
    "        break\n",
    "    output = seq2seq(toTensor(Q_vocab, src), toTensor(A_vocab, \" \"), len(src.split()), 1)\n",
    "    response = \"\"\n",
    "    for o in output[\"decoder_output\"]:\n",
    "        response += A_vocab.index2word[o.argmax().item()] + \" \"\n",
    "    \n",
    "    print(\"<\", response)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "(Starter Code) LSTM Bot",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
