{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T20:17:27.682419Z",
     "iopub.status.busy": "2024-07-02T20:17:27.682115Z",
     "iopub.status.idle": "2024-07-02T20:17:30.597078Z",
     "shell.execute_reply": "2024-07-02T20:17:30.596113Z",
     "shell.execute_reply.started": "2024-07-02T20:17:27.682391Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "import neptune\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "from collections import Counter\n",
    "from torchinfo import summary\n",
    "from sklearn.decomposition import PCA\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T20:17:30.598900Z",
     "iopub.status.busy": "2024-07-02T20:17:30.598458Z",
     "iopub.status.idle": "2024-07-02T20:17:32.694354Z",
     "shell.execute_reply": "2024-07-02T20:17:32.693406Z",
     "shell.execute_reply.started": "2024-07-02T20:17:30.598873Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pertanyaan</th>\n",
       "      <th>Jawaban</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>visi filkom</td>\n",
       "      <td>menjadi fakultas yang berdaya saing internasio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>misi filkom</td>\n",
       "      <td>menyelenggarakan pendidikan di bidang teknolog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>apa tujuan filkom?</td>\n",
       "      <td>menghasilkan lulusan yang kompeten , profesion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sasaran pendidikan filkom</td>\n",
       "      <td>meningkatkan kompetensi dan kualifikasi pendid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>email fitra a. bachtiar</td>\n",
       "      <td>fitra.bachtiar[at]ub.ac.id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bidang penelitian fitra a. bachtiar</td>\n",
       "      <td>affective computing, affective engineering, in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tanggal dibentuk ptiik</td>\n",
       "      <td>27 oktober 2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sasaran pengabdian filkom</td>\n",
       "      <td>1. meningkatkan kualitas dan kuantitas pengabd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sasaran kerjasama filkom</td>\n",
       "      <td>1. mengadakan kerjasama pendidikan, penlitian ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dekan fakultas ilmu komputer filkom</td>\n",
       "      <td>prof. ir. wayan firdaus mahmudy, s.si., mt., p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>wakil dekan bidang akademik / wakil dekan 1</td>\n",
       "      <td>dr. eng. ir. herman tolle, st., mt.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>wakil dekan bidang umum, keuangan, dan sumber ...</td>\n",
       "      <td>agus wahyu widodo, st., m.cs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>wakil dekan bidang kemahasiswaan, alumni, dan ...</td>\n",
       "      <td>drs. muh. arif rahman, m.kom.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ketua departemen teknik informatika</td>\n",
       "      <td>achmad basuki, s.t., m.mg., ph.d.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sekretaris departemen teknik informatika</td>\n",
       "      <td>ir. primantara hari trisnawan, m.sc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ketua program studi magister ilmu komputer</td>\n",
       "      <td>sabriansyah rizqika akbar, s.t., m.eng., ph.d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ketua program studi sarjana teknik informatika</td>\n",
       "      <td>adhitya bhawiyuga, s.kom., m.sc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ketua program studi sarjana teknik komputer</td>\n",
       "      <td>barlian henryranu prasetio, s.t., m.t., ph.d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ketua departemen sistem informasi</td>\n",
       "      <td>issa arwani, s.kom., m.sc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>seketaris departemen sistem informasi</td>\n",
       "      <td>satrio agung wicaksono, s.kom., m.kom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ketua program studi sarjana sistem informasi</td>\n",
       "      <td>yusi tyroni mursityo, s.kom., m.s.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ketua program studi sarjana pendidikan teknolo...</td>\n",
       "      <td>ir. admaja dwi herlambang, s.pd., m.pd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ketua program studi sarjana teknologi informasi</td>\n",
       "      <td>ir. widhy hayuhardhika nugraha putra, s.kom., ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>berikan saya informasi alumni</td>\n",
       "      <td>informasi alumni dapat diakses pada link berik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>apa saja layanan kemahasiswaan filkom ub ?</td>\n",
       "      <td>1. pengajuan proposal dan lpj kegiatan kemahas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>bagaimana pengajuan proposal dan lpj kegiatan ...</td>\n",
       "      <td>pengajuan proposal kegiatan kemahasiswaan\\npen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>berikan informasi dokumen kemahasiswaan ?</td>\n",
       "      <td>informasi dokumen kemahasiswaan dapat dilihat ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>bagaimana pengajuan surat tugas dosen pembimbi...</td>\n",
       "      <td>informasi pengajuan surat tugas dosen pembimbi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>bagaimana permohonan validasi data skm ?</td>\n",
       "      <td>permohonan validasi data skm dapat dilihat pad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>berikan informasi mengenai validasi syarat wisuda</td>\n",
       "      <td>1. unggah dokumen di siam\\n2. mengisi gform pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>bagaimana mengakses tracer study fakultas ?</td>\n",
       "      <td>tracer study fakultas dapat diakses pada tauta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>bagaimana cara pendaftaran wisuda ulang ?</td>\n",
       "      <td>pendaftaran wisuda ulang dapat diakses pada ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>berikan informasi mengenai layanan bimbingan d...</td>\n",
       "      <td>layanan bimbingan dan konseling dapat diaksesp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>berikan informasi mengenai layanan ultksp (uni...</td>\n",
       "      <td>layanan ultksp dapat diaksespada tautan beriku...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>berikan informasi mengenai tracking layanan ke...</td>\n",
       "      <td>tracking layanan kemahasiswaan dapat diaksespa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>berikan informasi mengenai bimbingan dan konse...</td>\n",
       "      <td>dalam perjalanannya menuntut ilmu, mahasiswa t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>apa tujuan unit konseling ?</td>\n",
       "      <td>1. mewujudkan potensi dirinya secara optimal, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>apa fungsi bimbingan dan konseling serta penas...</td>\n",
       "      <td>1. penyaluran: bimbingan berfungsi dalam memba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>apa saja program layanan unit konseling ?</td>\n",
       "      <td>1. pelayanan bantuan pemecahan masalah, baik y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>apa manfaat konseling filkom ?</td>\n",
       "      <td>1. masalah ditangani oleh ahli yang kompeten d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>berikan informasi mengenai layanan konseling</td>\n",
       "      <td>informasi mengenai layanan konseling dapat dia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>siapa konselor bimbingan dan konseling di filk...</td>\n",
       "      <td>ada 2 konselor bimbingan dan konseling di filk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>siapa koordinator konselor sebaya ?</td>\n",
       "      <td>koordinator konselor sebaya adalah muhammad da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>berikan rincian layanan ultksp</td>\n",
       "      <td>rincian layanan ultksp dapat diakses pada taut...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Pertanyaan  \\\n",
       "0                                         visi filkom   \n",
       "1                                         misi filkom   \n",
       "2                                  apa tujuan filkom?   \n",
       "3                           sasaran pendidikan filkom   \n",
       "4                             email fitra a. bachtiar   \n",
       "5                 bidang penelitian fitra a. bachtiar   \n",
       "6                              tanggal dibentuk ptiik   \n",
       "7                           sasaran pengabdian filkom   \n",
       "8                            sasaran kerjasama filkom   \n",
       "9                 dekan fakultas ilmu komputer filkom   \n",
       "10        wakil dekan bidang akademik / wakil dekan 1   \n",
       "11  wakil dekan bidang umum, keuangan, dan sumber ...   \n",
       "12  wakil dekan bidang kemahasiswaan, alumni, dan ...   \n",
       "13                ketua departemen teknik informatika   \n",
       "14           sekretaris departemen teknik informatika   \n",
       "15         ketua program studi magister ilmu komputer   \n",
       "16     ketua program studi sarjana teknik informatika   \n",
       "17        ketua program studi sarjana teknik komputer   \n",
       "18                  ketua departemen sistem informasi   \n",
       "19              seketaris departemen sistem informasi   \n",
       "20       ketua program studi sarjana sistem informasi   \n",
       "21  ketua program studi sarjana pendidikan teknolo...   \n",
       "22    ketua program studi sarjana teknologi informasi   \n",
       "23                      berikan saya informasi alumni   \n",
       "24         apa saja layanan kemahasiswaan filkom ub ?   \n",
       "25  bagaimana pengajuan proposal dan lpj kegiatan ...   \n",
       "26          berikan informasi dokumen kemahasiswaan ?   \n",
       "27  bagaimana pengajuan surat tugas dosen pembimbi...   \n",
       "28           bagaimana permohonan validasi data skm ?   \n",
       "29  berikan informasi mengenai validasi syarat wisuda   \n",
       "30        bagaimana mengakses tracer study fakultas ?   \n",
       "31          bagaimana cara pendaftaran wisuda ulang ?   \n",
       "32  berikan informasi mengenai layanan bimbingan d...   \n",
       "33  berikan informasi mengenai layanan ultksp (uni...   \n",
       "34  berikan informasi mengenai tracking layanan ke...   \n",
       "35  berikan informasi mengenai bimbingan dan konse...   \n",
       "36                        apa tujuan unit konseling ?   \n",
       "37  apa fungsi bimbingan dan konseling serta penas...   \n",
       "38          apa saja program layanan unit konseling ?   \n",
       "39                     apa manfaat konseling filkom ?   \n",
       "40       berikan informasi mengenai layanan konseling   \n",
       "41  siapa konselor bimbingan dan konseling di filk...   \n",
       "42                siapa koordinator konselor sebaya ?   \n",
       "43                     berikan rincian layanan ultksp   \n",
       "\n",
       "                                              Jawaban  \n",
       "0   menjadi fakultas yang berdaya saing internasio...  \n",
       "1   menyelenggarakan pendidikan di bidang teknolog...  \n",
       "2   menghasilkan lulusan yang kompeten , profesion...  \n",
       "3   meningkatkan kompetensi dan kualifikasi pendid...  \n",
       "4                          fitra.bachtiar[at]ub.ac.id  \n",
       "5   affective computing, affective engineering, in...  \n",
       "6                                     27 oktober 2011  \n",
       "7   1. meningkatkan kualitas dan kuantitas pengabd...  \n",
       "8   1. mengadakan kerjasama pendidikan, penlitian ...  \n",
       "9   prof. ir. wayan firdaus mahmudy, s.si., mt., p...  \n",
       "10                dr. eng. ir. herman tolle, st., mt.  \n",
       "11                      agus wahyu widodo, st., m.cs.  \n",
       "12                      drs. muh. arif rahman, m.kom.  \n",
       "13                  achmad basuki, s.t., m.mg., ph.d.  \n",
       "14               ir. primantara hari trisnawan, m.sc.  \n",
       "15      sabriansyah rizqika akbar, s.t., m.eng., ph.d  \n",
       "16                   adhitya bhawiyuga, s.kom., m.sc.  \n",
       "17       barlian henryranu prasetio, s.t., m.t., ph.d  \n",
       "18                         issa arwani, s.kom., m.sc.  \n",
       "19              satrio agung wicaksono, s.kom., m.kom  \n",
       "20                 yusi tyroni mursityo, s.kom., m.s.  \n",
       "21            ir. admaja dwi herlambang, s.pd., m.pd.  \n",
       "22  ir. widhy hayuhardhika nugraha putra, s.kom., ...  \n",
       "23  informasi alumni dapat diakses pada link berik...  \n",
       "24  1. pengajuan proposal dan lpj kegiatan kemahas...  \n",
       "25  pengajuan proposal kegiatan kemahasiswaan\\npen...  \n",
       "26  informasi dokumen kemahasiswaan dapat dilihat ...  \n",
       "27  informasi pengajuan surat tugas dosen pembimbi...  \n",
       "28  permohonan validasi data skm dapat dilihat pad...  \n",
       "29  1. unggah dokumen di siam\\n2. mengisi gform pe...  \n",
       "30  tracer study fakultas dapat diakses pada tauta...  \n",
       "31  pendaftaran wisuda ulang dapat diakses pada ta...  \n",
       "32  layanan bimbingan dan konseling dapat diaksesp...  \n",
       "33  layanan ultksp dapat diaksespada tautan beriku...  \n",
       "34  tracking layanan kemahasiswaan dapat diaksespa...  \n",
       "35  dalam perjalanannya menuntut ilmu, mahasiswa t...  \n",
       "36  1. mewujudkan potensi dirinya secara optimal, ...  \n",
       "37  1. penyaluran: bimbingan berfungsi dalam memba...  \n",
       "38  1. pelayanan bantuan pemecahan masalah, baik y...  \n",
       "39  1. masalah ditangani oleh ahli yang kompeten d...  \n",
       "40  informasi mengenai layanan konseling dapat dia...  \n",
       "41  ada 2 konselor bimbingan dan konseling di filk...  \n",
       "42  koordinator konselor sebaya adalah muhammad da...  \n",
       "43  rincian layanan ultksp dapat diakses pada taut...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# knowledgebase_url = 'https://github.com/AndiAlifs/FLUENT-Chatbot-2023/raw/main/KnowledgeBaseFilkom.xlsx'\n",
    "knowledgebase_url = 'https://github.com/AndiAlifs/FLUENT-Chatbot-2023/raw/main/KnowledgeBaseFilkom_simple.xlsx'\n",
    "knowledgebase_url_test = 'https://github.com/AndiAlifs/FLUENT-Chatbot-2023/raw/main/KnowledgeBaseFilkom_eval.xlsx'\n",
    "knowledgebase = pd.read_excel(knowledgebase_url)\n",
    "\n",
    "qa_paired = knowledgebase.drop(columns=knowledgebase.columns.drop(['Pertanyaan','Jawaban']))\n",
    "# qa_paired = knowledgebase.drop(columns=knowledgebase.columns.drop(['Pertanyaan', 'Labels' ,'Jawaban']))\n",
    "qa_paired.dropna(inplace=True)\n",
    "qa_paired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T20:17:32.697066Z",
     "iopub.status.busy": "2024-07-02T20:17:32.696633Z",
     "iopub.status.idle": "2024-07-02T20:17:32.702322Z",
     "shell.execute_reply": "2024-07-02T20:17:32.701334Z",
     "shell.execute_reply.started": "2024-07-02T20:17:32.697038Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def remove_punc(string):\n",
    "    punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "    no_punct = \"\"\n",
    "    for char in string:\n",
    "        if char not in punctuations:\n",
    "            no_punct = no_punct + char  # space is also a character\n",
    "    return no_punct.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T20:17:32.703938Z",
     "iopub.status.busy": "2024-07-02T20:17:32.703658Z",
     "iopub.status.idle": "2024-07-02T20:17:32.827025Z",
     "shell.execute_reply": "2024-07-02T20:17:32.825935Z",
     "shell.execute_reply.started": "2024-07-02T20:17:32.703915Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pairs = []\n",
    "max_len = 90\n",
    "\n",
    "for line in qa_paired.iterrows():\n",
    "    pertanyaan = line[1]['Pertanyaan']\n",
    "    jawaban = line[1]['Jawaban']\n",
    "    qa_pairs = []\n",
    "    first = remove_punc(pertanyaan.strip())      \n",
    "    second = remove_punc(jawaban.strip())\n",
    "\n",
    "    if len(first) == 0 or len(second) == 0:\n",
    "        continue\n",
    "\n",
    "    \n",
    "    qa_pairs.append(first.split()[:max_len])\n",
    "    qa_pairs.append(second.split()[:max_len])\n",
    "    pairs.append(qa_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[visi, filkom]</td>\n",
       "      <td>[menjadi, fakultas, yang, berdaya, saing, inte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[misi, filkom]</td>\n",
       "      <td>[menyelenggarakan, pendidikan, di, bidang, tek...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[apa, tujuan, filkom]</td>\n",
       "      <td>[menghasilkan, lulusan, yang, kompeten, profes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[sasaran, pendidikan, filkom]</td>\n",
       "      <td>[meningkatkan, kompetensi, dan, kualifikasi, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[email, fitra, a, bachtiar]</td>\n",
       "      <td>[fitrabachtiaratubacid]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[bidang, penelitian, fitra, a, bachtiar]</td>\n",
       "      <td>[affective, computing, affective, engineering,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[tanggal, dibentuk, ptiik]</td>\n",
       "      <td>[27, oktober, 2011]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[sasaran, pengabdian, filkom]</td>\n",
       "      <td>[1, meningkatkan, kualitas, dan, kuantitas, pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[sasaran, kerjasama, filkom]</td>\n",
       "      <td>[1, mengadakan, kerjasama, pendidikan, penliti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[dekan, fakultas, ilmu, komputer, filkom]</td>\n",
       "      <td>[prof, ir, wayan, firdaus, mahmudy, ssi, mt, phd]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[wakil, dekan, bidang, akademik, wakil, dekan, 1]</td>\n",
       "      <td>[dr, eng, ir, herman, tolle, st, mt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[wakil, dekan, bidang, umum, keuangan, dan, su...</td>\n",
       "      <td>[agus, wahyu, widodo, st, mcs]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[wakil, dekan, bidang, kemahasiswaan, alumni, ...</td>\n",
       "      <td>[drs, muh, arif, rahman, mkom]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[ketua, departemen, teknik, informatika]</td>\n",
       "      <td>[achmad, basuki, st, mmg, phd]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[sekretaris, departemen, teknik, informatika]</td>\n",
       "      <td>[ir, primantara, hari, trisnawan, msc]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[ketua, program, studi, magister, ilmu, komputer]</td>\n",
       "      <td>[sabriansyah, rizqika, akbar, st, meng, phd]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[ketua, program, studi, sarjana, teknik, infor...</td>\n",
       "      <td>[adhitya, bhawiyuga, skom, msc]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[ketua, program, studi, sarjana, teknik, kompu...</td>\n",
       "      <td>[barlian, henryranu, prasetio, st, mt, phd]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[ketua, departemen, sistem, informasi]</td>\n",
       "      <td>[issa, arwani, skom, msc]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[seketaris, departemen, sistem, informasi]</td>\n",
       "      <td>[satrio, agung, wicaksono, skom, mkom]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[ketua, program, studi, sarjana, sistem, infor...</td>\n",
       "      <td>[yusi, tyroni, mursityo, skom, ms]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[ketua, program, studi, sarjana, pendidikan, t...</td>\n",
       "      <td>[ir, admaja, dwi, herlambang, spd, mpd]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[ketua, program, studi, sarjana, teknologi, in...</td>\n",
       "      <td>[ir, widhy, hayuhardhika, nugraha, putra, skom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[berikan, saya, informasi, alumni]</td>\n",
       "      <td>[informasi, alumni, dapat, diakses, pada, link...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[apa, saja, layanan, kemahasiswaan, filkom, ub]</td>\n",
       "      <td>[1, pengajuan, proposal, dan, lpj, kegiatan, k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[bagaimana, pengajuan, proposal, dan, lpj, keg...</td>\n",
       "      <td>[pengajuan, proposal, kegiatan, kemahasiswaan,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[berikan, informasi, dokumen, kemahasiswaan]</td>\n",
       "      <td>[informasi, dokumen, kemahasiswaan, dapat, dil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[bagaimana, pengajuan, surat, tugas, dosen, pe...</td>\n",
       "      <td>[informasi, pengajuan, surat, tugas, dosen, pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[bagaimana, permohonan, validasi, data, skm]</td>\n",
       "      <td>[permohonan, validasi, data, skm, dapat, dilih...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[berikan, informasi, mengenai, validasi, syara...</td>\n",
       "      <td>[1, unggah, dokumen, di, siam, 2, mengisi, gfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[bagaimana, mengakses, tracer, study, fakultas]</td>\n",
       "      <td>[tracer, study, fakultas, dapat, diakses, pada...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[bagaimana, cara, pendaftaran, wisuda, ulang]</td>\n",
       "      <td>[pendaftaran, wisuda, ulang, dapat, diakses, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[berikan, informasi, mengenai, layanan, bimbin...</td>\n",
       "      <td>[layanan, bimbingan, dan, konseling, dapat, di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[berikan, informasi, mengenai, layanan, ultksp...</td>\n",
       "      <td>[layanan, ultksp, dapat, diaksespada, tautan, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[berikan, informasi, mengenai, tracking, layan...</td>\n",
       "      <td>[tracking, layanan, kemahasiswaan, dapat, diak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[berikan, informasi, mengenai, bimbingan, dan,...</td>\n",
       "      <td>[dalam, perjalanannya, menuntut, ilmu, mahasis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[apa, tujuan, unit, konseling]</td>\n",
       "      <td>[1, mewujudkan, potensi, dirinya, secara, opti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[apa, fungsi, bimbingan, dan, konseling, serta...</td>\n",
       "      <td>[1, penyaluran, bimbingan, berfungsi, dalam, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[apa, saja, program, layanan, unit, konseling]</td>\n",
       "      <td>[1, pelayanan, bantuan, pemecahan, masalah, ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[apa, manfaat, konseling, filkom]</td>\n",
       "      <td>[1, masalah, ditangani, oleh, ahli, yang, komp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[berikan, informasi, mengenai, layanan, konsel...</td>\n",
       "      <td>[informasi, mengenai, layanan, konseling, dapa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[siapa, konselor, bimbingan, dan, konseling, d...</td>\n",
       "      <td>[ada, 2, konselor, bimbingan, dan, konseling, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[siapa, koordinator, konselor, sebaya]</td>\n",
       "      <td>[koordinator, konselor, sebaya, adalah, muhamm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[berikan, rincian, layanan, ultksp]</td>\n",
       "      <td>[rincian, layanan, ultksp, dapat, diakses, pad...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question  \\\n",
       "0                                      [visi, filkom]   \n",
       "1                                      [misi, filkom]   \n",
       "2                               [apa, tujuan, filkom]   \n",
       "3                       [sasaran, pendidikan, filkom]   \n",
       "4                         [email, fitra, a, bachtiar]   \n",
       "5            [bidang, penelitian, fitra, a, bachtiar]   \n",
       "6                          [tanggal, dibentuk, ptiik]   \n",
       "7                       [sasaran, pengabdian, filkom]   \n",
       "8                        [sasaran, kerjasama, filkom]   \n",
       "9           [dekan, fakultas, ilmu, komputer, filkom]   \n",
       "10  [wakil, dekan, bidang, akademik, wakil, dekan, 1]   \n",
       "11  [wakil, dekan, bidang, umum, keuangan, dan, su...   \n",
       "12  [wakil, dekan, bidang, kemahasiswaan, alumni, ...   \n",
       "13           [ketua, departemen, teknik, informatika]   \n",
       "14      [sekretaris, departemen, teknik, informatika]   \n",
       "15  [ketua, program, studi, magister, ilmu, komputer]   \n",
       "16  [ketua, program, studi, sarjana, teknik, infor...   \n",
       "17  [ketua, program, studi, sarjana, teknik, kompu...   \n",
       "18             [ketua, departemen, sistem, informasi]   \n",
       "19         [seketaris, departemen, sistem, informasi]   \n",
       "20  [ketua, program, studi, sarjana, sistem, infor...   \n",
       "21  [ketua, program, studi, sarjana, pendidikan, t...   \n",
       "22  [ketua, program, studi, sarjana, teknologi, in...   \n",
       "23                 [berikan, saya, informasi, alumni]   \n",
       "24    [apa, saja, layanan, kemahasiswaan, filkom, ub]   \n",
       "25  [bagaimana, pengajuan, proposal, dan, lpj, keg...   \n",
       "26       [berikan, informasi, dokumen, kemahasiswaan]   \n",
       "27  [bagaimana, pengajuan, surat, tugas, dosen, pe...   \n",
       "28       [bagaimana, permohonan, validasi, data, skm]   \n",
       "29  [berikan, informasi, mengenai, validasi, syara...   \n",
       "30    [bagaimana, mengakses, tracer, study, fakultas]   \n",
       "31      [bagaimana, cara, pendaftaran, wisuda, ulang]   \n",
       "32  [berikan, informasi, mengenai, layanan, bimbin...   \n",
       "33  [berikan, informasi, mengenai, layanan, ultksp...   \n",
       "34  [berikan, informasi, mengenai, tracking, layan...   \n",
       "35  [berikan, informasi, mengenai, bimbingan, dan,...   \n",
       "36                     [apa, tujuan, unit, konseling]   \n",
       "37  [apa, fungsi, bimbingan, dan, konseling, serta...   \n",
       "38     [apa, saja, program, layanan, unit, konseling]   \n",
       "39                  [apa, manfaat, konseling, filkom]   \n",
       "40  [berikan, informasi, mengenai, layanan, konsel...   \n",
       "41  [siapa, konselor, bimbingan, dan, konseling, d...   \n",
       "42             [siapa, koordinator, konselor, sebaya]   \n",
       "43                [berikan, rincian, layanan, ultksp]   \n",
       "\n",
       "                                               answer  \n",
       "0   [menjadi, fakultas, yang, berdaya, saing, inte...  \n",
       "1   [menyelenggarakan, pendidikan, di, bidang, tek...  \n",
       "2   [menghasilkan, lulusan, yang, kompeten, profes...  \n",
       "3   [meningkatkan, kompetensi, dan, kualifikasi, p...  \n",
       "4                             [fitrabachtiaratubacid]  \n",
       "5   [affective, computing, affective, engineering,...  \n",
       "6                                 [27, oktober, 2011]  \n",
       "7   [1, meningkatkan, kualitas, dan, kuantitas, pe...  \n",
       "8   [1, mengadakan, kerjasama, pendidikan, penliti...  \n",
       "9   [prof, ir, wayan, firdaus, mahmudy, ssi, mt, phd]  \n",
       "10               [dr, eng, ir, herman, tolle, st, mt]  \n",
       "11                     [agus, wahyu, widodo, st, mcs]  \n",
       "12                     [drs, muh, arif, rahman, mkom]  \n",
       "13                     [achmad, basuki, st, mmg, phd]  \n",
       "14             [ir, primantara, hari, trisnawan, msc]  \n",
       "15       [sabriansyah, rizqika, akbar, st, meng, phd]  \n",
       "16                    [adhitya, bhawiyuga, skom, msc]  \n",
       "17        [barlian, henryranu, prasetio, st, mt, phd]  \n",
       "18                          [issa, arwani, skom, msc]  \n",
       "19             [satrio, agung, wicaksono, skom, mkom]  \n",
       "20                 [yusi, tyroni, mursityo, skom, ms]  \n",
       "21            [ir, admaja, dwi, herlambang, spd, mpd]  \n",
       "22  [ir, widhy, hayuhardhika, nugraha, putra, skom...  \n",
       "23  [informasi, alumni, dapat, diakses, pada, link...  \n",
       "24  [1, pengajuan, proposal, dan, lpj, kegiatan, k...  \n",
       "25  [pengajuan, proposal, kegiatan, kemahasiswaan,...  \n",
       "26  [informasi, dokumen, kemahasiswaan, dapat, dil...  \n",
       "27  [informasi, pengajuan, surat, tugas, dosen, pe...  \n",
       "28  [permohonan, validasi, data, skm, dapat, dilih...  \n",
       "29  [1, unggah, dokumen, di, siam, 2, mengisi, gfo...  \n",
       "30  [tracer, study, fakultas, dapat, diakses, pada...  \n",
       "31  [pendaftaran, wisuda, ulang, dapat, diakses, p...  \n",
       "32  [layanan, bimbingan, dan, konseling, dapat, di...  \n",
       "33  [layanan, ultksp, dapat, diaksespada, tautan, ...  \n",
       "34  [tracking, layanan, kemahasiswaan, dapat, diak...  \n",
       "35  [dalam, perjalanannya, menuntut, ilmu, mahasis...  \n",
       "36  [1, mewujudkan, potensi, dirinya, secara, opti...  \n",
       "37  [1, penyaluran, bimbingan, berfungsi, dalam, m...  \n",
       "38  [1, pelayanan, bantuan, pemecahan, masalah, ba...  \n",
       "39  [1, masalah, ditangani, oleh, ahli, yang, komp...  \n",
       "40  [informasi, mengenai, layanan, konseling, dapa...  \n",
       "41  [ada, 2, konselor, bimbingan, dan, konseling, ...  \n",
       "42  [koordinator, konselor, sebaya, adalah, muhamm...  \n",
       "43  [rincian, layanan, ultksp, dapat, diakses, pad...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_df = pd.DataFrame(pairs, columns=['question', 'answer'])\n",
    "pairs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T20:17:32.828565Z",
     "iopub.status.busy": "2024-07-02T20:17:32.828255Z",
     "iopub.status.idle": "2024-07-02T20:17:32.838911Z",
     "shell.execute_reply": "2024-07-02T20:17:32.837848Z",
     "shell.execute_reply.started": "2024-07-02T20:17:32.828539Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "word_freq = Counter()\n",
    "for pair in pairs:\n",
    "    word_freq.update(pair[0])\n",
    "    word_freq.update(pair[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T20:17:32.840576Z",
     "iopub.status.busy": "2024-07-02T20:17:32.840244Z",
     "iopub.status.idle": "2024-07-02T20:17:32.850265Z",
     "shell.execute_reply": "2024-07-02T20:17:32.849352Z",
     "shell.execute_reply.started": "2024-07-02T20:17:32.840548Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "min_word_freq = 0\n",
    "words = [w for w in word_freq.keys() if word_freq[w] > min_word_freq]\n",
    "word_map = {k: v + 1 for v, k in enumerate(words)}\n",
    "word_map['<unk>'] = len(word_map) + 1\n",
    "word_map['<start>'] = len(word_map) + 1\n",
    "word_map['<end>'] = len(word_map) + 1\n",
    "word_map['<pad>'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T20:17:32.851802Z",
     "iopub.status.busy": "2024-07-02T20:17:32.851465Z",
     "iopub.status.idle": "2024-07-02T20:17:32.860482Z",
     "shell.execute_reply": "2024-07-02T20:17:32.859625Z",
     "shell.execute_reply.started": "2024-07-02T20:17:32.851770Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words are: 449\n"
     ]
    }
   ],
   "source": [
    "print(\"Total words are: {}\".format(len(word_map)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T20:17:32.861919Z",
     "iopub.status.busy": "2024-07-02T20:17:32.861579Z",
     "iopub.status.idle": "2024-07-02T20:17:32.872138Z",
     "shell.execute_reply": "2024-07-02T20:17:32.871399Z",
     "shell.execute_reply.started": "2024-07-02T20:17:32.861895Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with open('WORDMAP_corpus_KBFILKOM.json', 'w') as j:\n",
    "    json.dump(word_map, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T20:17:32.877074Z",
     "iopub.status.busy": "2024-07-02T20:17:32.876749Z",
     "iopub.status.idle": "2024-07-02T20:17:32.884325Z",
     "shell.execute_reply": "2024-07-02T20:17:32.883430Z",
     "shell.execute_reply.started": "2024-07-02T20:17:32.877048Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def encode_question(words, word_map):\n",
    "    enc_c = [word_map.get(word, word_map['<unk>']) for word in words] + [word_map['<pad>']] * (max_len - len(words))\n",
    "    return enc_c\n",
    "\n",
    "\n",
    "def encode_question_left(words, word_map):\n",
    "    enc_c = [word_map['<pad>']] * (max_len - len(words)) + [word_map.get(word, word_map['<unk>']) for word in words]\n",
    "    return enc_c\n",
    "\n",
    "def encode_reply(words, word_map):\n",
    "    enc_c = [word_map['<start>']] + [word_map.get(word, word_map['<unk>']) for word in words] + \\\n",
    "    [word_map['<end>']] + [word_map['<pad>']] * (max_len - len(words))\n",
    "    return enc_c\n",
    "\n",
    "def encode_reply_with_maxlen(words, word_map):\n",
    "    enc_c = [word_map['<start>']] + [word_map.get(word, word_map['<unk>']) for word in words] + [word_map['<end>']] + [word_map['<pad>']] * (max_len-2 - len(words))\n",
    "    return enc_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T20:17:32.885632Z",
     "iopub.status.busy": "2024-07-02T20:17:32.885341Z",
     "iopub.status.idle": "2024-07-02T20:17:33.099456Z",
     "shell.execute_reply": "2024-07-02T20:17:33.098486Z",
     "shell.execute_reply.started": "2024-07-02T20:17:32.885608Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pairs_encoded = []\n",
    "for pair in pairs:\n",
    "    qus = encode_question(pair[0], word_map)\n",
    "    # qus = encode_question_left(pair[0], word_map)\n",
    "    ans = encode_reply(pair[1], word_map)\n",
    "    pairs_encoded.append([qus, ans])\n",
    "\n",
    "with open('pairs_encoded_kbfilkom.json', 'w') as p:\n",
    "    json.dump(pairs_encoded, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T20:17:33.318791Z",
     "iopub.status.busy": "2024-07-02T20:17:33.318483Z",
     "iopub.status.idle": "2024-07-02T20:17:33.325793Z",
     "shell.execute_reply": "2024-07-02T20:17:33.325035Z",
     "shell.execute_reply.started": "2024-07-02T20:17:33.318756Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.pairs = json.load(open('pairs_encoded_kbfilkom.json'))\n",
    "        self.dataset_size = len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        question = torch.LongTensor(self.pairs[i][0])\n",
    "        reply = torch.LongTensor(self.pairs[i][1])\n",
    "            \n",
    "        return question, reply\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T20:17:33.337842Z",
     "iopub.status.busy": "2024-07-02T20:17:33.337481Z",
     "iopub.status.idle": "2024-07-02T20:17:33.379910Z",
     "shell.execute_reply": "2024-07-02T20:17:33.378865Z",
     "shell.execute_reply.started": "2024-07-02T20:17:33.337813Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(Dataset(),\n",
    "                                           batch_size = 100, \n",
    "                                           shuffle=True, \n",
    "                                           pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T20:17:33.381467Z",
     "iopub.status.busy": "2024-07-02T20:17:33.381114Z",
     "iopub.status.idle": "2024-07-02T20:17:33.388963Z",
     "shell.execute_reply": "2024-07-02T20:17:33.388016Z",
     "shell.execute_reply.started": "2024-07-02T20:17:33.381434Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_masks(question, reply_input, reply_target):\n",
    "    \n",
    "    def subsequent_mask(size):\n",
    "        mask = torch.triu(torch.ones(size, size)).transpose(0, 1).type(dtype=torch.uint8)\n",
    "        return mask.unsqueeze(0)\n",
    "    \n",
    "    question_mask = question!=0\n",
    "    question_mask = question_mask.to(device)\n",
    "    question_mask = question_mask.unsqueeze(1).unsqueeze(1)         # (batch_size, 1, 1, max_words)\n",
    "     \n",
    "    reply_input_mask = reply_input!=0\n",
    "    reply_input_mask = reply_input_mask.unsqueeze(1)  # (batch_size, 1, max_words)\n",
    "    reply_input_mask = reply_input_mask & subsequent_mask(reply_input.size(-1)).type_as(reply_input_mask.data) \n",
    "    reply_input_mask = reply_input_mask.unsqueeze(1) # (batch_size, 1, max_words, max_words)\n",
    "    reply_target_mask = reply_target!=0              # (batch_size, max_words)\n",
    "    \n",
    "    return question_mask, reply_input_mask, reply_target_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T20:17:33.390611Z",
     "iopub.status.busy": "2024-07-02T20:17:33.390255Z",
     "iopub.status.idle": "2024-07-02T20:17:33.397673Z",
     "shell.execute_reply": "2024-07-02T20:17:33.396839Z",
     "shell.execute_reply.started": "2024-07-02T20:17:33.390578Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def create_directory(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "        print(f\"Directory created at {path}\")\n",
    "    else:\n",
    "        print(f\"Directory already exists at {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T20:17:33.399270Z",
     "iopub.status.busy": "2024-07-02T20:17:33.398914Z",
     "iopub.status.idle": "2024-07-02T20:17:33.421634Z",
     "shell.execute_reply": "2024-07-02T20:17:33.420718Z",
     "shell.execute_reply.started": "2024-07-02T20:17:33.399239Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Embeddings(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements embeddings of the words and adds their positional encodings. \n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, d_model, max_len = 50, num_layers = 6):\n",
    "        super(Embeddings, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.embed = nn.Embedding(vocab_size, d_model)\n",
    "        self.pe = self.create_positinal_encoding(max_len, self.d_model)     # (1, max_len, d_model)\n",
    "        self.te = self.create_positinal_encoding(num_layers, self.d_model)  # (1, num_layers, d_model)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "    def create_positinal_encoding(self, max_len, d_model):\n",
    "        pe = torch.zeros(max_len, d_model).to(device)\n",
    "        for pos in range(max_len):   # for each position of the word\n",
    "            for i in range(0, d_model, 2):   # for each dimension of the each position\n",
    "                pe[pos, i] = math.sin(pos / (10000 ** ((2 * i)/d_model)))\n",
    "                pe[pos, i + 1] = math.cos(pos / (10000 ** ((2 * (i + 1))/d_model)))\n",
    "        pe = pe.unsqueeze(0)   # include the batch size\n",
    "        return pe\n",
    "        \n",
    "    def forward(self, embedding, layer_idx):\n",
    "        if layer_idx == 0:\n",
    "            embedding = self.embed(embedding) * math.sqrt(self.d_model)\n",
    "        embedding += self.pe[:, :embedding.size(1)]   # pe will automatically be expanded with the same batch size as encoded_words\n",
    "        # embedding: (batch_size, max_len, d_model), te: (batch_size, 1, d_model)\n",
    "        embedding += self.te[:, layer_idx, :].unsqueeze(1).repeat(1, embedding.size(1), 1)\n",
    "        embedding = self.dropout(embedding)\n",
    "        return embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T20:17:33.423711Z",
     "iopub.status.busy": "2024-07-02T20:17:33.423056Z",
     "iopub.status.idle": "2024-07-02T20:17:33.435766Z",
     "shell.execute_reply": "2024-07-02T20:17:33.435028Z",
     "shell.execute_reply.started": "2024-07-02T20:17:33.423675Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self, heads, d_model):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        assert d_model % heads == 0\n",
    "        self.d_k = d_model // heads\n",
    "        self.heads = heads\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.query = nn.Linear(d_model, d_model)\n",
    "        self.key = nn.Linear(d_model, d_model)\n",
    "        self.value = nn.Linear(d_model, d_model)\n",
    "        self.concat = nn.Linear(d_model, d_model)\n",
    "        \n",
    "    def forward(self, query, key, value, mask):\n",
    "        \"\"\"\n",
    "        query, key, value of shape: (batch_size, max_len, 512)\n",
    "        mask of shape: (batch_size, 1, 1, max_words)\n",
    "        \"\"\"\n",
    "        # (batch_size, max_len, 512)\n",
    "        query = self.query(query)\n",
    "        key = self.key(key)        \n",
    "        value = self.value(value)   \n",
    "        \n",
    "        # (batch_size, max_len, 512) --> (batch_size, max_len, h, d_k) --> (batch_size, h, max_len, d_k)\n",
    "        query = query.view(query.shape[0], -1, self.heads, self.d_k).permute(0, 2, 1, 3)   \n",
    "        key = key.view(key.shape[0], -1, self.heads, self.d_k).permute(0, 2, 1, 3)  \n",
    "        value = value.view(value.shape[0], -1, self.heads, self.d_k).permute(0, 2, 1, 3)  \n",
    "        \n",
    "        # (batch_size, h, max_len, d_k) matmul (batch_size, h, d_k, max_len) --> (batch_size, h, max_len, max_len)\n",
    "        scores = torch.matmul(query, key.permute(0,1,3,2)) / math.sqrt(query.size(-1))\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)    # (batch_size, h, max_len, max_len)\n",
    "        weights = F.softmax(scores, dim = -1)           # (batch_size, h, max_len, max_len)\n",
    "        weights = self.dropout(weights)\n",
    "        # (batch_size, h, max_len, max_len) matmul (batch_size, h, max_len, d_k) --> (batch_size, h, max_len, d_k)\n",
    "        context = torch.matmul(weights, value)\n",
    "        # (batch_size, h, max_len, d_k) --> (batch_size, max_len, h, d_k) --> (batch_size, max_len, h * d_k)\n",
    "        context = context.permute(0,2,1,3).contiguous().view(context.shape[0], -1, self.heads * self.d_k)\n",
    "        # (batch_size, max_len, h * d_k)\n",
    "        interacted = self.concat(context)\n",
    "        return interacted "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed Forward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T20:17:33.437331Z",
     "iopub.status.busy": "2024-07-02T20:17:33.437039Z",
     "iopub.status.idle": "2024-07-02T20:17:33.450588Z",
     "shell.execute_reply": "2024-07-02T20:17:33.449684Z",
     "shell.execute_reply.started": "2024-07-02T20:17:33.437306Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, middle_dim = 2048):\n",
    "        super(FeedForward, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(d_model, middle_dim)\n",
    "        self.fc2 = nn.Linear(middle_dim, d_model)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.fc1(x))\n",
    "        out = self.fc2(self.dropout(out))\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T20:17:33.452046Z",
     "iopub.status.busy": "2024-07-02T20:17:33.451709Z",
     "iopub.status.idle": "2024-07-02T20:17:33.461741Z",
     "shell.execute_reply": "2024-07-02T20:17:33.460847Z",
     "shell.execute_reply.started": "2024-07-02T20:17:33.452019Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, heads):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.layernorm = nn.LayerNorm(d_model)\n",
    "        self.self_multihead = MultiHeadAttention(heads, d_model)\n",
    "        self.feed_forward = FeedForward(d_model)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, embeddings, mask):\n",
    "        interacted = self.dropout(self.self_multihead(embeddings, embeddings, embeddings, mask))\n",
    "        interacted = self.layernorm(interacted + embeddings)\n",
    "        feed_forward_out = self.dropout(self.feed_forward(interacted))\n",
    "        encoded = self.layernorm(feed_forward_out + interacted)\n",
    "        return encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T20:17:33.463365Z",
     "iopub.status.busy": "2024-07-02T20:17:33.463025Z",
     "iopub.status.idle": "2024-07-02T20:17:33.475859Z",
     "shell.execute_reply": "2024-07-02T20:17:33.475008Z",
     "shell.execute_reply.started": "2024-07-02T20:17:33.463339Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_model, heads):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.layernorm = nn.LayerNorm(d_model)\n",
    "        self.self_multihead = MultiHeadAttention(heads, d_model)\n",
    "        self.src_multihead = MultiHeadAttention(heads, d_model)\n",
    "        self.feed_forward = FeedForward(d_model)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "    def forward(self, embeddings, encoded, src_mask, target_mask):\n",
    "        query = self.dropout(self.self_multihead(embeddings, embeddings, embeddings, target_mask))\n",
    "        query = self.layernorm(query + embeddings)\n",
    "        interacted = self.dropout(self.src_multihead(query, encoded, encoded, src_mask))\n",
    "        interacted = self.layernorm(interacted + query)\n",
    "        feed_forward_out = self.dropout(self.feed_forward(interacted))\n",
    "        decoded = self.layernorm(feed_forward_out + interacted)\n",
    "        return decoded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T20:17:33.478079Z",
     "iopub.status.busy": "2024-07-02T20:17:33.477782Z",
     "iopub.status.idle": "2024-07-02T20:17:33.514932Z",
     "shell.execute_reply": "2024-07-02T20:17:33.514023Z",
     "shell.execute_reply.started": "2024-07-02T20:17:33.478055Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_model, heads, num_layers_enc, num_layers_dec, word_map, max_len = 50):\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.num_layers_enc = num_layers_enc\n",
    "        self.num_layers_dec = num_layers_dec\n",
    "        self.vocab_size = len(word_map)\n",
    "        self.embed_enc = Embeddings(self.vocab_size, d_model, num_layers = num_layers_enc, max_len = max_len)\n",
    "        self.embed_dec = Embeddings(self.vocab_size, d_model, num_layers = num_layers_dec, max_len = max_len)\n",
    "        self.encoder = EncoderLayer(d_model, heads) \n",
    "        self.decoder = DecoderLayer(d_model, heads)\n",
    "        self.logit = nn.Linear(d_model, self.vocab_size)\n",
    "        \n",
    "    def encode(self, src_embeddings, src_mask):\n",
    "        for i in range(self.num_layers_enc):\n",
    "            src_embeddings = self.embed_enc(src_embeddings, i)\n",
    "            src_embeddings = self.encoder(src_embeddings, src_mask)\n",
    "        return src_embeddings\n",
    "    \n",
    "    def decode(self, tgt_embeddings, target_mask, src_embeddings, src_mask):\n",
    "        for i in range(self.num_layers_enc):\n",
    "            tgt_embeddings = self.embed_enc(tgt_embeddings, i)\n",
    "            tgt_embeddings = self.decoder(tgt_embeddings, src_embeddings, src_mask, target_mask)\n",
    "        return tgt_embeddings\n",
    "        \n",
    "    def forward(self, src_words, src_mask, target_words, target_mask):\n",
    "        encoded = self.encode(src_words, src_mask)\n",
    "        decoded = self.decode(target_words, target_mask, encoded, src_mask)\n",
    "        out = F.log_softmax(self.logit(decoded), dim = 2)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T20:17:33.516425Z",
     "iopub.status.busy": "2024-07-02T20:17:33.516094Z",
     "iopub.status.idle": "2024-07-02T20:17:33.527522Z",
     "shell.execute_reply": "2024-07-02T20:17:33.526734Z",
     "shell.execute_reply.started": "2024-07-02T20:17:33.516394Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class AdamWarmup:\n",
    "    \n",
    "    def __init__(self, model_size, warmup_steps, optimizer):\n",
    "        \n",
    "        self.model_size = model_size\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.optimizer = optimizer\n",
    "        self.current_step = 0\n",
    "        self.lr = 0\n",
    "        \n",
    "    def get_lr(self):\n",
    "        return self.model_size ** (-0.5) * min(self.current_step ** (-0.5), self.current_step * self.warmup_steps ** (-1.5))\n",
    "        \n",
    "    def step(self):\n",
    "        # Increment the number of steps each time we call the step function\n",
    "        self.current_step += 1\n",
    "        lr = self.get_lr()\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "        # update the learning rate\n",
    "        self.lr = lr\n",
    "        self.optimizer.step()       \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T20:17:33.529363Z",
     "iopub.status.busy": "2024-07-02T20:17:33.528622Z",
     "iopub.status.idle": "2024-07-02T20:17:33.540886Z",
     "shell.execute_reply": "2024-07-02T20:17:33.540153Z",
     "shell.execute_reply.started": "2024-07-02T20:17:33.529331Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class LossWithLS(nn.Module):\n",
    "\n",
    "    def __init__(self, size, smooth):\n",
    "        super(LossWithLS, self).__init__()\n",
    "        self.criterion = nn.KLDivLoss(size_average=False, reduce=False)\n",
    "        self.confidence = 1.0 - smooth\n",
    "        self.smooth = smooth\n",
    "        self.size = size\n",
    "        \n",
    "    def forward(self, prediction, target, mask):\n",
    "        \"\"\"\n",
    "        prediction of shape: (batch_size, max_words, vocab_size)\n",
    "        target and mask of shape: (batch_size, max_words)\n",
    "        \"\"\"\n",
    "        prediction = prediction.view(-1, prediction.size(-1))   # (batch_size * max_words, vocab_size)\n",
    "        target = target.contiguous().view(-1)   # (batch_size * max_words)\n",
    "        mask = mask.float()\n",
    "        mask = mask.view(-1)       # (batch_size * max_words)\n",
    "        labels = prediction.data.clone()\n",
    "        labels.fill_(self.smooth / (self.size - 1))\n",
    "        labels.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        loss = self.criterion(prediction, labels)    # (batch_size * max_words, vocab_size)\n",
    "        loss = (loss.sum(1) * mask).sum() / mask.sum()\n",
    "        return loss\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Neptune Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T20:17:33.542496Z",
     "iopub.status.busy": "2024-07-02T20:17:33.542228Z",
     "iopub.status.idle": "2024-07-02T20:17:33.550662Z",
     "shell.execute_reply": "2024-07-02T20:17:33.549840Z",
     "shell.execute_reply.started": "2024-07-02T20:17:33.542473Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "project = \"andialifs/siet-24\"\n",
    "api_token = \"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJjZTY2YWQ3My04OTBkLTQ2OWUtYTc1Ni1jYjk0MGZhMWFiNGEifQ==\"\n",
    "\n",
    "def neptune_init(name):\n",
    "    run = neptune.init_run(\n",
    "        project=project,\n",
    "        api_token=api_token,\n",
    "        name=name\n",
    "    )\n",
    "    return run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T20:17:33.564996Z",
     "iopub.status.busy": "2024-07-02T20:17:33.564656Z",
     "iopub.status.idle": "2024-07-02T20:17:33.574590Z",
     "shell.execute_reply": "2024-07-02T20:17:33.573653Z",
     "shell.execute_reply.started": "2024-07-02T20:17:33.564947Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train(train_loader, transformer, criterion, epoch):\n",
    "    transformer.train()\n",
    "    sum_loss = 0\n",
    "    count = 0\n",
    "\n",
    "    for i, (question, reply) in enumerate(train_loader):\n",
    "        \n",
    "        samples = question.shape[0]\n",
    "\n",
    "        # Move to device\n",
    "        question = question.to(device)\n",
    "        reply = reply.to(device)\n",
    "\n",
    "        # Prepare Target Data\n",
    "        reply_input = reply[:, :-1]\n",
    "        reply_target = reply[:, 1:]\n",
    "\n",
    "        # Create mask and add dimensions\n",
    "        question_mask, reply_input_mask, reply_target_mask = create_masks(question, reply_input, reply_target)\n",
    "\n",
    "        # Get the transformer outputs\n",
    "        out = transformer(question, question_mask, reply_input, reply_input_mask)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(out, reply_target, reply_target_mask)\n",
    "        \n",
    "        # Backprop\n",
    "        transformer_optimizer.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        transformer_optimizer.step()\n",
    "        \n",
    "        sum_loss += loss.item() * samples\n",
    "        count += samples\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(\"Epoch [{}][{}/{}]\\tLoss: {:.3f}\".format(epoch, i, len(train_loader), sum_loss/count))\n",
    "    \n",
    "    return sum_loss/count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T20:17:33.576127Z",
     "iopub.status.busy": "2024-07-02T20:17:33.575799Z",
     "iopub.status.idle": "2024-07-02T20:17:33.587390Z",
     "shell.execute_reply": "2024-07-02T20:17:33.586545Z",
     "shell.execute_reply.started": "2024-07-02T20:17:33.576103Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate(transformer, question, question_mask, max_len, word_map):\n",
    "    \"\"\"\n",
    "    Performs Greedy Decoding with a batch size of 1\n",
    "    \"\"\"\n",
    "    rev_word_map = {v: k for k, v in word_map.items()}\n",
    "    transformer.eval()\n",
    "    start_token = word_map['<start>']\n",
    "    encoded = transformer.encode(question, question_mask)\n",
    "    words = torch.LongTensor([[start_token]]).to(device)\n",
    "    \n",
    "    for step in range(max_len - 1):\n",
    "        size = words.shape[1]\n",
    "        target_mask = torch.triu(torch.ones(size, size)).transpose(0, 1).type(dtype=torch.uint8)\n",
    "        target_mask = target_mask.to(device).unsqueeze(0).unsqueeze(0)\n",
    "        decoded = transformer.decode(words, target_mask, encoded, question_mask)\n",
    "        predictions = transformer.logit(decoded[:, -1])\n",
    "        _, next_word = torch.max(predictions, dim = 1)\n",
    "        next_word = next_word.item()\n",
    "        if next_word == word_map['<end>']:\n",
    "            break\n",
    "        words = torch.cat([words, torch.LongTensor([[next_word]]).to(device)], dim = 1)   # (1,step+2)\n",
    "        \n",
    "    # Construct Sentence\n",
    "    if words.dim() == 2:\n",
    "        words = words.squeeze(0)\n",
    "        words = words.tolist()\n",
    "        \n",
    "    sen_idx = [w for w in words if w not in {word_map['<start>']}]\n",
    "    sentence = ' '.join([rev_word_map[sen_idx[k]] for k in range(len(sen_idx))])\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "def calculate_bleu(preds, questions, answers):\n",
    "    bleu_score_1 = 0\n",
    "    bleu_score_2 = 0\n",
    "    bleu_score_3 = 0\n",
    "    bleu_score_4 = 0\n",
    "    bleu_score_all = 0\n",
    "\n",
    "    num_of_rows_calculated = 0\n",
    "\n",
    "    for i, (question, real_answer) in enumerate(zip(questions, answers)):\n",
    "        # print(f\"Question: {question}\")\n",
    "        # print(f\"Real Answer: {real_answer}\")\n",
    "        # print(f\"Predicted Answer: {preds[i]}\")\n",
    "        try:\n",
    "            refs = [real_answer.split(' ')]\n",
    "            hyp = preds[i].split(' ')\n",
    "\n",
    "            bleu_score_1 += sentence_bleu(refs, hyp, weights=(1,0,0,0))\n",
    "            bleu_score_2 += sentence_bleu(refs, hyp, weights=(0,1,0,0))\n",
    "            bleu_score_3 += sentence_bleu(refs, hyp, weights=(0,0,1,0))\n",
    "            bleu_score_4 += sentence_bleu(refs, hyp, weights=(0,0,0,1))\n",
    "            bleu_score_all += sentence_bleu(refs, hyp, weights=(.25,.25,.25,.25))\n",
    "\n",
    "            num_of_rows_calculated+=1\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    results = {\"1-gram\": (bleu_score_1/num_of_rows_calculated),\n",
    "                \"2-gram\": (bleu_score_2/num_of_rows_calculated),\n",
    "                \"3-gram\": (bleu_score_3/num_of_rows_calculated),\n",
    "                \"4-gram\": (bleu_score_all/num_of_rows_calculated)}\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "knowledgebase_url_test = 'https://github.com/AndiAlifs/FLUENT-Chatbot-2023/raw/main/KnowledgeBaseFilkom_eval.xlsx'\n",
    "knowledgebase_test = pd.read_excel(knowledgebase_url_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pertanyaan</th>\n",
       "      <th>Labels</th>\n",
       "      <th>Jawaban</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apa visi fakultas</td>\n",
       "      <td>visi</td>\n",
       "      <td>menjadi fakultas yang berdaya saing internasio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>visi dari filkom</td>\n",
       "      <td>visi</td>\n",
       "      <td>menjadi fakultas yang berdaya saing internasio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>apa saja visi filkom</td>\n",
       "      <td>visi</td>\n",
       "      <td>menjadi fakultas yang berdaya saing internasio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>apa misi fakultas</td>\n",
       "      <td>misi</td>\n",
       "      <td>menyelenggarakan pendidikan di bidang teknolog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>apa saja misi flkom</td>\n",
       "      <td>misi</td>\n",
       "      <td>menyelenggarakan pendidikan di bidang teknolog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>dapatkah anda memberi tahu siapa konselor bimb...</td>\n",
       "      <td>other</td>\n",
       "      <td>ada 2 konselor bimbingan dan konseling di filk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>siapa yang menjadi koordinator konselor sebaya?</td>\n",
       "      <td>other</td>\n",
       "      <td>koordinator konselor sebaya adalah muhammad da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>siapa koordinator untuk konselor sebaya?</td>\n",
       "      <td>other</td>\n",
       "      <td>koordinator konselor sebaya adalah muhammad da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>mohon rincian mengenai layanan ultksp.</td>\n",
       "      <td>other</td>\n",
       "      <td>rincian layanan ultksp dapat diakses pada taut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>berikan rincian layanan ultksp</td>\n",
       "      <td>other</td>\n",
       "      <td>rincian layanan ultksp dapat diakses pada taut...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Pertanyaan Labels  \\\n",
       "0                                   apa visi fakultas   visi   \n",
       "1                                    visi dari filkom   visi   \n",
       "2                                apa saja visi filkom   visi   \n",
       "3                                   apa misi fakultas   misi   \n",
       "4                                 apa saja misi flkom   misi   \n",
       "..                                                ...    ...   \n",
       "86  dapatkah anda memberi tahu siapa konselor bimb...  other   \n",
       "87    siapa yang menjadi koordinator konselor sebaya?  other   \n",
       "88           siapa koordinator untuk konselor sebaya?  other   \n",
       "89             mohon rincian mengenai layanan ultksp.  other   \n",
       "90                     berikan rincian layanan ultksp  other   \n",
       "\n",
       "                                              Jawaban  \n",
       "0   menjadi fakultas yang berdaya saing internasio...  \n",
       "1   menjadi fakultas yang berdaya saing internasio...  \n",
       "2   menjadi fakultas yang berdaya saing internasio...  \n",
       "3   menyelenggarakan pendidikan di bidang teknolog...  \n",
       "4   menyelenggarakan pendidikan di bidang teknolog...  \n",
       "..                                                ...  \n",
       "86  ada 2 konselor bimbingan dan konseling di filk...  \n",
       "87  koordinator konselor sebaya adalah muhammad da...  \n",
       "88  koordinator konselor sebaya adalah muhammad da...  \n",
       "89  rincian layanan ultksp dapat diakses pada taut...  \n",
       "90  rincian layanan ultksp dapat diakses pada taut...  \n",
       "\n",
       "[91 rows x 3 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knowledgebase_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "truncated_real_answers = []\n",
    "for i in list(tests['Jawaban']):\n",
    "    cleaned = remove_punc(i)\n",
    "    splited = cleaned.split()\n",
    "    truncated_real_answers.append(' '.join(splited[:50]))\n",
    "\n",
    "real_questions = list(tests['Pertanyaan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['menjadi fakultas yang berdaya saing internasional dan berkontribusi kepada pengembangan teknologi informasi dan ilmu komputer untuk menunjang industri dan masyarakat dengan menyelaraskan pelaksanaan pendidikan penelitian dan pengabdian kepada masyarakat',\n",
       " 'menjadi fakultas yang berdaya saing internasional dan berkontribusi kepada pengembangan teknologi informasi dan ilmu komputer untuk menunjang industri dan masyarakat dengan menyelaraskan pelaksanaan pendidikan penelitian dan pengabdian kepada masyarakat',\n",
       " 'menjadi fakultas yang berdaya saing internasional dan berkontribusi kepada pengembangan teknologi informasi dan ilmu komputer untuk menunjang industri dan masyarakat dengan menyelaraskan pelaksanaan pendidikan penelitian dan pengabdian kepada masyarakat',\n",
       " 'menyelenggarakan pendidikan di bidang teknologi informasi dan ilmu komputer yang berkualitas dan berstandar internasional secara berkelanjutan meningkatkan kemampuan sivitas akademika dalam pengembangan penelitian dan pengabdian yang selaras dengan kebutuhan industri dan masyarakat mengintegrasikan pengembangan pendidikan penelitian dan pengabdian kepada masyarakat yang ditunjang dengan tatakelola organisasi yang transparan akuntabel efektif dan',\n",
       " 'menyelenggarakan pendidikan di bidang teknologi informasi dan ilmu komputer yang berkualitas dan berstandar internasional secara berkelanjutan meningkatkan kemampuan sivitas akademika dalam pengembangan penelitian dan pengabdian yang selaras dengan kebutuhan industri dan masyarakat mengintegrasikan pengembangan pendidikan penelitian dan pengabdian kepada masyarakat yang ditunjang dengan tatakelola organisasi yang transparan akuntabel efektif dan',\n",
       " 'menyelenggarakan pendidikan di bidang teknologi informasi dan ilmu komputer yang berkualitas dan berstandar internasional secara berkelanjutan meningkatkan kemampuan sivitas akademika dalam pengembangan penelitian dan pengabdian yang selaras dengan kebutuhan industri dan masyarakat mengintegrasikan pengembangan pendidikan penelitian dan pengabdian kepada masyarakat yang ditunjang dengan tatakelola organisasi yang transparan akuntabel efektif dan',\n",
       " 'menghasilkan lulusan yang kompeten profesional berbudi pekerti luhur berjiwa entrepreneur dan berdaya saing internasional menghasilkan sivitas akademika yang mampu mengembangkan penelitiandan pengabdian yang berorientasi pada pembaruan dan teknologi tepat guna untuk industri dan masyarakat terwujudnya suasana akademik yang kondusif dalam bidang pendidikan penelitian dan pengabdian kepada masyarakat yang berdaya saing',\n",
       " 'menghasilkan lulusan yang kompeten profesional berbudi pekerti luhur berjiwa entrepreneur dan berdaya saing internasional menghasilkan sivitas akademika yang mampu mengembangkan penelitiandan pengabdian yang berorientasi pada pembaruan dan teknologi tepat guna untuk industri dan masyarakat terwujudnya suasana akademik yang kondusif dalam bidang pendidikan penelitian dan pengabdian kepada masyarakat yang berdaya saing',\n",
       " 'meningkatkan kompetensi dan kualifikasi pendidikan dosen meningkatkan sarana dan prasarana pembelajaran mengembangkan kurikulum mengkuti perkembangan dan kebutuhan pemangku kepentingan meningkatkan mutu lulusan yang berkualitas mempercepat masa studi meningkatkan kompetensi lulusan tersertifikasi bidang tik meningkatkan prestasi mahasiswa meningkatkan mutu kelembagaan',\n",
       " 'fitrabachtiaratubacid']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truncated_real_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu_scores_all = pd.DataFrame(\n",
    "    columns=[\"experiment_name\", \"1-gram\", \"2-gram\", \"3-gram\", \"4-gram\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_24.pth.tar\n",
      "generating all_response for experiment_24\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_24 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_25.pth.tar\n",
      "generating all_response for experiment_25\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_25 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_26.pth.tar\n",
      "generating all_response for experiment_26\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_26 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_27.pth.tar\n",
      "generating all_response for experiment_27\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_27 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_28.pth.tar\n",
      "generating all_response for experiment_28\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_28 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_29.pth.tar\n",
      "generating all_response for experiment_29\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_29 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_30.pth.tar\n",
      "generating all_response for experiment_30\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_30 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_31.pth.tar\n",
      "generating all_response for experiment_31\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_31 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_32.pth.tar\n",
      "generating all_response for experiment_32\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_32 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_33.pth.tar\n",
      "generating all_response for experiment_33\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_33 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_34.pth.tar\n",
      "generating all_response for experiment_34\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_34 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_35.pth.tar\n",
      "generating all_response for experiment_35\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_35 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_36.pth.tar\n",
      "generating all_response for experiment_36\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_36 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_37.pth.tar\n",
      "generating all_response for experiment_37\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_37 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_38.pth.tar\n",
      "generating all_response for experiment_38\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_38 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_39.pth.tar\n",
      "generating all_response for experiment_39\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_39 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_40.pth.tar\n",
      "generating all_response for experiment_40\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_40 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_41.pth.tar\n",
      "generating all_response for experiment_41\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_41 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_42.pth.tar\n",
      "generating all_response for experiment_42\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_42 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_43.pth.tar\n",
      "generating all_response for experiment_43\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_43 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_44.pth.tar\n",
      "generating all_response for experiment_44\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_44 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_45.pth.tar\n",
      "generating all_response for experiment_45\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_45 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_46.pth.tar\n",
      "generating all_response for experiment_46\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_46 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_47.pth.tar\n",
      "generating all_response for experiment_47\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_47 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_48.pth.tar\n",
      "generating all_response for experiment_48\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_48 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_49.pth.tar\n",
      "generating all_response for experiment_49\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_49 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_50.pth.tar\n",
      "generating all_response for experiment_50\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_50 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_51.pth.tar\n",
      "generating all_response for experiment_51\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_51 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_52.pth.tar\n",
      "generating all_response for experiment_52\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_52 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_53.pth.tar\n",
      "generating all_response for experiment_53\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_53 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_54.pth.tar\n",
      "generating all_response for experiment_54\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_54 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_55.pth.tar\n",
      "generating all_response for experiment_55\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_55 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_56.pth.tar\n",
      "generating all_response for experiment_56\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_56 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_57.pth.tar\n",
      "generating all_response for experiment_57\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_57 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_58.pth.tar\n",
      "generating all_response for experiment_58\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_58 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_59.pth.tar\n",
      "generating all_response for experiment_59\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_59 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_60.pth.tar\n",
      "generating all_response for experiment_60\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_60 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_61.pth.tar\n",
      "generating all_response for experiment_61\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_61 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_62.pth.tar\n",
      "generating all_response for experiment_62\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_62 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_63.pth.tar\n",
      "generating all_response for experiment_63\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_63 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_64.pth.tar\n",
      "generating all_response for experiment_64\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_64 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_65.pth.tar\n",
      "generating all_response for experiment_65\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_65 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_66.pth.tar\n",
      "generating all_response for experiment_66\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_66 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_67.pth.tar\n",
      "generating all_response for experiment_67\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_67 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_68.pth.tar\n",
      "generating all_response for experiment_68\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_68 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_69.pth.tar\n",
      "generating all_response for experiment_69\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_69 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_70.pth.tar\n",
      "generating all_response for experiment_70\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_70 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_71.pth.tar\n",
      "generating all_response for experiment_71\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_71 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_72.pth.tar\n",
      "generating all_response for experiment_72\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_72 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_73.pth.tar\n",
      "generating all_response for experiment_73\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_73 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_74.pth.tar\n",
      "generating all_response for experiment_74\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_74 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_75.pth.tar\n",
      "generating all_response for experiment_75\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_75 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_76.pth.tar\n",
      "generating all_response for experiment_76\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_76 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_77.pth.tar\n",
      "generating all_response for experiment_77\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_77 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_78.pth.tar\n",
      "generating all_response for experiment_78\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_78 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_79.pth.tar\n",
      "generating all_response for experiment_79\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_79 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_80.pth.tar\n",
      "generating all_response for experiment_80\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_80 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_81.pth.tar\n",
      "generating all_response for experiment_81\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_81 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_82.pth.tar\n",
      "generating all_response for experiment_82\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_82 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_83.pth.tar\n",
      "generating all_response for experiment_83\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_83 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_84.pth.tar\n",
      "generating all_response for experiment_84\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_84 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_85.pth.tar\n",
      "generating all_response for experiment_85\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_85 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_86.pth.tar\n",
      "generating all_response for experiment_86\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_86 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_87.pth.tar\n",
      "generating all_response for experiment_87\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_87 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_88.pth.tar\n",
      "generating all_response for experiment_88\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_88 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_89.pth.tar\n",
      "generating all_response for experiment_89\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_89 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_90.pth.tar\n",
      "generating all_response for experiment_90\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_90 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_91.pth.tar\n",
      "generating all_response for experiment_91\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_91 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_92.pth.tar\n",
      "generating all_response for experiment_92\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_92 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_93.pth.tar\n",
      "generating all_response for experiment_93\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_93 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_94.pth.tar\n",
      "generating all_response for experiment_94\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_94 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_95.pth.tar\n",
      "generating all_response for experiment_95\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_95 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_96.pth.tar\n",
      "generating all_response for experiment_96\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_96 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_97.pth.tar\n",
      "generating all_response for experiment_97\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_97 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_98.pth.tar\n",
      "generating all_response for experiment_98\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_98 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_99.pth.tar\n",
      "generating all_response for experiment_99\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_99 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_100.pth.tar\n",
      "generating all_response for experiment_100\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_100 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_101.pth.tar\n",
      "generating all_response for experiment_101\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_101 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_102.pth.tar\n",
      "generating all_response for experiment_102\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_102 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_103.pth.tar\n",
      "generating all_response for experiment_103\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_103 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_104.pth.tar\n",
      "generating all_response for experiment_104\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_104 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_105.pth.tar\n",
      "generating all_response for experiment_105\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_105 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_106.pth.tar\n",
      "generating all_response for experiment_106\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_106 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_107.pth.tar\n",
      "generating all_response for experiment_107\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_107 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_108.pth.tar\n",
      "generating all_response for experiment_108\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_108 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_109.pth.tar\n",
      "generating all_response for experiment_109\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_109 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_110.pth.tar\n",
      "generating all_response for experiment_110\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_110 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_111.pth.tar\n",
      "generating all_response for experiment_111\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_111 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_112.pth.tar\n",
      "generating all_response for experiment_112\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_112 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_113.pth.tar\n",
      "generating all_response for experiment_113\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_113 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_114.pth.tar\n",
      "generating all_response for experiment_114\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_114 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_115.pth.tar\n",
      "generating all_response for experiment_115\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_115 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_116.pth.tar\n",
      "generating all_response for experiment_116\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_116 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_117.pth.tar\n",
      "generating all_response for experiment_117\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_117 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_118.pth.tar\n",
      "generating all_response for experiment_118\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_118 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_119.pth.tar\n",
      "generating all_response for experiment_119\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_119 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_120.pth.tar\n",
      "generating all_response for experiment_120\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_120 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_121.pth.tar\n",
      "generating all_response for experiment_121\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_121 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_122.pth.tar\n",
      "generating all_response for experiment_122\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_122 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_123.pth.tar\n",
      "generating all_response for experiment_123\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_123 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_124.pth.tar\n",
      "generating all_response for experiment_124\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_124 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_125.pth.tar\n",
      "generating all_response for experiment_125\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_125 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_126.pth.tar\n",
      "generating all_response for experiment_126\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_126 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_127.pth.tar\n",
      "generating all_response for experiment_127\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_127 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_128.pth.tar\n",
      "generating all_response for experiment_128\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_128 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_129.pth.tar\n",
      "generating all_response for experiment_129\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_129 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_130.pth.tar\n",
      "generating all_response for experiment_130\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_130 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_131.pth.tar\n",
      "generating all_response for experiment_131\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_131 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_132.pth.tar\n",
      "generating all_response for experiment_132\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_132 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_133.pth.tar\n",
      "generating all_response for experiment_133\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_133 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_134.pth.tar\n",
      "generating all_response for experiment_134\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_134 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_135.pth.tar\n",
      "generating all_response for experiment_135\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_135 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_136.pth.tar\n",
      "generating all_response for experiment_136\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_136 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from experiment_137.pth.tar\n",
      "generating all_response for experiment_137\n",
      "finish generating all_response for experiment_{ix}\n",
      "BLEU Scores for experiment_137 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/tmp/ipykernel_2069878/598199919.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bleu_scores_all = bleu_scores_all.append({\n"
     ]
    }
   ],
   "source": [
    "for ix in range(24,138):\n",
    "    saved_model_path = f\"/home/andyalyfsyah/experiment_siet24_288/experiment_{ix}.pth.tar\"\n",
    "    checkpoint = torch.load(saved_model_path)\n",
    "    transformer = checkpoint['transformer']\n",
    "    print(f\"\\nModel loaded from experiment_{ix}.pth.tar\")\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    transformer.to(device)\n",
    "\n",
    "    all_response = []\n",
    "    print(f\"generating all_response for experiment_{ix}\")\n",
    "    for q in real_questions:\n",
    "        question = q\n",
    "        # print('\\n'+question)\n",
    "        max_len = 50\n",
    "        enc_qus = [word_map.get(word, word_map['<unk>']) for word in question.split()]\n",
    "        question = torch.LongTensor(enc_qus).to(device).unsqueeze(0)\n",
    "        question_mask = (question!=0).to(device).unsqueeze(1).unsqueeze(1)  \n",
    "        sentence = evaluate(transformer, question, question_mask, int(max_len), word_map)\n",
    "        # print(sentence)\n",
    "        all_response.append(sentence)\n",
    "    print(\"finish generating all_response for experiment_{ix}\")\n",
    "\n",
    "    bleu_scores = calculate_bleu(all_response, real_questions, truncated_real_answers)\n",
    "\n",
    "    bleu_scores_all = bleu_scores_all.append({\n",
    "        \"experiment_name\": f\"experiment_{ix}\",\n",
    "        \"1-gram\": bleu_scores[\"1-gram\"],\n",
    "        \"2-gram\": bleu_scores[\"2-gram\"],\n",
    "        \"3-gram\": bleu_scores[\"3-gram\"],\n",
    "        \"4-gram\": bleu_scores[\"4-gram\"]\n",
    "    }, ignore_index=True)\n",
    "    print(f\"BLEU Scores for experiment_{ix} calculated\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu_scores_all.to_csv(\"bleu_scores_all.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    experiment_name    1-gram    2-gram    3-gram    4-gram\n",
      "0     experiment_24  0.920669  0.790903  0.770163  0.782015\n",
      "1     experiment_25  0.931911  0.818456  0.810682  0.815262\n",
      "2     experiment_26  0.871356  0.758510  0.745022  0.750883\n",
      "3     experiment_27  0.634309  0.471373  0.437171  0.451383\n",
      "4     experiment_28  0.591492  0.418977  0.377563  0.390961\n",
      "5     experiment_29  0.598911  0.418861  0.376464  0.387229\n",
      "6     experiment_30  0.706700  0.590267  0.576943  0.583581\n",
      "7     experiment_31  0.766027  0.607968  0.572834  0.594035\n",
      "8     experiment_32  0.738768  0.621266  0.613978  0.618792\n",
      "9     experiment_33  0.813790  0.703287  0.694124  0.699015\n",
      "10    experiment_34  0.943909  0.832744  0.827359  0.831197\n",
      "11    experiment_35  0.873903  0.869487  0.864883  0.866926\n",
      "12    experiment_36  0.332189  0.309546  0.285430  0.294863\n",
      "13    experiment_37  0.327926  0.139421  0.100119  0.122888\n",
      "14    experiment_38  0.390100  0.218181  0.191654  0.206341\n",
      "15    experiment_39  0.773305  0.652422  0.636368  0.644757\n",
      "16    experiment_40  0.728992  0.576090  0.530459  0.551299\n",
      "17    experiment_41  0.706188  0.539486  0.493481  0.511587\n",
      "18    experiment_42  0.837931  0.695981  0.681432  0.685526\n",
      "19    experiment_43  0.989899  0.889899  0.889899  0.889899\n",
      "20    experiment_44  0.894467  0.787144  0.785786  0.787267\n",
      "21    experiment_45  0.543110  0.383232  0.356611  0.372949\n",
      "22    experiment_46  0.512139  0.368326  0.331631  0.350146\n",
      "23    experiment_47  0.609045  0.457337  0.427647  0.434138\n",
      "24    experiment_48  0.725918  0.578651  0.546704  0.563260\n",
      "25    experiment_49  0.814433  0.671186  0.649168  0.665128\n",
      "26    experiment_50  0.639028  0.494721  0.466697  0.474186\n",
      "27    experiment_51  0.985900  0.881734  0.877391  0.879408\n",
      "28    experiment_52  0.989899  0.889899  0.889899  0.889899\n",
      "29    experiment_53  0.989899  0.889899  0.889899  0.889899\n",
      "30    experiment_54  0.534773  0.390474  0.358665  0.366882\n",
      "31    experiment_55  0.593845  0.410730  0.375287  0.384674\n",
      "32    experiment_56  0.593940  0.442930  0.408373  0.422118\n",
      "33    experiment_57  0.685847  0.581108  0.575657  0.577378\n",
      "34    experiment_58  0.712801  0.587527  0.571073  0.579758\n",
      "35    experiment_59  0.635431  0.504109  0.483419  0.495162\n",
      "36    experiment_60  0.944437  0.839608  0.838064  0.839533\n",
      "37    experiment_61  0.989899  0.887858  0.885730  0.886719\n",
      "38    experiment_62  0.953662  0.853662  0.853662  0.853662\n",
      "39    experiment_63  0.600284  0.475879  0.464406  0.471978\n",
      "40    experiment_64  0.617050  0.460447  0.427442  0.437244\n",
      "41    experiment_65  0.612572  0.460533  0.412021  0.434919\n",
      "42    experiment_66  0.822048  0.697571  0.676692  0.687630\n",
      "43    experiment_67  0.653278  0.546807  0.540294  0.542993\n",
      "44    experiment_68  0.736247  0.627586  0.616861  0.621311\n",
      "45    experiment_69  0.949663  0.845497  0.841154  0.843170\n",
      "46    experiment_70  0.989899  0.889899  0.889899  0.889899\n",
      "47    experiment_71  0.989899  0.889899  0.889899  0.889899\n",
      "48    experiment_72  0.488889  0.306671  0.267032  0.291163\n",
      "49    experiment_73  0.417943  0.226705  0.173913  0.198733\n",
      "50    experiment_74  0.470748  0.304611  0.243593  0.255205\n",
      "51    experiment_75  0.719387  0.556630  0.525957  0.545565\n",
      "52    experiment_76  0.704489  0.570664  0.556704  0.565508\n",
      "53    experiment_77  0.764718  0.599465  0.580948  0.590101\n",
      "54    experiment_78  0.888859  0.786485  0.784224  0.785188\n",
      "55    experiment_79  0.989899  0.889899  0.889899  0.889899\n",
      "56    experiment_80  0.920147  0.815809  0.812530  0.814453\n",
      "57    experiment_81  0.502655  0.360607  0.325660  0.340736\n",
      "58    experiment_82  0.516487  0.383403  0.358197  0.369227\n",
      "59    experiment_83  0.421434  0.269189  0.235580  0.251626\n",
      "60    experiment_84  0.585666  0.472834  0.459397  0.456397\n",
      "61    experiment_85  0.765851  0.609430  0.579321  0.585987\n",
      "62    experiment_86  0.637868  0.529632  0.522604  0.525110\n",
      "63    experiment_87  0.989899  0.889899  0.889899  0.889899\n",
      "64    experiment_88  0.989899  0.889899  0.889899  0.889899\n",
      "65    experiment_89  0.899918  0.791919  0.791919  0.791919\n",
      "66    experiment_90  0.531709  0.357644  0.317517  0.342422\n",
      "67    experiment_91  0.583837  0.462878  0.450843  0.457149\n",
      "68    experiment_92  0.582877  0.422733  0.388889  0.390440\n",
      "69    experiment_93  0.706349  0.566282  0.542395  0.553441\n",
      "70    experiment_94  0.691433  0.587217  0.568857  0.575490\n",
      "71    experiment_95  0.774379  0.651928  0.640215  0.646462\n",
      "72    experiment_96  0.989899  0.889899  0.889899  0.889899\n",
      "73    experiment_97  0.989899  0.889899  0.889899  0.889899\n",
      "74    experiment_98  0.917437  0.816145  0.814769  0.815401\n",
      "75    experiment_99  0.475463  0.358202  0.350841  0.355410\n",
      "76   experiment_100  0.672934  0.527795  0.515878  0.527368\n",
      "77   experiment_101  0.631363  0.495446  0.486246  0.493919\n",
      "78   experiment_102  0.739345  0.635311  0.631026  0.632954\n",
      "79   experiment_103  0.695402  0.594817  0.593940  0.593940\n",
      "80   experiment_104  0.712778  0.590706  0.577853  0.586003\n",
      "81   experiment_105  0.989899  0.889899  0.889899  0.889899\n",
      "82   experiment_106  0.977902  0.875611  0.871137  0.872660\n",
      "83   experiment_107  0.936363  0.836181  0.829393  0.831499\n",
      "84   experiment_108  0.220842  0.155672  0.110193  0.117585\n",
      "85   experiment_109  0.339660  0.187025  0.154707  0.171604\n",
      "86   experiment_110  0.530144  0.374903  0.341432  0.357365\n",
      "87   experiment_111  0.722491  0.602774  0.586980  0.595048\n",
      "88   experiment_112  0.801566  0.668071  0.640790  0.655992\n",
      "89   experiment_113  0.886702  0.773975  0.765766  0.771466\n",
      "90   experiment_114  0.891342  0.790765  0.789899  0.789899\n",
      "91   experiment_115  0.936838  0.829483  0.826070  0.827717\n",
      "92   experiment_116  0.750316  0.746149  0.743091  0.744448\n",
      "93   experiment_117  0.443613  0.275218  0.234263  0.248935\n",
      "94   experiment_118  0.442354  0.312452  0.288086  0.297748\n",
      "95   experiment_119  0.547615  0.375655  0.321273  0.350031\n",
      "96   experiment_120  0.739179  0.623182  0.609398  0.613371\n",
      "97   experiment_121  0.793959  0.693952  0.693940  0.693940\n",
      "98   experiment_122  0.702231  0.599007  0.597687  0.598256\n",
      "99   experiment_123  0.989899  0.889899  0.889899  0.889899\n",
      "100  experiment_124  0.989899  0.889899  0.889899  0.889899\n",
      "101  experiment_125  0.888968  0.779479  0.775619  0.778734\n",
      "102  experiment_126  0.402005  0.278276  0.256697  0.265907\n",
      "103  experiment_127  0.410868  0.287211  0.270412  0.277783\n",
      "104  experiment_128  0.445281  0.305369  0.280250  0.289403\n",
      "105  experiment_129  0.755112  0.651370  0.647296  0.649071\n",
      "106  experiment_130  0.762818  0.615688  0.580903  0.595034\n",
      "107  experiment_131  0.753303  0.624772  0.608256  0.617228\n",
      "108  experiment_132  0.893018  0.763861  0.755064  0.758518\n",
      "109  experiment_133  0.989899  0.887858  0.885730  0.886719\n",
      "110  experiment_134  0.793506  0.692929  0.692063  0.692063\n",
      "111  experiment_135  0.573673  0.436212  0.403378  0.410975\n",
      "112  experiment_136  0.645975  0.498052  0.470380  0.486581\n",
      "113  experiment_137  0.751159  0.598944  0.557605  0.577592\n"
     ]
    }
   ],
   "source": [
    "# Print all rows of the dataframe\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Print all rows of the dataframe\n",
    "print(bleu_scores_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_path = f\"/home/andyalyfsyah/experiment_siet24_288/experiment_43.pth.tar\"\n",
    "checkpoint = torch.load(saved_model_path)\n",
    "transformer = checkpoint['transformer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "apa visi fakultas saya\n",
      "menjadi fakultas yang berdaya saing internasional dan berkontribusi kepada pengembangan teknologi informasi dan ilmu komputer untuk menunjang industri dan masyarakat dengan menyelaraskan pelaksanaan pendidikan penelitian dan pengabdian kepada masyarakat\n"
     ]
    }
   ],
   "source": [
    "question = \"apa visi fakultas saya\"\n",
    "print('\\n'+question)\n",
    "max_len = 50\n",
    "enc_qus = [word_map.get(word, word_map['<unk>']) for word in question.split()]\n",
    "question = torch.LongTensor(enc_qus).to(device).unsqueeze(0)\n",
    "question_mask = (question!=0).to(device).unsqueeze(1).unsqueeze(1)  \n",
    "sentence = evaluate(transformer, question, question_mask, int(max_len), word_map)\n",
    "print(sentence)\n",
    "all_response.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "apa visi filkom\n",
      "menjadi fakultas yang berdaya saing internasional dan berkontribusi kepada pengembangan teknologi informasi dan ilmu komputer untuk menunjang industri dan masyarakat dengan menyelaraskan pelaksanaan pendidikan penelitian dan pengabdian kepada masyarakat\n"
     ]
    }
   ],
   "source": [
    "question = \"apa visi filkom\"\n",
    "print('\\n'+question)\n",
    "max_len = 50\n",
    "enc_qus = [word_map.get(word, word_map['<unk>']) for word in question.split()]\n",
    "question = torch.LongTensor(enc_qus).to(device).unsqueeze(0)\n",
    "question_mask = (question!=0).to(device).unsqueeze(1).unsqueeze(1)  \n",
    "sentence = evaluate(transformer, question, question_mask, int(max_len), word_map)\n",
    "print(sentence)\n",
    "all_response.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_path = f\"/home/andyalyfsyah/experiment_siet24_288/experiment_37.pth.tar\"\n",
    "checkpoint = torch.load(saved_model_path)\n",
    "transformer = checkpoint['transformer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "apa visi fakultas saya\n",
      "menjadi program studi bereputasi internasional\n"
     ]
    }
   ],
   "source": [
    "question = \"apa visi fakultas saya\"\n",
    "print('\\n'+question)\n",
    "max_len = 50\n",
    "enc_qus = [word_map.get(word, word_map['<unk>']) for word in question.split()]\n",
    "question = torch.LongTensor(enc_qus).to(device).unsqueeze(0)\n",
    "question_mask = (question!=0).to(device).unsqueeze(1).unsqueeze(1)  \n",
    "sentence = evaluate(transformer, question, question_mask, int(max_len), word_map)\n",
    "print(sentence)\n",
    "all_response.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "apa visi filkom\n",
      "menjadi fakultas yang berdaya saing internasional dan berkontribusi kepada pengembangan teknologi informasi dan pengabdian kepada pengembangan teknologi informasi dan pengabdian kepada pengembangan teknologi informasi dan pengabdian kepada pengembangan teknologi informasi dan pengabdian kepada pengembangan teknologi informasi dan pengabdian kepada pengembangan teknologi informasi dan pengabdian kepada pengembangan teknologi informasi dan\n"
     ]
    }
   ],
   "source": [
    "question = \"apa visi filkom\"\n",
    "print('\\n'+question)\n",
    "max_len = 50\n",
    "enc_qus = [word_map.get(word, word_map['<unk>']) for word in question.split()]\n",
    "question = torch.LongTensor(enc_qus).to(device).unsqueeze(0)\n",
    "question_mask = (question!=0).to(device).unsqueeze(1).unsqueeze(1)  \n",
    "sentence = evaluate(transformer, question, question_mask, int(max_len), word_map)\n",
    "print(sentence)\n",
    "all_response.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "apa visi fakultas\n",
      "menjadi fakultas ilmu komputer untuk menunjang industri tahun\n",
      "\n",
      "visi dari filkokm\n",
      "menjadi program studi bereputasi internasional\n",
      "\n",
      "apa saja visi filkom\n",
      "menjadi fakultas ilmu komputer untuk menunjang industri dan internasional dan internasional dan internasional dan internasional dan internasional dan internasional dan internasional dan internasional dan internasional dan internasional dan internasional dan internasional dan internasional dan internasional dan internasional dan internasional dan internasional dan internasional dan internasional dan internasional dan internasional\n",
      "\n",
      "apa misi fakultas\n",
      "menyelenggarakan pendidikan dengan mengikuti perkembangan metode teknik informatika merupakan komunitas robotika penelitian lomba ilmu komputer yang berkualitas guna untuk masyarakat yang berkualitas guna untuk masyarakat yang berkualitas guna untuk masyarakat yang berkualitas guna untuk masyarakat yang berkualitas guna untuk masyarakat yang berkualitas guna untuk masyarakat yang berkualitas guna untuk\n",
      "\n",
      "apa saja misi flkom\n",
      "menyelenggarakan pendidikan dengan kebutuhan pelangganpengguna terkait penyelenggaraan pendidikan dengan kebutuhan pelangganpengguna terkait\n",
      "\n",
      "apa misi filkom\n",
      "menyelenggarakan pendidikan penelitian dan pengabdian kepada masyarakat yang berkelanjutan dalam pengembangan pendidikan penelitian dan efisien mewujudkan kerja sama yang berkelanjutan dalam bidang pendidikan penelitian dan efisien mewujudkan kerja sama yang transparan akuntabel efektif dan efisien mewujudkan kerja sama yang transparan akuntabel efektif dan efisien mewujudkan kerja sama yang transparan\n",
      "\n",
      "bagaimana tujuan filkom\n",
      "menghasilkan lulusan yang kompeten berkualitas dan pengabdian yang kompeten berkualitas dan pengabdian yang kompeten berkualitas dan pengabdian yang kompeten berkualitas dan pengabdian yang kompeten berkualitas dan pengabdian yang kompeten berkualitas dan pengabdian yang kompeten berkualitas dan pengabdian yang kompeten berkualitas dan pengabdian yang kompeten berkualitas dan pengabdian yang kompeten\n",
      "\n",
      "apa tujuan filkom\n",
      "menghasilkan lulusan yang kompeten profesional berbudi pekerti luhur berjiwa entrepreneur dan berdaya saing internasional menghasilkan sivitas akademika yang berkelanjutan di bidang pendidikan penelitian dan pengabdian yang berkelanjutan di bidang pendidikan penelitian dan pengabdian yang berkelanjutan di bidang pendidikan penelitian dan pengabdian yang berkelanjutan di bidang pendidikan penelitian dan pengabdian\n",
      "\n",
      "apa sasaran pendidikan filkom\n",
      "meningkatkan kompetensi dan kualifikasi pendidikan dosen meningkatkan sarana dan kebutuhan pemangku kepentingan meningkatkan sarana dan kebutuhan pemangku kepentingan meningkatkan sarana dan kebutuhan pemangku kepentingan meningkatkan sarana dan kebutuhan pemangku kepentingan meningkatkan sarana dan kebutuhan pemangku kepentingan meningkatkan sarana dan kebutuhan pemangku kepentingan meningkatkan sarana dan kebutuhan pemangku kepentingan meningkatkan\n",
      "\n",
      "apa email fitra a. bachtiar\n",
      "fitrabachtiaratubacid\n"
     ]
    }
   ],
   "source": [
    "all_response = []\n",
    "\n",
    "for q in real_questions:\n",
    "    question = q\n",
    "    print('\\n'+question)\n",
    "    max_len = 50\n",
    "    enc_qus = [word_map.get(word, word_map['<unk>']) for word in question.split()]\n",
    "    question = torch.LongTensor(enc_qus).to(device).unsqueeze(0)\n",
    "    question_mask = (question!=0).to(device).unsqueeze(1).unsqueeze(1)  \n",
    "    sentence = evaluate(transformer, question, question_mask, int(max_len), word_map)\n",
    "    print(sentence)\n",
    "    all_response.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use('bmh')\n",
    "plt.xlabel('BLEU Score')\n",
    "plt.ylabel('Score')\n",
    "for index, (key, value) in enumerate(bleu_scores.items()):\n",
    "    if index == len(bleu_scores.values()) - 1:\n",
    "        plt.bar(index, value, color='orange', hatch='//')\n",
    "    else:\n",
    "        plt.bar(index, value, color='orange')\n",
    "    plt.text(index, value, str(round(value, 4)))\n",
    "plt.xticks(range(len(bleu_scores)), bleu_scores.keys())\n",
    "plt.yticks(np.arange(0, 1.03, 0.2))\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_path = f\"/home/andyalyfsyah/experiment_siet24_288/experiment_105.pth.tar\"\n",
    "checkpoint = torch.load(saved_model_path)\n",
    "transformer = checkpoint['transformer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([[  0,   0,   0,   0,   0,   0,   0, 104,  62,  28]], device='cuda:0')\n",
      "tensor([[[[False, False, False, False, False, False, False,  True,  True,  True]]]],\n",
      "       device='cuda:0')\n",
      "tensor([[[-0.4308,  1.7268, -3.5057,  ..., -1.0437, -0.1656, -2.3352],\n",
      "         [ 0.1414,  0.6119, -1.3479,  ..., -0.7701, -0.0793, -2.6979],\n",
      "         [ 0.7828, -1.3572, -1.7044,  ..., -1.2023, -0.4344, -1.9561],\n",
      "         ...,\n",
      "         [ 0.4359,  1.7354, -3.2791,  ..., -0.9037, -0.2538, -1.3264],\n",
      "         [ 0.2782,  0.3698, -0.4754,  ..., -1.3937, -0.4852, -0.8032],\n",
      "         [ 0.6412,  0.5493, -1.4470,  ..., -1.2273, -0.6602, -0.6006]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n",
      "\n",
      "tensor([[   0,    0,    0,    0,    0,    0,    0,   62,   51, 2546]],\n",
      "       device='cuda:0')\n",
      "tensor([[[[False, False, False, False, False, False, False,  True,  True,  True]]]],\n",
      "       device='cuda:0')\n",
      "tensor([[[-0.0617,  1.8195, -3.9824,  ..., -0.4691, -0.5702, -1.6658],\n",
      "         [ 0.8550, -0.0067, -3.4525,  ...,  0.1882, -0.1577,  0.0902],\n",
      "         [ 0.5388, -0.3943, -2.8081,  ..., -0.5049, -0.4440, -1.9878],\n",
      "         ...,\n",
      "         [ 0.7482,  1.4113, -2.7304,  ..., -0.7106, -0.4823, -0.3586],\n",
      "         [ 0.9376, -0.1056, -1.8167,  ..., -0.0759, -0.7552,  0.1246],\n",
      "         [ 0.8967, -0.5191, -2.1836,  ..., -0.4130, -0.9827, -0.4933]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n",
      "\n",
      "tensor([[   0,    0,    0,    0,    0,    0,  104, 2477,   62,   29]],\n",
      "       device='cuda:0')\n",
      "tensor([[[[False, False, False, False, False, False,  True,  True,  True,  True]]]],\n",
      "       device='cuda:0')\n",
      "tensor([[[-0.5390,  0.4557, -3.2164,  ...,  0.5686, -0.7704, -1.3335],\n",
      "         [ 0.1414,  0.3296, -1.8789,  ...,  0.3195, -0.9627, -1.9954],\n",
      "         [ 0.2733,  0.1564, -1.3148,  ..., -0.4491, -0.7456, -1.6636],\n",
      "         ...,\n",
      "         [ 0.0835,  0.5357, -2.9609,  ...,  0.2457, -0.9606, -1.1657],\n",
      "         [ 0.9307, -0.3933, -1.1429,  ..., -0.3905, -0.2839, -0.4601],\n",
      "         [-0.3686, -0.9498, -2.0098,  ..., -0.0745, -0.5243, -1.7964]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n",
      "\n",
      "tensor([[  0,   0,   0,   0,   0,   0,   0, 104,  79,  28]], device='cuda:0')\n",
      "tensor([[[[False, False, False, False, False, False, False,  True,  True,  True]]]],\n",
      "       device='cuda:0')\n",
      "tensor([[[-1.0536,  0.7052, -3.8602,  ..., -0.3814, -0.2501, -2.0267],\n",
      "         [-0.2730,  0.3508, -2.5168,  ..., -0.5274, -0.0895, -1.1701],\n",
      "         [ 0.1688, -1.0146, -2.3551,  ...,  0.1187, -0.5021, -1.2756],\n",
      "         ...,\n",
      "         [ 0.0946,  1.1744, -3.6480,  ..., -0.7216, -0.5207, -1.7673],\n",
      "         [ 0.3133,  0.2805, -3.2518,  ..., -0.8721, -0.7474, -1.0514],\n",
      "         [ 0.3359, -0.4621, -1.9457,  ..., -0.9137, -0.5262, -0.3596]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n",
      "\n",
      "tensor([[   0,    0,    0,    0,    0,    0,  104, 2477,   79, 2546]],\n",
      "       device='cuda:0')\n",
      "tensor([[[[False, False, False, False, False, False,  True,  True,  True,  True]]]],\n",
      "       device='cuda:0')\n",
      "tensor([[[-1.0564,  1.1277, -3.7125,  ...,  0.0094, -0.5640, -1.9448],\n",
      "         [-0.3560, -0.0261, -2.5437,  ...,  0.3037, -0.6317, -2.0133],\n",
      "         [ 0.3339,  0.4356, -2.6762,  ...,  0.4527, -0.2568, -1.2381],\n",
      "         ...,\n",
      "         [-0.3651,  0.8968, -3.3225,  ..., -0.2953, -0.5407, -1.2496],\n",
      "         [ 0.1012, -0.2322, -1.8136,  ...,  0.0435, -0.6941, -1.0284],\n",
      "         [-0.1239, -0.5676, -3.3020,  ..., -0.9865, -1.0331, -0.9491]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n",
      "\n",
      "tensor([[  0,   0,   0,   0,   0,   0,   0, 104,  79,  29]], device='cuda:0')\n",
      "tensor([[[[False, False, False, False, False, False, False,  True,  True,  True]]]],\n",
      "       device='cuda:0')\n",
      "tensor([[[-7.8730e-01,  9.4643e-01, -3.4294e+00,  ...,  1.2953e-02,\n",
      "           4.2770e-03, -1.0908e+00],\n",
      "         [ 4.7172e-01,  4.0114e-01, -2.6541e+00,  ..., -8.5919e-02,\n",
      "           7.1047e-02, -1.7294e+00],\n",
      "         [ 4.6361e-01, -9.9233e-01, -2.4352e+00,  ...,  3.6467e-02,\n",
      "          -3.2382e-02, -1.1778e+00],\n",
      "         ...,\n",
      "         [-1.3765e-01,  1.2077e+00, -3.7466e+00,  ..., -1.9778e-03,\n",
      "          -2.2253e-01, -7.0975e-02],\n",
      "         [ 1.5741e-01,  4.6392e-01, -2.5641e+00,  ...,  1.0090e-01,\n",
      "          -4.8207e-01, -2.3184e-01],\n",
      "         [-2.1454e-01, -1.2773e+00, -7.8763e-01,  ..., -5.3662e-01,\n",
      "          -4.1682e-01, -1.7568e+00]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "\n",
      "tensor([[   0,    0,    0,    0,    0,    0,    0, 2275,  105,   29]],\n",
      "       device='cuda:0')\n",
      "tensor([[[[False, False, False, False, False, False, False,  True,  True,  True]]]],\n",
      "       device='cuda:0')\n",
      "tensor([[[-0.8574,  0.8402, -2.7598,  ..., -0.3884, -0.7962, -2.2389],\n",
      "         [ 0.2403,  0.2345, -2.1041,  ...,  0.5935, -0.6984, -1.1746],\n",
      "         [ 0.2169, -1.5084, -1.5767,  ...,  0.8535, -0.6563, -0.0648],\n",
      "         ...,\n",
      "         [-0.0610,  0.5193, -2.3948,  ..., -1.2421, -0.7381, -0.4880],\n",
      "         [ 0.2846, -1.0060, -1.4728,  ..., -0.5859, -0.6390, -0.7424],\n",
      "         [-0.3078, -0.2137, -2.5365,  ...,  0.6244, -0.2846, -1.3939]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n",
      "\n",
      "tensor([[  0,   0,   0,   0,   0,   0,   0, 104, 105,  29]], device='cuda:0')\n",
      "tensor([[[[False, False, False, False, False, False, False,  True,  True,  True]]]],\n",
      "       device='cuda:0')\n",
      "tensor([[[-8.8092e-01,  1.3475e+00, -2.8927e+00,  ..., -3.3020e-04,\n",
      "          -6.1321e-01, -1.6932e+00],\n",
      "         [-4.2122e-01,  1.8257e-01, -3.1760e+00,  ...,  2.3567e-01,\n",
      "          -3.7593e-01, -1.3193e+00],\n",
      "         [-6.9935e-01, -5.4622e-01, -2.5373e+00,  ...,  7.7808e-01,\n",
      "          -7.4744e-01, -1.4792e+00],\n",
      "         ...,\n",
      "         [-3.3167e-01,  4.3830e-01, -3.6473e+00,  ..., -6.2469e-01,\n",
      "          -6.1884e-01, -1.5030e+00],\n",
      "         [-1.2763e-01, -2.3883e-01, -1.9211e+00,  ..., -5.3459e-01,\n",
      "          -4.4158e-01, -4.4573e-01],\n",
      "         [-4.5951e-01, -1.0260e+00, -2.2392e+00,  ..., -1.3950e-01,\n",
      "          -1.0546e+00, -1.5399e+00]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "\n",
      "tensor([[  0,   0,   0,   0,   0,   0, 104, 132,  77,  29]], device='cuda:0')\n",
      "tensor([[[[False, False, False, False, False, False,  True,  True,  True,  True]]]],\n",
      "       device='cuda:0')\n",
      "tensor([[[-0.7869,  0.8710, -3.1900,  ..., -0.3056, -0.3568, -1.8661],\n",
      "         [-0.1208, -0.2640, -2.0063,  ..., -0.4051, -0.0363, -0.6228],\n",
      "         [ 0.2982, -0.3457, -2.1212,  ...,  0.8438,  0.0752, -0.7071],\n",
      "         ...,\n",
      "         [ 0.5193,  1.4283, -3.2375,  ..., -0.1681, -0.3569, -0.1090],\n",
      "         [ 1.4162,  0.9182, -2.9431,  ...,  0.5701,  0.0764, -0.1033],\n",
      "         [ 0.1324, -0.3532, -1.8841,  ...,  0.2458, -0.0349, -1.9173]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n",
      "\n",
      "tensor([[   0,    0,    0,    0,    0,  104,    1,    2, 2546,    4]],\n",
      "       device='cuda:0')\n",
      "tensor([[[[False, False, False, False, False,  True,  True,  True,  True,  True]]]],\n",
      "       device='cuda:0')\n",
      "tensor([[[-0.9507,  1.3020, -2.6281,  ...,  1.0012,  1.5649,  0.2164],\n",
      "         [ 0.5052, -0.2690, -1.4508,  ...,  0.8670,  0.3170,  0.3905],\n",
      "         [-0.1171, -1.6650, -1.4092,  ...,  0.6634,  0.2656, -1.2066],\n",
      "         ...,\n",
      "         [ 0.0314,  0.5418, -2.4892,  ...,  0.1507,  0.1159,  0.9978],\n",
      "         [ 1.4637, -0.5715, -1.8801,  ..., -0.0529,  0.0744,  1.6134],\n",
      "         [-0.2915, -1.2829, -2.2757,  ...,  0.3102,  0.1346,  0.8770]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "encoded_play = []\n",
    "\n",
    "words = list(tests['Pertanyaan'])\n",
    "labels_words = list(tests['Labels'] )\n",
    "\n",
    "for i in range(len(words)):\n",
    "    words[i] = words[i].lower()\n",
    "    question = words[i] \n",
    "    max_len = 50\n",
    "    enc_qus = [word_map.get(word, word_map['<unk>']) for word in question.split()]\n",
    "    if len(enc_qus) < 10:\n",
    "        left_pad = [word_map['<pad>']] * (10 - len(enc_qus))\n",
    "        enc_qus = left_pad + enc_qus\n",
    "    question = torch.LongTensor(enc_qus).to(device).unsqueeze(0)\n",
    "    print()\n",
    "    print(question)\n",
    "    question_mask = (question!=0).to(device).unsqueeze(1).unsqueeze(1)  \n",
    "    print(question_mask)\n",
    "    encoded = transformer.encode(question, question_mask)\n",
    "    print(encoded)\n",
    "    encoded = encoded.detach().cpu().numpy()\n",
    "    if encoded.shape[0] > 1:\n",
    "        concetaned_encoded = np.concatenate(encoded, axis=0)\n",
    "        encoded = concetaned_encoded\n",
    "    encoded_play.append(encoded[0].flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl0AAAI/CAYAAABNvmx6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAAsTAAALEwEAmpwYAAAxEElEQVR4nO3de3RU9b338c83MyHExIpiQiVcDC1CIYEEQhAwPiBqqVBAalWUekHw9CACz+PRUmuPyNLWeljVWqVYrKIFjyBWjFpBVFDQpRhIlJuIIhEEAaPBEm65/J4/MqZEyIVk8psJvF9rscjsvWfv32wm5u2+TMw5JwAAADStmEgPAAAA4GRAdAEAAHhAdAEAAHhAdAEAAHhAdAEAAHhAdAEAAHgQjPQAjnTmmWe6s88+O9LDAAAAqNPq1au/dM4l1Xf5qIqus88+W3l5eZEeBgAAQJ3MrPB4luf0IgAAgAdEFwAAgAdEFwAAgAdEFwAAgAdEFwAAgAdEFwAAgAdEFwAAgAdEFwAAgAdEFwAAgAdEFwAAgAdEFwAAgAdEFwAAgAdEFwAAgAdEFwAAgAdEFwAAgAdEFxAmO3bs0GWXXVbrMv379/c0GgBAtDHnXKTHUCUrK8vl5eVFehgAAAB1MrPVzrms+i7PkS6gAaZOnaqHH3646vG0adM0Y8YMpaWlSZLWr1+v7OxsZWRkqEePHtq8ebMkKTExMSLjBQBEHtEF1FNhUYnuWLRWaXcu0ZO72uq2+x7RHYvWqrCoRAsWLFDfvn2rlp01a5YmT56sgoIC5eXlqV27dhEcOQAgGgQjPQCgOVi2abcmzF2j0vIKlVU4tWjzAx3e97Xmvlagef9coYSWiWrfvn3V8v369dM999yj7du3a9SoUercuXMERw8AiAYc6QLqUFhUoglz1+hAabnKKv59DWRC1/P0zcaV+mrtcu1J6q3tX++vmnfVVVcpNzdX8fHxuuSSS/T6669HYOQAgGhCdAF1mL1ii0rLK46afkrXHO3f+Kb2b3pL8V0GaP5726rmbdmyRZ06ddKkSZM0YsQIffDBBz6HDACIQkQXUIdF+TuqHeH6Voukjqo4fECBU1tLp5yuJeu/qJq3YMECpaWlKSMjQ+vWrdM111zjc8gAgCjER0YAdUid+pLq811iJn36+6FNPh4AQHTgIyOAMEuIq9/9JgktuC8FAFAzoguow8jMtgrGWK3LBGNMl2ameBoRAKA5IrqAOozP6aTYQO3fKrGBGI3LSfU0IgBAc0R0AXXo2DpBM8f0Unxs4KgjXsEYU3xsQDPH9FLH1gkRGiEAoDkguoB6GNQlWYun5Gh0dgclxgVlJiXGBTU6u4MWT8nRoC7JkR4iACDKcfciAABAA3D3IgAAQBQiugAAADwgugAAADwgugAAADwgugAAADwgugAAADwgugAAADwgugAAADwgugAAADwgugAAADwIS3SZWSszW2hmH5rZRjPrZ2ZnmNlSM9sc+vv0cGwLAACgOQrXka4/SVrsnOsqqaekjZKmSnrNOddZ0muhxwAAACelRkeXmZ0m6XxJf5Mk59xh51yxpBGSnggt9oSkkY3dFgAAQHMVjiNdqZL2SHrczPLN7FEzS5DUxjm3M7TMF5LahGFbAAAAzVI4oisoqZekvzjnMiWV6DunEp1zTpI71pPN7EYzyzOzvD179oRhOAAAANEnHNG1XdJ259y7occLVRlhu8zsLEkK/b37WE92zv3VOZflnMtKSkoKw3AAAACiT6Ojyzn3haRtZtYlNGmwpA2SciVdG5p2raTnG7stAACA5ioYpvXcLGmembWQtEXS9aoMugVmdoOkQkmXh2lbAAAAzU5Yoss5VyAp6xizBodj/QAAAM0dn0gPAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFAADgAdEFhMmOHTt02WWX1bpM//79PY0GABBtwhZdZhYws3wzezH0ONXM3jWzj81svpm1CNe2gGjUtm1bLVy4sNZl3n77bU+jAQBEm3Ae6ZosaeMRj/8g6X7n3A8lfS3phjBuC4ioqVOn6uGHH656PG3aNM2YMUNpaWmSpPXr1ys7O1sZGRnq0aOHNm/eLElKTEyMyHgBAJEXlugys3aShkp6NPTYJF0g6dv/7X9C0shwbAuIlMKiEt2xaK3S7lyiJ3e11W33PaI7Fq1VYVGJFixYoL59+1YtO2vWLE2ePFkFBQXKy8tTu3btIjhyAEA0CIZpPQ9Iuk3SqaHHrSUVO+fKQo+3S0oJ07YA75Zt2q0Jc9eotLxCZRVOLdr8QIf3fa25rxVo3j9XKKFlotq3b1+1fL9+/XTPPfdo+/btGjVqlDp37hzB0QMAokGjj3SZ2TBJu51zqxv4/BvNLM/M8vbs2dPY4QBhV1hUoglz1+hAabnKKlzV9ISu5+mbjSv11drl2pPUW9u/3l8176qrrlJubq7i4+N1ySWX6PXXX4/AyAEA0SQcpxcHSBpuZlslPa3K04p/ktTKzL49ktZO0ufHerJz7q/OuSznXFZSUlIYhgOE1+wVW1RaXnHU9FO65mj/xje1f9Nbiu8yQPPf21Y1b8uWLerUqZMmTZqkESNG6IMPPvA5ZABAFGp0dDnnfu2ca+ecO1vSlZJed85dLWmZpG/vn79W0vON3RYQCYvyd1Q7wvWtFkkdVXH4gAKntpZOOV1L1n9RNW/BggVKS0tTRkaG1q1bp2uuucbnkAEAUcicO/qHSYNXZjZQ0n8554aZWSdVHvk6Q1K+pDHOuUO1PT8rK8vl5eWFbTxAOKROfUn1+S4xkz79/dAmHw8AIDqY2WrnXFZ9lw/XhfSSJOfccknLQ19vkZQdzvUDkZAQF9S+Q2V1L9cirN9OAIATDJ9ID9RhZGZbBWOs1mWCMaZLM7lBFwBQM6ILqMP4nE6KDdT+rRIbiNG4nFRPIwIANEdEF1CHjq0TNHNML8XHBo464hWMMcXHBjRzTC91bJ0QoRECAJoDoguoh0FdkrV4So5GZ3dQYlxQZlJiXFCjszto8ZQcDeqSHOkhAgCiXFjvXmws7l4EAADNxfHevciRLgAAAA+ILgAAAA+ILgAAAA+ILgAAAA+ILgAAAA+ILgAAAA+ILgAAAA+ILgAAAA+ILgAAAA+ILqCRduzYocsuu6zWZfr37+9pNACAaMWvAQIAAGgAfg0Q0ISmTp2qhx9+uOrxtGnTNGPGDKWlpUmS1q9fr+zsbGVkZKhHjx7avHmzJCkxMTEi4wUARA+iC6hDYVGJ7li0Vml3LtGTu9rqtvse0R2L1qqwqEQLFixQ3759q5adNWuWJk+erIKCAuXl5aldu3YRHDkAIJoEIz0AIJot27RbE+auUWl5hcoqnFq0+YEO7/tac18r0Lx/rlBCy0S1b9++avl+/frpnnvu0fbt2zVq1Ch17tw5gqMHAEQTjnQBNSgsKtGEuWt0oLRcZRX/vvYxoet5+mbjSn21drn2JPXW9q/3V8276qqrlJubq/j4eF1yySV6/fXXIzByAEA0IrqAGsxesUWl5RVHTT+la472b3xT+ze9pfguAzT/vW1V87Zs2aJOnTpp0qRJGjFihD744AOfQwYARDGiC6jBovwd1Y5wfatFUkdVHD6gwKmtpVNO15L1X1TNW7BggdLS0pSRkaF169bpmmuu8TlkAEAU4yMjgBqkTn1J9fnuMJM+/f3QJh8PACC68JERQJgkxNXvPpOEFtyPAgCoG9EF1GBkZlsFY6zWZYIxpkszUzyNCADQnBFdQA3G53RSbKD2b5HYQIzG5aR6GhEAoDkjuoAadGydoJljeik+NnDUEa9gjCk+NqCZY3qpY+uECI0QANCcEF1ALQZ1SdbiKTkand1BiXFBmUmJcUGNzu6gxVNyNKhLcqSHCABoJrh7EQAAoAG4exEAACAKEV0AAAAeEF0AAAAeEF0AAAAeEF0AAAAeEF0AAAAeEF0AAAAeEF0AAAAeEF0AAAAeEF0AAAAeEF0AAAAeEF0AAAAeEF0AAAAeEF0AAAAeEF0AAAAeEF0AAAAeEF0AAAAeEF0AAAAeEF0AAAAeEF0AAAAeEF0AAAAeEF0AAAAeEF0AAAAeEF0AAAAeEF0AAAAeEF0AAAAeEF0AAAAeEF0AAAAeEF0AAAAeEF0AAAAeEF0AAAAeEF0AAAAeEF0AAAAeEF0AAAAeEF0AAAAeEF0AAAAeEF0AAAAeEF0AAAAeEF0AAAAeEF0AAAAeEF0AAAAeEF0AAAAeEF0AAAAeEF0AAAAeEF0AAAAeEF0AAAAeEF0AAAAeEF0AAAAeEF0AAAAeEF0AAAAeEF0AAAAeEF0AAAAeEF0AAAAeEF0AAAAeEF0AAAAeEF0AAAAeEF0AAAAeNDq6zKy9mS0zsw1mtt7MJoemn2FmS81sc+jv0xs/XAAAgOYpHEe6yiTd4pzrJulcSTeZWTdJUyW95pzrLOm10GMAAICTUqOjyzm30zm3JvT1vyRtlJQiaYSkJ0KLPSFpZGO3BQAA0FyF9ZouMztbUqakdyW1cc7tDM36QlKbcG4LAACgOQlbdJlZoqRnJU1xzn1z5DznnJPkanjejWaWZ2Z5e/bsCddwAAAAokpYosvMYlUZXPOcc/8ITd5lZmeF5p8lafexnuuc+6tzLss5l5WUlBSO4QAAAESdcNy9aJL+Jmmjc+6PR8zKlXRt6OtrJT3f2G0BAAA0V8EwrGOApF9IWmtmBaFpt0u6V9ICM7tBUqGky8OwLQAAgGap0dHlnFspyWqYPbix6wcAADgR8In0AAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHhBdAAAAHjR5dJnZEDPbZGYfm9nUpt4eAABANGrS6DKzgKSHJf1EUjdJo82sW1NuEwAAIBo19ZGubEkfO+e2OOcOS3pa0ogm3iYAAEDUaeroSpG07YjH20PTAAAATioRv5DezG40szwzy9uzZ0+khwMAANAkmjq6PpfU/ojH7ULTqjjn/uqcy3LOZSUlJTXxcAAAACKjqaPrPUmdzSzVzFpIulJSbhNvEwAAIOoEm3LlzrkyM5soaYmkgKTHnHPrm3KbAAAA0ahJo0uSnHP/lPTPpt4OAABANIv4hfQAAAAnA6ILAADAA6ILAADAA6ILAADAA6ILAADAA6ILAADAA6ILAADAA6ILAADAA6ILAADAA6ILAADAA6ILAADAA6ILAADAA6ILAADAA6ILAADAA6ILAADAA6ILAADAA6ILAADAA6ILAADAA6ILAADAA6ILAADAA6ILAADAA6ILAADAA6ILAADAA6ILAADAA6ILAADAA6ILAADAA6ILAADAA6ILAADAA6ILAADAA6ILAADAA6ILAADAA6LrBFVcXKyZM2fWudy4ceO0YcMGDyMCAODkRnSdoOobXY8++qi6devmYUQAAJzciK4T1NSpU/XJJ58oIyNDffr00bBhw6rmTZw4UXPmzJEkDRw4UHl5eZKkxMTEqmUWLlyo6667TpL0wgsvqG/fvsrMzNSFF16oXbt2SZKmTZumsWPHauDAgerUqZMefPBBPy8OAIBmiOg6gRQWleiORWuVducSrTz9YrlT22jYtL/rljumN2q95513nt555x3l5+fryiuv1H333Vc178MPP9SSJUu0atUq3XXXXSotLW3sywAA4IQUjPQAEB7LNu3WhLlrVFpeobIKJ0mqcE5Pr9qmw9vWKWXfoQave/v27briiiu0c+dOHT58WKmpqVXzhg4dqri4OMXFxSk5OVm7du1Su3btGv16AAA40XCk6wRQWFSiCXPX6EBpeVVwfauswumwk9ZuL1ZhUYkk6eDBg8dcj5lVfX3kMjfffLMmTpyotWvX6pFHHqk2Ly4ururrQCCgsrKysLwmAABONESXR7m5ubr33ntrnJ+Xl6dJkyYd93pnr9ii0vKKatOsRbwqDh+QJAW/l6xDX36mWa9vUnFxsV577bVjrqdNmzbauHGjKioq9Nxzz1VN37t3r1JSUiRJTzzxxHGPDwAAcHrRq+HDh2v48OE1zs/KylJWVtZxr3dR/o6jjnAF4r+nuJRu2vG3CYrvlKVTupynP/7yp1rdu7syMzOrLfvtEa57771Xw4YNU1JSkrKysrRv3z5JlRfM//znP9fpp5+uCy64QJ9++ulxjxEAgJOdOefqXsqTrKws9+2ddM3N1q1bNWTIEJ177rl6++231adPH11//fW68847tXv3bs2bN08bNmxQXl6eHnroIT3zzDO66667FAgEdNppp+nNN9/U8uXLNWPGDL344ovHte3UqS+pPv+KZtKnvx9abVp6erpyc3OrXacFAADqZmarnXP1PlrCka4GKiwq0ewVW7Qof4dKDpUp9sCX+njzx/rT7Cf02GOPqU+fPnrqqae0cuVK5ebm6ne/+51GjhxZ9fzp06dryZIlSklJUXFxcaPGkhAX1L5DdV9LldCi+j/3RRddpPT0dIILAAAPiK4GONadgvsPlyt4WhtNeeVrzUz+Ut27d9fgwYNlZkpPT9fWrVurrWPAgAG67rrrdPnll2vUqFGNGs/IzLZ6etW2o04xHikYY7o0M6XatKVLlzZquwAAoP64kP441XanoAJBHSgt14S5a7S/tKLqzr6YmJij7uqbNWuW7r77bm3btk29e/dWUVFRg8c0PqeTYgO1/1PGBmI0LocjWgAARArRdZyOdafgd5WWV2jzrn/Vuswnn3yivn37avr06UpKStK2bdsaPKaOrRM0c0wvxccGFIyxavOCMab42IBmjumljq0TGrwNAADQOETXcTrWnYLfVVbh9NlX+2td5tZbb1V6errS0tLUv39/9ezZs1HjGtQlWYun5Gh0dgclxgVlJiXGBTU6u4MWT8nRoC7JjVo/AABoHO5ePE6NuVMQAACcOI737kWOdB2nhLj63Xvw3TsFAQDAyY3oOk4jM9sedd3Udx3rTkEAAHByI7qOE3cKAgCAhiC6jhN3CgIAgIYguhqAOwUBAMDx4u5FAACABuDuRQAAgChEdAEAAHhAdAEAAHhAdAEAAHhAdAEAAHhAdAEAAHhAdAEAAHhAdAEAAHhAdAEAAHhAdAEAAHhAdAEAAHhAdHlWXFysmTNn1rncuHHjtGHDBg8jAgAAPhBdntUnunJzc/XDH/5Q3bp1O+b8vLw8TZo0qSmGBwAAmgjR5dnUqVP1ySefKCMjQ3369NGwYcOq5k2cOFFz5szR8OHDtXjxYuXl5UmSEhMTq5ZZuHChHnroIT344IN64YUX1LdvX2VmZurCCy/Url27JEnTpk3T2LFjNXDgQHXq1EkPPvig3xcJAACOQnR5UFhUojsWrVXanUu0PNBLh0rL5M7oqO2f71B+fr5effVVDRgwQHPnztWWLVs0Z84cbd68WZL0zDPP6MCBA+rZs6fOP/98SdIXX3yhYcOG6bzzztM777yj/Px8XXnllbrvvvuqtvnhhx9qyZIlWrVqle666y6VlpZG5LUDAIBKwUgP4EQ3/73PdPtz61Re4aqmufIyfdXpYsWm9FPRot/pqaee0sqVKzVs2DC9+OKL1U4dTp8+XS1bttT777+v4uJivfrqq1Xztm/friuuuEI7d+7U4cOHlZqaWjVv6NChiouLU1xcnJKTk7Vr1y61a9fOz4sGAABH4UhXE5r/3mf61bNrqwWXJCkmqMCZZ+uwi9FhtVDP7PNkZkpMTNSXX35ZbdEBAwbo0KFDmj17tsrLy3Xw4MGqeTfffLMmTpyotWvX6pFHHqk2Ly4ururrQCCgsrKypnmRAACgXoiuJlJYVKLb/7H2qOnWoqWkyggLfi9Z5YdKtPyjL1VcXKy3335b5eXl1ZafNWuWzjrrLK1Zs0a9evXS/Pnzq+bt3btXKSkpkqQnnnii6V4MAABoNKKricxesUXl7ujpgZaJstg47fjbBP1r9QsKnpasF2ffq8svv1zdu3evtqyZ6ZNPPtH999+vV155RUVFRUpISKiaP23aNP385z9X7969deaZZzb1SwIAAI3ANV1NZFH+jhrnBU89U21vqPzYiPL9e3XKD/voled+r61bt1bdzXjw4EGdccYZuuWWW7R582bFx8frhhtu0AMPPKA33nhDM2bM0IgRIzRixIij1j9t2rRqj9etWxe+FwYAABrEnDvG4ZgIycrKct9+TEJzlzr1JdV3zybGBbXurh9XPb7ooouUlJSkp556qmkGBwAAGs3MVjvnsuq7PEe6mkhCXFD7DtXv4vVLM1OqPV66dGlTDAkAAEQQ13Q1kZGZbRWwupcLxJjG5aTWvSAAAGjWiK4mMj6nk1oEA3Uu97tL09SxdUKdywEAgOaN6GoiHVsnaOaYXoqPDRzziFfApD/8LF1X9Ongf3AAAMA7rulqQoO6JGvxlBw9uuJTPZf/uUoOlymhRVCXZqZoXE4qR7gAADiJcPciAABAAxzv3YucXgQAAPCA6AIAAPCA6AIAAPCA6AIAAPCA6AIAAPCA6AIAAPCA6AIAAPCgUdFlZv9jZh+a2Qdm9pyZtTpi3q/N7GMz22RmP270SAEAAJqxxh7pWiopzTnXQ9JHkn4tSWbWTdKVkrpLGiJpppnV/YsIAQAATlCNii7n3CvOubLQw3cktQt9PULS0865Q865TyV9LCm7MdvyLTc3V/fee2+N8/Py8jRp0iSPIwIAAM1ZOH/34lhJ80Nfp6gywr61PTSt2Rg+fLiGDx9e4/ysrCxlZdX7k/8BAMBJrs4jXWb2qpmtO8afEUcs8xtJZZLmHe8AzOxGM8szs7w9e/Yc79MbZOvWreratauuu+46nXPOObr66qv16quvasCAAercubNWrVqlOXPmaOLEiZKkZ555RmlpaerZs6fOP/98SdLy5cs1bNgwL+MFAADNX51HupxzF9Y238yukzRM0mD379+e/bmk9kcs1i407Vjr/6ukv0qVv/C67iE3TGFRiWav2KJF+TtUvPtzff7RZp3/n/doyf/8WZcNGainnnpKK1euVG5urn73u99p5MiRVc+dPn26lixZopSUFBUXFzfVEAEAwAmssXcvDpF0m6Thzrn9R8zKlXSlmcWZWaqkzpJWNWZbjbFs024NeWCFnl61TfsOVV6CFmzVRq/vitclD76l1u1/oMGDB8vMlJ6erq1bt1Z7/oABA3Tddddp9uzZKi8vj8ArAAAAzV1j7158SNKpkpaaWYGZzZIk59x6SQskbZC0WNJNzrmI1EphUYkmzF2jA6XlKqv494E0C8SqrMLpQGm53v30a31zuHJeTEyMysrKqq1j1qxZuvvuu7Vt2zb17t1bRUVFXl8DAABo/hp1Ib1z7oe1zLtH0j2NWX84zF6xRaXlFbUu45zTaxt36z9rmP/JJ5+ob9++6tu3r15++WVt27Yt/AMFAAAntBP+E+kX5e+odoTrWCqc9O6nX9U4/9Zbb1V6errS0tLUv39/9ezZM9zDBAAAJzj797XvkZeVleXy8vLCus7UqS+pPq/QTPr090PDum0AAHDiMrPVzrl6f37UCX+kKyGufmdQE1qE8yPLAAAAqjvho2tkZlsFY6zWZYIxpkszm9VntwIAgGbmhI+u8TmdFBuo/WXGBmI0LifV04gAAMDJ6ISPro6tEzRzTC/FxwaOOuIVjDHFxwY0c0wvdWydEKERAgCAk8EJH12SNKhLshZPydHo7A5KjAvKTEqMC2p0dgctnpKjQV2SIz1EAABwgjvh714EAABoCty9CAAA0AR27Nihyy67TJK0fPlySarxQ+KPhegCAACoh7Zt22rhwoUNfj7RBQAATkhz585Vdna2MjIy9B//8R8qLy9XYmKibr31VnXv3l0XXnihVq1apYEDB6pTp07Kzc2VJG3dulU5OTnq1auXevXqpbfffrtqelpaWoPHQ3QBAIATQmFRie5YtFZpdy5RyrhZ+s/pD2nwbbP0/GtvKRAIaN68eSopKdEFF1yg9evX69RTT9Udd9yhpUuX6rnnntN///d/S5KSk5O1dOlSrVmzRvPnz9ekSZPCMj4+hh0AADR7yzbt1oS5a1RaXqGyCqcDhQU6sHOz/njTZbrfTEnxpuTkZLVo0UJDhgyRJKWnpysuLk6xsbFKT0/X1q1bJUmlpaWaOHGiCgoKFAgE9NFHH4VljEQXAABo1gqLSjRh7hodKC2vNj0h7QKd/n+ukyTFxwZ0/c05mjFjhswqP7czJiZGcXFxVV+XlZVJku6//361adNG77//vioqKtSyZcuwjJPTiwAAoFmbvWKLSssrqk1r2bGn9m96S+UlxZKkg/v2asazb9VrfXv37tVZZ52lmJgY/f3vf1d5eXndT6oHjnQBAIBmbVH+DpVVVP/c0RZndlCrnF9o14LfSs7JYgJ6aejEeq1vwoQJ+tnPfqYnn3xSQ4YMUUJCeH5rDR+OCgAAmrXUqS+pPjVjJn36+6Fh2y4fjgoAAE4qCXH1O3GX0CKyJ/iILgAA0KyNzGyrYIzVukwwxnRpZoqnER0b0QUAAJq18TmdFBuoPWliAzEal5PqaUTHRnQBAIBmrWPrBM0c00vxsYGjjngFY0zxsQHNHNNLHVuH54L4hiK6AABAszeoS7IWT8nR6OwOSowLykxKjAtqdHYHLZ6So0FdkiM9RO5eBAAAaAjuXgQAAIhCRBcAAIAHRBcAAIAHRBcAAIAHRBcAAIAHRBcAAIAHRBcAAIAHRBcAAIAHRBcAAIAHRBcAAIAHRBcAAIAHRBcAAIAHRBcAAIAHRBcAAIAHRBcAAIAHRBcAAIAHRBcAAIAHRBcAAIAHRBcAAIAHRBcAAIAHRBcAAIAHRBcAAIAHRBcAAIAHRBcAAIAHRBcAAIAHRBcAAIAHRBcAAIAHRBcAAIAHRBcAAIAHRBcAAIAHRBcAAIAHRBcAAIAHRBcAAIAHRBcAAIAHRBcAAIAHRBcAAIAHRBcAAIAHRBcAAIAHRBcAAIAHRBcAAIAHRBcAAIAHRBcAAIAHRBcAAIAHRBcAAIAHRBcAAIAHRBcAAIAHRBcAAIAHRBcAAIAHRBcAAIAHRBcAAIAHRBcAAIAHRBcAAIAHRBcAAIAHRBcAAIAHRBcAAIAHRBcAAIAHRBcAAIAHRBcAAIAHRBcAAIAHRBeARpszZ44mTpwoSZo1a5aefPLJo5bZunWr0tLSJEl5eXmaNGmSJGnatGmaMWOGv8ECQIQEIz0AALUrKytTMNh8vlV/+ctf1rlMVlaWsrKyPIwGAKIHR7qA41RYVKI7Fq1V2p1L1PH/PatTO2erTWoXdflRN82fP1/Tp09Xnz59lJaWphtvvFHOOUnSgw8+qG7duqlHjx668sorJUmrVq1Sv379lJmZqf79+2vTpk2SKo8cDR8+XBdccIEGDx6sffv2afDgwerVq5fS09P1/PPPS6o8evSjH/1I48ePV/fu3XXxxRfrwIEDNY594MCBmjx5sjIyMpSWlqZVq1ZJkkpKSjR27FhlZ2crMzOzav1z5szRqFGjNGTIEHXu3Fm33XZb1boef/xxnXPOOcrOztZbb71VNf3II1erV69Wz5491bNnTz388MNVyyxfvlzDhg07anyzZ8/WT37yEx04cKDG/Thw4ED96le/UnZ2ts455xytWLHiOP8FASAywhJdZnaLmTkzOzP02MzsQTP72Mw+MLNe4dgOEGnLNu3WkAdW6OlV27TvUJn2f7paOuV0nTr6fsVc9ked8oPemjhxot577z2tW7dOBw4c0IsvvihJuvfee5Wfn68PPvhAs2bNkiR17dpVK1asUH5+vqZPn67bb7+9altr1qzRwoUL9cYbb6hly5Z67rnntGbNGi1btky33HJLVYRs3rxZN910k9avX69WrVrp2WefrfU17N+/XwUFBZo5c6bGjh0rSbrnnnt0wQUXaNWqVVq2bJluvfVWlZSUSJIKCgo0f/58rV27VvPnz9e2bdu0c+dO3XnnnXrrrbe0cuVKbdiw4Zjbuv766/XnP/9Z77//fp379qGHHtKLL76oRYsWKT4+vsb9KFUe/Vu1apUeeOAB3XXXXXWuGwCiQaPPWZhZe0kXS/rsiMk/kdQ59KevpL+E/gaarcKiEk2Yu0YHSsurprVIOltfv/437Xn9McX/oI9ue16a/IMiPf6XB7V//3599dVX6t69u37605+qR48euvrqqzVy5EiNHDlSkrR3715de+212rx5s8xMpaWlVeu+6KKLdMYZZ0iSnHO6/fbb9eabbyomJkaff/65du3aJUlKTU1VRkaGJKl3797aunVrra9j9OjRkqTzzz9f33zzjYqLi/XKK68oNze36gjVwYMH9dlnld/SgwcP1mmnnSZJ6tatmwoLC/Xll19q4MCBSkpKkiRdccUV+uijj6ptp7i4WMXFxTr//PMlSb/4xS/08ssvH3NMTz75pNq3b69FixYpNjZWkrRs2TLdd999R+1HSRo1alS9Xy8ARItwHOm6X9JtktwR00ZIetJVekdSKzM7KwzbAiJm9ootKi2vqDYt9owUnXXdnxSbdLaKV8zVrjfm6r+mTNLChQu1du1ajR8/XgcPHpQkvfTSS7rpppu0Zs0a9enTR2VlZfrtb3+rQYMGad26dXrhhReqlpWkhISEqq/nzZunPXv2aPXq1SooKFCbNm2qlo2Li6taLhAIqKysrNbXYWZHPXbO6dlnn1VBQYEKCgr02Wef6Uc/+lGD1t8Q6enp2rp1q7Zv3y6pMvomTJhwzP145JiaajwA0BQaFV1mNkLS58657547SJG07YjH20PTgGZrUf4OlVW4atPK/lWkmNg4JXYfpO9lj9LBLz7RwbIKnXnmmdq3b58WLlwoSaqoqNC2bds0aNAg/eEPf9DevXu1b98+7d27Vykpld8ac+bMqXHbe/fuVXJysmJjY7Vs2TIVFhY2+HXMnz9fkrRy5UqddtppOu200/TjH/9Yf/7zn6tOWebn59e6jr59++qNN95QUVGRSktL9cwzzxy1TKtWrdSqVSutXLlSUmU41iQzM1OPPPKIhg8frh07dlQF1nf3IwA0Z3WeXjSzVyV9/xizfiPpdlWeWmwwM7tR0o2S1KFDh8asCmhSJYeOPqJSumerdi9/XDKTxQR1xsUTdODjd5SWlqbvf//76tOnjySpvLxcY8aM0d69e+Wc06RJk9SqVSvddtttuvbaa3X33Xdr6NChNW776quv1k9/+lOlp6crKytLXbt2bfDraNmypTIzM1VaWqrHHntMkvTb3/5WU6ZMUY8ePVRRUaHU1NRq11B911lnnaVp06apX79+atWqVdXpze96/PHHNXbsWJmZLr649v9UnHfeeZoxY4aGDh2qpUuXavz48UftRwBozuzb/7M97ieapUt6TdL+0KR2knZIypZ0l6Tlzrn/DS27SdJA59zO2taZlZXl8vLyGjQeoKml3blE+44RXt+VGBfUurt+7GFEx2/gwIGaMWMGH9cAAGFgZqudc/X+D2qDTy8659Y655Kdc2c7585W5SnEXs65LyTlSromdBfjuZL21hVcQLQbmdlWwRirdZlgjOnSTM6kAwCO1lSfuPhPSZdI+liVR8Kub6LtAN6Mz+mkZ1d/rrKK8hqXiQ3EaFxOqsdRHdtNN91U7bOzJGny5Mlavnx5ZAYEAGj46cWmwOlFRLtlm3Zrwtw1Ki2vqHZRfTDGFBuI0cwxvTSoS3IERwgA8MXb6UXgZDSoS7IWT8nR6OwOSowLyqzyGq7R2R20eEoOwQUAqBFHugAAABqAI10AAABRiOgCAADwgOgCAADwgOgCAADwgOgCAADwgOgCAADwgOgCAADwgOgCAADwgOgCAADwgOgCAADwgOgCAADwgOgCAADwgOgCAADwgOgCAADwgOgCAADwgOgCAADwgOgCAADwgOgCAADwwJxzkR5DFTPbI6kw0uOIEmdK+jLSg2jm2IeNxz4MD/Zj47EPG4992Hjf3YcdnXNJ9X1yVEUX/s3M8pxzWZEeR3PGPmw89mF4sB8bj33YeOzDxmvsPuT0IgAAgAdEFwAAgAdEV/T6a6QHcAJgHzYe+zA82I+Nxz5sPPZh4zVqH3JNFwAAgAcc6QIAAPCA6IoyZvY/ZvahmX1gZs+ZWasj5v3azD42s01m9uMIDjPqmdmQ0H762MymRno8zYGZtTezZWa2wczWm9nk0PQzzGypmW0O/X16pMca7cwsYGb5ZvZi6HGqmb0bej/ON7MWkR5jNDOzVma2MPTfwo1m1o/34fExs/8b+j5eZ2b/a2YteR/WzsweM7PdZrbuiGnHfN9ZpQdD+/IDM+tVn20QXdFnqaQ051wPSR9J+rUkmVk3SVdK6i5piKSZZhaI2CijWGi/PCzpJ5K6SRod2n+oXZmkW5xz3SSdK+mm0H6bKuk151xnSa+FHqN2kyVtPOLxHyTd75z7oaSvJd0QkVE1H3+StNg511VST1XuS96H9WRmKZImScpyzqVJCqjy5wfvw9rNUeXP1yPV9L77iaTOoT83SvpLfTZAdEUZ59wrzrmy0MN3JLULfT1C0tPOuUPOuU8lfSwpOxJjbAayJX3snNvinDss6WlV7j/Uwjm30zm3JvT1v1T5gy5FlfvuidBiT0gaGZEBNhNm1k7SUEmPhh6bpAskLQwtwj6shZmdJul8SX+TJOfcYedcsXgfHq+gpHgzC0o6RdJO8T6slXPuTUlffWdyTe+7EZKedJXekdTKzM6qaxtEV3QbK+nl0NcpkrYdMW97aBqOxr5qJDM7W1KmpHcltXHO7QzN+kJSm0iNq5l4QNJtkipCj1tLKj7if6Z4P9YuVdIeSY+HTtE+amYJ4n1Yb865zyXNkPSZKmNrr6TV4n3YEDW97xr0c4boigAzezV0nv27f0YcscxvVHm6Z17kRoqTkZklSnpW0hTn3DdHznOVtztzy3MNzGyYpN3OudWRHkszFpTUS9JfnHOZkkr0nVOJvA9rF7ruaIQqA7atpAQdfdoMxykc77tgmMaC4+Ccu7C2+WZ2naRhkga7f3+mx+eS2h+xWLvQNByNfdVAZharyuCa55z7R2jyLjM7yzm3M3T4fHfkRhj1BkgabmaXSGop6XuqvD6plZkFQ0cZeD/Wbruk7c65d0OPF6oyungf1t+Fkj51zu2RJDP7hyrfm7wPj19N77sG/ZzhSFeUMbMhqjw1Mdw5t/+IWbmSrjSzODNLVeXFe6siMcZm4D1JnUN36rRQ5QWkuREeU9QLXXv0N0kbnXN/PGJWrqRrQ19fK+l532NrLpxzv3bOtXPOna3K993rzrmrJS2TdFloMfZhLZxzX0jaZmZdQpMGS9og3ofH4zNJ55rZKaHv62/3Ie/D41fT+y5X0jWhuxjPlbT3iNOQNeLDUaOMmX0sKU5SUWjSO865X4bm/UaV13mVqfLUz8vHXgtCRxoeUOVdO4855+6J7Iiin5mdJ2mFpLX69/VIt6vyuq4FkjpIKpR0uXPuuxeb4jvMbKCk/3LODTOzTqq8oeMMSfmSxjjnDkVweFHNzDJUeSNCC0lbJF2vyoMEvA/ryczuknSFKn9e5Esap8prjngf1sDM/lfSQElnStol6U5Ji3SM910oZh9S5Wnb/ZKud87l1bkNogsAAKDpcXoRAADAA6ILAADAA6ILAADAA6ILAADAA6ILAADAA6ILAADAA6ILAADAA6ILAADAg/8Pcrw+Kt+2zTQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca = PCA(n_components=2)\n",
    "encoded_play_pca = pca.fit_transform(encoded_play)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(encoded_play_pca[:,0], encoded_play_pca[:,1], s=100)\n",
    "for i, txt in enumerate(labels_words):\n",
    "    plt.annotate(txt, (encoded_play_pca[i,0], encoded_play_pca[i,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "Transformer                              --\n",
       "├─Embeddings: 1-1                        --\n",
       "│    └─Dropout: 2-1                      --\n",
       "│    └─Embedding: 2-2                    2,610,176\n",
       "├─Embeddings: 1-2                        --\n",
       "│    └─Dropout: 2-3                      --\n",
       "│    └─Embedding: 2-4                    2,610,176\n",
       "├─EncoderLayer: 1-3                      --\n",
       "│    └─LayerNorm: 2-5                    2,048\n",
       "│    └─MultiHeadAttention: 2-6           --\n",
       "│    │    └─Dropout: 3-1                 --\n",
       "│    │    └─Linear: 3-2                  1,049,600\n",
       "│    │    └─Linear: 3-3                  1,049,600\n",
       "│    │    └─Linear: 3-4                  1,049,600\n",
       "│    │    └─Linear: 3-5                  1,049,600\n",
       "│    └─FeedForward: 2-7                  --\n",
       "│    │    └─Linear: 3-6                  2,099,200\n",
       "│    │    └─Linear: 3-7                  2,098,176\n",
       "│    │    └─Dropout: 3-8                 --\n",
       "│    └─Dropout: 2-8                      --\n",
       "├─DecoderLayer: 1-4                      --\n",
       "│    └─LayerNorm: 2-9                    2,048\n",
       "│    └─MultiHeadAttention: 2-10          --\n",
       "│    │    └─Dropout: 3-9                 --\n",
       "│    │    └─Linear: 3-10                 1,049,600\n",
       "│    │    └─Linear: 3-11                 1,049,600\n",
       "│    │    └─Linear: 3-12                 1,049,600\n",
       "│    │    └─Linear: 3-13                 1,049,600\n",
       "│    └─MultiHeadAttention: 2-11          --\n",
       "│    │    └─Dropout: 3-14                --\n",
       "│    │    └─Linear: 3-15                 1,049,600\n",
       "│    │    └─Linear: 3-16                 1,049,600\n",
       "│    │    └─Linear: 3-17                 1,049,600\n",
       "│    │    └─Linear: 3-18                 1,049,600\n",
       "│    └─FeedForward: 2-12                 --\n",
       "│    │    └─Linear: 3-19                 2,099,200\n",
       "│    │    └─Linear: 3-20                 2,098,176\n",
       "│    │    └─Dropout: 3-21                --\n",
       "│    └─Dropout: 2-13                     --\n",
       "├─Linear: 1-5                            2,612,725\n",
       "=================================================================\n",
       "Total params: 28,827,125\n",
       "Trainable params: 28,827,125\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_path = f\"/home/andyalyfsyah/experiment_siet24_288/experiment_37.pth.tar\"\n",
    "checkpoint = torch.load(saved_model_path)\n",
    "transformer = checkpoint['transformer']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([[  0,   0,   0,   0,   0,   0,   0, 104,  62,  28]], device='cuda:0')\n",
      "tensor([[[[False, False, False, False, False, False, False,  True,  True,  True]]]],\n",
      "       device='cuda:0')\n",
      "tensor([[[ 0.4176, -0.6113, -0.1019,  ..., -1.2706, -0.0157,  1.6080],\n",
      "         [-0.4089, -1.2244,  0.2697,  ..., -1.4513,  0.4917,  2.2217],\n",
      "         [-0.0678, -0.7721, -0.2333,  ..., -1.9323,  0.0137, -0.4056],\n",
      "         ...,\n",
      "         [-0.8394, -0.6284, -0.4258,  ..., -0.7151, -1.1960, -1.3372],\n",
      "         [ 0.4464,  2.0722, -1.3132,  ..., -1.9323, -0.6144,  0.5126],\n",
      "         [ 1.3352,  1.7453, -1.9330,  ..., -1.1546, -0.2814,  0.8742]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n",
      "\n",
      "tensor([[   0,    0,    0,    0,    0,    0,    0,   62,   51, 2546]],\n",
      "       device='cuda:0')\n",
      "tensor([[[[False, False, False, False, False, False, False,  True,  True,  True]]]],\n",
      "       device='cuda:0')\n",
      "tensor([[[ 0.3516, -0.6032, -0.0806,  ..., -0.7005, -0.0933,  1.5685],\n",
      "         [ 0.3668, -0.8181,  0.6925,  ..., -1.2771,  0.2943,  1.7121],\n",
      "         [ 0.1583, -1.0777,  0.1842,  ..., -0.9961, -0.3708, -0.3764],\n",
      "         ...,\n",
      "         [ 0.8437,  1.4159, -1.4568,  ..., -0.9817, -0.5698, -0.6854],\n",
      "         [-1.4064,  0.4060,  0.1101,  ...,  0.7516,  1.3376,  0.0465],\n",
      "         [-0.3475,  0.5349,  0.9843,  ...,  1.2061,  0.0537, -1.2523]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n",
      "\n",
      "tensor([[   0,    0,    0,    0,    0,    0,  104, 2477,   62,   29]],\n",
      "       device='cuda:0')\n",
      "tensor([[[[False, False, False, False, False, False,  True,  True,  True,  True]]]],\n",
      "       device='cuda:0')\n",
      "tensor([[[ 0.6760,  0.0904, -0.6019,  ..., -0.7839,  0.3169,  2.4231],\n",
      "         [ 0.2136, -0.0236, -1.1179,  ..., -0.4857,  0.1713,  1.5038],\n",
      "         [ 0.9346, -0.1844, -1.1285,  ..., -0.5554, -0.2596,  1.2420],\n",
      "         ...,\n",
      "         [ 1.8245, -1.3177, -0.4218,  ...,  2.1606,  0.2316, -0.5425],\n",
      "         [ 0.3245,  1.9866, -1.3932,  ..., -1.5596, -0.3710, -0.4548],\n",
      "         [-0.8544,  0.6902, -0.7000,  ...,  0.0341, -0.1367,  1.0419]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n",
      "\n",
      "tensor([[  0,   0,   0,   0,   0,   0,   0, 104,  79,  28]], device='cuda:0')\n",
      "tensor([[[[False, False, False, False, False, False, False,  True,  True,  True]]]],\n",
      "       device='cuda:0')\n",
      "tensor([[[ 0.5555, -0.7647,  0.0164,  ..., -1.3390, -0.0443,  1.1567],\n",
      "         [ 1.5037, -1.0515, -0.0511,  ..., -0.3671,  0.5898,  1.5817],\n",
      "         [ 1.0207, -0.9162,  0.1218,  ..., -0.9032,  0.2191,  1.3313],\n",
      "         ...,\n",
      "         [-0.8526, -0.9533, -0.3668,  ..., -0.2324, -1.4733, -1.6993],\n",
      "         [-1.6273, -0.7565, -0.4384,  ...,  0.7779,  0.2931, -0.4841],\n",
      "         [ 1.7673,  0.7266, -1.9532,  ..., -0.8838, -0.2756,  1.8412]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n",
      "\n",
      "tensor([[   0,    0,    0,    0,    0,    0,  104, 2477,   79, 2546]],\n",
      "       device='cuda:0')\n",
      "tensor([[[[False, False, False, False, False, False,  True,  True,  True,  True]]]],\n",
      "       device='cuda:0')\n",
      "tensor([[[ 1.2220e+00, -8.4468e-01, -6.1490e-01,  ..., -1.0473e-03,\n",
      "          -7.3293e-03,  1.6631e+00],\n",
      "         [ 8.5771e-01, -7.7604e-01, -9.2486e-01,  ..., -7.9077e-01,\n",
      "           1.6969e-01,  1.7999e+00],\n",
      "         [ 5.6819e-01, -6.2687e-01, -8.7711e-01,  ...,  2.3605e-01,\n",
      "           1.9231e-01, -3.3814e-01],\n",
      "         ...,\n",
      "         [ 2.7878e+00, -1.4484e+00, -1.6220e+00,  ...,  1.7435e+00,\n",
      "           3.7155e-01, -3.3707e-02],\n",
      "         [ 9.8907e-02, -8.4467e-01, -4.9475e-01,  ...,  6.4869e-01,\n",
      "           1.4663e-01, -2.4470e-01],\n",
      "         [ 1.0893e+00, -1.0108e+00,  1.8013e-01,  ...,  1.7772e+00,\n",
      "           2.5830e-01, -1.3315e+00]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "\n",
      "tensor([[  0,   0,   0,   0,   0,   0,   0, 104,  79,  29]], device='cuda:0')\n",
      "tensor([[[[False, False, False, False, False, False, False,  True,  True,  True]]]],\n",
      "       device='cuda:0')\n",
      "tensor([[[ 9.1488e-01, -5.5363e-02,  1.0949e-01,  ..., -1.9554e+00,\n",
      "           1.1037e-03,  1.8795e+00],\n",
      "         [ 1.3380e+00, -4.7537e-01, -4.3963e-01,  ..., -8.5915e-01,\n",
      "           1.8278e-01,  1.1968e+00],\n",
      "         [ 9.2756e-01, -8.2362e-01, -4.7732e-01,  ...,  9.4355e-02,\n",
      "           2.2345e-01,  1.7334e+00],\n",
      "         ...,\n",
      "         [ 6.8423e-01,  2.9643e-01, -9.1795e-01,  ...,  9.4562e-02,\n",
      "          -1.0010e+00, -1.2519e+00],\n",
      "         [-1.0978e+00, -5.6455e-02, -7.3512e-01,  ...,  1.3252e+00,\n",
      "           1.0354e+00,  4.5039e-02],\n",
      "         [ 6.7397e-01, -1.2989e-01, -1.1147e+00,  ..., -4.2385e-01,\n",
      "           4.9337e-01,  7.5998e-01]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "\n",
      "tensor([[   0,    0,    0,    0,    0,    0,    0, 2275,  105,   29]],\n",
      "       device='cuda:0')\n",
      "tensor([[[[False, False, False, False, False, False, False,  True,  True,  True]]]],\n",
      "       device='cuda:0')\n",
      "tensor([[[ 0.7816,  0.0908,  0.0606,  ..., -0.8543,  0.0369, -0.3482],\n",
      "         [ 1.2677, -0.2874, -1.0649,  ..., -0.3835,  0.1145,  2.7509],\n",
      "         [ 0.9546,  0.0272, -1.0555,  ..., -1.0280,  0.0780,  2.2766],\n",
      "         ...,\n",
      "         [-0.7615,  1.4016, -0.8020,  ...,  1.1136, -0.1532, -1.2108],\n",
      "         [-0.5044,  0.8284, -0.1283,  ..., -0.4908,  1.2831,  0.6284],\n",
      "         [-0.7102, -0.4867, -0.0182,  ..., -0.3965, -0.6729, -0.4372]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n",
      "\n",
      "tensor([[  0,   0,   0,   0,   0,   0,   0, 104, 105,  29]], device='cuda:0')\n",
      "tensor([[[[False, False, False, False, False, False, False,  True,  True,  True]]]],\n",
      "       device='cuda:0')\n",
      "tensor([[[ 1.0764,  0.1063, -0.2160,  ..., -0.8052, -0.1896,  1.4528],\n",
      "         [ 1.0947, -0.7565, -0.1902,  ..., -1.2303,  0.0249,  2.0194],\n",
      "         [ 0.7435,  0.1384, -0.2309,  ..., -0.1890,  0.2184,  1.1226],\n",
      "         ...,\n",
      "         [-0.0553, -0.6213, -0.5129,  ...,  0.3756, -1.6436, -1.1407],\n",
      "         [-0.2550,  0.9297,  0.3850,  ..., -0.8295,  1.1594,  0.5849],\n",
      "         [-0.8822,  0.4831,  0.1948,  ..., -2.4056, -0.1369,  1.0436]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n",
      "\n",
      "tensor([[  0,   0,   0,   0,   0,   0, 104, 132,  77,  29]], device='cuda:0')\n",
      "tensor([[[[False, False, False, False, False, False,  True,  True,  True,  True]]]],\n",
      "       device='cuda:0')\n",
      "tensor([[[ 1.2769, -0.6127, -0.3008,  ..., -1.5545,  0.1478,  1.4986],\n",
      "         [ 1.2596, -0.7044, -0.1723,  ..., -1.0295, -0.7296,  1.5897],\n",
      "         [ 0.9823, -0.2518, -0.5409,  ..., -0.8564, -0.6313,  1.4351],\n",
      "         ...,\n",
      "         [-0.5792,  0.3876, -1.0530,  ...,  0.6087,  0.9295, -1.2605],\n",
      "         [-1.7862,  0.4620,  1.4092,  ..., -1.4485, -1.2450,  0.2308],\n",
      "         [-1.2427,  0.5363,  0.1550,  ..., -0.6765,  0.2376,  0.6635]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n",
      "\n",
      "tensor([[   0,    0,    0,    0,    0,  104,    1,    2, 2546,    4]],\n",
      "       device='cuda:0')\n",
      "tensor([[[[False, False, False, False, False,  True,  True,  True,  True,  True]]]],\n",
      "       device='cuda:0')\n",
      "tensor([[[ 1.0632, -0.7697, -0.7263,  ..., -0.9670, -0.2807,  1.9906],\n",
      "         [ 0.9134, -0.5998, -0.0347,  ..., -0.9806, -0.3094,  1.6762],\n",
      "         [ 0.6022,  0.1175, -0.0198,  ..., -1.0542, -0.7247,  1.9018],\n",
      "         ...,\n",
      "         [-1.6627,  0.8676, -0.1384,  ...,  0.6088, -0.8992,  0.5487],\n",
      "         [ 0.3628,  0.1359, -0.4334,  ...,  1.4945, -0.9839, -1.3974],\n",
      "         [-0.7415,  0.5449, -0.8766,  ..., -1.0871,  0.0584,  0.7473]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "encoded_play = []\n",
    "\n",
    "words = list(tests['Pertanyaan'])\n",
    "labels_words = list(tests['Labels'] )\n",
    "\n",
    "for i in range(len(words)):\n",
    "    words[i] = words[i].lower()\n",
    "    question = words[i] \n",
    "    max_len = 50\n",
    "    enc_qus = [word_map.get(word, word_map['<unk>']) for word in question.split()]\n",
    "    if len(enc_qus) < 10:\n",
    "        left_pad = [word_map['<pad>']] * (10 - len(enc_qus))\n",
    "        enc_qus = left_pad + enc_qus\n",
    "    question = torch.LongTensor(enc_qus).to(device).unsqueeze(0)\n",
    "    print()\n",
    "    print(question)\n",
    "    question_mask = (question!=0).to(device).unsqueeze(1).unsqueeze(1)  \n",
    "    print(question_mask)\n",
    "    encoded = transformer.encode(question, question_mask)\n",
    "    print(encoded)\n",
    "    encoded = encoded.detach().cpu().numpy()\n",
    "    if encoded.shape[0] > 1:\n",
    "        concetaned_encoded = np.concatenate(encoded, axis=0)\n",
    "        encoded = concetaned_encoded\n",
    "    encoded_play.append(encoded[0].flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca = PCA(n_components=2)\n",
    "encoded_play_pca = pca.fit_transform(encoded_play)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(encoded_play_pca[:,0], encoded_play_pca[:,1], s=100)\n",
    "for i, txt in enumerate(labels_words):\n",
    "    plt.annotate(txt, (encoded_play_pca[i,0], encoded_play_pca[i,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "Transformer                              --\n",
       "├─Embeddings: 1-1                        --\n",
       "│    └─Dropout: 2-1                      --\n",
       "│    └─Embedding: 2-2                    2,610,176\n",
       "├─Embeddings: 1-2                        --\n",
       "│    └─Dropout: 2-3                      --\n",
       "│    └─Embedding: 2-4                    2,610,176\n",
       "├─EncoderLayer: 1-3                      --\n",
       "│    └─LayerNorm: 2-5                    2,048\n",
       "│    └─MultiHeadAttention: 2-6           --\n",
       "│    │    └─Dropout: 3-1                 --\n",
       "│    │    └─Linear: 3-2                  1,049,600\n",
       "│    │    └─Linear: 3-3                  1,049,600\n",
       "│    │    └─Linear: 3-4                  1,049,600\n",
       "│    │    └─Linear: 3-5                  1,049,600\n",
       "│    └─FeedForward: 2-7                  --\n",
       "│    │    └─Linear: 3-6                  2,099,200\n",
       "│    │    └─Linear: 3-7                  2,098,176\n",
       "│    │    └─Dropout: 3-8                 --\n",
       "│    └─Dropout: 2-8                      --\n",
       "├─DecoderLayer: 1-4                      --\n",
       "│    └─LayerNorm: 2-9                    2,048\n",
       "│    └─MultiHeadAttention: 2-10          --\n",
       "│    │    └─Dropout: 3-9                 --\n",
       "│    │    └─Linear: 3-10                 1,049,600\n",
       "│    │    └─Linear: 3-11                 1,049,600\n",
       "│    │    └─Linear: 3-12                 1,049,600\n",
       "│    │    └─Linear: 3-13                 1,049,600\n",
       "│    └─MultiHeadAttention: 2-11          --\n",
       "│    │    └─Dropout: 3-14                --\n",
       "│    │    └─Linear: 3-15                 1,049,600\n",
       "│    │    └─Linear: 3-16                 1,049,600\n",
       "│    │    └─Linear: 3-17                 1,049,600\n",
       "│    │    └─Linear: 3-18                 1,049,600\n",
       "│    └─FeedForward: 2-12                 --\n",
       "│    │    └─Linear: 3-19                 2,099,200\n",
       "│    │    └─Linear: 3-20                 2,098,176\n",
       "│    │    └─Dropout: 3-21                --\n",
       "│    └─Dropout: 2-13                     --\n",
       "├─Linear: 1-5                            2,612,725\n",
       "=================================================================\n",
       "Total params: 28,827,125\n",
       "Trainable params: 28,827,125\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(transformer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reset Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "print(torch.cuda.memory_summary(device=None, abbreviated=False))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
